<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Bioinfo | CUT&amp;Tag sequencing and ChIP sequencing</title>
    <url>/2021/10/20/Bioinfo-CUT-Tag-sequencing-and-ChIP-sequencing/</url>
    <content><![CDATA[<p>CUT&amp;Tag 技术研究蛋白与染色质结合，相对于 ChIP Seq 技术具有显著优势，这个方法的原理是什么？先需要提到的是染色质免疫切割技术。CUT&amp;RUN 是一项对染色质免疫切割技术（ChIC）在全基因组范围的扩展方法，由 Laemmli 实验室开发（Schmid et al., 2004）。ChIC 使用蛋白 A-MNase 融合蛋白切割与靶蛋白相关并被特异性抗体识别的 DNA 区域。但是，ChIC 只能通过 southern blot 对特定位点进行分析。与此有关的一种方法是染色质内源性切割（ChEC），这种方法通过融合目标蛋白和 MNase 来分析目标蛋白在全基因组范围的结合位点（Schmid et al., 2004; Zentner et al ., 2015）。这种方法有一个明显的缺点，那就是需要为各目标蛋白生成特异性融合蛋白。CUT&amp;RUN 在这两种方法的基础上有了重大改进，它通过抗体将重组蛋白 A/G-MNase 固定在了目标蛋白处（Meers et al., 2019; Skene and Henikoff, 2017）。</p>
<p>重要的是，该方法可以回收 MNase 消化的片段，因此可用于基于测序的蛋白占用和组蛋白修饰定位的全基因组分析。与基于 ChIP 的方法相比，CUT&amp;RUN 具有以下优势：使用磁珠固定细胞核，简化了操作步骤；适用于新鲜组织样本和冷冻组织样本；缩短了生成 DNA 测序文库制备材料的时间（1-2 天）。此外，由于对目标蛋白两侧的 DNA 进行了原位靶向切割，因此只有靶点 DNA 片段才会从细胞核中释放并被收集，从而留下脱靶序列。因此，CUT&amp;RUN 产生的背景信号比 ChIP 少得多。自开发以来，CUT&amp;RUN 已被调整用于多种实验设置，包括自动化高通量表观遗传学分析（AutoCUT&amp;RUN）（Janssens et al., 2018）、不溶性染色质分析（如使用 CUT &amp; RUN.Salt (Thakur and Henikoff, 2018) 和 CUT&amp;RUN.ChIP 对着丝粒区域进行分析），用于检查 CUT &amp; RUN 消化 (Brahma and Henikoff, 2019) 释放的复合物中的特定蛋白组分。最显著的是，CUT&amp;RUN 对 input 的要求极低且信噪比高，这意味着其可用于单细胞分析，例如，用于研究单个小鼠胚胎细胞中的转录因子占有率（Hainer and Fazzio, 2019）。</p>
<p>CUT&amp;Tag 由 Henikoff 实验室（Kaya-Okur et al., 2019）于 2019 年发布，衍生自 CUT&amp;RUN 实验方案，可以加快文库制备并简化自动化操作。<font color=blue>CUT&amp;Tag 对天然或轻微固定的染色质进行抗体引导的标签化，并据此识别全基因组中目标蛋白占据的位置。CUT&amp;Tag 方法中用到了预装接头 DNA 并与蛋白 A 融合的超高活性 Tn5 转座酶。这种融合蛋白能与一抗结合，在抗体附近切割 DNA，并插入带有接头序列的短标签（标签化）。回收标签化的 DNA 片段后，使用引物识别添加的标签中的序列进行 PCR 扩增，以生成下一代测序（NGS）文库。特定区域的序列读取频率与靶蛋白占据的位置或组蛋白修饰的位置对应。</font></p>
<p>CUT&amp;RUN 和 CUT&amp;Tag 是两种操作简单、用途广泛且功能强大的 DNA-蛋白质相互作用分析方法，应成为每位分子生物学家的必备工具。这两种方法都有助于在全基因组范围内识别特定基因，以及以组蛋白修饰标记或与目标蛋白结合的顺式调控因子，从而深入了解基于染色质的基因控制机制。由于所需的起始材料极少，所以 CUT&amp;RUN 和 CUT&amp;Tag 在稀有细胞类型研究方面具有独特的优势。最重要的是，这两种方法的实验方案都简单易用，省时省力，可以快速周转，因此研究人员能够进行多项平行分析，从而更加全面地了解基因组调控的复杂性。</p>
<p>转录因子和组蛋白通过与DNA相互作用（DNA-Protein Interaction, DPI）发挥着调控基因复制、表达、重组和修复的重要作用，在实现细胞功能的过程中至关重要。其中转录因子组合决定了细胞的增值、分化以及死亡，是表观基因组学研究的重要组成部分。研究 DNA-蛋白质相互作用的实验方法主要有凝胶阻滞实验、DNase 1 足迹实验、甲基化干扰实验、体内足迹实验和 ChIP-seq 等。基于 NGS 研究手段的 ChIP-seq 技术可以真实反应靶蛋白在全基因组上的结合情况，是非常经典的 DNA 结合位点分析方法，至今仍然在广泛使用。</p>
<p>ChIP-Seq 的基本实验流程过程包括（图1）：甲醛交联将 DNA 结合蛋白和 DNA 紧密固定；然后抽提染色质，超声破碎 DNA 断裂，片段范围在 200-500 bp 之间；抗体孵育结合靶转录因子，Protein A/G 磁珠拉取抗体-蛋白-DNA 复合物；蛋白消化后再通过 PCR、芯片或者二代测序对 DNA 序列进行鉴定。</p>
<p><img src="https://i.imgur.com/l384XKj.jpeg" alt="图1 ChIP Seq 原理示意图" /></p>
<p>看似简单，实则有几个技术难题，如果实验条件摸索不成熟会消耗大量时间。首先，ChIP需要较多的细胞量，免疫共沉淀需要足够的靶标蛋白，而靶标蛋白有限的情况下就需要提供大量的细胞；<br />
其次，信噪比低，很多转录因子和染色体的结合相对松散，需要甲醛强交联，以防止后续洗涤过程破坏这些结合，这样导致很多非特异性信号，需要更高的数据量得到真实peak值；此外，实验的打断条件、重复性差等都需要系统的摸索才能得到较好的结果。这些因素综合起来导致ChIP对新手非常不友好，需要采购特定的设备、很长时间的预实验才能得到满意的结果。</p>
<p>为了克服这些难题，CUT&amp;Run 以及更加成熟 CUT&amp;Tag 被开发出来。2019 年，美国弗雷德哈钦森癌症研究中心的 Henikoff 博士在 Nature Communication 公开了 CUT&amp;Tag 技术的详细结果与实验方案。</p>
<p><font color=blue>CUT&amp;Tag（Cleavage Under Targets and Tagmentation, CUT&amp;Tag）技术，它免去了甲醛交联、超声破碎和免疫共沉淀的过程，这样既节省了初始实验材料又提高了信噪比、提升了实验重复性。</font>基本技术流程包括（图2）：首先，特异性抗体和靶标蛋白孵育结合；加入Tn5转座酶—Protein A复合物，其中Tn5转座酶两端已装载好建库接头引物；特异性抗体和Protein A相结合，转座酶Tn5被“拉”到转录因子附近；转座酶Tn5一次性完成附近DNA打断并完成NGS加接头过程，可直接建库[2]。基于CUT&amp;Tag，单细胞转录因子结合位点的研究也成为可能[2]，这也展示了CUT-Tag的潜能。<br />
转录组测序</p>
<p><img src="https://i.imgur.com/mSTAtC1.jpeg" alt="图2 CUT&amp;Tag seq 原理示意图" /></p>
<p>为证明Cut&amp;Tag技术的有效性，Henikoff 博士在对组蛋白H3K27me3进行研究时对比使用了 ChIP-seq、Cut&amp;RUN、Cut&amp;Tag 三种方法。从不同角度对三组数据进行比较后，发现 Cut&amp;Tag 技术具有显著优势，具体结果如下：</p>
<ol>
<li>CUT&amp;Tag 具有更好的信噪比和更低的背景<br />
研究者将三种方法的数据量都设置为8M Reads，结果显示三者得到的染色体pattern相似。但ChIP-seq的背景噪声非常高，增加数据量到50M Reads时，才能达到类似的峰图，因此ChIP-seq需要更大的测序深度才能达到去背景噪音的结果。相反，Cut＆RUN和Cut＆Tag均具有极低的背景噪声水平，其中Cut＆Tag的背景噪音最低。</li>
</ol>
<p><img src="https://i.imgur.com/dFuPanX.jpeg" alt="图3 ChIP-Seq 、CUT&amp;RUN、CUT&amp;Tag 实验结果对比" /></p>
<ol start="2">
<li>CUT&amp;Tag 在识别染色质特征时最高效</li>
</ol>
<p><img src="https://i.imgur.com/4kiBShb.jpeg" alt="Fig 4" /></p>
<p>图 4 左图为 CUT&amp;Tag、CUT&amp;RUN、ChIP-Seq 三种方法分析 H3K4me1 组蛋白修饰，CUT&amp;Tag 在识别染色质特征时最有效，能够给出 ChIP-Seq 无法读出的信息；右图为 peak-calling 的对比，使用默认参数调用每种方法上的峰值，结果显示 CUT&amp;Tag 比 CUT&amp;RUN、ChIP-seq 或 ATAC-seq 有更高的信号。</p>
<ol start="3">
<li>重复性好，灵敏度高</li>
</ol>
<p>三种方法对H3K4me1数据分析，并对结果进行分层聚类相关矩阵分析，结果显示显示CUT&amp;Tag重复样本的数据有高度的相似性，说明了CUT&amp;Tag的可重复性高。</p>
<p><img src="https://i.imgur.com/J9MfdEm.jpeg" alt="Fig 5" /></p>
<p>图5 a：CUT&amp;Tag、CUT&amp;RUN、ChIP-Seq三种方法分析H3K4me1组蛋白修饰：CUT&amp;Tag在识别染色质特征时最有效，能够给出ChIP-Seq无法读出的信息；b：peak-Calling的对比，使用默认参数调用每种方法上的峰值，结果显示CUT&amp;Tag比CUT&amp;RUN、ChIP-seq或ATAC-seq有更高的信号。</p>
<ol start="4">
<li>CUT&amp;Tag 能对极少量细胞甚至单细胞进行分析</li>
</ol>
<p>CUT&amp;Tag 能够对极少量细胞（60 个细胞）甚至单细胞进行分析。由于 PCR 之前的反应都在细胞内进行，Henikoff 博士通过分配单个细胞到 5184 纳米孔，再加入带随机标签的引物进行扩增的办法，实现单细胞测序。</p>
<p><img src="https://i.imgur.com/pgHzjVI.jpeg" alt="图6 CUT&amp;Tag 单细胞测序流程" /></p>
<p>Cut&amp;Tag注意事项：一个好的抗体是CUT&amp;Tag成功的前提！这个抗体要能识别天然构象蛋白且特异性强，最好选用文献验证过的抗体，实验前并进行IP验证。如果实在没有合适的抗体，可以选择标签蛋白，如FLAG和HA等经过有效验证的单克隆抗体。</p>
<p>参考文献：</p>
<p>genewiz: <a href="https://www.genewiz.com.cn/Public/Resources/zxzx/0038/">https://www.genewiz.com.cn/Public/Resources/zxzx/0038/</a><br />
abcam: <a href="https://www.abcam.cn/epigenetics/chromatin-profiling-guide-1">https://www.abcam.cn/epigenetics/chromatin-profiling-guide-1</a></p>
<p>[1] Kaya-Okur HS, Wu SJ, Codomo CA, Pledger ES, Bryson TD, Henikoff JG,Ahmad K, Henikoff S. CUT&amp;Tag for efficient epigenomic profilingof small samples and single cells. Nat Commun. 2019 Apr29;10(1):1930. doi: 10.1038/s41467-019-09982-5. PMID: 31036827;PMCID: PMC6488672.<br />
[2] Wang Q, Xiong H, Ai S, Yu X,Liu Y, Zhang J, He A. CoBATCH for High-Throughput Single-CellEpigenomic Profiling. Mol Cell. 2019 Oct 3;76(1):206-216.e7. doi:10.1016/j.molcel.2019.07.015. Epub 2019 Aug 27. PMID: 31471188.</p>
<p>CUT&amp;RUN 实验方案概述</p>
<p>运行 CUT&amp;RUN 过程中，需使用靶向目标蛋白（例如具有特定修饰的组蛋白或转录因子）的抗体将蛋白 A/G 标记的 MNase 引导至基因组中目标蛋白所在区域。</p>
<p>然后，活化 MNase，切除那些接近目标蛋白的 DNA 序列，这时小片段会从细胞核中释放出来。收集这些 DNA 片段，并通过低 input DNA 文库制备试剂盒生成 NGS 文库。</p>
<p><img src="https://i.imgur.com/Vwb1FCW.png" alt="" /></p>
<p>图 1. CUT&amp;RUN 实验方案示意图。细胞核附着在磁性伴刀豆球蛋白 A 磁珠上，以便进行细胞处理并在每次洗涤后安全除去液体。对细胞核进行通透处理，同时与靶向目标蛋白的抗体一起孵育。蛋白 A/G-MNase 融合蛋白与靶向目标蛋白的抗体结合。添加 Ca2+ 时，MNase 会切割所形成的复合物两侧的 DNA，并释放从细胞核中扩散出的 DNA 片段。提取 DNA 并在基于末端修复和接头连接制备 DNA 文库时使用。NGS 通过特定区域中序列的频率给出目标蛋白的结合信息。</p>
<p>该实验方案可分为五个部分：<br />
1.提取细胞核并与磁珠结合<br />
CUT&amp;RUN 通常使用未固定的新鲜样本作为起始材料，但是对实验方案做出调整后，也可以使用在 10% DMSO 中冷冻保存的样本（Janssens et al ., 2018; Skene et al ., 2018）。</p>
<p>进行该实验方案所需的材料很少，一般建议先使用不超过 500,000 个细胞（哺乳动物）。</p>
<p>用 Henikoff 推荐的细胞核提取缓冲液释放细胞或细胞核，并与伴刀豆球蛋白 A 磁珠结合，这种磁珠具有独特的糖结合特性。也可以使用其他兼容的细胞核提取实验方案（使用含 Triton X-100 的缓冲液时，请查看下述建议）。执行剩余实验方案时，可以使用磁力架轻松洗涤样本。</p>
<p>2.通透技术和抗体结合<br />
对与伴刀豆球蛋白 A 磁珠结合的细胞核作通透处理，同时在含洋地黄皂苷和 EDTA 的缓冲液中与靶向目的蛋白的抗体（一抗）一起孵育。EDTA 可迅速中断细胞代谢，从而抑制内源性 DNAse 的活性，保留染色质并降低总体背景信号。用户可自行调整该步骤的持续时间；通常为 2 小时到过夜不等。建议首先按 1:100 或 0.5 µg - 1.0 µg 稀释抗体，但需优化抗体的用量。建议加入阳性（α-H3K27me3）和阴性对照（同型对照 IgG）样本。</p>
<p>需要注意的是，抗体种属不同，蛋白 A 和蛋白 G 的结合效率也不同（点击查看）。虽然相较单独使用蛋白 A 而言，使用蛋白 A/G 可以增强抗体的兼容性，但在某些情况下可能需要使用二抗。二抗通过增加蛋白 A/G 结合区域的数量将 MNAse 引导至目标区域，从而帮助回收低丰度的目标序列。</p>
<p>3.MNase 结合和靶序列切割<br />
为了将蛋白 A/G-MNase 定位到抗体结合的基因组靶区域，需在含洋地黄皂苷的洗涤缓冲液中稀释融合蛋白并与细胞核一起孵育。然后洗去未结合的酶融合蛋白，于 0℃ 加入 Ca2+ 离子激活 MNase。虽然切割本身对温度不是特别敏感，但是切割后的 DNA 片段的后续扩散对温度很敏感，而且温度升高会导致更高的背景。如果最终物质中的高分子量片段过多或过少，可以调整消化时间。</p>
<p>4.DNA 回收<br />
添加含 EGTA 的终止缓冲液，终止 MNase 活性。该缓冲液可以选择性地包含异源 DNA 添加物，以便在数据处理过程中用于校准 CUT&amp;RUN 分析。通过提高孵育温度，促使细胞核释放 MNase 产生的片段，并用苯酚/氯仿/异戊醇提取这些片段，然后用乙醇进行沉淀。</p>
<p>修改实验方案可以进一步限制 MNase 融合蛋白从其结合位点过早释放、扩散以及非特异性切割。</p>
<p>该版本实验方案联合使用低盐缓冲液和高浓度 Ca2+ 溶液激活 MNase，非常适合主要在活性开放染色质中发现的靶点，但抗体显示高背景信号时，也可以使用。</p>
<p>5.文库制备和测序<br />
清除切割后的 DNA 片段后，根据制造商指南，使用标准末端修复和接头连接方法生成低 input DNA 文库。Henikoff 实验室最初建议使用 TRUseq 文库制备法，但是现在已有大量使用 NEBNext® Ultra™ II DNA 文库试剂盒的报告。与自动化 CUT&amp;RUN 实验方案（Jenssens et al. 2018）类似，您也可以省略苯酚/氯仿/异戊醇提取步骤，直接将释放的 DNA 片段用于基于末端修复和接头连接的实验方案。</p>
<p>文库的大小分布和浓度可通过毛细管电泳（例如 Bioanalyzer 或 TapeStation）确定。可以将多个文库合并，每个文库获得约 800 万配对末端测序读段。由于 CUT&amp;RUN 文库的背景较低，因此 800 万配对末端读段足以分析组蛋白修饰，甚至转录因子。</p>
<p>大部分常规 ChIP-seq 数据分析工具都可以分析 CUT&amp;RUN 数据。Henikoff 实验室也专门为 CUT&amp;RUN 数据设计了一些分析工具，例如 SEACR peak caller（Meers et al ., 2019b）。对于经校准的 CUT&amp;RUN，添加了终止缓冲液的异源 DNA 添加物可用于样本信号的归一化。此外，重组蛋白 A/G-MNase 残留的大肠杆菌 DNA 也可用作添加物。</p>
<p>CUT&amp;Tag 实验方案概述<br />
运行 CUT&amp;Tag 过程中，需使用抗体将蛋白 A 标记的 Tn5 转座酶引导至目标蛋白（例如具有特定修饰的组蛋白或转录因子）所在的基因组区域。Tn5 片段和标签靶向带有特定预定义核苷酸序列（接头）的 DNA。标签化的 DNA 可以轻松回收，并进行 PCR 扩增，从而生成 NGS 文库。整个实验方案仅需一天即可完成，具体取决于抗体孵育时间。</p>
<p><img src="https://i.imgur.com/OC0ezUh.png" alt="" /></p>
<p>​​图 2. CUT&amp;Tag 实验方案示意图。细胞核附着在磁性伴刀豆球蛋白 A 磁珠上，以便进行细胞处理并在每次洗涤后安全除去液体。对细胞核进行通透处理，同时与靶向目标蛋白的一抗一起孵育，然后与识别一抗的二抗一起孵育。蛋白 A-Tn5 融合蛋白与目标蛋白上形成的抗体复合物结合。添加 Mg2+ 离子时，Tn5 会切割所形成的复合物两侧的 DNA，并释放从细胞核中扩散出的已切割 DNA 片段。提取 DNA 并在基于 PCR 扩增制备 DNA 文库时使用。NGS 通过特定区域中序列的频率给出目标蛋白的结合信息。</p>
<p>该实验方案可分为五个部分：</p>
<ol>
<li>提取细胞核并与磁珠结合</li>
</ol>
<p>CUT&amp;Tag 通常使用未固定的新鲜样本作为起始材料，但对实验方案进行修改后，也可以使用冷冻样本，近期，还可使用提取细胞核后经福尔马林轻微固定的样本。固定步骤可以降低执行实验方案期间细胞核聚集在一起的可能性。使用由含 Triton X-100 的缓冲液产生的固定和冷冻保存样本时，可从所有缓冲液中除去洋地黄皂苷，这样可以进一步减少磁珠结块。但是，需要注意，在某些情况下，表位固定会干扰抗体的结合。通常建议先使用不超过 500,000 个细胞（哺乳动物）。使用新鲜或冷冻组织时，细胞核的制备与 CUT&amp;RUN 实验方案中的细胞核制备类似（Janssens et al ., 2018; Skene et al ., 2018）。对于 CUT&amp;RUN，细胞核与伴刀豆球蛋白 A 磁珠结合，可以使用磁力架轻松洗涤样本。但是，该步骤可以省略，并且整个实验方案可以按以下方式执行：每次洗涤后，温和离心，然后小心除去上清液，不干扰沉淀的细胞核。</p>
<ol start="2">
<li>通透技术和抗体结合</li>
</ol>
<p>对结合至伴刀豆球蛋白 A 磁珠的细胞核进行通透处理，同时在含洋地黄皂苷的缓冲液中与靶向目的蛋白的抗体（一抗）一起孵育。该步骤的持续时间可以调整，最短 2 小时，最长 5 天。抗体的推荐稀释度通常在 1:50 至 1:100（或 0.5 µg - 1.0 µg）之间，但需优化抗体的使用量。建议加入阳性（α-H3K27me3）和阴性对照（同型对照 IgG）样本。一抗孵育后，用含洋地黄皂苷的洗涤缓冲液快速洗涤，然后将细胞核与二抗一起孵育，这里使用的二抗需靶向一抗，充当桥接抗体并且可以增加蛋白 A 结合位点的数量。在 CUT&amp;RUN 实验方案中，这一步骤可以省略；但在 CUT&amp;Tag 实验方案中，必须执行这一步骤，以增强信号。需要注意的是，抗体类别不同，蛋白 A 的结合效率也不同，因此需要事先检查二抗与蛋白 A 的兼容性。</p>
<ol start="3">
<li>Tn5 结合和标签化</li>
</ol>
<p>为了将蛋白 A-Tn5 转座酶与目标抗体结合，需在含洋地黄皂苷的高盐缓冲液中稀释带接头的 Tn5 融合蛋白，并与细胞核一起孵育。在该步骤中增加盐浓度有助于减少脱靶标签化，主要是可接触的基因组区域的脱靶标签化，从而产生类似 ATAC 的峰。与 Tn5 融合蛋白一起孵育后，洗涤细胞核，以除去未结合的 Tn5，并在添加 Mg2+ 离子的高盐洋地黄皂苷缓冲液中于 37℃ 下孵育，从而激活标签化。</p>
<ol start="4">
<li>DNA 回收</li>
</ol>
<p>添加 EDTA 终止标签化，并用 SDS 和蛋白酶 K 裂解细胞核。然后可以通过多种方式清除 DNA 片段，原实验方案建议先用苯酚/氯仿/异戊醇提取这些片段，再用乙醇进行沉淀。您也可以使用 AMPure 磁珠来清除 DNA 片段。建议在沉淀步骤中避免使用任何载体，例如糖原，因为载体会降低后续 PCR 反应的效率。</p>
<ol start="5">
<li>通过 PCR 扩增和测序制备文库</li>
</ol>
<p>由于 Tn5 在标签化过程中会在 DNA 片段中引入兼容序列，所以使用通用 i5 引物和带条形码的 i7 引物进行的简单 PCR 反应就可以生成测序文库，让 DNA 文库的制备变得极为快速简便。该步骤与 ATAC-seq 类似，因此可以使用 ATAC 实验方案描述的引物序列（Buenrostro et al ., 2013）。但需要根据用户的机器调整循环程序。为了确保 PCR 有效，需要进行短时间的退火操作；如使用缓慢升温循环仪，则可以省略退火步骤，因为变性和延伸之间的冷却时间较长，足以退火。如使用快速升温机器，则必须增加退火步骤。通常，建议不超过 12 到 14 个扩增循环，否则，文库的复杂性将降低，而 PCR 的重复率升高。</p>
<p>在 PCR 扩增后，可用毛细管凝胶电泳法（例如 Bioanalyzer 或 TapeStation）对 CUT&amp;Tag 文库进行评估。CUT&amp;Tag 实验的失败通常表现在阳性对照样本中不存在核小体片段。</p>
<p>但是，如果只在转录因子 CUT&amp;Tag 文库中观察到非常弱的信号，实验仍然可以继续，这种情况很常见。通过凝胶电泳进行评估后，可以使用 SPRI 磁珠清理并浓缩文库。可以将多个文库合并，每个文库获得约 200 万配对末端测序读段。</p>
<p>大部分常规 ChIP-seq 数据分析工具都可以分析 CUT&amp;Tag 数据。Henikoff 实验室也专门为 CUT&amp;RUN 和 CUT&amp;Tag 数据设计了一些分析工具，例如 SEACR peak caller（Meers et al ., 2019b）。要想校准 CUT&amp;Tag 数据，可以将重组蛋白 A-Tn5 残留的大肠杆菌 DNA 用作普通添加物。</p>
<p>样本制备</p>
<p>由于 CUT&amp;RUN 和 CUT&amp;Tag 都可以使用未固定的新鲜样本，所以，它们的样本制备非常简单。但是需要以适合所用细胞类型的方式制备单细胞悬液，包括使用解离试剂（如 Accutase™）、从细胞培养皿上刮下细胞或机械解离组织等。</p>
<p>为了便于收集，可以在 10% DMSO 中冷冻保存样本，并在 Mr. Frosty 异丙醇冻存盒内冻存。两种方法均不需要固定样本，但是，如果磁珠在洗涤过程中结块，则应在孵育抗体前，于室温下使用 0.1% 福尔马林对样本进行轻固定，2 分钟即可。</p>
<p>抗体选择</p>
<p>至于 ChIP，并非所有抗体都可以用于 CUT&amp;RUN 和 CUT&amp;Tag。由于这两种方法较新，大多数抗体均未经过兼容性测试，因此终端用户需要对抗体进行测试和优化。ChIP 级抗体大都适用于 CUT&amp;RUN 和 CUT&amp;Tag，特别是适用于天然 ChIP 的 ChIP 级抗体。</p>
<p>试用非 ChIP 级抗体时，假设特异性已进行充分表征，可以首先选择能够识别目标蛋白天然形式的抗体；例如，在免疫沉淀或免疫细胞化学中起作用的抗体。同理，在考虑 CUT&amp;RUN 或 CUT&amp;Tag 实验所用的抗体浓度时，可以将免疫荧光法的推荐浓度作为起始浓度。需测试抗体与蛋白 A 和蛋白 G 的兼容性，必要时，可使用合适的二抗。</p>
<p>对照</p>
<p>与其他实验类型一样，添加合适的对照是确保实验符合预期并能在实验失败时轻松确定问题区域的关键。</p>
<p>与 ChIP 不同，该实验方案不需要 input 样本，因为非抗体引导的 MNase 处理或标签化仅可识别可接触的染色质。为了从样本中获取背景并为实验设置基线，应添加 IgG 对照。在抗体对照方面，Henikoff 实验室建议使用 H3K27me3 作为 CUT&amp;RUN 和 CUT&amp;Tag 实验的阳性对照。使用未修饰的总组蛋白对照，例如总组蛋白 H3，可以按比例显示组蛋白修饰。</p>
<p>优化</p>
<p>使用这些技术时，需要在多个阶段对 CUT&amp;RUN 和 CUT&amp;Tag 实验方案进行优化。</p>
<p>透化</p>
<p>初版实验方案要求对洗涤缓冲液中所用的洋地黄皂苷的浓度进行测定，以确保有效地对细胞核作通透处理。如果您对实验方案作了改进，具体来说就是在洗涤缓冲液中添加了 NP40，则有可能不需要进行上述测定。但是，在新材料上使用这两种技术时，应牢记细胞核的通透效率。</p>
<p>抗体浓度</p>
<p>采用滴定法测定每次反应使用的抗体量很重要，起始稀释度可以参考 ChIP 或免疫荧光检测法的推荐稀释度。</p>
<p>抗体孵育时间</p>
<p>室温下，一抗孵育 1 小时即可；但在冷藏室中，孵育时间可延长至 1 至 5 天。对于每项实验使用的抗体，可以对孵育时间进行优化；但应牢记，孵育时间过长可能会增加背景信号，最终导致总体信噪比不佳。</p>
<p>使用二抗</p>
<p>如果在只使用一抗的情况下，回收率较低，则强烈建议在 CUT&amp;Tag 中使用二抗，还可以考虑在 CUT&amp;RUN 中使用二抗。添加二抗的另一个原因是为了避免蛋白 A/G 与一抗的配对不符合预期，添加合适类别的二抗可以改善这一点。</p>
<p>消化和标签化时间</p>
<p>MNase 消化和 Tn5 标签化的时间可以根据目标蛋白进行调整。低丰度蛋白要想回收所有位点可能需要花费更多时间。要记住的是，消化或标签化时间过长可能会导致无针对性的切割，从而产生高背景信号。</p>
<p>常见问题</p>
<ul>
<li>
<p>起始材料应该使用多少个细胞？<br />
模式生物的基因组小于人/小鼠基因组时，是否需要增加细胞数量？建议每个样本不超过 500,000 个细胞。一般来说，起始量为 50,000 个细胞比较好。与 ChIP 不同，CUT &amp;RUN 和 CUT＆Tag 非常敏感，所以不需要上百万个细胞作为起始材料。细胞数量过多会降低收率，甚至降低文库的复杂性。</p>
</li>
<li>
<p>增加细胞用量时，是否应增加伴刀豆球蛋白 A 磁珠的用量？<br />
每次实验使用的细胞数不应超过 500,000 个。由于实验方案已对使用 50,000 至 500,000 个细胞时的磁珠数量进行了优化，因此不需要在实验方案建议的磁珠用量基础上另行增加。</p>
</li>
<li>
<p>如何冷冻保存细胞确保其可用于 CUT＆RUN 或 CUT &amp;Tag？<br />
建议在合适的缓冲液或培养基中添加 10％ DMSO，然后使用 Mr. Frosty 异丙醇冻存盒缓慢冻存。不建议快速冻存。</p>
</li>
<li>
<p>我有固定和冷冻 ChIP 细胞，可以将它们用于 CUT&amp;RUN 或 CUT＆Tag 吗？<br />
可以，但具体要看 ChIP 样本的固定和冷冻保存条件。由于 ChIP 样本的细胞数可能会超过 CUT&amp;RUN 和 CUT&amp;Tag 的推荐用量，并且使用强固定条件（如双重固定和淬灭）会损害 MNase 或 Tn5 的活性，所以标准实验方案可能不太适合。您可以将样本分成多份，这样可以轻松避免 ChIP 样本中细胞数超过 CUT&amp;RUN 或 CUT&amp;Tag 推荐起始量的问题。但是，样本固定和冻存等问题仍然存在。ChIP 实验方案的固定条件比较严格，很难与 CUT&amp;RUN 或 CUT&amp;Tag 兼容，因为严格的固定条件很可能会损害 MNase 或 Tn5 片段化/标签化目标序列的能力，并且已有大量报道暗示了这种不兼容性。另外，固定还有可能导致抗原表位被掩盖。因此，不建议固定样本。冷冻保存用于 CUT&amp;RUN 或 CUT&amp;Tag 的细胞时，需要使用 10% DMSO 和 Mr. Frosty 异丙醇冻存盒缓慢冻存样本。不建议在大多数 ChIP 实验方案中增加快速冻存步骤。</p>
</li>
<li>
<p>为什么洗涤过程中磁珠会结块？<br />
结块可能是因为细胞与磁珠的比例过高或含洋地黄皂苷的缓冲液中的细胞核/细胞发生裂解，从而释放 DNA 并导致结块。这种情况下，首先要检查细胞数量是否超过推荐数量。此外，在与抗体一起孵育前，建议先用福尔马林轻微固定样本（室温下使用 0.1% 福尔马林固定 2 分钟），以减少磁珠在含洋地黄皂苷的洗涤缓冲液中的结块。但需记住的是，固定可能会影响表位的可用性，因此需要对每种抗体进行测试。</p>
</li>
<li>
<p>为什么用于一抗孵育的缓冲液中含 EDTA？<br />
建议在通透和抗体孵育缓冲液中添加 EDTA，因为它会螯合 Mg2+ 离子，从而终止所有依赖 ATP 的细胞过程（包括复制和染色质重塑），同时终止内源性 DNase。</p>
</li>
<li>
<p>哪里可以得到蛋白 A/G-MNase 或蛋白 A-Tn5？<br />
这两种融合蛋白最初都由 Henikoff 实验室提供。现在已经有了制备融合蛋白的实验方案（Kaya-Okur et al ., 2019; Meers et al ., 2019a），而且质粒、蛋白 A-MNase、蛋白 A/G-MNase 和蛋白 A-Tn5 都可以从试剂供应商处购买。</p>
</li>
<li>
<p>在 CUT&amp;Tag 中，是否会得到非抗体引导的标签化，从而产生类似 ATAC 的峰？<br />
按照标准实验方案的建议增加标签化缓冲液中的盐浓度即可解决这一问题。在某些情况下，依据目标蛋白的情况，可能会人为发现一些峰看起来像 Kaya-Okur et al 2019 的报道中所示的 ATAC 峰。</p>
</li>
</ul>
<p>参考文献<br />
Brahma, S ., Henikoff, S. RSC-associated subnucleosomes define MNase-sensitive promoters in yeast . Mol Cell 73, 238–249, e233 (2019).</p>
<p>Buenrostro, J .D ., Giresi, P .G ., Zaba, L .C ., Chang, H .Y ., Greenleaf, W .J . Transposition of native chromatin for fast and sensitive epigenomic profiling of open chromatin, DNA-binding proteins and nucleosome position. Nat Methods 10, 1213–1218 (2013).</p>
<p>Hainer, S .J ., Fazzio, T .G. High-resolution chromatin profiling using CUT&amp;RUN. Curr Protoc Mol Biol 126, e85 (2019).</p>
<p>Janssens, D .H ., et al. Automated in situ chromatin profiling efficiently resolves cell types and gene regulatory programs. Epigenet Chromatin 11, 74 (2018).</p>
<p>Kaya-Okur, H .S ., et al. CUT&amp;Tag for efficient epigenomic profiling of small samples and single cells. Nat Commun 10, 1930 (2019).</p>
<p>Meers, M .P ., Bryson, T .D ., Henikoff, J .G ., Henikoff, S. Improved CUT&amp;RUN chromatin profiling tools. eLife 8: e46314 (2019).</p>
<p>Meers, M .P ., Tenenbaum, D ., Henikoff, S . Peak calling by Sparse Enrichment Analysis for CUT&amp;RUN chromatin profiling . Epigenet Chromatin 12, 42 (2019).</p>
<p>Schmid, M ., Durussel, T ., Laemmli, U .K. ChIC and ChEC; genomic mapping of chromatin proteins. Mol Cell 16, 147–157 (2004).</p>
<p>Skene, P .J ., Henikoff, J .G ., Henikoff, S. Targeted in situ genome-wide profiling with high efficiency for low cell numbers. Nat Protoc 13, 1006–1019 (2018).</p>
<p>Skene, P .J ., Henikoff, S. An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites. eLife 6: e21856 (2017).</p>
<p>Thakur, J ., Henikoff, S. Unexpected conformational variations of the human centromeric chromatin complex. Genes Dev 32, 20–25 (2018).</p>
<p>Zentner, G .E ., Kasinathan, S ., Xin, B ., Rohs, R ., Henikoff, S. ChEC-seq kinetics discriminates transcription factor binding sites by DNA sequence and shape in vivo. Nat Commun 6, 8733 (2015).</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | DRIMM synteny and ancestor genomes</title>
    <url>/2022/04/20/Bioinfo-DRIMM-synteny-lab-notes/</url>
    <content><![CDATA[<h3 id="重新进行编译-drimm-程序"><a class="markdownIt-Anchor" href="#重新进行编译-drimm-程序"></a> 重新进行编译 drimm 程序</h3>
<p>安装 dotnet 的方法，进入 <a href="https://dotnet.microsoft.com/zh-cn/download/dotnet/6.0">https://dotnet.microsoft.com/zh-cn/download/dotnet/6.0</a> ，选择 Wondows 10 栏目的 x64 版本，就可以得到名为“dotnet-sdk-6.0.202-win-x64.exe”的一个安装文件，双击之后默认安装在系统即可。</p>
<p>根据 IAGS 作者的建议：drimm 目录为 IAGS 团队整理的核心代码，因为各个 PC 的 dotnet 版本可能存在不同，我们建议重新进行编译，生成新的exe文件。<br />
在 ./drimm 路径下使用：dotnet publish -c Release -r win-x64 进行编译，可以在./drimm/drimm/bin/Release/netcoreapp3.1/win-x64路径下得到drimm.exe</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">D:\Program Files\processDRIMM\drimm&gt;dotnet publish -c Release -r win-x64</span><br><span class="line"></span><br><span class="line">欢迎使用 .NET 6.0!</span><br><span class="line">---------------------</span><br><span class="line">SDK 版本: 6.0.202</span><br><span class="line"></span><br><span class="line">遥测</span><br><span class="line">---------</span><br><span class="line">.NET 工具会收集用法数据，帮助我们改善你的体验。它由 Microsoft 收集并与社区共享。你可通过使用喜欢的 shell 将 DOTNET_CLI_TELEMETRY_OPTOUT 环境变量设置为 &quot;1&quot; 或 &quot;true&quot; 来选择退出遥测。</span><br><span class="line"></span><br><span class="line">阅读有关 .NET CLI 工具遥测的更多信息: https://aka.ms/dotnet-cli-telemetry</span><br><span class="line"></span><br><span class="line">----------------</span><br><span class="line">已安装 ASP.NET Core HTTPS 开发证书。</span><br><span class="line">若要信任该证书，请运行 &quot;dotnet dev-certs https --trust&quot; (仅限 Windows 和 macOS)。</span><br><span class="line">了解 HTTPS: https://aka.ms/dotnet-https</span><br><span class="line">----------------</span><br><span class="line">编写你的第一个应用: https://aka.ms/dotnet-hello-world</span><br><span class="line">查找新增功能: https://aka.ms/dotnet-whats-new</span><br><span class="line">浏览文档: https://aka.ms/dotnet-docs</span><br><span class="line">在 GitHub 上报告问题和查找源: https://github.com/dotnet/core</span><br><span class="line">使用 &quot;dotnet --help&quot; 查看可用命令或访问: https://aka.ms/dotnet-cli</span><br><span class="line">--------------------------------------------------------------------------------------</span><br><span class="line">用于 .NET 的 Microsoft (R) 生成引擎版本 17.1.1+a02f73656</span><br><span class="line">版权所有(C) Microsoft Corporation。保留所有权利。</span><br><span class="line"></span><br><span class="line">  正在确定要还原的项目…</span><br><span class="line">  已还原 D:\Program Files\processDRIMM\drimm\drimm\drimm.csproj (用时 13.61 sec)。</span><br><span class="line">  drimm -&gt; D:\Program Files\processDRIMM\drimm\drimm\bin\Release\netcoreapp3.1\win-x64\drimm.dll</span><br><span class="line">  drimm -&gt; D:\Program Files\processDRIMM\drimm\drimm\bin\Release\netcoreapp3.1\win-x64\publish\</span><br><span class="line"></span><br><span class="line">D:\Program Files\processDRIMM\drimm&gt;</span><br></pre></td></tr></table></figure>
<h3 id="orthofinder-的使用"><a class="markdownIt-Anchor" href="#orthofinder-的使用"></a> Orthofinder 的使用</h3>
<p>OrthoFinder 的使用需要注意几点：<br />
(1) gff 文件，只包含染色体信息即可，不必包含scaffolds，因为研究对象是染色体进化。染色体的命名要统一规范化，以大豆（Glycine max）为例，数据库自带的命名为Gm01、Gm02 …… 我统一改为：Gmax_chr01、Gmax_chr02 …… 这种“物种名+染色体编号的”格式。<br />
(2) 蛋白数据集，剔除来自scaffolds和细胞器的蛋白序列，只保留来自染色体的蛋白序列。要注意一个基因可能存在若干转录本的情况，Phytozome 下载的数据会提供 primary transcripts 文件，相当于每个基因只提供一个转录本。对于其他情况就需要自己去甄别并采用一定的脚本来做数据规范化处理。<br />
(3) OrthoFinder 运行时，input 目录下是各个物种的蛋白序列文件，注意命名为 Mtruncatula.fasta、Gmax.fasta 这样的格式，因为最后生成的 OrthoGroup.tsv 文件中，文件第一行就是 Mtruncatula、Gmax 字样，这对于后续处理是有益的。<br />
(4) 意外情况，花生的蛋白序列，很多错误，比如蛋白序列中含有点号，这是什么意思？OrthoFinder会报错：Error reading input stream at line 14: Invalid character (.) in sequence\n。</p>
<h3 id="将-orthofinder-的结果转化成下一步的-drimm-synteny-的输入文件"><a class="markdownIt-Anchor" href="#将-orthofinder-的结果转化成下一步的-drimm-synteny-的输入文件"></a> 将 OrthoFinder 的结果转化成下一步的 DRIMM-synteny 的输入文件</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost processDRIMM]$ ll example_fl</span><br><span class="line">total 10380</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1235362 Apr 22 14:33 Brachy.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1617027 Apr 22 14:33 Maize.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1222139 Apr 22 14:33 Rice.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1367402 Apr 22 14:33 Sorghum.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 2717575 Apr 22 14:33 Telongatum.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 2458531 Apr 22 14:33 Orthogroups.tsv</span><br></pre></td></tr></table></figure>
<p>下面运行 <code>./processOrthofinder.py</code> 程序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 在 ./processOrthofinder.py 首行加上“#!/home/fenglei/local/app/anaconda3/envs/python37/bin/python3”</span><br><span class="line">dos2unix ./processOrthofinder.py    ### 作者原来的文档实在win系统撰写的，拿到linux里面运行会出现结尾符为^M的错误警告</span><br><span class="line">python3 ./processOrthofinder.py     ###</span><br></pre></td></tr></table></figure>
<p>下面检查生成的文件。processOrthofinder 会根据物种目标拷贝数对超过目标拷贝数的同源基因进行过滤，得到用来制备共线块的基因，结果为 *.sequence 文件（Maize.sequence）。之后需要将各个 *.sequence 文件进行合并，得到 drimm.sequence 文件作为 DRIMM 的输入。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost processDRIMM]$ ll example_fl/</span><br><span class="line">total 18068</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  418312 Apr 22 14:42 Telongatum.all.sequence.genename</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  142096 Apr 22 14:42 Telongatum.all.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   80934 Apr 22 14:42 Telongatum.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  455606 Apr 22 14:42 Sorghum.all.sequence.genename</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  128955 Apr 22 14:42 Sorghum.all.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   80002 Apr 22 14:42 Sorghum.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  376841 Apr 22 14:42 Rice.all.sequence.genename</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  127914 Apr 22 14:42 Rice.all.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   80069 Apr 22 14:42 Rice.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  488212 Apr 22 14:42 Maize.all.sequence.genename</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  140247 Apr 22 14:42 Maize.all.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   95546 Apr 22 14:42 Maize.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  442444 Apr 22 14:42 Brachy.all.sequence.genename</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  121269 Apr 22 14:42 Brachy.all.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   79332 Apr 22 14:42 Brachy.sequence</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1732515 Apr 22 14:42 filter_group.xls</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 2841844 Apr 22 14:42 group.xls</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1235362 Apr 22 14:33 Brachy.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1617027 Apr 22 14:33 Maize.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1222139 Apr 22 14:33 Rice.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1367402 Apr 22 14:33 Sorghum.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 2717575 Apr 22 14:33 Telongatum.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 2458531 Apr 22 14:33 Orthogroups.tsv</span><br></pre></td></tr></table></figure>
<p>将上面的drimm.sequence文件拷贝到win系统的工作目录下，如下所示，我放在“D:\Program Files\processDRIMM\example_fl”，随后进入 DOS 界面。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">D:\Program Files\processDRIMM\example_fl&gt; dir</span><br><span class="line"> 驱动器 D 中的卷没有标签。</span><br><span class="line"> 卷的序列号是 7EAB-2AD7</span><br><span class="line"></span><br><span class="line"> D:\Program Files\processDRIMM\example_fl 的目录</span><br><span class="line"></span><br><span class="line">2022/04/22  15:43    &lt;DIR&gt;          .</span><br><span class="line">2022/04/22  15:43    &lt;DIR&gt;          ..</span><br><span class="line">2022/04/22  14:57           415,883 drimm.sequence</span><br><span class="line">               1 个文件        415,883 字节</span><br><span class="line">               2 个目录 444,340,531,200 可用字节</span><br></pre></td></tr></table></figure>
<p>这一步骤的操作引起问题，原因是路径中有空格。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">### &quot;D:\Program Files\Informed-Proteomics\ProMex.exe&quot;</span><br><span class="line">C:&gt;D</span><br><span class="line">cd &quot;D:\Program Files\processDRIMM\example_fl&quot;</span><br><span class="line">&gt;&quot;D:\Program Files\processDRIMM\drimm\drimm\bin\Release\netcoreapp3.1\win-x64\drimm.exe&quot;</span><br><span class="line">&quot;D:\Program Files\processDRIMM\example_fl&quot;</span><br></pre></td></tr></table></figure>
<p>在 D 盘新建 InferAncestorGenome 目录，将 processDRIMM 文件夹从 “D:\Program Files\processDRIMM” 复制一份到 D:\InferAncestorGenome 目录。<br />
现在 drimm.sequence 文件存放在 D:\InferAncestorGenome\processDRIMM\example_fl，如下方代码所示，我们在 DOS 界面下进入这个目录，然后执行 <code>dir</code> 命令就可以看到 drimm.sequence 文件；继而调用命令 <code>D:\InferAncestorGenome\processDRIMM\drimm\drimm\bin\Release\netcoreapp3.1\win-x64\drimm.exe</code> 即开始运行 DRIMM-synteny，这时候按照程序的提示分别设定如下内容：</p>
<p>(1) 输入文件：drimm.sequence；<br />
(2) 输出路径：D:\InferAncestorGenome\processDRIMM\example_fl\drimm；<br />
(3) cycleLengthThreshold参数控制产生共线块的大小，设置小参数时会考虑到一些小的变异产生共线块比较破碎打断会比较频繁，设置大参数时运行会比较慢会忽略一些小的变异保留更大的特征，DRIMM 原文中测试数据为酵母基因组选择默认参数为 20，IAGS 文章中处理植物基因组时选择参数为 60，这个参数可以根据研究需要进行调整，一般可以选择默认参数 20<br />
(4) dustThreshold 为最大同源基因多样性，会将同源基因个数中超过这个上限的同源基因组进行过滤，推荐设置为目标拷贝数总和 +1，<br />
例如 IAGS 文章中禾本科五个物种：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sp_list = [&#x27;Brachy&#x27;,&#x27;Maize&#x27;,&#x27;Rice&#x27;,&#x27;Sorghum&#x27;,&#x27;Telongatum&#x27;]  </span><br><span class="line">target_rate = &#x27;2:4:2:2:2&#x27;  </span><br><span class="line">dustThreshold为13（12+1）</span><br></pre></td></tr></table></figure>
<p>下面记载了 DOS 界面下运行 drimm.exe 的场景。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">D:\Program Files\processDRIMM\example_fl&gt;cd D:\InferAncestorGenome\processDRIMM\example_fl</span><br><span class="line"></span><br><span class="line">D:\InferAncestorGenome\processDRIMM\example_fl&gt;dir</span><br><span class="line"> 驱动器 D 中的卷没有标签。</span><br><span class="line"> 卷的序列号是 7EAB-2AD7</span><br><span class="line"></span><br><span class="line"> D:\InferAncestorGenome\processDRIMM\example_fl 的目录</span><br><span class="line"></span><br><span class="line">2022/04/22  15:59    &lt;DIR&gt;          .</span><br><span class="line">2022/04/22  15:59    &lt;DIR&gt;          ..</span><br><span class="line">2022/04/22  14:57           415,883 drimm.sequence</span><br><span class="line">               1 个文件        415,883 字节</span><br><span class="line">               2 个目录 444,175,998,976 可用字节</span><br><span class="line"></span><br><span class="line">D:\InferAncestorGenome\processDRIMM\example_fl&gt;D:\InferAncestorGenome\processDRIMM\drimm\drimm\bin\Release\netcoreapp3.1\win-x64\drimm.exe</span><br><span class="line">Enter inputfile</span><br><span class="line">drimm.sequence</span><br><span class="line">Enter outdir</span><br><span class="line">D:\InferAncestorGenome\processDRIMM\example_fl</span><br><span class="line">### D:\InferAncestorGenome\processDRIMM\example_fl\drimm</span><br><span class="line">Enter cycleLengthThreshold</span><br><span class="line">20</span><br><span class="line">Enter dustThreshold</span><br><span class="line">13</span><br><span class="line">Padding numb924</span><br><span class="line">Nodes: 14133</span><br><span class="line">Number of edges: 36364</span><br><span class="line">Nodes:14039</span><br><span class="line">Number of edges: 19134</span><br><span class="line">Nodes:13823</span><br><span class="line">Number of edges: 16765</span><br><span class="line">Nodes:13686</span><br><span class="line">Number of edges: 15998</span><br><span class="line">Nodes:13575</span><br><span class="line">Number of edges: 15636</span><br><span class="line">Nodes:13411</span><br><span class="line">Number of edges: 15326</span><br><span class="line">Nodes:13273</span><br><span class="line">Number of edges: 15035</span><br><span class="line">Nodes:12959</span><br><span class="line">Number of edges: 14540</span><br><span class="line">Nodes:12754</span><br><span class="line">Number of edges: 14244</span><br><span class="line">Nodes:12692</span><br><span class="line">Number of edges: 14152</span><br><span class="line">Nodes:12653</span><br><span class="line">Number of edges: 14099</span><br><span class="line">Nodes:12652</span><br><span class="line">Number of edges: 14090</span><br><span class="line">Nodes:12646</span><br><span class="line">Number of edges: 14084</span><br><span class="line">Nodes:12642</span><br><span class="line">Number of edges: 14075</span><br><span class="line">Nodes:12642</span><br><span class="line">Number of edges: 14102</span><br><span class="line">Nodes:13311</span><br></pre></td></tr></table></figure>
<p>执行 drimm.exe 之后的输出中有两个重要的文件 synteny.txt 以及 blocks.txt 文件。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">D:\InferAncestorGenome\processDRIMM\example_fl&gt;dir</span><br><span class="line"> 驱动器 D 中的卷没有标签。</span><br><span class="line"> 卷的序列号是 7EAB-2AD7</span><br><span class="line"></span><br><span class="line"> D:\InferAncestorGenome\processDRIMM\example_fl 的目录</span><br><span class="line"></span><br><span class="line">2022/04/22  16:03    &lt;DIR&gt;          .</span><br><span class="line">2022/04/22  16:03    &lt;DIR&gt;          ..</span><br><span class="line">2022/04/22  16:03            33,056 blocks.txt</span><br><span class="line">2022/04/22  14:57           415,883 drimm.sequence</span><br><span class="line">2022/04/22  16:03           474,580 modifiedSequence.txt</span><br><span class="line">2022/04/22  16:03           766,866 sequenceColor.txt</span><br><span class="line">2022/04/22  16:03             4,010 split.txt</span><br><span class="line">2022/04/22  16:03            97,352 synteny.txt</span><br><span class="line">               6 个文件      1,791,747 字节</span><br><span class="line">               2 个目录 444,174,614,528 可用字节</span><br></pre></td></tr></table></figure>
<p>其中 synteny.txt 文件截取展示如下，第一列为 block 的 ID，冒号后为在全部物种中出现次数，之后的若干个数字为 block 内部同源基因的 ID。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">1534:11 7400 14370 14369 </span><br><span class="line">1535:11 9549 9548 </span><br><span class="line">1536:12 7957 </span><br><span class="line">1537:12 1306 1305 </span><br><span class="line">1538:12 3698 1612 5338 2860 1611 1610 </span><br><span class="line">1539:12 2336 </span><br><span class="line">1540:12 1320 </span><br><span class="line">1541:12 3089 6660 6659 12584 1800 6658 6657 12583 12582 6656 6655 12581 1799 </span><br><span class="line">1542:12 1782 6228 3674 6229 1783 6592 12460 12461 12462 12463 12464 6593 12465 12466 1784 2349 </span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>blocks.txt 文件为全部物种的共线块信息，其中负号表示方向。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">-666 -736 -1441 -781 -1435 -657 -1372 395 -607 -928 1461 -1333 ...</span><br><span class="line">-1003 1173 -1004 -990 -1271 1019 -897 1390 1033 671 1070 -1429 -1629</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>把 synteny.txt 以及 blocks.txt 文件拷贝到 Linux 服务器，同时修改 <a href="http://processDrimm.py">processDrimm.py</a> 程序，然后运行就可以得到 IAGS 要求的 input files。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost processDRIMM]$ ./processDrimm.py</span><br><span class="line">-bash: ./processDrimm.py: /home/fenglei/local/app/anaconda3/envs/python37/bin/python3^M: bad interpreter: No such file or directory</span><br><span class="line">(python37) [fenglei@localhost processDRIMM]$ dos2unix processDrimm.py </span><br><span class="line">dos2unix: converting file processDrimm.py to Unix format ...</span><br><span class="line">(python37) [fenglei@localhost processDRIMM]$ ./processDrimm.py </span><br><span class="line">98</span><br><span class="line">98</span><br><span class="line"></span><br><span class="line">(python37) [fenglei@localhost processDRIMM]$ ll example_fl/drimm</span><br><span class="line">total 152</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  1094 Apr 22 16:09 Telongatum.block</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  1107 Apr 22 16:09 Sorghum.block</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  1101 Apr 22 16:09 Rice.block</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  2176 Apr 22 16:09 Maize.block</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  1111 Apr 22 16:09 Brachy.block</span><br><span class="line">-rw-r--r-- 1 fenglei fenglei 33056 Apr 22 16:03 blocks.txt</span><br><span class="line">-rw-r--r-- 1 fenglei fenglei 97352 Apr 22 16:03 synteny.txt</span><br></pre></td></tr></table></figure>
<p>此时打开 Rice.block，就是我们期望得到的格式！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost drimm]$ cat Rice.block</span><br><span class="line">s -1629 -1628 1590 1591 1671 -1613 1648 -1657 -1660 -1659 -1654 -1550 -1566 -1577 -1582 -1583 1542 1578 -1558 1544 -1568 -1541 -1581 -1571 1631 1633 </span><br><span class="line">s 1553 1543 -1672 -1554 -1573 -1569 -1538 -1679 1625 -1697 -1684 1682 -1685 1658 -1696 1691 1627 1622 -1694 1592 -1677 1678 -1662 -1668 -1675 -1673 -1667 1666 -1664 -1655 -1551 </span><br><span class="line">s -1630 1632 1634 1636 1639 1643 1644 1572 1645 -1615 -1651 1623 -1602 1562 1580 1600 -1593 1621 1586 1609 1687 </span><br><span class="line">s 1625 -1697 -1684 1682 -1685 1658 -1696 1691 1627 1622 -1694 1592 -1677 1678 </span><br><span class="line">s 1631 1633 -1617 -1629 -1628 -1571 1581 1541 1568 -1544 1558 -1578 -1542 1583 1582 1577 1566 1550 1654 1659 1660 1657 -1648 1613 -1671 -1591 -1590 </span><br><span class="line">s 1551 1655 1664 -1666 1667 1673 1675 1668 1662 1679 1538 1569 1573 1554 1672 -1543 -1553 -1572 </span><br><span class="line">s 1586 1609 1687 1651 1615 </span><br><span class="line">s 1617 1595 -1603 1619 -1604 1656 -1607 -1608 -1610 1624 1606 1611 -1612 </span><br><span class="line">s 1595 -1603 1619 -1604 1656 -1607 -1608 -1610 1624 1606 1611 -1612 </span><br><span class="line">s 1634 1636 1639 -1644 -1643 1645 -1632 1630 </span><br><span class="line">s -1557 1560 1616 1597 -1559 1605 1601 </span><br><span class="line">s -1557 1560 1616 1597 -1559 1605 -1601 1623 -1602 1562 1580 1600 -1593 1621 </span><br></pre></td></tr></table></figure>
<h3 id="一个需要注意的地方"><a class="markdownIt-Anchor" href="#一个需要注意的地方"></a> 一个需要注意的地方</h3>
<p>drimm.sequence 一共 44 行，每行都是一个数列，所有物种的染色体数目加起来刚好是 44 行。但是这里文件里面是没有描述物种顺序的内容的。<br />
所以一定要注意，<a href="http://processOrthofinder.py">processOrthofinder.py</a> 运行之后，有一个合并所有物种 xxx.sequence 文件的操作，一定要跟脚本中保持一致。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">### 下面内容摘取自：processOrthofinder.py</span><br><span class="line">sp = [&#x27;Brachy&#x27;,&#x27;Maize&#x27;,&#x27;Rice&#x27;,&#x27;Sorghum&#x27;,&#x27;Telongatum&#x27;]</span><br><span class="line">gff_list = [&#x27;Brachy.gff&#x27;,&#x27;Maize.gff&#x27;,&#x27;Rice.gff&#x27;,&#x27;Sorghum.gff&#x27;,&#x27;Telongatum.gff&#x27;]</span><br><span class="line">sp_ratio = [2,4,2,2,2]</span><br><span class="line"></span><br><span class="line">### 注意这里物种的顺序，需要跟上一步骤保持一致</span><br><span class="line">cat Brachy.sequence Maize.sequence Rice.sequence Sorghum.sequence Telongatum.sequence &gt; drimm.sequence</span><br><span class="line"></span><br><span class="line">### 下面内容摘取自：processDrimm.py</span><br><span class="line">chr_number = [5,10,12,10,7]</span><br><span class="line">sp_list = [&#x27;Brachy&#x27;,&#x27;Maize&#x27;,&#x27;Rice&#x27;,&#x27;Sorghum&#x27;,&#x27;Telongatum&#x27;]   ### 注意这里物种的顺序，需要跟上一步骤保持一致</span><br><span class="line">target_rate = &#x27;2:4:2:2:2&#x27;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="cyclelengththreshold-参数测试"><a class="markdownIt-Anchor" href="#cyclelengththreshold-参数测试"></a> cycleLengthThreshold 参数测试</h3>
<p>之前将 cycleLengthThreshold 设置为 20，这次设定为 60 试试。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">D:\InferAncestorGenome\processDRIMM\example_fl&gt;D:\InferAncestorGenome\processDRIMM\drimm\drimm\bin\Release\netcoreapp3.1\win-x64\drimm.exe</span><br><span class="line">Enter inputfile</span><br><span class="line">drimm.sequence</span><br><span class="line">Enter outdir</span><br><span class="line">D:\InferAncestorGenome\processDRIMM\example_fl\drimm</span><br><span class="line">Enter cycleLengthThreshold</span><br><span class="line">60</span><br><span class="line">Enter dustThreshold</span><br><span class="line">13</span><br><span class="line">Padding numb2684</span><br><span class="line">Nodes: 15893</span><br><span class="line">Number of edges: 38124</span><br><span class="line">Nodes:15757</span><br><span class="line">Number of edges: 21030</span><br><span class="line">Nodes:15446</span><br><span class="line">Number of edges: 18309</span><br><span class="line">Nodes:15106</span><br><span class="line">Number of edges: 17037</span><br><span class="line">Nodes:14781</span><br><span class="line">Number of edges: 16338</span><br><span class="line">Nodes:14416</span><br><span class="line">Number of edges: 15723</span><br><span class="line">Nodes:13923</span><br><span class="line">Number of edges: 15033</span><br><span class="line">Nodes:13519</span><br><span class="line">Number of edges: 14462</span><br><span class="line">Nodes:12991</span><br><span class="line">Number of edges: 13799</span><br><span class="line">Nodes:12805</span><br><span class="line">Number of edges: 13575</span><br><span class="line">Nodes:12713</span><br><span class="line">Number of edges: 13456</span><br><span class="line">Nodes:12635</span><br><span class="line">Number of edges: 13358</span><br><span class="line">Nodes:12624</span><br><span class="line">Number of edges: 13330</span><br><span class="line">Nodes:12609</span><br><span class="line">Number of edges: 13310</span><br><span class="line">Nodes:12599</span><br><span class="line">Number of edges: 13319</span><br><span class="line">Nodes:12801</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost processDRIMM]$ ./processDrimm.py</span><br><span class="line">27</span><br><span class="line">27</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | 依据序列名字列表从 fasta 文件提取序列</title>
    <url>/2021/03/10/Bioinfo-Extracting-sequence-by-names/</url>
    <content><![CDATA[<p>依据序列名称从fasta文件提取序列是一个很常见的操作。seqkit 这个工具可以很方便地实现。<br />
比如 input.fa 包含若干条序列，名称分别为 1、2、3……100 。而 name list 文件包含 40——49 这十个ID，那么通过下面的代码就可以提取编号 40——49 对应的序列。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit grep -r -f name_list.txt input.fa -o out.fa</span><br></pre></td></tr></table></figure>
<p>上面只是一种简单的情况，而大部分原始 fasta 文件中，序列名除了 ID，还可能会包含其他信息（比如基因注释）。当输入的 name list 文件只有 ID，默认的“名称完全匹配”就提取不了，就需要加上 <code>-r</code> 参数来申明使用正则匹配（regular expression）进行提取。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit grep -r -f name_list.txt input.fa -o out.fa</span><br></pre></td></tr></table></figure>
<p>另一种情况就是，对于拟南芥，每个基因有多个 isoforms，如果我们只需要依据基因 ID 输出一个 isoform，那么可以通过 <code>--delete-matched</code> 参数来控制，即当某个 ID 出现了一次匹配，则立即停止继续检索该 ID，进入下一个 ID 检索。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">seqkit grep -r --delete-matched -f Arabidopsis_name_list.txt Araport11_pep_20160703.pep.fa -o Arabidopsis_pep_list_nonrebundant.fa</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>一些FASTA/FASTQ序列处理工具</title>
    <url>/2020/12/15/Bioinfo-FASTA-FASTQ-tools/</url>
    <content><![CDATA[<p>序列分析的常见操作包括：序列长度统计（包括总长度、N50 length等），序列提取（根据序列名称或ID、根据序列坐标范围），序列格式转换（fasta-&gt;tab，调整fasta每行碱基数，序列翻转），序列重新命名，序列重新排序，序列切割与重新组合。下面的几个工具就像瑞士军刀一样灵活，基本能满足这些分析需求。</p>
<h3 id="1-seqtk"><a class="markdownIt-Anchor" href="#1-seqtk"></a> 1. seqtk</h3>
<p>Seqtk is a fast and lightweight tool for processing sequences in the FASTA or FASTQ format.<br />
It seamlessly parses both FASTA and FASTQ files which can also be optionally compressed by gzip.<br />
To install seqtk,</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/lh3/seqtk.git;</span><br><span class="line">cd seqtk; make</span><br></pre></td></tr></table></figure>
<p>Usage:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Usage:   seqtk &lt;command&gt; &lt;arguments&gt;</span><br><span class="line">Version: 1.3-r114-dirty</span><br><span class="line"></span><br><span class="line">Command: seq       common transformation of FASTA/Q</span><br><span class="line">         comp      get the nucleotide composition of FASTA/Q</span><br><span class="line">         sample    subsample sequences</span><br><span class="line">         subseq    extract subsequences from FASTA/Q</span><br><span class="line">         fqchk     fastq QC (base/quality summary)</span><br><span class="line">         mergepe   interleave two PE FASTA/Q files</span><br><span class="line">         trimfq    trim FASTQ using the Phred algorithm</span><br><span class="line"></span><br><span class="line">         hety      regional heterozygosity</span><br><span class="line">         gc        identify high- or low-GC regions</span><br><span class="line">         mutfa     point mutate FASTA at specified positions</span><br><span class="line">         mergefa   merge two FASTA/Q files</span><br><span class="line">         famask    apply a X-coded FASTA to a source FASTA</span><br><span class="line">         dropse    drop unpaired from interleaved PE FASTA/Q</span><br><span class="line">         rename    rename sequence names</span><br><span class="line">         randbase  choose a random base from hets</span><br><span class="line">         cutN      cut sequence at long N</span><br><span class="line">         gap       get the gap locations</span><br><span class="line">         listhet   extract the position of each het</span><br></pre></td></tr></table></figure>
<h3 id="2-seqkit"><a class="markdownIt-Anchor" href="#2-seqkit"></a> 2. seqkit</h3>
<p>To install, type <code>conda install -c bioconda seqkit</code>.<br />
Usage:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SeqKit -- a cross-platform and ultrafast toolkit for FASTA/Q file manipulation</span><br><span class="line"></span><br><span class="line">Version: 0.14.0</span><br><span class="line"></span><br><span class="line">Author: Wei Shen &lt;shenwei356&gt;</span><br><span class="line"></span><br><span class="line">Documents  : http://bioinf.shenwei.me/seqkit</span><br><span class="line">Source code: https://github.com/shenwei356/seqkit</span><br><span class="line">Please cite: https://doi.org/10.1371/journal.pone.0163962</span><br><span class="line"></span><br><span class="line">Usage:</span><br><span class="line">  seqkit [command]</span><br><span class="line"></span><br><span class="line">Available Commands:</span><br><span class="line">  amplicon        retrieve amplicon (or specific region around it) via primer(s)</span><br><span class="line">  bam             monitoring and online histograms of BAM record features</span><br><span class="line">  common          find common sequences of multiple files by id/name/sequence</span><br><span class="line">  concat          concatenate sequences with same ID from multiple files</span><br><span class="line">  convert         convert FASTQ quality encoding between Sanger, Solexa and Illumina</span><br><span class="line">  duplicate       duplicate sequences N times</span><br><span class="line">  faidx           create FASTA index file and extract subsequence</span><br><span class="line">  fish            look for short sequences in larger sequences using local alignment</span><br><span class="line">  fq2fa           convert FASTQ to FASTA</span><br><span class="line">  fx2tab          convert FASTA/Q to tabular format (with length/GC content/GC skew)</span><br><span class="line">  genautocomplete generate shell autocompletion script</span><br><span class="line">  grep            search sequences by ID/name/sequence/sequence motifs, mismatch allowed</span><br><span class="line">  head            print first N FASTA/Q records</span><br><span class="line">  help            Help about any command</span><br><span class="line">  locate          locate subsequences/motifs, mismatch allowed</span><br><span class="line">  mutate          edit sequence (point mutation, insertion, deletion)</span><br><span class="line">  pair            match up paired-end reads from two fastq files</span><br><span class="line">  range           print FASTA/Q records in a range (start:end)</span><br><span class="line">  rename          rename duplicated IDs</span><br><span class="line">  replace         replace name/sequence by regular expression</span><br><span class="line">  restart         reset start position for circular genome</span><br><span class="line">  rmdup           remove duplicated sequences by id/name/sequence</span><br><span class="line">  sample          sample sequences by number or proportion</span><br><span class="line">  sana            sanitize broken single line fastq files</span><br><span class="line">  scat            real time recursive concatenation and streaming of fastx files</span><br><span class="line">  seq             transform sequences (revserse, complement, extract ID...)</span><br><span class="line">  shuffle         shuffle sequences</span><br><span class="line">  sliding         sliding sequences, circular genome supported</span><br><span class="line">  sort            sort sequences by id/name/sequence/length</span><br><span class="line">  split           split sequences into files by id/seq region/size/parts (mainly for FASTA)</span><br><span class="line">  split2          split sequences into files by size/parts (FASTA, PE/SE FASTQ)</span><br><span class="line">  stats           simple statistics of FASTA/Q files</span><br><span class="line">  subseq          get subsequences by region/gtf/bed, including flanking sequences</span><br><span class="line">  tab2fx          convert tabular format to FASTA/Q format</span><br><span class="line">  translate       translate DNA/RNA to protein sequence (supporting ambiguous bases)</span><br><span class="line">  version         print version information and check for update</span><br><span class="line">  watch           monitoring and online histograms of sequence features</span><br></pre></td></tr></table></figure>
<h3 id="3-itools-reseqtools"><a class="markdownIt-Anchor" href="#3-itools-reseqtools"></a> 3. iTools (Reseqtools)</h3>
<p>To install, use <code>git clone git@github.com:BGI-shenzhen/Reseqtools.git</code>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Program: iTools (ReSeqtools)</span><br><span class="line">Version: 0.25   author:hewm2008      Oct 23 2018</span><br><span class="line"></span><br><span class="line">        Usage:</span><br><span class="line"></span><br><span class="line">                Fatools        Tools For Fasta</span><br><span class="line">                Fqtools        Tools For Fastq</span><br><span class="line">                SOAPtools      Tools For SOAP </span><br><span class="line">                Vartools       Tools For SOAP Variant</span><br><span class="line">                CNStools       Tools For CNS</span><br><span class="line">                Xamtools       Tools For Sam/Bam</span><br><span class="line">                Gfftools       Tools For Gff</span><br><span class="line">                Formtools      Tools For Form convert</span><br><span class="line">                Filetools      Tools For Specified File</span><br><span class="line">                Othertools     Tools For Other</span><br><span class="line">                Gametools      Tools For Game</span><br></pre></td></tr></table></figure>
<h3 id="4-ngsqctoolkit"><a class="markdownIt-Anchor" href="#4-ngsqctoolkit"></a> 4. NGSQCToolkit</h3>
<p>A toolkit for the quality control (QC) of next generation sequencing (NGS) data. The toolkit comprises of user-friendly stand alone tools for quality control of the sequence data generated using Illumina and Roche 454 platforms with detailed results in the form of tables and graphs, and filtering of high-quality sequence data. It also includes few other tools, which are helpful in NGS data quality control and analysis.<br />
原下载链接已经失效：<a href="http://www.nipgr.ac.in/ngsqctoolkit.html">http://www.nipgr.ac.in/ngsqctoolkit.html</a><br />
我把它上传到GitHub了：<code>git clone git@github.com:bioinfx/NGSQCToolkit.git</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">perl ~/local/app/NGSQCToolkit/Statistics/N50Stat.pl   </span><br><span class="line">Usage: perl /home/fenglei/local/app/NGSQCToolkit/Statistics/N50Stat.pl &lt;options&gt;</span><br><span class="line"></span><br><span class="line">\### Input reads/sequences (FASTA) (Required)</span><br><span class="line">  -i &lt;Read/Sequence file&gt;</span><br><span class="line">    Read/Sequence in fasta format</span><br><span class="line">\### Other options [Optional]</span><br><span class="line">  -h | -help</span><br><span class="line">    Prints this help</span><br><span class="line">  -o | -outputFile &lt;Output file name&gt;</span><br><span class="line">    Output will be stored in the given file</span><br><span class="line">    default: By default, N50 statistics file will be stored where the input file is</span><br></pre></td></tr></table></figure>
<h3 id="5-fastx-toolkit"><a class="markdownIt-Anchor" href="#5-fastx-toolkit"></a> 5. FASTX-Toolkit</h3>
<p><a href="http://hannonlab.cshl.edu/fastx_toolkit/">http://hannonlab.cshl.edu/fastx_toolkit/</a><br />
Usage:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">FASTQ-to-FASTA converter</span><br><span class="line">	Convert FASTQ files to FASTA files.</span><br><span class="line">FASTQ Information</span><br><span class="line">	Chart Quality Statistics and Nucleotide Distribution</span><br><span class="line">FASTQ/A Collapser</span><br><span class="line">	Collapsing identical sequences in a FASTQ/A file into a single sequence (while maintaining reads counts)</span><br><span class="line">FASTQ/A Trimmer</span><br><span class="line">	Shortening reads in a FASTQ or FASTQ files (removing barcodes or noise).</span><br><span class="line">FASTQ/A Renamer</span><br><span class="line">	Renames the sequence identifiers in FASTQ/A file.</span><br><span class="line">FASTQ/A Clipper</span><br><span class="line">	Removing sequencing adapters / linkers</span><br><span class="line">FASTQ/A Reverse-Complement</span><br><span class="line">	Producing the Reverse-complement of each sequence in a FASTQ/FASTA file.</span><br><span class="line">FASTQ/A Barcode splitter</span><br><span class="line">	Splitting a FASTQ/FASTA files containning multiple samples</span><br><span class="line">FASTA Formatter</span><br><span class="line">	changes the width of sequences line in a FASTA file</span><br><span class="line">FASTA Nucleotide Changer</span><br><span class="line">	Convets FASTA sequences from/to RNA/DNA</span><br><span class="line">FASTQ Quality Filter</span><br><span class="line">	Filters sequences based on quality</span><br><span class="line">FASTQ Quality Trimmer</span><br><span class="line">	Trims (cuts) sequences based on quality</span><br><span class="line">FASTQ Masker</span><br><span class="line">	Masks nucleotides with &#x27;N&#x27; (or other character) based on quality</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | Gene Ontology - Enrichment Analysis</title>
    <url>/2021/06/29/Bioinfo-Gene-Ontology-Enrichment-Analysis/</url>
    <content><![CDATA[<p>下面是我做的大豆GO数据库（version Gmax_508_Wm82_a4.v1）构建与富集分析。数据文件在：<a href="https://github.com/bioinfx/Glycine_max_Gene_Ontology">https://github.com/bioinfx/Glycine_max_Gene_Ontology</a>。</p>
<p>经过前期数据比对和整理（比如依据 swissprot、blast2GO，或 GOMAP），得到下面“基因——GO号——Ontology 类别——证据”这四列格式的文件 GMA_GO_TERM.txt，就可以在R程序里面用于 GO 数据库的构建。</p>
<h3 id="数据库源文件准备"><a class="markdownIt-Anchor" href="#数据库源文件准备"></a> 数据库源文件准备</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ zcat GMA_GO_TERM.txt.gz | head</span><br><span class="line">GID     GO      ONTOLOGY        EVIDENCE</span><br><span class="line">Glyma.01G000100 GO:0006412      P       IEA</span><br><span class="line">Glyma.01G000100 GO:0009063      P       IEA</span><br><span class="line">Glyma.01G000100 GO:0009234      P       IEA</span><br><span class="line">Glyma.01G000100 GO:0016021      C       IEA</span><br><span class="line">Glyma.01G000100 GO:0031969      C       IEA</span><br><span class="line">Glyma.01G000100 GO:0016835      F       IEA</span><br><span class="line">Glyma.01G000100 GO:0030976      F       IEA</span><br><span class="line">Glyma.01G000100 GO:0070204      F       IEA</span><br><span class="line">Glyma.01G000137 GO:0016043      P       IEA</span><br></pre></td></tr></table></figure>
<h3 id="数据库导入-r"><a class="markdownIt-Anchor" href="#数据库导入-r"></a> 数据库导入 R</h3>
<p>构建过程如下，调用 makeOrgPackage 函数构建 GO 数据库。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## Makes an organism package for Glycine max data.frames:</span><br><span class="line"></span><br><span class="line">library(RSQLite)</span><br><span class="line">library(AnnotationForge)</span><br><span class="line"></span><br><span class="line">## Now prepare some data.frames</span><br><span class="line">fGO &lt;- read.table(&quot;../3_final-result/GMA_GO_TERM.txt&quot;, sep=&quot;\t&quot;, head=TRUE)</span><br><span class="line"></span><br><span class="line">## remove duplication in the table</span><br><span class="line">go_df &lt;- fGO[!duplicated(fGO),]</span><br><span class="line"></span><br><span class="line">## only tree coloums are needed: GID, GO, EVIDENCE</span><br><span class="line">go_df &lt;- go_df[,c(1,2,4)]</span><br><span class="line"></span><br><span class="line">## Making Organism packages </span><br><span class="line">makeOrgPackage(go=go_df,</span><br><span class="line">    version = &quot;0.0.1&quot;,</span><br><span class="line">    maintainer = &quot;FENG Lei &lt;fengleiluck@gmail.com&gt;&quot;,</span><br><span class="line">    author = &quot;FENG Lei &lt;fengleiluck@gmail.com&gt;&quot;,</span><br><span class="line">    outputDir = &quot;./&quot;,</span><br><span class="line">    tax_id = &quot;3847&quot;,</span><br><span class="line">    genus = &quot;Glycine&quot;,</span><br><span class="line">    species = &quot;max&quot;,</span><br><span class="line">    goTable = &quot;go&quot;</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">## then you can call install.packages based on the return value</span><br><span class="line">install.packages(&quot;./org.Gmax.eg.db&quot;, repos = NULL, type=&quot;source&quot;)</span><br><span class="line">library(org.Gmax.eg.db)</span><br><span class="line">org &lt;- org.Gmax.eg.db</span><br><span class="line"></span><br><span class="line">## A demo for using the database</span><br><span class="line"># BiocManager::install(&quot;Rgraphviz&quot;)</span><br><span class="line"># BiocManager::install(&quot;topGO&quot;)</span><br><span class="line">library()</span><br><span class="line">geneTable = read.table(&quot;./Gmax_ABA_exp.xls&quot;, head=T)</span><br><span class="line">geneList=geneTable[,5]</span><br><span class="line">geneList=geneList[!duplicated(geneList)]</span><br><span class="line"># Biology process</span><br><span class="line">ego_up &lt;-enrichGO(gene = geneList, OrgDb = org, keyType = &quot;GID&quot;, ont = &quot;BP&quot;)</span><br><span class="line">pdf(&quot;up_GO_BP_barplot.pdf&quot;, height=10, width=15)</span><br><span class="line">barplot(ego_up, drop=TRUE, showCategory=12)</span><br><span class="line">dev.off()</span><br><span class="line">pdf(&quot;up_GO_BP_dotPlot.pdf&quot;, height=10, width=15)</span><br><span class="line">dotplot(ego_up)</span><br><span class="line">dev.off()</span><br><span class="line">pdf(&quot;up_GO_BP_tree.pdf&quot;)</span><br><span class="line">plotGOgraph(ego_up)</span><br><span class="line">dev.off()</span><br><span class="line">write.csv(as.data.frame( ego_up@result ), file=&quot;up_GO_BP.csv&quot;)</span><br></pre></td></tr></table></figure>
<h1 id="数据库开启与富集分析"><a class="markdownIt-Anchor" href="#数据库开启与富集分析"></a> 数据库开启与富集分析</h1>
<p>下面代码示范如何引用上构建的数据库，并且开展 GO 分析：BP、MF 和 CC 三个类别。<br />
图片可输出为柱状图 barplot 和点状图 dotplot，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">library(org.Gmax.eg.db)</span><br><span class="line">org &lt;- org.Gmax.eg.db</span><br><span class="line"></span><br><span class="line">## A demo for using the database</span><br><span class="line"># BiocManager::install(&quot;Rgraphviz&quot;)</span><br><span class="line"># BiocManager::install(&quot;topGO&quot;)</span><br><span class="line">library(topGO)</span><br><span class="line">library(clusterProfiler)</span><br><span class="line">geneTable = read.table(&quot;./gene_table.txt&quot;, head=T, sep=&quot;\t&quot;)</span><br><span class="line">#geneTable = geneTable[!apply(geneTable == &quot;&quot;, 1, all),]</span><br><span class="line">geneList=geneTable[,5]</span><br><span class="line"></span><br><span class="line">geneList=geneList[!duplicated(geneList)]</span><br><span class="line"># Biology process</span><br><span class="line">b=geneList</span><br><span class="line"></span><br><span class="line"># biological progress</span><br><span class="line">ego_up &lt;-enrichGO(</span><br><span class="line">                  gene = b, </span><br><span class="line">                  OrgDb = org, </span><br><span class="line">                  keyType = &quot;GID&quot;, </span><br><span class="line">                  ont = &quot;BP&quot;</span><br><span class="line">                  )</span><br><span class="line">pdf(&quot;test_GO_BP_barplot.pdf&quot;, height=10, width=15)</span><br><span class="line">barplot(ego_up, drop=TRUE, showCategory=12)</span><br><span class="line">dev.off()</span><br><span class="line">pdf(&quot;test_GO_BP_dotPlot.pdf&quot;, height=10, width=15)</span><br><span class="line">dotplot(ego_up)</span><br><span class="line">dev.off()</span><br><span class="line">#pdf(&quot;up_GO_BP_tree.pdf&quot;)</span><br><span class="line">#plotGOgraph(ego_up)</span><br><span class="line">#dev.off()</span><br><span class="line">write.csv(as.data.frame( ego_up@result ), file=&quot;test_GO_BP.csv&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># molecular function</span><br><span class="line">ego_down &lt;-enrichGO(</span><br><span class="line">                    gene = b,</span><br><span class="line">                    OrgDb = org,</span><br><span class="line">                    keyType = &quot;GID&quot;,</span><br><span class="line">                    ont = &quot;MF&quot;</span><br><span class="line">                    )</span><br><span class="line">pdf(&quot;test_GO_MF_barplot.pdf&quot;, height=10, width=15)</span><br><span class="line">barplot(ego_down, drop=TRUE, showCategory=12)</span><br><span class="line">dev.off()</span><br><span class="line">pdf(&quot;test_GO_MF_dotPlot.pdf&quot;, height=10, width=15)</span><br><span class="line">dotplot(ego_down)</span><br><span class="line">dev.off()</span><br><span class="line">#pdf(&quot;test_GO_MF_tree.pdf&quot;)</span><br><span class="line">#plotGOgraph(ego_down)</span><br><span class="line">#dev.off()</span><br><span class="line">write.csv(as.data.frame( ego_down@result), file=&quot;test_GO_MF.csv&quot;)</span><br><span class="line"></span><br><span class="line"># cellular component</span><br><span class="line">ego_down &lt;-enrichGO(</span><br><span class="line">                    gene = b,</span><br><span class="line">                    OrgDb = org,</span><br><span class="line">                    keyType = &quot;GID&quot;,</span><br><span class="line">                    ont = &quot;CC&quot;</span><br><span class="line">                    )</span><br><span class="line">pdf(&quot;test_GO_CC_barplot.pdf&quot;, height=10, width=15)</span><br><span class="line">barplot(ego_down, drop=TRUE, showCategory=12)</span><br><span class="line">dev.off()</span><br><span class="line">pdf(&quot;test_GO_CC_dotPlot.pdf&quot;, height=10, width=15)</span><br><span class="line">dotplot(ego_down)</span><br><span class="line">dev.off()</span><br><span class="line">#pdf(&quot;test_GO_CC_tree.pdf&quot;)</span><br><span class="line">#plotGOgraph(ego_down)</span><br><span class="line">#dev.off()</span><br><span class="line">write.csv(as.data.frame( ego_down@result), file=&quot;test_GO_CC.csv&quot;)</span><br></pre></td></tr></table></figure>
<p>有时候 GO 项目的名称过长，基于默认作图代码出来的图片会出现文字将图形区域挤压得无法显示。</p>
<p><img src="https://i.imgur.com/FlARCCO.jpeg" alt="" /></p>
<p>有两种优化方案，一是将长的文字换行；二是只截取一部分文字显示。</p>
<h3 id="一过长的文字换行显示"><a class="markdownIt-Anchor" href="#一过长的文字换行显示"></a> 一：过长的文字换行显示，</h3>
<p>参考资料：<a href="https://www.cnblogs.com/songbiao/articles/12717670.html">songbiao: GO term name太长的处理</a><br />
在使用clusterProfiler进行绘制GO dotplot时，会遇到 GO term 的 name 过长，压缩了图形区域的情况。<br />
因为 clusterProfiler 作图是基于 ggplot2 的，所以这个处理办法也适用于其他 ggplot2 作图遇到此种情况。<br />
解决文本过长的办法就是，用stringr包的str_wrap来完成文本自动换行。<br />
效果如下图所示，其实还是不太完美，需要后期手工调整才美观。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">library(ggplot2)  # 需要开启 ggplot2 才可以使用 scale_y_discrete 函数</span><br><span class="line">library(stringr)</span><br><span class="line">dotplot(mf, showCategory=30) + scale_y_discrete(labels=function(mf) str_wrap(mf, width=40))</span><br></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/JRkomgm.jpeg" alt="" /></p>
<h3 id="二只截取一部分文字显示"><a class="markdownIt-Anchor" href="#二只截取一部分文字显示"></a> 二：只截取一部分文字显示</h3>
<p>参考资料：<a href="https://r.bio-spring.info/2018/11/26/enrichplot-fancy-label/">在enrichplot中使用更好的Label</a><br />
该方法是定义一个截取短 label 的函数, 将其传递给 scale_y_discrete() 即可. 在输出 ggplot 对象时做修改。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#&#x27; Truncate string vector of ggplot axis label</span><br><span class="line">#&#x27;</span><br><span class="line">#&#x27; @param label    a ordered string vector</span><br><span class="line">#&#x27; @param maxLen   max length of character (nchar) to show in label</span><br><span class="line">#&#x27; @param maxWord  max count of words allowed to show in label</span><br><span class="line">#&#x27; @param pattern  Word separater</span><br><span class="line">#&#x27; @param dot      If true, three dots will added to truncated label</span><br><span class="line">#&#x27;</span><br><span class="line">#&#x27; @return a vector of truncated strings</span><br><span class="line">#&#x27; @export</span><br><span class="line">#&#x27;</span><br><span class="line">#&#x27; @examples</span><br><span class="line"># 默认最多显示 50 个字符, 5 个单词.</span><br><span class="line">short_label &lt;- function(label, maxLen = 50, maxWord = 5, pattern = &quot; &quot;, dot = TRUE)&#123;</span><br><span class="line">  l &lt;- strsplit(label, pattern)</span><br><span class="line">  short_label &lt;- vector(&quot;character&quot;,length(l))</span><br><span class="line">  </span><br><span class="line">  for (i in seq_along(l))&#123;</span><br><span class="line">    truncated &lt;- FALSE</span><br><span class="line">    s &lt;- l[[i]]</span><br><span class="line">    if (length(s) &gt; maxWord)&#123;</span><br><span class="line">      ll &lt;- paste(s[1:maxWord], collapse = &quot; &quot;)</span><br><span class="line">      truncated &lt;- TRUE</span><br><span class="line">    &#125;</span><br><span class="line">    else&#123;</span><br><span class="line">      ll &lt;- paste(s, collapse = &quot; &quot;)</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    if (nchar(ll) &gt; maxLen)&#123;</span><br><span class="line">      ll &lt;- substr(ll, 1, maxLen)</span><br><span class="line">      truncated &lt;- TRUE</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    if (dot &amp; truncated) ll &lt;- paste(ll, &quot;...&quot;,sep = &quot; &quot;)</span><br><span class="line">    </span><br><span class="line">    short_label[[i]] &lt;- ll</span><br><span class="line">  &#125;</span><br><span class="line">  attr(short_label, &quot;pos&quot;) &lt;- attr(label,&quot;pos&quot;)</span><br><span class="line">  return(short_label)</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>画图代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">library(ggplot2)</span><br><span class="line">dotplot(mf) + scale_y_discrete(label=short_label)</span><br></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/pALA2H9.jpeg" alt="" /></p>
<p>注意上面的图，其实很多项目都是高度近似的，怎么优化？对于模式物种而言，CytoScape的插件ClueGO有一个选项可以实现，就是设置Ontology的级别。因为Ontology的结构就是树状，从根部到.</p>
<p>构建GO数据库的过程中，如果成功会输出下面的信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; head(go_df)</span><br><span class="line">           GID         GO EVIDENCE</span><br><span class="line">1 Chr01.g00016 GO:0003676      IEA</span><br><span class="line">2 Chr01.g00016 GO:0003964      IEA</span><br><span class="line">3 Chr01.g00016 GO:0004190      IEA</span><br><span class="line">4 Chr01.g00016 GO:0004519      IEA</span><br><span class="line">5 Chr01.g00016 GO:0006310      IEA</span><br><span class="line">6 Chr01.g00016 GO:0015074      IEA</span><br><span class="line">&gt; makeOrgPackage(go=go_df,</span><br><span class="line">+                version = &quot;0.0.1&quot;,</span><br><span class="line">+                maintainer = &quot;FENG Lei &lt;fengleiluck@gmail.com&gt;&quot;,</span><br><span class="line">+                author = &quot;FENG Lei &lt;fengleiluck@gmail.com&gt;&quot;,</span><br><span class="line">+                outputDir = &quot;.&quot;,</span><br><span class="line">+                tax_id = &quot;126911&quot;,</span><br><span class="line">+                genus = &quot;Ammopiptanthus&quot;,</span><br><span class="line">+                species = &quot;mongolicus&quot;,</span><br><span class="line">+                goTable = &quot;go&quot;</span><br><span class="line">+ )</span><br><span class="line">Populating genes table:</span><br><span class="line">genes table filled</span><br><span class="line">Populating go table:</span><br><span class="line">go table filled</span><br><span class="line">table metadata filled</span><br><span class="line">&#x27;select()&#x27; returned many:1 mapping between keys and columns</span><br><span class="line">Dropping GO IDs that are too new for the current GO.db</span><br><span class="line">Populating go table:</span><br><span class="line">go table filled</span><br><span class="line">Populating go_bp table:</span><br><span class="line">go_bp table filled</span><br><span class="line">Populating go_cc table:</span><br><span class="line">go_cc table filled</span><br><span class="line">Populating go_mf table:</span><br><span class="line">go_mf table filled</span><br><span class="line">&#x27;select()&#x27; returned many:1 mapping between keys and columns</span><br><span class="line">Populating go_bp_all table:</span><br><span class="line">go_bp_all table filled</span><br><span class="line">Populating go_cc_all table:</span><br><span class="line">go_cc_all table filled</span><br><span class="line">Populating go_mf_all table:</span><br><span class="line">go_mf_all table filled</span><br><span class="line">Populating go_all table:</span><br><span class="line">go_all table filled</span><br><span class="line">Creating package in ./org.Amongolicus.eg.db </span><br><span class="line">Now deleting temporary database file</span><br><span class="line">[1] &quot;./org.Amongolicus.eg.db&quot;</span><br><span class="line">There were 50 or more warnings (use warnings() to see the first 50)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>基因组浏览器 JBrowse 安装（基于 Nginx 的 Web 服务器）</title>
    <url>/2020/10/03/Bioinfo-Genome-Browser-jbrowse-based-on-nginx-web-server/</url>
    <content><![CDATA[<p>需求：将基因组浏览器 JBrowse 安装在 Linux 服务器，在内网中用客户端电脑的网页浏览器可以打开 JBrowse 进行操作。安装过程如下，以 CentOS 7 系统为例，需要 root 权限。</p>
<p>JBrowse 是一款快速的，可以嵌入的基因组浏览器，它采用 JavaScript 和 HTML5 开发，同时提供了 Perl 脚本处理数据。JBrowse 采用了 Ajax 技术，主要的计算在客户端上完成， 对服务器资源的占用非常低，速度非常快，可以轻松部署上 G 的数据。JBrowse 支持 GFF3, BED, FASTA, Wiggle, BigWig, BAM, VCF (with tabix), REST 等众多数据格式，BAM, BigWig，VCF 格式的数据可以不需要转换而直接使用。 JBrowse 对系统依赖非常低，只需要一个 web 服务器，因此部署起来非常方便。Nginx 是一款轻量级、高性能 web 服务器，它占用内存少，并发能力强。越来越多的网站使用 Nginx 作为 web 服务器。</p>
<h3 id="1-安装-jbrowse-依赖的软件"><a class="markdownIt-Anchor" href="#1-安装-jbrowse-依赖的软件"></a> 1 安装 Jbrowse 依赖的软件</h3>
<p>参考资料：<a href="https://jbrowse.org/docs/installation.html">https://jbrowse.org/docs/installation.html</a></p>
<p>需要先安装依赖的一些工具，即“system pre-requisites”。我用的 CentOS 7系统，操作如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo yum groupinstall &quot;Development Tools&quot;</span><br><span class="line">sudo yum install zlib-devel perl-ExtUtils-MakeMaker</span><br></pre></td></tr></table></figure>
<p>安装 node 和 npm<br />
源代码下载 <a href="https://nodejs.org/dist/v12.18.4/node-v12.18.4-linux-x64.tar.xz">https://nodejs.org/dist/v12.18.4/node-v12.18.4-linux-x64.tar.xz</a><br />
xz文件解压：<code>tar -xvJf node-v8.11.1-linux-x64.tar.xz</code><br />
解压之后文件目录里面包含bin目录（node，npm，npx 三个程序），将bin目录加入环境变量。<br />
<code>export PATH=/xxx/xxx/bin:$PATH</code><br />
source ~/.bashrc 之后即可测试 node -h 与 npm -h，均可以运行。</p>
<h3 id="2-安装基因组浏览器-jbrowe"><a class="markdownIt-Anchor" href="#2-安装基因组浏览器-jbrowe"></a> 2 安装基因组浏览器 Jbrowe</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># make a directory that this user can write to</span><br><span class="line"># for ubuntu/Debian that is /var/www/; for centos is /var/www/html</span><br><span class="line">sudo mkdir /var/www/html/jbrowse;</span><br><span class="line">sudo chown `whoami` /var/www/html/jbrowse;</span><br><span class="line"></span><br><span class="line"># cd into it</span><br><span class="line">cd /var/www/html/jbrowse;</span><br><span class="line"></span><br><span class="line"># fetch a JBrowse release zip file</span><br><span class="line">curl -O http://jbrowse.org/releases/jbrowse-1.16.10-release.tar.gz</span><br><span class="line"></span><br><span class="line"># unzip it and cd into it</span><br><span class="line">unzip JBrowse-1.12.3.zip</span><br><span class="line">cd JBrowse-1.12.3</span><br><span class="line"></span><br><span class="line"># run setup.sh, quick start with example data</span><br><span class="line">./setup.sh</span><br></pre></td></tr></table></figure>
<p>运行 <a href="http://setup.sh">setup.sh</a> 自动安装成功，setup.log 文件如下所示。./setup.sh 这一步需要安装很多 perl 依赖库，需要的时间可能有点久。如果报错，请查看 setup.log 文件，一般是系统可能缺某个依赖库。</p>
<p><img src="https://genehub.files.wordpress.com/2020/10/jbrowse.jpg?w=1024" alt="" /></p>
<p><img src="https://genehub.files.wordpress.com/2020/10/e5ae89e8a385jbrowse.png?w=1024" alt="" /></p>
<p>到这一步是无法从其他客户端访问服务器上的 JBrowse 的，需要在服务器上面安装 Web 服务器。比如 appache/xampp/nginx 等。</p>
<p>xampp案例见：<a href="https://www.jianshu.com/p/1dddec8dc29c">https://www.jianshu.com/p/1dddec8dc29c</a><br />
nginx案例见：<a href="https://yq.aliyun.com/articles/650480">https://yq.aliyun.com/articles/650480</a></p>
<h3 id="3-安装-web-服务器-nginx"><a class="markdownIt-Anchor" href="#3-安装-web-服务器-nginx"></a> 3 安装 Web 服务器 Nginx</h3>
<p>我使用 nginx 做测试的。下载 ngnix 源文件 <a href="http://nginx.org/download/nginx-1.18.0.tar.gz">nginx-1.18.0.tar.gz</a>，root 权限下，解压在 <code>/usr/local/ngnix</code> 下。</p>
<p>运行 <code>./configure &amp;&amp; make &amp;&amp; make install</code> 成功安装nginx（默认web端口是80），然后就可以在客户端浏览器输入服务器地址，看到初始页面：</p>
<p><img src="https://genehub.files.wordpress.com/2020/10/nginx-default-page.jpg?w=834" alt="" /></p>
<p><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201003182915.jpg?w=795" alt="" /></p>
<p>上方的截图所显示的 <em>Welcome to Nginx</em> 初始网页，实际上是由 nginx 安装目录下的 nginx.conf 配置文件控制的，红色标记处，<code>location</code> 字样下的 <code>index.html</code> 是指默认的 <code>/usr/local/nginx/html/index.html</code>。</p>
<p>nginx安装参考：<a href="https://blog.csdn.net/t8116189520/article/details/81909574">https://blog.csdn.net/t8116189520/article/details/81909574</a> （实测：修改nginx.conf里面端口号之后暂时无法访问。需要linux系开放相应的端口。见下文。）</p>
<p>下面是启动与关闭 nginx 的操作。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 停止运行 nginx </span><br><span class="line">/usr/local/nginx/sbin/nginx -s stop  </span><br><span class="line"></span><br><span class="line"># 重启（reload）如果报错，就要先输入下面的命令`</span><br><span class="line">/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf  </span><br><span class="line"></span><br><span class="line"># 重启 nginx</span><br><span class="line">/usr/local/nginx/sbin/nginx -s reload</span><br></pre></td></tr></table></figure>
<h3 id="4-设置-nginx使-jbrowse-可以在-web-浏览器访问"><a class="markdownIt-Anchor" href="#4-设置-nginx使-jbrowse-可以在-web-浏览器访问"></a> 4 设置 nginx，使 Jbrowse 可以在 Web 浏览器访问</h3>
<p>那么如何将 Jbrowse 相关文档经过 Nginx 平台呈现在客户端的web界面？需要修改 nginx的配置文件：<code>/usr/local/nginx/conf/nginx.conf</code>，root权限下vim这个配置文件，在 http 内容里面加入下面的文字。端口号可以自己设置，比如8080、8082等。location指向<code>/var/www/html/jbrowse/index.html</code></p>
<p>查询资料的过程中发现其他人安装nginx之后有这两个目录 <code>/etc/nginx/sites-available/</code> 和 <code>/etc/nginx/sites-enabled</code>，我安装之后是没有的，后面发现并没有影响。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen     8000;</span><br><span class="line">    server\_name  192.168.1.108;</span><br><span class="line">    location / &#123;</span><br><span class="line">        root   /var/www/html/jbrowse;</span><br><span class="line">        index  index.html;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201003183445.jpg" alt="" /></p>
<p><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201003183654.jpg" alt="" /></p>
<p>按照上图修改并保存，重启 nginx 理论上可以在客户端打开 192.168.1.108:8000 即可看到 jbrowse，可是我遇到了打不开的问题。原来不仅需要在 nginx 里面设置端口，还需要linux系开放相应的端口：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">iptables -A INPUT -ptcp --dport 8000 -j ACCEPT</span><br></pre></td></tr></table></figure>
<p>然后就顺利打开了 Jbrowse 浏览器，可以看到欢迎页面。</p>
<p><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201003184126.jpg?w=852" alt="" /></p>
<p>访问 <a href="http://192.168.1.108/index.html?data=sample_data/json/volvox">http://192.168.1.108/index.html?data=sample_data/json/volvox</a> 可以看到示例页面：</p>
<p><img src="http://blog.biochen.com/wp-content/uploads/2016/06/JBrowse_1.png" alt="" /></p>
<h3 id="5-如何配置自己的基因组"><a class="markdownIt-Anchor" href="#5-如何配置自己的基因组"></a> 5 如何配置自己的基因组</h3>
<p>基因组浏览器一般展示如下文件</p>
<ol>
<li>reference genome sequence (.fasta)</li>
<li>gene/mRNA/ncRNA annotation file (.gff3)</li>
<li>ChIP Peak file (.bed)</li>
<li>RNA expression file (?)</li>
</ol>
<p>下图所示，JBrowse 浏览器窗口左侧是一个目录，即 Available Tracks，下面通常包括 Reference、Annotation、RNA expression、Histone PTM等栏目，是需要逐个配置的。控制这些“栏目”的配置文件是<code>/var/www/html/jbrowse/data/trackList.json</code>。</p>
<p><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201003184221.jpg?w=1024" alt="" /></p>
<p><strong>载入参考基因组</strong></p>
<p>我们需要准备一个物种的基因组 fasta 文件，在其他应用场景下 RNA 和 protein 都没有问题。通过 <code>prepare-refseqs.pl</code> 格式化生成的track，这为后续所有添加的文件提供一个坐标系，在网页端参考序列就可以被加载浏览，放大后连碱基序列可以显示出来。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># jbrowse家目录：/var/www/html/jbrowse</span><br><span class="line"># 以下操作在jbrowse家目录，序列文件根据实际情况修改</span><br><span class="line">./bin/prepare-refseqs.pl --fasta ~/database/Glycine_max/Gmax_275_Wm82_a2.v1/Gmax_275_v2.0.softmasked.fa</span><br><span class="line"># ./bin/prepare-refseqs.pl --fasta ~/lyrata/Sequence/Alyrata_384_v1.fa</span><br></pre></td></tr></table></figure>
<p>这就会在当前目录（/var/www/html/jbrowse）生成一个 data 文件夹，直接访问IP地址所看到的序列就来源于该文件夹。</p>
<p><strong>载入基因注释信息</strong></p>
<p>特征序列一般以&quot;gff|gbk|bed&quot;格式存放，用于注明序列的信息。所需工具为 <a href="http://flatfile-to-json.pl">flatfile-to-json.pl</a>，注意 <code>--trackLabel</code> 参数可以设置 Tracks。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./bin/flatfile-to-json.pl --gff /home/fenglei/database/Glycine_max/Gmax_275_Wm82_a2.v1/Gmax_275_Wm82.a2.v1.gene.gff3 --trackLabel &#x27;Gene_a2.v1&#x27;</span><br><span class="line"># ./bin/flatfile-to-json.pl --gff ~/Athalina/TAIR10/TAIR10_GFF3_genes.gtf --tracklabel gene --out ./Athaliana/   </span><br><span class="line"># 结果是在当前目录下生成data，data里包括序列track配置文件. 同样可以用--out参数输出到指定文件夹。</span><br></pre></td></tr></table></figure>
<p>注意，基因组浏览器有一个搜索框，在完成上述操作之后可以浏览基因组和基因信息，也可以输入 <code>Chr02:123-456</code> 这样的坐标查看我们感兴趣的区域，但是还不能使用搜索功能。需要在上两步的基础上运行下面程序才可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./bin/generate-names.pl</span><br></pre></td></tr></table></figure>
<p><strong>载入bed格式数据</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./bin/flatfile-to-json.pl --bed ./ChIP_peaks/CCK9_peaks.xls.bed --trackType CanvasFeatures --trackLabel BED_CCK9_p0.01</span><br><span class="line">./bin/flatfile-to-json.pl --bed ./ChIP_peaks/CSK9_peaks.xls.bed --trackType CanvasFeatures --trackLabel BED_CSK9_p0.01</span><br><span class="line">./bin/flatfile-to-json.pl --bed ./ChIP_peaks/CCK9_peaks.unfilter.bed --trackType CanvasFeatures --trackLabel BED_CCK9_all</span><br><span class="line">./bin/flatfile-to-json.pl --bed ./ChIP_peaks/CSK9_peaks.unfilter.bed --trackType CanvasFeatures --trackLabel BED_CSK9_all</span><br></pre></td></tr></table></figure>
<p><strong>载入bigwig格式的peak信息</strong></p>
<p>直接在data目录下新建一个 histone_BigWig 文件夹，把需要展示的bigwig文件放置在里面。然后编辑 /var/www/html/jbrowse/data/trackList.json 文件，逐个设置。</p>
<p>每一个bigwig文件，都需要增加下面这样的代码块。我针对样品设计和网页端展示效果，做了很多次调整。下面仅仅列出某个文件的配置信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">   &quot;autoscale&quot; : &quot;local&quot;,</span><br><span class="line">   &quot;category&quot; : &quot;Histone&quot;,  # 设定文件所属的 Track</span><br><span class="line">   &quot;key&quot; : &quot;BigWig input control&quot;,</span><br><span class="line">   &quot;label&quot; : &quot;BigWig input control&quot;, # 设定在网页上显示的标签</span><br><span class="line">   &quot;logScaleOption&quot; : true,</span><br><span class="line">   &quot;maxExportSpan&quot; : 500000,</span><br><span class="line">   &quot;max_score&quot; : 6,  # 设定所需展示的最大数值。大于这个阈值的数字就按照该值展示。消除极大值带来的展示问题。</span><br><span class="line">   &quot;metadata&quot; : &#123;&#125;,</span><br><span class="line">   &quot;min_score&quot; : 0,</span><br><span class="line">   &quot;scale&quot; : &quot;log&quot;,  # 设定是否以log形式展示数值。因为测序数据经常有个别极大值，log处理更利于展示</span><br><span class="line">   &quot;storeClass&quot; : &quot;JBrowse/Store/SeqFeature/BigWig&quot;,  # 什么意思？表示这个代码块需要展示的是bigWig格式的文件。</span><br><span class="line">   &quot;style&quot; : &#123;</span><br><span class="line">      &quot;height&quot; : 60,  # 设定展示条带的高度。因为有多个文件要展示，如何设定其高度，将使浏览器打开后的视角比较舒适。</span><br><span class="line">      &quot;neg_color&quot; : &quot;red&quot;,  # 负值的颜色。</span><br><span class="line">      &quot;origin_color&quot; : &quot;#888&quot;,</span><br><span class="line">      &quot;pos_color&quot; : &quot;#DDB6A1&quot;,  # 正数值的颜色。</span><br><span class="line">      &quot;variance_band_color&quot; : &quot;rgba(0,0,0,0.3)&quot;</span><br><span class="line">   &#125;,</span><br><span class="line">   &quot;type&quot; : &quot;JBrowse/View/Track/Wiggle/XYPlot&quot;,</span><br><span class="line">   &quot;urlTemplate&quot; : &quot;histone_BigWig/CCinput.bw&quot;   # 这里指定文件路径。</span><br><span class="line">&#125;,</span><br></pre></td></tr></table></figure>
<p>配置完成之后就类似下面的结果了。</p>
<p><img src="https://ics.hutton.ac.uk/wp-content/uploads/2015/07/jbrowse.png" alt="" /></p>
<p><strong>参考资料</strong><br />
<a href="https://www.plob.org/article/14590.html">JBrowse使用说明：参考基因组格式化</a></p>
<p>-END-</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>基因组序列的共线性分析</title>
    <url>/2017/09/20/Bioinfo-Genome-synteny-analysis/</url>
    <content><![CDATA[<h3 id="1-mummer"><a class="markdownIt-Anchor" href="#1-mummer"></a> 1 MUMMER</h3>
<p>基因组序列直接比较的首选工具。参考资料很多。</p>
<h3 id="2-lastz"><a class="markdownIt-Anchor" href="#2-lastz"></a> 2 LASTZ</h3>
<p><img src="https://genehub.files.wordpress.com/2017/09/13742_2016_141_fig5_html.gif" alt="13742_2016_141_fig5_html" /><br />
Ref：<a href="http://www.bx.psu.edu/miller%5C_lab/dist/README.lastz-1.02.00/README.lastz-1.02.00a.html">http://www.bx.psu.edu/miller\_lab/dist/README.lastz-1.02.00/README.lastz-1.02.00a.html</a><br />
Paper：<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6">https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6</a></p>
<h3 id="3-gepard"><a class="markdownIt-Anchor" href="#3-gepard"></a> 3 Gepard</h3>
<p><img src="https://genehub.files.wordpress.com/2017/09/f4-large.jpg" alt="f4-large" /><br />
Ref：<a href="http://cube.univie.ac.at/gepard">http://cube.univie.ac.at/gepard</a><br />
Paper：<a href="http://www.plantcell.org/content/23/1/27">http://www.plantcell.org/content/23/1/27</a></p>
<h3 id="4-mauve-multiple-alignment-of-conserved-genomic-sequence"><a class="markdownIt-Anchor" href="#4-mauve-multiple-alignment-of-conserved-genomic-sequence"></a> 4 MAUVE ( Multiple Alignment of Conserved Genomic Sequence )</h3>
<p><img src="https://genehub.files.wordpress.com/2017/09/fmicb-02-00236-g001.jpg" alt="fmicb-02-00236-g001" /> Ref：<a href="http://darlinglab.org/mauve/mauve.html">darlinglab.org/mauve/mauve.html</a></p>
<h3 id="5-mcscanx"><a class="markdownIt-Anchor" href="#5-mcscanx"></a> 5 MCscanX</h3>
<p><img src="https://genehub.files.wordpress.com/2017/09/circle.png" alt="circle" /><br />
<img src="https://genehub.files.wordpress.com/2017/09/dual_synteny.png" alt="dual_synteny" /><br />
<img src="https://genehub.files.wordpress.com/2017/09/dot.png" alt="dot" /></p>
<p>MCScanX采用改进了的MCScan算法，分析基因组内或者基因组间的共线性区块。它利用两个物种蛋白质blastp比对结果，再结合这些蛋白质基因在基因组中的位置，得到两个物种基因组的共线性区块。如果是分析基因组内的共线性区块，物种内蛋白质自己比对自己就好了。</p>
<p>Ref：<a href="http://chibba.pgml.uga.edu/mcscan2/examples/example7.php">http://chibba.pgml.uga.edu/mcscan2/examples/example7.php</a></p>
<h3 id="6-c-sibelia"><a class="markdownIt-Anchor" href="#6-c-sibelia"></a> 6 C-Sibelia</h3>
<p>an easy-to-use and highly accurate tool for bacterial genome comparison <img src="https://genehub.files.wordpress.com/2017/09/9c8a61c3-6abf-49a0-8637-fec6d0ed1aa7_figure1.gif" alt="9c8a61c3-6abf-49a0-8637-fec6d0ed1aa7_figure1" /></p>
<p>ref:</p>
<h3 id="7-symap"><a class="markdownIt-Anchor" href="#7-symap"></a> 7 SyMAP</h3>
<p><a href="http://www.symapdb.org/">http://www.symapdb.org/</a></p>
<p><img src="https://genehub.files.wordpress.com/2017/09/alignment2d.png" alt="alignment2d" /></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Hi-C：3d-dna挂载染色体</title>
    <url>/2020/12/15/Bioinfo-HiC-3d-dna-for-chromosome-assembly/</url>
    <content><![CDATA[<p>使用二代数据或三代数据得到contig后，下一步就是将contig提升到染色体水平。有很多策略可以做到这一点，比如说遗传图谱，BioNano, HiC, 参考近源物种。如果利用HiC进行准染色体水平，那么目前常见的组装软件有下面几个。</p>
<ul>
<li>HiRise: 2015年后的GitHub就不再更新</li>
<li>LACHESIS: 发表在NBT，2017年后不再更新</li>
<li>SALSA: 发表在BMC genomics, 仍在更新中</li>
<li>3D-DNA: 发表在science，仍在更新中</li>
<li>ALLHiC: 发表在Nature Plants, 用于解决植物多倍体组装问题</li>
</ul>
<p>对于二倍体物种而言，目前3D-DNA应该是组装效果最好的一个软件。<a href="https://github.com/theaidenlab/3d-dna">3d-dna</a>是一款简单、方便的处理Hi-C软件，可将contig提升到染色体水平。3D-DNA流程简介:</p>
<ul>
<li>将Hi-C数据比对到draft.genome.fa。（利用Juicer分析Hi-C数据）</li>
<li>利用自动化流程进行纠错（misjoin），排序（order），确定正确方向（orient），最后scaffolding，得到染色体水平的组装结果（3D-DNA分析）</li>
<li>Juicebox 进行人工纠错</li>
</ul>
<h3 id="一-分析软件安装"><a class="markdownIt-Anchor" href="#一-分析软件安装"></a> 一、分析软件安装</h3>
<p>依赖的软件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LastZ (version 1.03.73 released 20150708) – for diploid mode only</span><br><span class="line">Java version &gt;=1.8</span><br><span class="line">Bash &gt;=4</span><br><span class="line">GNU Awk &gt;=4.0.2</span><br><span class="line">GNU coreutils sort &gt;=8.11</span><br><span class="line">Python &gt;=2.7 - for chromosome number-aware splitter module only</span><br><span class="line">scipy numpy matplotlib - for chromosome number-aware splitter module only</span><br><span class="line">GUN Parallel &gt;=20150322 (可选，建议装)</span><br><span class="line">bwa</span><br></pre></td></tr></table></figure>
<p>安装Juicer</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/theaidenlab/juicer.git</span><br><span class="line">cd juicer</span><br><span class="line">ln -s CPU scripts</span><br><span class="line">cd scripts/common</span><br><span class="line">wget https://hicfiles.tc4ga.com/public/juicer/juicer_tools.1.9.9_jcuda.0.8.jar</span><br><span class="line"># wget https://s3.amazonaws.com/hicfiles.tc4ga.com/public/juicer/juicer_tools_1.22.01.jar</span><br><span class="line">ln -s juicer_tools.1.9.9_jcuda.0.8.jar  juicer_tools.jar</span><br></pre></td></tr></table></figure>
<p>安装3D-DNA</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/theaidenlab/3d-dna.git</span><br></pre></td></tr></table></figure>
<p>数据准备<br />
<code>ref</code>文件夹： 存放<code>draft.genome.fa</code><br />
<code>fastq</code>文件夹: 存放Hi-C测序双端reads, 注意reads文件名的格式 <code>*_R1.fastq, *_R2.fastq</code>。<br />
否则报错<code>Failed to find any files matching /xxx/fastq/*_R*.fastq*</code>。</p>
<h3 id="二-利用-juicer-分析将hi-c数据比对到contigsscaffolds"><a class="markdownIt-Anchor" href="#二-利用-juicer-分析将hi-c数据比对到contigsscaffolds"></a> 二、利用 Juicer 分析将Hi-C数据比对到contigs/scaffolds</h3>
<ol>
<li>基因组建立索引</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bwa index draft.genome.fa</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>创建可能的酶切位点文件</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python ~/software/juicer/misc/generate_site_positions.py  MboI  draft.genome  draft.genome.fa</span><br><span class="line">\# 如果使用的是 HindIII 进行酶切，就设定为HindIII；这里我设定为MboI</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>获取每条contig的长度</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">awk &#x27;BEGIN&#123;OFS=&quot;\t&quot;&#125;&#123;print $1, $NF&#125;&#x27; draft.genome_MboI.txt &gt; draft.genome.chrom.sizes</span><br></pre></td></tr></table></figure>
<p>设置当前工作目录的文件结构如下，目录存在fastq和ref文件夹。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ref</span><br><span class="line">├── draft.genome.chrom.sizes</span><br><span class="line">├── draft.genome.fa -&gt; ../draft.genome.fa</span><br><span class="line">├── draft.genome.fa.amb</span><br><span class="line">├── draft.genome.fa.ann</span><br><span class="line">├── draft.genome.fa.bwt</span><br><span class="line">├── draft.genome.fa.pac</span><br><span class="line">├── draft.genome.fa.sa</span><br><span class="line">├── draft.genome_MboI.txt</span><br><span class="line">└── opt.sh</span><br><span class="line">fastq</span><br><span class="line">├── XXX_R1.fastq.gz -&gt; /PATH/TO/XXX_R1.fastq.gz</span><br><span class="line">└── XXX_R2.fastq.gz -&gt; /PATH/TO/XXX_R2.fastq.gz</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>运行juicer<br />
注意：必须在当前目录存在fastq和ref文件夹， -z,-p,-y,-D是必须参数</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/software/juicer/scripts/juicer.sh -g draft_genome -s HindIII -z ./ref/draft.genome.fa -y ./ref/draft.genome_HindIII.txt -p ./ref/draft.genome.chrom.sizes -D /PATH/TO/juicer -t 8</span><br><span class="line"></span><br><span class="line">\## juicer 参数</span><br><span class="line">-g： 定义一个物种名</span><br><span class="line">-s：酶切类型, HindIII(AAGCTAGCTT), MboI(GATCGATC) , DpnII(GATCGATC), NcoI(CCATGCATGG)</span><br><span class="line">-z : 参考基因组文件</span><br><span class="line">-y: 限制性酶切位点可能出现位置文件</span><br><span class="line">-p: 染色体大小文件</span><br><span class="line">-C: 将原来的文件进行拆分，必须是4的倍数，默认是90000000, 即22.5M reads</span><br><span class="line">-S: 和任务重运行有关，从中途的某一步开始,&quot;merge&quot;, &quot;dedup&quot;, &quot;final&quot;, &quot;postproc&quot; 或 &quot;early&quot;</span><br><span class="line">-d: juicer的目录</span><br><span class="line">-D: juicer scripts的目录</span><br><span class="line">-t: 线程数</span><br></pre></td></tr></table></figure>
<p>运行记录。（5G Hi-C数据 + 900 Mb contigs 耗时6 h。）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Using ./ref/draft.genome_MboI.txt as site file</span><br><span class="line">(-: Looking for fastq files...fastq files exist</span><br><span class="line">(-: Aligning files matching /PATH/TO/WORK/DIRECTORY/fastq/\*_R\*.fastq*</span><br><span class="line"> to genome draft_genome with site file ./ref/draft.genome_MboI.txt</span><br><span class="line">(-: Created /PATH/TO/WORK/DIRECTORY/splits and /PATH/TO/WORK/DIRECTORY/aligned.</span><br><span class="line">(...  ...)</span><br><span class="line">(-: Postprocessing successfully completed, maps too sparse to annotate or GPUs unavailable (-:</span><br><span class="line">(-: Pipeline successfully completed (-:</span><br><span class="line">Run cleanup.sh to remove the splits directory</span><br><span class="line">Check /PATH/TO/WORK/DIRECTORY/aligned for results</span><br></pre></td></tr></table></figure>
<p>结果：结果文件在aligned目录下，其中“<code>merged_nodups.txt</code>”就是下一步3D-DNA的输入文件之一。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">splits/</span><br><span class="line">├── MySample.fastq.gz_abnorm.sam</span><br><span class="line">├── MySample.fastq.gz_linecount.txt</span><br><span class="line">├── MySample.fastq.gz_norm.txt.res.txt</span><br><span class="line">├── MySample.fastq.gz.sam</span><br><span class="line">├── MySample.fastq.gz.sort.txt</span><br><span class="line">├── MySample.fastq.gz_unmapped.sam</span><br><span class="line">├── MySample_R1.fastq.gz -&gt; /PATH/TO/WORK/DIRECTORY/fastq/MySample_R1.fastq.gz</span><br><span class="line">└── MySample_R2.fastq.gz -&gt; /PATH/TO/WORK/DIRECTORY/fastq/MySample_R2.fastq.gz</span><br><span class="line">aligned/</span><br><span class="line">├── abnormal.sam</span><br><span class="line">├── collisions_nodups.txt</span><br><span class="line">├── collisions.txt</span><br><span class="line">├── dups.txt</span><br><span class="line">├── header</span><br><span class="line">├── inter_30_contact_domains</span><br><span class="line">├── inter_30.hic</span><br><span class="line">├── inter_30_hists.m</span><br><span class="line">├── inter_30.txt</span><br><span class="line">├── inter.hic</span><br><span class="line">├── inter_hists.m</span><br><span class="line">├── inter.txt</span><br><span class="line">├── merged_nodups.txt</span><br><span class="line">├── merged_sort.txt</span><br><span class="line">├── opt_dups.txt</span><br><span class="line">└── unmapped.sam</span><br></pre></td></tr></table></figure>
<p>Note: 测试的过程中遇到报错信息，原来是默认的“/opt/juicer/scripts/”需要根据实际安装路径，通过设定<code>-D</code>参数修改之。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(-:  Align of /PATH/TO/WORK/DIRECTORY/splits/XXX.fastq.gz.sam done successfully</span><br><span class="line">awk: fatal: can&#x27;t open source file `/opt/juicer/scripts/common/chimeric_blacklist.awk&#x27; for reading (No such file or directory)</span><br><span class="line">***! Failure during chimera handling of /PATH/TO/WORK/DIRECTORY/splits/MySample.fastq.gz</span><br></pre></td></tr></table></figure>
<p>原来是<code>-D</code>参数指定juicer目录（包含script文件夹那个路径），<code>vi juicer.sh</code> 可见到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">75 # Juicer directory, contains scripts/, references/, and restriction_sites/</span><br><span class="line">76 # can also be set in options via -D</span><br><span class="line">77 juiceDir=&quot;/opt/juicer&quot;</span><br></pre></td></tr></table></figure>
<h3 id="三-运行3d-dna对contigscaffolds进行组装"><a class="markdownIt-Anchor" href="#三-运行3d-dna对contigscaffolds进行组装"></a> 三、运行3D-DNA，对contig/scaffolds进行组装</h3>
<p>使用默认参数进行3D-DNA</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/software/3d-dna/run-asm-pipeline.sh ./ref/draft.genome.fa ./aligned/merged_nodups.txt</span><br><span class="line"># 通过-i参数设定允许挂载的最小尺寸</span><br><span class="line">~/software/3d-dna/run-asm-pipeline.sh -i 8000 ./ref/draft.genome.fa ./aligned/merged_nodups.txt</span><br></pre></td></tr></table></figure>
<p>最后输出文件中，包含 final 字样的文件就是我们需要的结果：<code>draft.genome.final.hic</code> 和 <code>draft.genome.final.assembly</code>。将这两个文件从服务器下载到客户端（我是win 10），并导入 JuiceBox 浏览器。</p>
<p>注意，生成的文件中，draft.genome.final.assembly 与 draft.genome.FINAL.assembly 是不同的文件。“FINAL” – chromosome-length scaffolds; “final” – input with all the misjoin correction introduced。<br />
这两个文件： draft.genome.final.hic 和 draft.genome.final.assembly，同时导入 JuiceBox 才可以进行人工手动矫正。我最初错误地导入了 draft.genome.FINAL.assembly 文件，就遇到了问题。</p>
<h3 id="四-juicebox进行手动纠错"><a class="markdownIt-Anchor" href="#四-juicebox进行手动纠错"></a> 四、JuiceBox进行手动纠错</h3>
<p>不少人将软件名写成juicerbox，其实正确写法是juicebox。下载该软件：<a href="https://github.com/aidenlab/Juicebox/wiki/Download">https://github.com/aidenlab/Juicebox/wiki/Download</a>。直接下载exe可执行程序，不用安装，双击即可进入界面。</p>
<p><img src="https://oscimg.oschina.net/oscnet/d8e47314-9ca7-409e-9293-614ba5f561b3.png" alt="juicebox" /></p>
<p>一般组装错误为：misjoin、translocations、inversions 和 chromosome boundaries。<br />
关于该软件用法，可看视频：油管地址 <a href="https://www.youtube.com/watch?v=Nj7RhQZHM18">Tutorial video for Juicebox Assembly Tools</a> 或 <a href="https://www.bilibili.com/video/av65134634">B 站</a></p>
<p>通过<code>File</code>-&gt;<code>open</code>可以导入后缀为.hic的文件<code>draft.genome.final.hic</code>，随后<code>Assembly</code>-&gt;<code>select</code>，选择<code>draft.genome.final.assembly</code>文件，这时候能看到“染色体”组装图（还不是完美的染色体，只是初步的scaffolds排序，但是我的数据里可看到9条染色体雏形，此外还有一部分没有定位到染色体上的contigs/scaffolds，但是从heatmap中可以看到他们中的大部分与某条染色体会有互作）。</p>
<p>怎么手动调整？左上角到右下角这一条线作为对角线，在对角线任选取两个点，就可以形成一个正方形，两点之间的线段就是“染色体”的一段。如果需要移动某个方形区域，按住shift键不动，在需要挪动的染色体区域左上角点击一次，即可看到一个黑色十字固定在此处，随后在右下角再单击一次，再次出现一个黑色十字，松开shift键，两个黑色十字即包围了这一段待调整的染色体，可以适当调整黑框大小。此时将鼠标移到另一个染色体位置，可见到鼠标白色图标变成黑色箭头，单击，上述的黑色框便移动到了这里，完成了移动选取的操作。如果需要对选择进行翻转呢？则只需要将鼠标移动到黑色框的右上角区域，这时候鼠标图标会变成黑色环状，单击，即可使之翻转。</p>
<p>纠错完以后，单击上方功能区<code>Assembly</code>-&gt;<code>Export Assembly</code>，导出<code>draft.genome.final.review.assembly</code>，或命名为<code>genome.review.assembly</code>，用于下一步的分析</p>
<h3 id="五-再次运行3d-dna"><a class="markdownIt-Anchor" href="#五-再次运行3d-dna"></a> 五、再次运行3D-DNA</h3>
<p>Generate a fasta sequence after JBAT review. In addition to the chromosome-length genome sequence (<em>.FINAL.fasta</em>), the pipeline will produce a new <em>.final.hic</em> file for concluding quality control.</p>
<p>会重新生成 draft.genome.rawchrom.* 和 draft.genome.final.* 这些文件，覆盖掉原来的文件。如果要避免覆盖。就需要另起一个目录运行程序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/software/3d-dna/run-asm-pipeline-post-review.sh -r genome.review.assembly ./ref/draft.genome.fa aligned/merged_nodups.txt</span><br></pre></td></tr></table></figure>
<p>结果文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">draft.genome.FINAL.fasta</span><br><span class="line">draft.genome.FINAL.hic</span><br><span class="line">draft.genome.FINAL_asm.superscaf_track.txt</span><br><span class="line">draft.genome.FINAL_asm.scaffold_track.txt</span><br><span class="line">draft.genome.FINAL.assembly</span><br><span class="line">draft.genome.rawchrom.fasta</span><br><span class="line">draft.genome.rawchrom.hic</span><br><span class="line">draft.genome.final_asm.superscaf_track.txt</span><br><span class="line">draft.genome.final_asm.scaffold_track.txt</span><br><span class="line">draft.genome.final.asm</span><br><span class="line">draft.genome.mnd.txt</span><br><span class="line">draft.genome.rawchrom.asm</span><br><span class="line">draft.genome.rawchrom.cprops</span><br><span class="line">draft.genome.60G.final.review.assembly</span><br><span class="line">draft.genome.cprops</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>安装HiC-Pro （HiC数据预处理工具）与绘制HiC染色体互作图谱</title>
    <url>/2020/12/06/Bioinfo-HiC-pro-installation/</url>
    <content><![CDATA[<p>HiC-Pro可以用来处理Hi-C数据，从原始的fastq文件(配对端Illumina数据)到标准化的交互图谱。简单的来说就是将Hi-C数据比对到拼装好的参考基因组上，并形成交互文件去存储Hi-C数据。</p>
<p>下载 HiC-Pro VERSION 2.11.4 安装包，依赖 Python 2。（后续更新：HiC-Pro version 3.0.0 要求 Python 3）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/nservant/HiC-Pro.git </span><br></pre></td></tr></table></figure>
<h3 id="安装-hic-pro-version-2114"><a class="markdownIt-Anchor" href="#安装-hic-pro-version-2114"></a> 安装 HiC-Pro VERSION 2.11.4</h3>
<p>由于需要python 2 （2.7以上），我之前已经在系统安装Anaconda3，并在里面分别安装了python3.7和python2.7，(<a href="https://genehub.wordpress.com/2020/04/21/1070/">原文链接</a>, 这里只需要切换到python2.7环境即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source activate python27</span><br></pre></td></tr></table></figure>
<p>再直接用conda命令安装相关软件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install -y samtools bowtie2 R </span><br><span class="line">conda install -y pysam bx-python numpy scipy </span><br><span class="line">#打开R </span><br><span class="line">install.packages(c(&#x27;ggplot2&#x27;,&#x27;RColorBrewer&#x27;)) </span><br></pre></td></tr></table></figure>
<p>通过 conda 安装 samtools，samtools 运行会报错。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools: error while loading shared libraries: libcrypto.so.1.0.0: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>
<p>现在samtools的版本已经在1.9以上了，但是conda安装的samtools版本依然是1.7，这是出现问题的原因。<a href="https://blog.csdn.net/zhangjunya/article/details/108235796">解决办法</a>：指定另一个更新的版本，重新安装如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install -c bioconda samtools=1.9 --force-reinstall</span><br></pre></td></tr></table></figure>
<p>或者刚开始安装的时候：<code>conda install samtools=1.9</code>，就不会再出现上述问题。</p>
<p>不知道为什么bx-python安装失败，换成下面的方法，可以安装。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install -c conda-forge -c bioconda bx-python</span><br></pre></td></tr></table></figure>
<p>然后进入HiC-Pro目录，修改config-install 文件，设置依赖软件的路径。PREFIX不要设置当前目录，会被覆盖。CLUSTER_SYS有四个选项，分别是TORQUE, SGE, SLURM 或 LSF，我随便填了一个TORQUE。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#</span><br><span class="line"> Paths and Settings  - Start editing here !</span><br><span class="line"> #</span><br><span class="line"> PREFIX = /home/user/local/scripts/HiC-Pro</span><br><span class="line"> BOWTIE2_PATH = /home/user/local/app/anaconda3/envs/python27/bin/</span><br><span class="line"> SAMTOOLS_PATH = /home/user/local/bin/</span><br><span class="line"> R_PATH = /home/user/local/app/anaconda3/envs/python27/bin</span><br><span class="line"> PYTHON_PATH = /home/user/local/app/anaconda3/envs/python27/bin</span><br><span class="line"> CLUSTER_SYS = TORQUE</span><br></pre></td></tr></table></figure>
<p>接下里 make configure ，通过之后屏幕显示如下信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python27) xxxxx/HiC-Pro$ make configure       </span><br><span class="line"> </span><br><span class="line">make -f ./scripts/install/Makefile CONFIG_SYS=./config-install.txt</span><br><span class="line"> make[1]: Entering directory &#x27;/home/-/local/app/HiC-Pro&#x27;</span><br><span class="line"> ./scripts/install/install_dependencies.sh -c ./config-install.txt -o  /home/-/local/scripts/HiC-Pro/HiC-Pro_2.11.4 -q</span><br><span class="line"> Make sure internet connection works for your shell prompt under current user&#x27;s privilege …</span><br><span class="line"> Starting HiC-Pro installation …</span><br><span class="line"> export /home/--/local/app/anaconda3/envs/python27/bin/ in PATH</span><br><span class="line"> export /home/-/local/bin/ in PATH</span><br><span class="line"> export /home/-/local/app/anaconda3/envs/python27/bin in PATH</span><br><span class="line"> export /home/-/local/app/anaconda3/envs/python27/bin in PATH</span><br><span class="line"> Checking dependencies … </span><br><span class="line"> Checking Python libraries …</span><br><span class="line"> The required Python libraries appear to be already installed. </span><br><span class="line"> Checking R installation …</span><br><span class="line"> The required R packages appear to be already installed. </span><br><span class="line"> Bowtie2 Aligner appears to be already installed. </span><br><span class="line"> Samtools appears to be already installed. </span><br><span class="line"> Dependencies checked !</span><br><span class="line"> Check HiC-Pro configuration … </span><br><span class="line"> Configuration for TORQUE/PBS system.</span><br><span class="line"> make[1]: Leaving directory &#x27;/home/-/local/app/HiC-Pro&#x27;</span><br></pre></td></tr></table></figure>
<p>然后 make，通过即安装成功。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(some information are not shown here due to size limitation)</span><br><span class="line">cp -Ri /home/-/local/app/HiC-Pro /home/-/local/scripts/HiC-Pro/HiC-Pro_2.11.4 </span><br><span class="line">HiC-Pro installed in /home/-/local/scripts/HiC-Pro/HiC-Pro_2.11.4 !</span><br></pre></td></tr></table></figure>
<p>测试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python27) XXX:~/local/scripts/HiC-Pro/HiC-Pro_2.11.4/bin$ ./HiC-Pro -h</span><br><span class="line"> usage : HiC-Pro -i INPUT -o OUTPUT -c CONFIG [-s ANALYSIS_STEP] [-p] [-h] [-v]</span><br><span class="line"> Use option -h--help for more information</span><br><span class="line"> HiC-Pro 2.11.4</span><br><span class="line"> OPTIONS</span><br><span class="line"> -i--input INPUT : input data folder; Must contains a folder per sample with input files</span><br><span class="line">    -o--output OUTPUT : output folder</span><br><span class="line">    -c--conf CONFIG : configuration file for Hi-C processing</span><br><span class="line">    [-p--parallel] : if specified run HiC-Pro on a cluster</span><br><span class="line">    [-s--step ANALYSIS_STEP] : run only a subset of the HiC-Pro workflow; if not specified the complete workflow is run</span><br><span class="line">       mapping: perform reads alignment - require fast files</span><br><span class="line">       proc_hic: perform Hi-C filtering - require BAM files</span><br><span class="line">       quality_checks: run Hi-C quality control plots</span><br><span class="line">       merge_persample: merge multiple inputs and remove duplicates if specified - require .validPairs files</span><br><span class="line">       build_contact_maps: Build raw inter/intrachromosomal contact maps - require .allValidPairs files</span><br><span class="line">       ice_norm : run ICE normalization on contact maps - require .matrix files</span><br></pre></td></tr></table></figure>
<h3 id="optional-安装-hic-pro-version-300"><a class="markdownIt-Anchor" href="#optional-安装-hic-pro-version-300"></a> <s>Optional: 安装 HiC-Pro VERSION 3.0.0</s></h3>
<p><s>conda create --name python38 python=3.8</s><br />
<s>source activate python38</s><br />
<s>conda install conda</s><br />
<s># 前面的conda是anaconda3的conda，后面的conda是python3.8的conda</s></p>
<p><s>conda install -c bioconda bowtie2</s><br />
<s>conda install -c bioconda samtools=1.9</s><br />
<s>conda install -c conda-forge -c bioconda bx-python</s></p>
<p><s>在conda里面安装R和pysam遇到很多问题，更换python版本3.7/3.8/3.9都没成功，真是浪费时间，放弃。</s></p>
<h3 id="使用hic-pro对hic数据进行分析的过程"><a class="markdownIt-Anchor" href="#使用hic-pro对hic数据进行分析的过程"></a> 使用HiC-Pro对HiC数据进行分析的过程</h3>
<p>1. 在工作目录（例如HiC-analysis-workdir），建立若干文件夹，例如index、rawdata，方便管理，当然这些数据也可以在其他位置。</p>
<p>2. 在index路径下，对参考基因组或者scaffolds建立index。HiC-Pro调用的比对软件是bowtie2。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bowtie2-build --threads 20 ref.fasta ref.fasta</span><br></pre></td></tr></table></figure>
<p>3. 在工作目录，建立一个文本文件，内含参考基因组（或scaffolds）各个染色体名称和长度的信息。可以用samtools fadix，也可以用iTools或R语言等工具。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cat chromosome_size.txt</span><br><span class="line"> Chr01   11111</span><br><span class="line"> Chr02   1233333</span><br><span class="line"> Chr03   4444</span><br><span class="line"> Chr04   105314844</span><br><span class="line">(continue ...)</span><br></pre></td></tr></table></figure>
<p>4. 在工作目录，新建一个文件夹（例如rawdata），用来存放作为input的测序数据。注意不能直接将测序文件放到rawdata目录下，而是要按照样品名先建立子文件夹（例如sample1、sample2）。sample1目录下即存放样品的测序文件，包含F/R两个测序文件，文件应该是.fastq(.gz)的命名，不可写成fq(.gz)；可以是软链接的形式。</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207122951.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207122951.png?w=506" alt="" /></a></p>
<p>4. 基因组的酶切位点识别。我用的MboI（酶切位点：^GATC）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python2.7 XXX/HiC-Pro/HiC-Pro_2.11.4/bin/utils/digest_genome.py -r ^GATC -o mboi_resfrag_genome.bed Ref_genome.fa</span><br></pre></td></tr></table></figure>
<p>得到的酶切信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> Chr01   0       3282    HIC_Chr01_1     0       +</span><br><span class="line"> Chr01   3282    3609    HIC_Chr01_2     0       +</span><br><span class="line"> Chr01   3609    3625    HIC_Chr01_3     0       +</span><br><span class="line"> Chr01   3625    4485    HIC_Chr01_4     0       +</span><br><span class="line"> Chr01   4485    5312    HIC_Chr01_5     0       +</span><br><span class="line"> Chr01   5312    5327    HIC_Chr01_6     0       +</span><br><span class="line"> Chr01   5327    5958    HIC_Chr01_7     0       +</span><br><span class="line"> Chr01   5958    6475    HIC_Chr01_8     0       +</span><br><span class="line"> Chr01   6475    7545    HIC_Chr01_9     0       +</span><br><span class="line">(continue ...)</span><br></pre></td></tr></table></figure>
<p>5. 将HiC-Pro程序安装包目录下的 config-hicpro.txt 文件拷贝到工作目录，对其进行编辑。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># N_CPU，例如N_CPU = 24</span><br><span class="line"># JOB_NAME，例如JOB_NAME = Ga</span><br><span class="line"># JOB_WALLTIME，例如JOB_WALLTIME = 11:00:00</span><br><span class="line"># JOB_QUEUE，例如JOB_QUEUE = normal</span><br><span class="line"># JOB_MAIL，例如JOB_MAIL = 1570447120@qq.com</span><br><span class="line"># BOWTIE2_IDX_PATH，填写用bowtie2对reference建立索引的目录，注意是目录，而不是索引路径!如/PATH/to/Ga.ref</span><br><span class="line"># REFERENCE_GENOME，例如Ga 注意：这里REFERENCE_GENOME一定要和bowtie2建立的索引对应上,名字为物种名</span><br><span class="line"># GENOME_SIZE，即生成的文件Ga.fasta.size（最好使用绝对路径）</span><br><span class="line"># GENOME_FRAGMENT，用digest_genome.py程序生成的文件Ga.HindIII.txt</span><br><span class="line"># LIGATION_SITE，酶的序列，例如HindIII，则为AAGCTAGCTT；如果是MboI则序列为GATCGATC。</span><br><span class="line"># MIN_FRAG_SIZE，例如MIN_FRAG_SIZE = 100</span><br><span class="line"># MAX_FRAG_SIZE，例如MAX_FRAG_SIZE = 160000</span><br><span class="line"># MIN_INSERT_SIZE，例如MIN_INSERT_SIZE = 200</span><br><span class="line"># MAX_INSERT_SIZE，例如MAX_INSERT_SIZE = 600</span><br><span class="line"># GET_PROCESS_SAM，例如GET_PROCESS_SAM = 1</span><br></pre></td></tr></table></figure>
<p>6. 运行</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/PATH/TO/HiC-Pro_2.11.1/bin/HiC-Pro -i /PATH/TO/rawdata --output hicpro_output --conf config-hicpro.txt </span><br><span class="line"># --input reads所在的文件</span><br><span class="line"># --output 输出的文件夹</span><br><span class="line"># --conf 配置文件</span><br></pre></td></tr></table></figure>
<p>7. 运行结果</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">.</span><br><span class="line">├── bowtie_results</span><br><span class="line">│   ├── bwt2</span><br><span class="line">│   │   └── sample1</span><br><span class="line">│   │       ├── mysample_R1_V3_20201206.fa.bwt2merged.bam</span><br><span class="line">│   │       ├── mysample_R1_V3_20201206.fa.mapstat</span><br><span class="line">│   │       ├── mysample_R2_V3_20201206.fa.bwt2merged.bam</span><br><span class="line">│   │       ├── mysample_R2_V3_20201206.fa.mapstat</span><br><span class="line">│   │       ├── _V3_20201206.fa.bwt2pairs.bam</span><br><span class="line">│   │       └── _V3_20201206.fa.bwt2pairs.pairstat</span><br><span class="line">│   ├── bwt2_global</span><br><span class="line">│   │   └── sample1</span><br><span class="line">│   │       ├── mysample_R1_V3_20201206.fa.bwt2glob.bam</span><br><span class="line">│   │       ├── mysample_R1_V3_20201206.fa.bwt2glob.unmap.fastq</span><br><span class="line">│   │       ├── mysample_R2_V3_20201206.fa.bwt2glob.bam</span><br><span class="line">│   │       └── mysample_R2_V3_20201206.fa.bwt2glob.unmap.fastq</span><br><span class="line">│   └── bwt2_local</span><br><span class="line">│       └── sample1</span><br><span class="line">│           ├── mysample_R1_V3_20201206.fa.bwt2glob.unmap_bwt2loc.bam</span><br><span class="line">│           ├── mysample_R1_V3_20201206.fa.bwt2glob.unmap_trimmed.fastq</span><br><span class="line">│           ├── mysample_R2_V3_20201206.fa.bwt2glob.unmap_bwt2loc.bam</span><br><span class="line">│           └── mysample_R2_V3_20201206.fa.bwt2glob.unmap_trimmed.fastq</span><br><span class="line">├── config-hicpro.txt</span><br><span class="line">├── hic_results</span><br><span class="line">│   ├── data</span><br><span class="line">│   │   └── sample1</span><br><span class="line">│   │       ├── sample1.allValidPairs</span><br><span class="line">│   │       ├── _V3_20201206.fa.bwt2pairs.DEPairs</span><br><span class="line">│   │       ├── _V3_20201206.fa.bwt2pairs.DumpPairs</span><br><span class="line">│   │       ├── _V3_20201206.fa.bwt2pairs.FiltPairs</span><br><span class="line">│   │       ├── _V3_20201206.fa.bwt2pairs.REPairs</span><br><span class="line">│   │       ├── _V3_20201206.fa.bwt2pairs.RSstat</span><br><span class="line">│   │       ├── _V3_20201206.fa.bwt2pairs.SCPairs</span><br><span class="line">│   │       ├── _V3_20201206.fa.bwt2pairs.SinglePairs</span><br><span class="line">│   │       └── _V3_20201206.fa.bwt2pairs.validPairs</span><br><span class="line">│   ├── matrix</span><br><span class="line">│   │   └── sample1</span><br><span class="line">│   │       ├── iced</span><br><span class="line">│   │       │   └── 200000</span><br><span class="line">│   │       │       ├── sample1_200000_iced.matrix</span><br><span class="line">│   │       │       └── sample1_200000_iced.matrix.biases</span><br><span class="line">│   │       └── raw</span><br><span class="line">│   │           └── 200000</span><br><span class="line">│   │               ├── sample1_200000_abs.bed</span><br><span class="line">│   │               └── sample1_200000.matrix</span><br><span class="line">│   ├── pic</span><br><span class="line">│   │   └── sample1</span><br><span class="line">│   │       ├── plotHiCContactRanges_sample1.pdf</span><br><span class="line">│   │       ├── plotHiCFragment_sample1.pdf</span><br><span class="line">│   │       ├── plotHiCFragmentSize_sample1.pdf</span><br><span class="line">│   │       ├── plotMappingPairing_sample1.pdf</span><br><span class="line">│   │       └── plotMapping_sample1.pdf</span><br><span class="line">│   └── stats</span><br><span class="line">│       └── sample1</span><br><span class="line">│           ├── sample1_allValidPairs.mergestat</span><br><span class="line">│           ├── sample1mysample_R1.mmapstat</span><br><span class="line">│           ├── sample1mysample_R2.mmapstat</span><br><span class="line">│           ├── sample1.mpairstat</span><br><span class="line">│           └── sample1.mRSstat</span><br><span class="line">├── logs</span><br><span class="line">│   └── sample1</span><br><span class="line">│       ├── build_raw_maps.log</span><br><span class="line">│       ├── mysample_R1_bowtie2.log</span><br><span class="line">│       ├── mysample_R1_V3_20201206.fa.bwt2glob.unmap_bowtie2.log</span><br><span class="line">│       ├── mysample_R1_V3_20201206.fa.bwt2glob.unmap_readsTrimming.log</span><br><span class="line">│       ├── mysample_R2_bowtie2.log</span><br><span class="line">│       ├── mysample_R2_V3_20201206.fa.bwt2glob.unmap_bowtie2.log</span><br><span class="line">│       ├── mysample_R2_V3_20201206.fa.bwt2glob.unmap_readsTrimming.log</span><br><span class="line">│       ├── ice_200000.log</span><br><span class="line">│       ├── make_Rplots.log</span><br><span class="line">│       ├── mapped_2hic_fragments.log</span><br><span class="line">│       ├── mapping_combine.log</span><br><span class="line">│       ├── mapping_stats.log</span><br><span class="line">│       ├── mapping_step1.log</span><br><span class="line">│       ├── mapping_step2.log</span><br><span class="line">│       ├── mergeSAM.log</span><br><span class="line">│       ├── merge_stats.log</span><br><span class="line">│       ├── merge_valid_interactions.log</span><br><span class="line">│       ├── plot_hic_contacts.Rout</span><br><span class="line">│       ├── plot_hic_fragment.Rout</span><br><span class="line">│       ├── plot_mapping_portion.Rout</span><br><span class="line">│       └── plot_pairing_portion.Rout</span><br><span class="line">├── rawdata -&gt; /PATH/TO//rawdata/</span><br><span class="line">└── tmp</span><br></pre></td></tr></table></figure>
<p><strong>画图</strong></p>
<p>HiC-Pro运行结果中，sample1.allValidPairs文件就表示 pair end reads 在染色体或 scaffolds 上面位置的信息，该文件是文本格式，需要进行格式转化成为.hic文件，才能放到 juicebox 软件中得到可视化的互作图谱。</p>
<p>如何转换成.hic文件？使用HiC-Pro安装路径下的<code>hicpro2juicebox.sh</code>程序按照下面的方式运行即可得到.hic文件。<br />
需要下载 juicer_tools_1.22.01.jar 文件作为输入文件。下载地址：<a href="https://github.com/aidenlab/juicer/wiki/Download">https://github.com/aidenlab/juicer/wiki/Download</a><br />
备注：我一开始下载错了，去<a href="https://github.com/aidenlab/Juicebox/wiki/Download">https://github.com/aidenlab/Juicebox/wiki/Download</a> 页面下了个Juicebox.jar，结果不能用于下面的步骤。原来这是 JuiceBox，不是 Juicer！从论坛发现遇到这个问题的不止我一个人<a href="https://groups.google.com/g/hic-pro/c/DF0zfZOivsE?pli=1">https://groups.google.com/g/hic-pro/c/DF0zfZOivsE?pli=1</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/PATH/TO/HiC-Pro/HiC-Pro_2.11.4/bin/utils/hicpro2juicebox.sh -i /PATH/TO//sample1.allValidPairs -g /PATH/TO//chromosome_sizes -j /PATH/TO/juicer_tools_1.22.01.jar -r /PATH/TO//mboi_resfrag_AMgenome.bed -t temp -o /PATH/TO/output</span><br></pre></td></tr></table></figure>
<p>用上面的命令就得到了 .hic 文件，然后从 Linux 服务器将该文件下载到本地客户端（客户端即我个人电脑用的 windows 系统），直接运行 Juicebox_1.11.08.exe 二进制程序，双击运行，菜单选 open，选择 .hic 文件，就得到下面的图谱，可以 export 成 pdf 或 svg 格式的图片。</p>
<p><img src="https://gblobscdn.gitbook.com/assets%2F-LijQZQE8sc7HbVdoxEA%2F-Lj2gavu4NTsjkOUMYaT%2F-Lj2js_V0JRQoDXKpVvE%2FScreen%20Shot%202019-07-05%20at%2012.51.13%20PM.png?alt=media&amp;token=fdae559d-237e-45dd-a0dd-a12a22ff7506" alt=".hic文件导入juicebox软件之后的示意图" /></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | Installation of BUSCO v4</title>
    <url>/2021/01/08/Bioinfo-Installation-of-BUSCO-v4/</url>
    <content><![CDATA[<h3 id="environment"><a class="markdownIt-Anchor" href="#environment"></a> Environment</h3>
<p>BUSCO is now Python 3.3+ only. I activate python 3.7 in Anaconda 3.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source activate python37</span><br></pre></td></tr></table></figure>
<h3 id="third-party-components"><a class="markdownIt-Anchor" href="#third-party-components"></a> Third-party components</h3>
<p>A full installation of BUSCO requires Python 3.3+ (2.7 is not supported from v4 onwards), BioPython, tBLASTn 2.2+, Augustus 3.2, Prodigal, Metaeuk, HMMER3.1+, SEPP, and R + ggplot2 for the plotting companion script. Some of these tools are necessary only for analysing certain type of organisms and input data, or for specific run modes.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># https://biopython.org/</span><br><span class="line">conda install -c biopython</span><br><span class="line"></span><br><span class="line"># https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST</span><br><span class="line"># WARNING:        You are using BLAST version 2.11.0+. This is known to yield inconsistent results when multithreading. BLAST will run on a single core as a result. </span><br><span class="line"># For performance improvement, please upgrade to BLAST 2.10.1+</span><br><span class="line">cd ~/local/app</span><br><span class="line">wget https://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.11.0+-x64-linux.tar.gz</span><br><span class="line">tar -zxvf ncbi-blast-2.11.0+-x64-linux.tar.gz</span><br><span class="line">mv ncbi-blast-2.11.0+ blast-2.11.0</span><br><span class="line">export PATH=/home/fenglei/local/app/blast-2.11.0/bin:$PATH</span><br><span class="line"></span><br><span class="line"># http://bioinf.uni-greifswald.de/augustus/</span><br><span class="line"># The following NEW packages will be INSTALLED:</span><br><span class="line"># augustus    bioconda/linux-64::augustus-3.2.2-0</span><br><span class="line"># conda install -c bioconda augustus   # ERROR when running it</span><br><span class="line">git clone https://github.com/Gaius-Augustus/Augustus</span><br><span class="line">sudo yum install boost-devel          # libboost-all-dev</span><br><span class="line">sudo yum install -y zlib zlib-devel   # zlib1g-dev</span><br><span class="line">sudo yum install gsl-devel            # libgsl-dev</span><br><span class="line">sudo yum install suitesparse-devel    # libsuitesparse-dev</span><br><span class="line">sudo yum install lpsolve              # liblpsolve55-dev</span><br><span class="line">sudo yum install sqlite-devel         # sqlite-devel - Development tools for the sqlite3 embeddable SQL database engine</span><br><span class="line"># sudo yum whatprovides libmysqlclient*</span><br><span class="line"># sudo yum install mariadb-libs-5.5.56-2.el7.i686</span><br><span class="line"></span><br><span class="line"># https://github.com/soedinglab/metaeuk</span><br><span class="line"># conda install -c bioconda Metaeuk # ERROR -- Package openssl conflicts</span><br><span class="line"># git clone git@github.com:soedinglab/metaeuk.git</span><br><span class="line"># downloading a statically compiled version:</span><br><span class="line">wget https://mmseqs.com/metaeuk/metaeuk-linux-sse41.tar.gz</span><br><span class="line">tar -zxvf metaeuk-linux-sse41.tar.gz</span><br><span class="line">export PATH=/home/fenglei/local/app/metaeuk/bin:$PATH</span><br><span class="line"></span><br><span class="line"># https://github.com/hyattpd/Prodigal</span><br><span class="line"># The following NEW packages will be INSTALLED:</span><br><span class="line"># prodigal    bioconda/linux-64::prodigal-2.6.3-h516909a_2</span><br><span class="line">conda install -c bioconda Prodigal</span><br><span class="line"></span><br><span class="line"># http://hmmer.org/</span><br><span class="line"># The following NEW packages will be INSTALLED:</span><br><span class="line"># hmmer    bioconda/linux-64::hmmer-3.3.1-he1b5a44_0</span><br><span class="line"># conda install -c bioconda hmmer  # X</span><br><span class="line">wget http://eddylab.org/software/hmmer/hmmer.tar.gz</span><br><span class="line">tar -zxvf hmmer.tar.gz</span><br><span class="line">cd hmmer-3.3.2</span><br><span class="line">./configure --prefix=/home/fenglei/local</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line"># https://github.com/smirarab/sepp/</span><br><span class="line"># Successfully installed sepp-0.9.0</span><br><span class="line"># git clone git@github.com:smirarab/sepp.git</span><br><span class="line"># cd sepp</span><br><span class="line"># python setup.py  install</span><br><span class="line"># Error was reported when running setup.py</span><br><span class="line">conda install -c bioconda sepp</span><br><span class="line"># sepp  bioconda/linux-64::sepp-4.3.10-py37hef7ab6a_2</span><br><span class="line"></span><br><span class="line">#https://www.r-project.org/</span><br><span class="line"># R version 3.5.1 (2018-07-02) -- &quot;Feather Spray&quot;</span><br><span class="line">conda install R</span><br></pre></td></tr></table></figure>
<p><strong>samtools, bcftools, htslib</strong><br />
Download below files from <a href="http://www.htslib.org/download/">http://www.htslib.org/download/</a>: <a href="https://github.com/samtools/samtools/releases/download/1.11/samtools-1.11.tar.bz2">samtools-1.11.tar.bz2</a>; <a href="https://github.com/samtools/bcftools/releases/download/1.11/bcftools-1.11.tar.bz2">bcftools-1.11.tar.bz2</a>; <a href="https://github.com/samtools/htslib/releases/download/1.11/htslib-1.11.tar.bz2">htslib-1.10.2.tar.bz2</a></p>
<p><strong>cmake 3.19.2</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://github.com/Kitware/CMake/releases/download/v3.19.2/cmake-3.19.2.tar.gz</span><br><span class="line">tar -zxvf cmake-3.19.2.tar.gz</span><br><span class="line">cd cmake-3.19.2</span><br><span class="line">sudo yum install gcc g++</span><br><span class="line">./bootstrap --prefix=/home/fenglei/local</span><br><span class="line">gmake &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<p><strong>bamtools</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone git://github.com/pezmaster31/bamtools.git</span><br><span class="line">mkdir build ； cd build</span><br><span class="line">cmake -DCMAKE_INSTALL_PREFIX=/your/path/to/bamtools ..</span><br><span class="line">#cmake ..</span><br><span class="line">make</span><br><span class="line">sudo make  install</span><br></pre></td></tr></table></figure>
<p><strong>augustus 3.3.1</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget http://bioinf.uni-greifswald.de/augustus/binaries/old/augustus-3.3.1.tar.gz</span><br><span class="line">tar -zxvf augustus-3.3.1.tar.gz</span><br><span class="line">cd augustus-3.3.1</span><br><span class="line"># edit some make files as below</span><br></pre></td></tr></table></figure>
<p>Edit make files of <a href="https://iamphioxus.org/2017/05/08/installing-augustus-with-manual-bamtools-installation/">bam2hints, and filterBam.</a> Download binary <a href="https://github.com/MikeAxtell/bam2wig">bam2wig</a> to replace source file of bam2wig. Then we can run <code>make</code> for Augustus. Augustus requires environment variables to be declared as follows:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PATH=&quot;/path/to/AUGUSTUS/augustus-3.2.3/bin:$PATH&quot;</span><br><span class="line">export PATH=&quot;/path/to/AUGUSTUS/augustus-3.2.3/scripts:$PATH&quot;</span><br><span class="line">export AUGUSTUS_CONFIG_PATH=&quot;/path/to/AUGUSTUS/augustus-3.2.3/config/&quot;</span><br></pre></td></tr></table></figure>
<h3 id="edit-config-file-of-busco"><a class="markdownIt-Anchor" href="#edit-config-file-of-busco"></a> Edit config file of BUSCO</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://gitlab.com/ezlab/busco.git</span><br><span class="line">cd busco/</span><br><span class="line">#Note: v4.1.4 is the latest stable release. To access v5.beta clone this repository and checkout the v5 branch with git checkout v5.beta</span><br><span class="line">sudo python3 setup.py</span><br><span class="line"># or</span><br><span class="line">python3 setup.py install --user</span><br><span class="line"># or: If you are running BUSCO in a Python virtual environment, the following should suffice:</span><br><span class="line">python3 setup.py install</span><br></pre></td></tr></table></figure>
<p>Edit <code>config.ini</code> as below.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># some words were not shown here due to space limitation</span><br><span class="line"></span><br><span class="line">[tblastn]</span><br><span class="line">path = /home/fenglei/local/app/blast-2.10.1/bin</span><br><span class="line">command = tblastn</span><br><span class="line"></span><br><span class="line">[makeblastdb]</span><br><span class="line">path = /home/fenglei/local/app/blast-2.10.1/bin</span><br><span class="line">command = makeblastdb</span><br><span class="line"></span><br><span class="line">[augustus]</span><br><span class="line">path = /home/fenglei/local/app/augustus-3.3.1/bin</span><br><span class="line">command = augustus</span><br><span class="line"></span><br><span class="line">[etraining]</span><br><span class="line">path = /home/fenglei/local/app/augustus-3.3.1/bin</span><br><span class="line">command = etraining</span><br><span class="line"></span><br><span class="line">[gff2gbSmallDNA.pl]</span><br><span class="line">path = /home/fenglei/local/app/augustus-3.3.1/scripts</span><br><span class="line">command = gff2gbSmallDNA.pl</span><br><span class="line"></span><br><span class="line">[new_species.pl]</span><br><span class="line">path = /home/fenglei/local/app/augustus-3.3.1/scripts</span><br><span class="line">command = new_species.pl</span><br><span class="line"></span><br><span class="line">[optimize_augustus.pl]</span><br><span class="line">path = /home/fenglei/local/app/augustus-3.3.1/scripts</span><br><span class="line">command = optimize_augustus.pl</span><br><span class="line"></span><br><span class="line">[hmmsearch]</span><br><span class="line">path = /home/fenglei/local/bin</span><br><span class="line">command = hmmsearch</span><br><span class="line"></span><br><span class="line">[sepp]</span><br><span class="line">path = /home/fenglei/local/app/anaconda3/envs/python37/bin</span><br><span class="line">command = run_sepp.py</span><br><span class="line"></span><br><span class="line">[prodigal]</span><br><span class="line">path = /home/fenglei/local/app/anaconda3/envs/python37/bin</span><br><span class="line">command = prodigal</span><br></pre></td></tr></table></figure>
<p>Test run of BUSCO.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost config]$ which busco</span><br><span class="line">~/.local/bin/busco</span><br><span class="line">(python37) [fenglei@localhost config]$ busco --version</span><br><span class="line">BUSCO 4.1.4</span><br><span class="line">(python37) [fenglei@localhost config]$ busco --help</span><br><span class="line">usage: busco -i [SEQUENCE_FILE] -l [LINEAGE] -o [OUTPUT_NAME] -m [MODE] [OTHER OPTIONS]</span><br><span class="line"></span><br><span class="line">Welcome to BUSCO 4.1.4: the Benchmarking Universal Single-Copy Ortholog assessment tool.</span><br><span class="line">For more detailed usage information, please review the README file provided with this distribution and the BUSCO user guide.</span><br><span class="line"></span><br><span class="line">optional arguments:</span><br><span class="line">  -i FASTA FILE, --in FASTA FILE</span><br><span class="line">                        Input sequence file in FASTA format. Can be an assembled genome or transcriptome (DNA), or protein sequences from an annotated gene set.</span><br><span class="line">  -c N, --cpu N         Specify the number (N=integer) of threads/cores to use.</span><br><span class="line">  -o OUTPUT, --out OUTPUT</span><br><span class="line">                        Give your analysis run a recognisable short name. Output folders and files will be labelled with this name. WARNING: do not provide a path</span><br><span class="line">  --out_path OUTPUT_PATH</span><br><span class="line">                        Optional location for results folder, excluding results folder name. Default is current working directory.</span><br><span class="line">  -e N, --evalue N      E-value cutoff for BLAST searches. Allowed formats, 0.001 or 1e-03 (Default: 1e-03)</span><br><span class="line">  -m MODE, --mode MODE  Specify which BUSCO analysis mode to run.</span><br><span class="line">                        There are three valid modes:</span><br><span class="line">                        - geno or genome, for genome assemblies (DNA)</span><br><span class="line">                        - tran or transcriptome, for transcriptome assemblies (DNA)</span><br><span class="line">                        - prot or proteins, for annotated gene sets (protein)</span><br><span class="line">  -l LINEAGE, --lineage_dataset LINEAGE</span><br><span class="line">                        Specify the name of the BUSCO lineage to be used.</span><br><span class="line">  -f, --force           Force rewriting of existing files. Must be used when output files with the provided name already exist.</span><br><span class="line">  -r, --restart         Continue a run that had already partially completed.</span><br><span class="line">  --limit REGION_LIMIT  How many candidate regions (contig or transcript) to consider per BUSCO (default: 3)</span><br><span class="line">  --long                Optimization mode Augustus self-training (Default: Off) adds considerably to the run time, but can improve results for some non-model organisms</span><br><span class="line">  -q, --quiet           Disable the info logs, displays only errors</span><br><span class="line">  --augustus_parameters AUGUSTUS_PARAMETERS</span><br><span class="line">                        Pass additional arguments to Augustus. All arguments should be contained within a single pair of quotation marks, separated by commas. E.g. &#x27;--param1=1,--param2=2&#x27;</span><br><span class="line">  --augustus_species AUGUSTUS_SPECIES</span><br><span class="line">                        Specify a species for Augustus training.</span><br><span class="line">  --auto-lineage        Run auto-lineage to find optimum lineage path</span><br><span class="line">  --auto-lineage-prok   Run auto-lineage just on non-eukaryote trees to find optimum lineage path</span><br><span class="line">  --auto-lineage-euk    Run auto-placement just on eukaryote tree to find optimum lineage path</span><br><span class="line">  --update-data         Download and replace with last versions all lineages datasets and files necessary to their automated selection</span><br><span class="line">  --offline             To indicate that BUSCO cannot attempt to download files</span><br><span class="line">  --config CONFIG_FILE  Provide a config file</span><br><span class="line">  -v, --version         Show this version and exit</span><br><span class="line">  -h, --help            Show this help message and exit</span><br><span class="line">  --list-datasets       Print the list of available BUSCO datasets</span><br></pre></td></tr></table></figure>
<h3 id="running-busco"><a class="markdownIt-Anchor" href="#running-busco"></a> Running BUSCO</h3>
<p>The munnual is <a href="https://busco.ezlab.org/busco_userguide.html#manual-installation"><em><u>busco_userguide.html</u></em></a></p>
<p>You have to set the environment variable <code>BUSCO_CONFIG_FILE</code> with the path to the file, for BUSCO to be able to locate it.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export BUSCO_CONFIG_FILE=&quot;/home/fenglei/local/app/busco-4/config/config.ini&quot;</span><br><span class="line">export AUGUSTUS_CONFIG_PATH=&quot;/home/fenglei/local/app/augustus-3.3.1/config/&quot;</span><br><span class="line"></span><br><span class="line">busco -i [SEQUENCE_FILE] -l [LINEAGE] -o [OUTPUT_NAME] -m [MODE] [OTHER OPTIONS]</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /home/fenglei/local/app/busco-4/test_data/eukaryota</span><br><span class="line"></span><br><span class="line">busco -i genome.fna -c 8 -m geno -f --out test_eukaryota</span><br><span class="line"></span><br><span class="line">####   BUSCO result   ####</span><br><span class="line">INFO:</span><br><span class="line"></span><br><span class="line">        --------------------------------------------------</span><br><span class="line">        |Results from generic domain eukaryota_odb10      |</span><br><span class="line">        --------------------------------------------------</span><br><span class="line">        |C:18.8%[S:18.8%,D:0.0%],F:0.4%,M:80.8%,n:255     |</span><br><span class="line">        |48     Complete BUSCOs (C)                       |</span><br><span class="line">        |48     Complete and single-copy BUSCOs (S)       |</span><br><span class="line">        |0      Complete and duplicated BUSCOs (D)        |</span><br><span class="line">        |1      Fragmented BUSCOs (F)                     |</span><br><span class="line">        |206    Missing BUSCOs (M)                        |</span><br><span class="line">        |255    Total BUSCO groups searched               |</span><br><span class="line">        --------------------------------------------------</span><br><span class="line"></span><br><span class="line">        --------------------------------------------------</span><br><span class="line">        |Results from dataset saccharomycetes_odb10       |</span><br><span class="line">        --------------------------------------------------</span><br><span class="line">        |C:2.0%[S:2.0%,D:0.0%],F:0.1%,M:97.9%,n:2137      |</span><br><span class="line">        |42     Complete BUSCOs (C)                       |</span><br><span class="line">        |42     Complete and single-copy BUSCOs (S)       |</span><br><span class="line">        |0      Complete and duplicated BUSCOs (D)        |</span><br><span class="line">        |3      Fragmented BUSCOs (F)                     |</span><br><span class="line">        |2092   Missing BUSCOs (M)                        |</span><br><span class="line">        |2137   Total BUSCO groups searched               |</span><br><span class="line">        --------------------------------------------------</span><br><span class="line">INFO:   BUSCO analysis done with WARNING(s). Total running time: 570 seconds</span><br><span class="line"></span><br><span class="line">#### files generated ####</span><br><span class="line">(python37) [fenglei@localhost eukaryota]$ tree -L 1</span><br><span class="line">.</span><br><span class="line">├── busco_1816363720.log</span><br><span class="line">├── busco_3672791891.log</span><br><span class="line">├── busco_downloads</span><br><span class="line">├── expected_log.txt</span><br><span class="line">├── genome.fna</span><br><span class="line">├── info.txt</span><br><span class="line">└── test_eukaryota</span><br><span class="line"></span><br><span class="line">2 directories, 5 files</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="case-study-soybean"><a class="markdownIt-Anchor" href="#case-study-soybean"></a> Case study: soybean</h3>
<p>The genome sequence of Glycine max v4.0 <code>Gmax_508_v4.0.softmasked.fa</code> was downloaded from Phytozome database.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source activate python37</span><br><span class="line">export BUSCO_CONFIG_FILE=&quot;/home/fenglei/local/app/busco-4/config/config.ini&quot;</span><br><span class="line">export AUGUSTUS_CONFIG_PATH=&quot;/home/fenglei/local/app/augustus-3.3.1/config/&quot;</span><br><span class="line">busco -i Gmax_508_v4.0.softmasked.fa -m genome -o BUSCO_soybean -c 16 --auto-lineage-euk</span><br><span class="line"></span><br><span class="line"># Running time: 10 hours. Below is the result:</span><br><span class="line"></span><br><span class="line">INFO:   </span><br><span class="line"></span><br><span class="line">        --------------------------------------------------</span><br><span class="line">        |Results from generic domain eukaryota_odb10      |</span><br><span class="line">        --------------------------------------------------</span><br><span class="line">        |C:98.1%[S:22.0%,D:76.1%],F:1.2%,M:0.7%,n:255     |</span><br><span class="line">        |250    Complete BUSCOs (C)                       |</span><br><span class="line">        |56     Complete and single-copy BUSCOs (S)       |</span><br><span class="line">        |194    Complete and duplicated BUSCOs (D)        |</span><br><span class="line">        |3      Fragmented BUSCOs (F)                     |</span><br><span class="line">        |2      Missing BUSCOs (M)                        |</span><br><span class="line">        |255    Total BUSCO groups searched               |</span><br><span class="line">        --------------------------------------------------</span><br><span class="line"></span><br><span class="line">        --------------------------------------------------</span><br><span class="line">        |Results from dataset fabales_odb10               |</span><br><span class="line">        --------------------------------------------------</span><br><span class="line">        |C:97.7%[S:48.7%,D:49.0%],F:0.4%,M:1.9%,n:5366    |</span><br><span class="line">        |5245   Complete BUSCOs (C)                       |</span><br><span class="line">        |2615   Complete and single-copy BUSCOs (S)       |</span><br><span class="line">        |2630   Complete and duplicated BUSCOs (D)        |</span><br><span class="line">        |19     Fragmented BUSCOs (F)                     |</span><br><span class="line">        |102    Missing BUSCOs (M)                        |</span><br><span class="line">        |5366   Total BUSCO groups searched               |</span><br><span class="line">        --------------------------------------------------</span><br><span class="line">INFO:   BUSCO analysis done. Total running time: 34378 seconds</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | Installation of OrthoMCL-pipeline</title>
    <url>/2021/06/02/Bioinfo-Installation-of-OrthoMCL-pipeline/</url>
    <content><![CDATA[<p>OrthoMCL (<a href="http://orthomcl.org/orthomcl/">http://orthomcl.org/orthomcl/</a>) 是现在用的最多的一款来找直系同源基因（Orthologs）以及旁系同源基因 (Paralog) 的软件。OrthoMCL 原始软件安装比较繁琐，根据官网的教程至少得十多步才能完成整个运行流程，包括Mysql数据库配置、修改OrthoMCL配置文件、转换序列格式、过滤、比对、解析结果和聚类等步骤，特别麻烦。有更方便的途径来完成安装：OrthoMCL Pipeline (<a href="https://github.com/apetkau/orthomcl-pipeline">https://github.com/apetkau/orthomcl-pipeline</a>)。Pipeline安装有点复杂，但是安装完成后，使用就方便了。</p>
<p>两年多前使用过 OrthoMCL-pipeline 流程来寻找一个物种内部的同源基因（paralogs）和物种间的同源基因（othologs）。物种内部的同源基因之间的碱基差别可能是若干年演化的结果，比如染色体倍增或基因扩张，导致出现同源基因，随后由于演化导致某些突变，尤其是同义替换（Ks 或称为 synonymous）不会引起氨基酸序列变化，常作为分子钟，也比如基因组分析种常见的 4dtv（四倍简并位点），也是用需要依靠同源基因的序列来做分析。</p>
<blockquote>
<p>2021.06.25 备注：OrthoMCL-pipeline 安装测试失败。改用 OrthoFinder 则十分顺利，只需要切换到 python37 环境，用 conda 一键安装 OrthoFinder，然后一句命令即可运行物种之间的同源基因比较与归类。下面的代码示例，orthofinder_data 目录下存放蛋白序列，比如含有若干序列比较的物种的蛋白序列集合:ath.fasta, gma.fasta等等，每个物种可以用一个序列文件。</p>
</blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source activate python37</span><br><span class="line">orthofinder -t 6 -f orthofinder_data -S diamond</span><br></pre></td></tr></table></figure>
<p>有哪些文章的示例？可以便于记忆与理解。</p>
<p><img src="https://i.imgur.com/aDN8Pcn.jpg" alt="Fig. 1" /></p>
<p>上图是 2011 年发表于 Nature 期刊的土豆基因组（<a href="https://www.nature.com/articles/nature10158">https://www.nature.com/articles/nature10158</a>），使用 OrthoMCL 分析 12 个植物之间的直系同源基因和旁系同源基因，统计数目并制作了条形图。</p>
<p><img src="https://i.imgur.com/XpDMtM8.jpg" alt="Fig. 2" /></p>
<p>上图是 2018 年发表于 PBJ 期刊的西葫芦基因组（<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5978595/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5978595/</a>）。使用 OrthoMCL 分析五个植物的同源基因，并且基于同源基因信息计算四倍简并位点（4tdv），推算基因组是否加倍。</p>
<h3 id="安装-orthomlc-pipeline"><a class="markdownIt-Anchor" href="#安装-orthomlc-pipeline"></a> 安装 OrthoMLC-pipeline</h3>
<p>下面是安装OrthoMCL的记录，其实可以不用看了。<br />
先下载 <strong>OrthoMCL-pipeline</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/apetkau/orthomcl-pipeline.git</span><br></pre></td></tr></table></figure>
<p>再安装 <strong>Perl 以及若干相关模块</strong>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cpanm BioPerl DBD::mysql DBI Parallel::ForkManager YAML::Tiny Set::Scalar Text::Table Exception::Class Test::Most Test::Warn Test::Exception Test::Deep Moose SVG Algorithm::Combinatorics</span><br></pre></td></tr></table></figure>
<p>实际上在安装 Perl 模块的过程中遇到问题，主要是 BioPerl 安装失败，报错信息：<code>Installing the dependencies failed: Module 'Alien::Libxml2' is not installed</code>。并且我发现不能通过 cpanm 来安装 Alien::Libxml2。经过检索，在一个论坛（<a href="https://github.com/PerlAlien/Alien-Libxml2/issues/7">https://github.com/PerlAlien/Alien-Libxml2/issues/7</a>）找到方法。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ which perl</span><br><span class="line"> ~/local/bin/perl</span><br><span class="line"></span><br><span class="line">$ perl --version</span><br><span class="line"> This is perl 5, version 30, subversion 3 (v5.30.3) built for x86_64-linux</span><br><span class="line"></span><br><span class="line">$ curl -O https://cpan.metacpan.org/authors/id/P/PL/PLICEASE/Alien-Build-1.71_01.tar.gz</span><br><span class="line">  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current</span><br><span class="line">                                 Dload  Upload   Total   Spent    Left  Speed</span><br><span class="line">100  257k  100  257k    0     0  1764k      0 --:--:-- --:--:-- --:--:-- 1775k</span><br><span class="line">$ tar xf Alien-Build-1.71_01.tar.gz </span><br><span class="line">$ cd Alien-Build-1.71_01</span><br><span class="line">$ perl Makefile.PL </span><br><span class="line">Checking if your kit is complete...</span><br><span class="line">Looks good</span><br><span class="line">Generating a Unix-style Makefile</span><br><span class="line">Writing Makefile for Alien::Build</span><br><span class="line">Writing MYMETA.yml and MYMETA.json</span><br><span class="line">...</span><br><span class="line">$ make</span><br><span class="line">$ make install</span><br><span class="line"># 最后这样就安装成功了</span><br><span class="line"># Appending installation info to /home/fenglei/local/lib/perl5/5.30.3/x86_64-linux/perllocal.pod</span><br></pre></td></tr></table></figure>
<p><strong><a href="http://orthomcl.org/common/downloads/software/v2.0/">OrthoMCL</a></strong> 或 OrthoMCL Custom （能够自定义序列识别符的修改版本）。OrhtoMCL 下载并解压之后，bin目录下的Perl程序首行是 <code>#!/usr/bin/perl</code>，我将其全部改为用户的 perl 了，因为我自己安装的perl位置是 <code>/home/fenglei/local/bin/perl</code>。</p>
<p><strong><a href="http://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&amp;PAGE_TYPE=BlastDocs&amp;DOC_TYPE=Download">BLAST</a></strong> (blastall, formatdb) 注意不是NCBI-blast+, 推荐使用 2.2.26 版本。由于我之前下载过 interproscan，在 interproscan 安装目录下游 blastall 和 formatdb 等程序，直接将其路径加入环境变量即可！</p>
<p><strong><a href="https://www.micans.org/mcl/src/">MCL</a></strong> The MCL algorithm is short for the Markov Cluster Algorithm, a fast and scalable unsupervised cluster algorithm for graphs (also known as networks) based on simulation of (stochastic) flow in graphs.</p>
<p>依赖环境解决后能够顺利运行设置脚本:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ perl scripts/orthomcl-pipeline-setup.pl</span><br><span class="line">Checking for Software dependencies...</span><br><span class="line">Checking for OthoMCL ... OK</span><br><span class="line">Checking for formatdb ... OK</span><br><span class="line">Checking for blastall ... OK</span><br><span class="line">Checking for mcl ... OK</span><br><span class="line">Wrote new configuration to orthomcl-pipeline/scripts/../etc/orthomcl-pipeline.conf</span><br><span class="line">Wrote executable file to orthomcl-pipeline/scripts/../bin/orthomcl-pipeline</span><br><span class="line">Please add directory orthomcl-pipeline/scripts/../bin to PATH</span><br></pre></td></tr></table></figure>
<p>然而，我重复以前的流程失败，还是卡在 BioPerl 安装失败。看来问题跟我使用 Anaconda3 有关，下面的错误提示信息种出现的 make 是来自 python37 环境。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">make: *** [Makefile:3290: test_dynamic] Error 255</span><br><span class="line">  CJFIELDS/BioPerl-1.7.8.tar.gz</span><br><span class="line">  /home/fenglei/local/app/anaconda3/envs/python37/bin/make test -- NOT OK</span><br><span class="line">//hint// to see the cpan-testers results for installing this module, try:</span><br><span class="line">  reports CJFIELDS/BioPerl-1.7.8.tar.gz</span><br><span class="line">Failed during this command:</span><br><span class="line"> (optional) CJFIELDS/BioPerl-1.7.8.tar.gz     : make_test NO</span><br></pre></td></tr></table></figure>
<h3 id="20210615-再次尝试安装测试"><a class="markdownIt-Anchor" href="#20210615-再次尝试安装测试"></a> 20210615 再次尝试安装测试</h3>
<p>由于系统自带了 Perl（/usr/bin/perl），我安装的Anaconda3下面的不同环境也分别有 Perl（<sub>/local/app/anaconda3/envs/python37/bin/perl、</sub>/local/app/anaconda3/envs/python27/bin/perl），另外自己又在用户目录下安装了 Perl（~/local/bin/perl），多个版本导致冲突。</p>
<p>软件测试：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source activate python37</span><br><span class="line">PERL5LIB=/home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0  </span><br><span class="line"># 上面其实应该设为 /home/fenglei/local/app/anaconda3/envs/python37/lib/site_perl/5.26.2/</span><br><span class="line"># 此时直接用 cpan -i 或者 perl -MCPAN -s shell 均无法安装 perl 模块，于是尝试 conda，conda基本可以安装这些模块</span><br><span class="line"> conda install -c bioconda perl-Moo</span><br><span class="line"> conda install -c bioconda perl-DBD::mysql # ERROR: Wrong command</span><br><span class="line"> conda install -c bioconda perl-DBD-mysql</span><br><span class="line"> conda install -c bioconda perl-Parallel-ForkManager</span><br><span class="line"> conda install -c bioconda perl-YAML-Tiny</span><br><span class="line"> conda install -c bioconda perl-Set-Scalar</span><br><span class="line"> conda install -c bioconda perl-Text-Table  # ERROR: PackagesNotFoundError</span><br><span class="line"> conda install -c bioconda perl-Exception-Class</span><br><span class="line"> conda install -c bioconda perl-Test-Most</span><br><span class="line"> conda install -c bioconda perl-Test-Warn</span><br><span class="line"> conda install -c bioconda perl-Test-Exception</span><br><span class="line"> conda install -c bioconda perl-Test-Deep</span><br><span class="line"> conda install -c bioconda perl-Moose</span><br><span class="line"> conda install -c bioconda perl-SVG</span><br><span class="line"> conda install -c bioconda perl-Algorithm-Combinatorics  # ERROR: PackagesNotFoundError</span><br></pre></td></tr></table></figure>
<p>conda 安装perl模块有两个安不上，所以手动尝试</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://cpan.metacpan.org/authors/id/S/SH/SHLOMIF/Text-Aligner-0.16.tar.gz</span><br><span class="line">perl Makefile.PL &amp;&amp; make &amp;&amp; make install</span><br><span class="line">## Installing /home/fenglei/perl5/man/man3/Text::Aligner.3</span><br><span class="line">## Appending installation info to /home/fenglei/perl5/lib/perl5/x86_64-linux-thread-multi/perllocal.pod</span><br><span class="line"></span><br><span class="line">conda install -c bioconda  perl-Module-Build</span><br><span class="line"></span><br><span class="line">wget https://cpan.metacpan.org/authors/id/S/SH/SHLOMIF/Text-Table-1.134.tar.gz</span><br><span class="line">perl Makefile.PL &amp;&amp; make &amp;&amp; make install</span><br><span class="line">## Installing /home/fenglei/perl5/man/man3/Text::Table.3</span><br><span class="line">## Appending installation info to /home/fenglei/perl5/lib/perl5/x86_64-linux-thread-multi/perllocal.pod</span><br><span class="line"></span><br><span class="line">## 安装上述模块之后， perl lib 路径下根本没有出现pm文件，我手动拷贝过去，为了保险，拷贝到两个位置：</span><br><span class="line">cp Aligner.pm /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi/auto/Text/</span><br><span class="line">cp Aligner.pm /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0/Text/</span><br><span class="line">cp Table.pm /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi/auto/Text/</span><br><span class="line">cp Table.pm /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0/Text/</span><br><span class="line">PERL5LIB=/home/fenglei/local/app/anaconda3/envs/python37/lib/site_perl/5.26.2/x86_64-linux-thread-multi/auto/:$PERL5LIB</span><br><span class="line"></span><br><span class="line">wget https://cpan.metacpan.org/authors/id/F/FX/FXN/Algorithm-Combinatorics-0.27.tar.gz</span><br><span class="line">## make 失败</span><br><span class="line">## 报错：unable to execute &#x27;x86_64-conda_cos6-linux-gnu-gcc&#x27;: No such file or directory  </span><br></pre></td></tr></table></figure>
<p>这次卡在了 Algorithm-Combinatorics。</p>
<p>在base环境下，自己安装的perl可以编译Algorithm-Combinatorics。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source activate base</span><br><span class="line">which perl</span><br><span class="line"># ~/local/bin/perl</span><br><span class="line">PERL5LIB=/home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0  </span><br><span class="line">cp Combinatorics.pm /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi/auto/</span><br><span class="line">cp Combinatorics.pm /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi/auto/Algorithm/</span><br><span class="line">cp Combinatorics.pm /home/fenglei/local/app/anaconda3/envs/python37/lib/site_perl/5.26.2/Algorithm/</span><br></pre></td></tr></table></figure>
<p>更改前后，都有报错，看来直接复制Combinatorics.pm也不行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost orthomcl-pipeline]$ perl ./scripts/orthomcl-pipeline-setup.pl</span><br><span class="line">Can&#x27;t locate Algorithm/Combinatorics.pm in @INC (you may need to install the Algorithm::Combinatorics module) (@INC contains: /home/fenglei/local/app/anaconda3/envs/python37/lib/site_perl/5.26.2/x86_64-linux-thread-multi/auto/ /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0 /home/fenglei/local/app/anaconda3/envs/python37/lib/site_perl/5.26.2/x86_64-linux-thread-multi /home/fenglei/local/app/anaconda3/envs/python37/lib/site_perl/5.26.2 /home/fenglei/local/app/anaconda3/envs/python37/lib/5.26.2/x86_64-linux-thread-multi /home/fenglei/local/app/anaconda3/envs/python37/lib/5.26.2 .) at ./scripts/orthomcl-pipeline-setup.pl line 21.</span><br><span class="line">BEGIN failed--compilation aborted at ./scripts/orthomcl-pipeline-setup.pl line 21.</span><br><span class="line"></span><br><span class="line">(python37) [fenglei@localhost orthomcl-pipeline]$ perl ./scripts/orthomcl-pipeline-setup.pl</span><br><span class="line">Can&#x27;t locate loadable object for module Algorithm::Combinatorics in @INC (@INC contains: /home/fenglei/local/app/anaconda3/envs/python37/lib/site_perl/5.26.2/x86_64-linux-thread-multi/auto/ /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0/x86_64-linux-thread-multi /home/fenglei/local/app/anaconda3/envs/python37/lib/perl5/site_perl/5.22.0 /home/fenglei/local/app/anaconda3/envs/python37/lib/site_perl/5.26.2/x86_64-linux-thread-multi /home/fenglei/local/app/anaconda3/envs/python37/lib/site_perl/5.26.2 /home/fenglei/local/app/anaconda3/envs/python37/lib/5.26.2/x86_64-linux-thread-multi /home/fenglei/local/app/anaconda3/envs/python37/lib/5.26.2 .) at ./scripts/orthomcl-pipeline-setup.pl line 21.</span><br><span class="line">Compilation failed in require at ./scripts/orthomcl-pipeline-setup.pl line 21.</span><br><span class="line">BEGIN failed--compilation aborted at ./scripts/orthomcl-pipeline-setup.pl line 21.</span><br></pre></td></tr></table></figure>
<h3 id="orthofinder-测试"><a class="markdownIt-Anchor" href="#orthofinder-测试"></a> orthofinder 测试</h3>
<p>安装可以很方便，就是conda：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source  activate python37</span><br><span class="line">conda install -c bioconda -y orthofinder</span><br><span class="line"></span><br><span class="line">(python37) [fenglei@localhost Results_Apr24]$ orthofinder -help</span><br><span class="line"></span><br><span class="line">OrthoFinder version 2.5.2 Copyright (C) 2014 David Emms</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | LTR identification and analysis</title>
    <url>/2021/07/17/Bioinfo-LTR-identification-and-analysis/</url>
    <content><![CDATA[<p>在植物基因组中，I 类转座因子，LTR-RT（LTR retrotransposons）是基因组扩张的主要原因。完整的LTR长度在 85 – 5000 bp 之间，下图表示的是一个完整的 LTR-RT，灰色框表示 TSD（target site duplications）, 红色三角形表示 LTR motif（长度在 2 bp 左右），蓝色框表示 LTR。LTR 中间序列长度在 1,000 – 15,000 之间波动。</p>
<p>完整的LTR-RT主要归为两大类: Gypsy 和 Copia。如果 LTR 中间的序列不包含开放阅读框（ORF）, 那么所属的 LTR-RT 就无法独立的转座。</p>
<p><img src="https://i.imgur.com/pDbuH66.jpeg" alt="" /></p>
<h3 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h3>
<p>LTR_retriever 不是一个独立的工具，他的主要作用就是整合 LTRharvest, LTR_FINDER, MGEScan 3.0.0, LTR_STRUC, 和 LtrDetector 的结果，过滤其中的假阳性 LTR-RT，得到高质量的LTR-RT库。</p>
<p>先下载 LTR_retriever：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/oushujun/LTR_retriever.git</span><br></pre></td></tr></table></figure>
<p>之后修改 LTR_retriever 下的 paths, 提供 BLAST+, RepeatMasker， HMMER， CDHIT 这些工具的路径。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">BLAST+=/your_path_to/BLAST+2.2.30/bin/</span><br><span class="line">RepeatMasker=/your_path_to/RepeatMasker4.0.0/</span><br><span class="line">HMMER=/your_path_to/HMMER3.1b2/bin/</span><br><span class="line">CDHIT=/your_path_to/CDHIT4.6.1/</span><br><span class="line">BLAST=/your_path_to/BLAST2.2.26/bin/ #not required if CDHIT provided</span><br></pre></td></tr></table></figure>
<p>下面是我实际操作中填写的案例。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> 1 ##This file will provide LTR_retriever paths to dependent programs.</span><br><span class="line"> 2 ##You can leave the respective paths empty if programs are accessible through ENV (i.e. exported to .bashrc)</span><br><span class="line"> 3 ##If you specify a path, please make sure that the required program(s) is directly contained in that path but not in any child directories.</span><br><span class="line"> 4 ##e.g. BLAST+=/opt/software/BLAST+/2.2.30--GCC-4.4.5/bin/</span><br><span class="line"> 5 ##LTR_retriever is build based on GenomeTools/1.5.4, BLAST+/2.2.28, BLAST/2.2.26, CDHIT/4.6.1c, HMMER/3.1b2, RepeatMasker/4.0.0 and Tandem Repeats Finder 4.07b</span><br><span class="line"> 6 </span><br><span class="line"> 7 BLAST+=/home/fenglei/local/app/blast-2.11.0/bin     #a path that contains makeblastdb, blastn, blastx</span><br><span class="line"> 8 RepeatMasker=/home/fenglei/local/app/RepeatMasker   #a path that contains RepeatMasker</span><br><span class="line"> 9 HMMER=/home/fenglei/local/bin       #a path that contains hmmsearch</span><br><span class="line">10 CDHIT=/home/fenglei/local/app/cdhit     #a path that contains cd-hit-est (preferred). CDHIT and BLAST are replaceable</span><br><span class="line">11 BLAST=      #a path that contains blastclust (optional)</span><br></pre></td></tr></table></figure>
<p>更加方便的安装方法用 Bioconda 安装好 cd-hit repeatmasker， 然后下载 LTR_retriever:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n LTR_retriever</span><br><span class="line">source activate LTR_retriever</span><br><span class="line">conda install -c conda-forge perl perl-text-soundex</span><br><span class="line">conda install -c bioconda cd-hit</span><br><span class="line">conda install -c bioconda/label/cf201901 repeatmasker</span><br><span class="line"></span><br><span class="line">git clone https://github.com/oushujun/LTR_retriever.git</span><br><span class="line">./LTR_retriever/LTR_retriever -h</span><br></pre></td></tr></table></figure>
<p>此外还需要额外安装 LTRharvest, LTR_FINDER 和 MGEScan_LTR。</p>
<p>LTRharverst: <a href="http://genometools.org/">http://genometools.org/</a><br />
LTR_FINDER: <a href="https://github.com/xzhub/LTR_Finder">https://github.com/xzhub/LTR_Finder</a><br />
LTR_FINDER_parallel: <a href="https://github.com/oushujun/LTR_FINDER_parallel">https://github.com/oushujun/LTR_FINDER_parallel</a><br />
修改版MGEScan_LTR: <a href="http://dawgpaws.sourceforge.net">http://dawgpaws.sourceforge.net</a></p>
<p>由于MGEScan_LTR装起来比我想象中麻烦，所以本文就仅使用LTRharverst和LTR_FINDER</p>
<h3 id="使用篇"><a class="markdownIt-Anchor" href="#使用篇"></a> 使用篇</h3>
<p>尽管 LTR_retriever 支持多个 LTR 工具的输入，但其实上 LTRharverst 和 LTR_FINDER 的结果就已经很不错了。</p>
<p>以拟南芥的基因组序列为例，分别使用 LTRharverst 和 LTR_FINDER 来寻找拟南芥中潜在 LTR 序列，之后用 LTR_retreiver 来合并结果。<br />
注意，也可以用 LTR-finder-parallel，应该会更快。</p>
<p>注意：LTRharvest 输出的结果中会将染色体名称成数字编号，可能会对后续分析造成问题。Unfortunately, LTRharvest has an annoying habit of not using the scaffold/chromosome names you give it (it outputs scaffolds as “seqX” where X is the 0-base number of your scaffold), so I remove all scaffolds in my fasta file, remove newline (“\n”) characters, and add a single scaffold name so that getting the fasta sequence for regions in the output gff3 is painless. 有人的解决方案是将自己的基因组手动拼成一条序列，因为只需要找LTR序列而已。 This is useful if you just want the distribution of insertion times of your LTRs, but if you need location information you’ll either have to rerun LTRharvest with the regular fasta, or use the length of each scaffold to figure out the real scaffold from your concatenated fasta.</p>
<p>20210719 备注：经过测试，LTRharvest输出的scn文件虽然有上面提到的问题，但是对后续导入LTR-retriever的整合分析不会造成影响。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># LTRharvest</span><br><span class="line">gt suffixerator \</span><br><span class="line">  -db TAIR10.fa \</span><br><span class="line">  -indexname TAIR10 \</span><br><span class="line">  -tis -suf -lcp -des -ssp -sds -dna</span><br><span class="line">gt ltrharvest \</span><br><span class="line">  -index TAIR10 \</span><br><span class="line">  -similar 90 -vic 10 -seed 20 -seqids yes \</span><br><span class="line">  -minlenltr 100 -maxlenltr 7000 -mintsd 4 -maxtsd 6 \</span><br><span class="line">  -motif TGCA -motifmis 1  &gt; TAIR10.harvest.scn &amp;</span><br><span class="line"></span><br><span class="line"># LTR_FINDER</span><br><span class="line"># ltr_finder -D 15000 -d 1000 -L 7000 -l 100 -p 20 -C -M 0.9 TAIR10.fa &gt; TAIR10.finder.scn &amp;</span><br><span class="line">~/local/app/LTR_FINDER_parallel/LTR_FINDER_parallel -seq genome.fasta -threads 10 -harvest_out -size 1000000 -time 300</span><br></pre></td></tr></table></figure>
<p>LTR_retriever支持单个候选的LTR：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LTR_retriever -genome TAIR10.fa -inharvest TAIR10.harvest.scn</span><br></pre></td></tr></table></figure>
<p>也支持多个候选LTR输入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LTR_retriever -genome TAIR10.fa -inharvest TAIR10.harvest.scn -infinder TAIR10.finder.scn -threads 20</span><br></pre></td></tr></table></figure>
<p>输出文件如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost 20210719_LTR_retriever_test]$ LTR_retriever -genome genome.fasta -inharvest genome.fasta.rawLTR.scn -threads 10</span><br><span class="line"></span><br><span class="line">##########################</span><br><span class="line">### LTR_retriever v2.9.0 ###</span><br><span class="line">##########################</span><br><span class="line"></span><br><span class="line">Contributors: Shujun Ou, Ning Jiang</span><br><span class="line"></span><br><span class="line">For LTR_retriever, please cite:</span><br><span class="line"></span><br><span class="line">        Ou S and Jiang N (2018). LTR_retriever: A Highly Accurate and Sensitive Program for Identification of Long Terminal Repeat Retrotransposons. Plant Physiol. 176(2): 1410-1422.</span><br><span class="line"></span><br><span class="line">For LAI, please cite:</span><br><span class="line"></span><br><span class="line">        Ou S, Chen J, Jiang N (2018). Assessing genome assembly quality using the LTR Assembly Index (LAI). Nucleic Acids Res. 2018;46(21):e126.</span><br><span class="line"></span><br><span class="line">Parameters: -genome genome.fasta -inharvest genome.fasta.rawLTR.scn -threads 10</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:09:05 CST 2021    Dependency checking: All passed!</span><br><span class="line">Mon Jul 19 09:09:24 CST 2021    LTR_retriever is starting from the Init step.</span><br><span class="line">Mon Jul 19 09:09:26 CST 2021    Start to convert inputs...</span><br><span class="line">                                Total candidates: 1110</span><br><span class="line">                                Total uniq candidates: 1045</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:09:28 CST 2021    Module 1: Start to clean up candidates...</span><br><span class="line">                                Sequences with 10 missing bp or 0.8 missing data rate will be discarded.</span><br><span class="line">                                Sequences containing tandem repeats will be discarded.</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:09:48 CST 2021    950 clean candidates remained</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:09:48 CST 2021    Modules 2-5: Start to analyze the structure of candidates...</span><br><span class="line">                                The terminal motif, TSD, boundary, orientation, age, and superfamily will be identified in this step.</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:16:20 CST 2021    Intact LTR-RT found: 230</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:16:24 CST 2021    Module 6: Start to analyze truncated LTR-RTs...</span><br><span class="line">                                Truncated LTR-RTs without the intact version will be retained in the LTR-RT library.</span><br><span class="line">                                Use -notrunc if you don&#x27;t want to keep them.</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:16:24 CST 2021    66 truncated LTR-RTs found</span><br><span class="line">Mon Jul 19 09:16:41 CST 2021    29 truncated LTR sequences have added to the library</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:16:41 CST 2021    Module 5: Start to remove DNA TE and LINE transposases, and remove plant protein sequences...</span><br><span class="line">                                Total library sequences: 355</span><br><span class="line">Mon Jul 19 09:18:52 CST 2021    Retained clean sequence: 348</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:18:52 CST 2021    Sequence clustering for genome.fasta.ltrTE ...</span><br><span class="line">Mon Jul 19 09:18:52 CST 2021    Unique lib sequence: 347</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:18:55 CST 2021    Module 6: Start to remove nested insertions in internal regions...</span><br><span class="line">Mon Jul 19 09:27:23 CST 2021    Raw internal region size (bit): 961029</span><br><span class="line">                                Clean internal region size (bit): 912840</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:27:24 CST 2021    Sequence number of the redundant LTR-RT library: 659</span><br><span class="line">                                The redundant LTR-RT library size (bit): 1422033</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:27:24 CST 2021    Module 8: Start to make non-redundant library...</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:27:27 CST 2021    Final LTR-RT library entries: 342</span><br><span class="line">                                Final LTR-RT library size (bit): 1025212</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:27:27 CST 2021    Total intact LTR-RTs found: 206</span><br><span class="line">                                Total intact non-TGCA LTR-RTs found: 43</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:27:28 CST 2021    Start to annotate whole-genome LTR-RTs...</span><br><span class="line">                                Use -noanno if you don&#x27;t want whole-genome LTR-RT annotation.</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">######################################</span><br><span class="line">### LTR Assembly Index (LAI) beta3.2 ###</span><br><span class="line">######################################</span><br><span class="line"></span><br><span class="line">Developer: Shujun Ou</span><br><span class="line"></span><br><span class="line">Please cite:</span><br><span class="line"></span><br><span class="line">Ou S., Chen J. and Jiang N. (2018). Assessing genome assembly quality using the LTR Assembly Index (LAI). Nucleic Acids Res. gky730: https://doi.org/10.1093/nar/gky730</span><br><span class="line"></span><br><span class="line">Parameters: -genome genome.fasta -intact genome.fasta.pass.list -all genome.fasta.out -t 10 -q -blast /home/fenglei/local/app/blast-2.11.0/bin/</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:32:57 CST 2021    Dependency checking: Passed!</span><br><span class="line">Mon Jul 19 09:32:57 CST 2021    Calculation of LAI will be based on the whole genome.</span><br><span class="line">                                Please use the -mono parameter if your genome is a recent ployploid, for high identity between homeologues will overcorrect raw LAI scores.</span><br><span class="line">Mon Jul 19 09:32:57 CST 2021    Estimate the identity of LTR sequences in the genome: quick mode</span><br><span class="line">Mon Jul 19 09:33:08 CST 2021    The identity of LTR sequences: 93.5158904793606%</span><br><span class="line">Mon Jul 19 09:33:08 CST 2021    Calculate LAI:</span><br><span class="line"></span><br><span class="line">                                                Done!</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:33:11 CST 2021    Result file: genome.fasta.out.LAI</span><br><span class="line"></span><br><span class="line">                                You may use either raw_LAI or LAI for intraspecific comparison</span><br><span class="line">                                but please use ONLY LAI for interspecific comparison</span><br><span class="line"></span><br><span class="line">Mon Jul 19 09:33:11 CST 2021    All analyses were finished!</span><br><span class="line"></span><br><span class="line">##############################</span><br><span class="line">####### Result files #########</span><br><span class="line">##############################</span><br><span class="line"></span><br><span class="line">Table output for intact LTR-RTs (detailed info)</span><br><span class="line">        genome.fasta.pass.list (All LTR-RTs)</span><br><span class="line">        genome.fasta.nmtf.pass.list (Non-TGCA LTR-RTs)</span><br><span class="line">        genome.fasta.pass.list.gff3 (GFF3 format for intact LTR-RTs)</span><br><span class="line"></span><br><span class="line">LTR-RT library</span><br><span class="line">        genome.fasta.LTRlib.redundant.fa (All LTR-RTs with redundancy)</span><br><span class="line">        genome.fasta.LTRlib.fa (All non-redundant LTR-RTs)</span><br><span class="line">        genome.fasta.nmtf.LTRlib.fa (Non-TGCA LTR-RTs)</span><br><span class="line"></span><br><span class="line">Whole-genome LTR-RT annotation by the non-redundant library</span><br><span class="line">        genome.fasta.LTR.gff3 (GFF3 format)</span><br><span class="line">        genome.fasta.out.fam.size.list (LTR family summary)</span><br><span class="line">        genome.fasta.out.superfam.size.list (LTR superfamily summary)</span><br><span class="line"></span><br><span class="line">LTR Assembly Index (LAI)</span><br><span class="line">        genome.fasta.out.LAI</span><br></pre></td></tr></table></figure>
<h3 id="ltr-rts-insertion-time"><a class="markdownIt-Anchor" href="#ltr-rts-insertion-time"></a> LTR-RTs insertion time</h3>
<p>根据LTR-RT的结构特点，即插入基因组新位置之后，反转录转座子的两端的LTR会独立进化，各自积累突变，计算出他们之间的遗传距离与进化时间，就可推断基因组里面大量LTR-RT出现的规律。“LTR-RTs are a case where we can exploit biology to provide insight into larger processes. LTR-RTs are a class of retrotransposon with long terminal repeats, which are identical upon insertion at the beginning and end of the TE’s sequence. Over time, mutations accumulate in these terminal repeats, roughly following a molecular clock. This allows us to more or less count the differences between the two LTRs of a LTR-RT, and calculate the time (in generations ago) it was inserted. If we do this for all LTR-RTs in a genome, we get a distribution of insertion times, and shifts in this distribution can tell us about the history of TE activity and/or selective pressures against TEs in our favourite species or between species.”</p>
<p>计算LTR插入时间可以参考：<a href="https://github.com/SIWLab/Lab_Info/wiki/Ageing-LTR-insertions">https://github.com/SIWLab/Lab_Info/wiki/Ageing-LTR-insertions</a></p>
<p>按照上面的流程，运行LTRretriever之后得到一系列文件，其中genome.fasta.pass.list.gff3是最终的LTR列表，包含三种类型：Copia、Gypsy和unknown。一般文献会分别统计Copia、Gypsy和non-autonomous这三个类型的LTR。那么non-autonomous是否就是unknown呢？我将这个gff3文件导入IGV浏览器，发现unknown LTR的特点就是具有双端LTR结构，但是中间区域很短，意味着其很可能不具备gag和pol序列，无法独立执行这个转座子单元的反转录的过程。</p>
<p><img src="https://i.imgur.com/AAVN4k5.jpeg" alt="" /></p>
<p>下截图所示，是gff3的文件内容，每个LTR-RT一般有6行，第3和第5行就是两端的LTR区域，将这两行提取出来，存入一个文件。我写了一个Perl脚本，逐个LTR-RT分别存入新的文件，每个文件两行，比如LTR_1.gff3、LTR_2.gff3、LTR_3.gff3 …… 然后基于这些gff3文件，用bedtools分别提取fasta序列，再用muscle软件做序列比对（注意muscle软件只能按照两条序列自然的方向作比较，他不会考虑两条序列是否反向之后匹配更好，当然，LTR-RT的两端的LTR序列本来就是方向一致的，所以不用担心。），muscle输出对齐的fasta格式文件，然后运用程序计算双端LTR之间的距离K，再依据 T=K/(2r) 公式就能推测到插入时间。将“插入时间”数据统一存入一个文本，导入R，用ggplot2的geom_histogram功能就可以得到下面的图。</p>
<p>上面公式中r的意思是“synonymous nucleotide substitution rate”，“r is the average substitution rate, taken as the Ks value estimated above”，<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1456784/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1456784/</a>，7e-9 substitutions/site/year, with standard deviation of 2.6e−9, was used as the rate of synonymous substitutions ®. 根据这篇文章，豆科的平均替换率是7e-9 substitutions/site/year，我在我研究的物种中也用这个数值。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#########################################################################</span><br><span class="line"># File Name: ltr.sh</span><br><span class="line"># Author: fenglei</span><br><span class="line"># Mail: fengleiluck@gmail.com</span><br><span class="line"># Created Time: Wed 21 Jul 2021 01:57:33 PM CST</span><br><span class="line">#########################################################################</span><br><span class="line">#!/usr/bin/bash</span><br><span class="line">set -e</span><br><span class="line">set -u</span><br><span class="line">set -o pipefail</span><br><span class="line"></span><br><span class="line">for IN in `find ./loop/ -name &quot;LTR*.gff3&quot;`; do</span><br><span class="line">        echo [`date +&quot;%Y-%m-%d %H:%M:%S&quot;`] &quot;   * processing $IN&quot;</span><br><span class="line">        path=$&#123;IN%/*&#125;    #  ./loop/LTR_85.gff3 -&gt; ./loop</span><br><span class="line">        file=$&#123;IN##*/&#125;   #  ./loop/LTR_85.gff3 -&gt; LTR_85.gff3</span><br><span class="line">        name=$&#123;file%.*&#125;  #  LTR_85.gff3 -&gt; LTR_85</span><br><span class="line">        # cat genome.fasta.finder.combine.scn genome.fasta.harvest.scn_new &gt;genome.fasta.rawLTR.scn </span><br><span class="line">        # awk &#x27;NR == 9 || NR == 11&#x27; genome.fasta.pass.list.gff3 &gt; LTR_1.gff3</span><br><span class="line">        # bedtools getfasta -fi genome.fasta -bed LTR_1.gff3 &gt; $&#123;name&#125;.fasta </span><br><span class="line">        bedtools getfasta -fi genome.fasta -bed $IN &gt; ./loop/$&#123;name&#125;.fasta</span><br><span class="line">        ~/local/app/muscle3.8.31/muscle3.8.31_i86linux64 -in ./loop/$&#123;name&#125;.fasta -out ./loop/$&#123;name&#125;.afa</span><br><span class="line">        # cat LTR_1.pair_diff</span><br><span class="line">        python ../../20210720_LTR_evolution/LTR_pairwise_differences.py --input ./loop/$&#123;name&#125;.afa --output ./loop/$&#123;name&#125;.pair_diff</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/Xkpiivl.jpeg" alt="" /></p>
<p>附画图R语言代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">library(ggplot2)</span><br><span class="line">setwd(&quot;C://R-data&quot;)</span><br><span class="line">ltr &lt;- read.table(&quot;Arabidopsis_LTR.txt&quot;, head=F)</span><br><span class="line">head(ltr)</span><br><span class="line">colnames(ltr) &lt;- c(&quot;locus&quot;, &quot;K&quot;, &quot;T&quot;)</span><br><span class="line">head(ltr$locus)</span><br><span class="line">ltr$newT &lt;- ltr$T/1000000</span><br><span class="line">head(ltr)</span><br><span class="line">ggplot() +</span><br><span class="line">  geom_histogram(data=ltr, aes(x=newT), fill=&quot;#0570c0&quot;, colour=&quot;black&quot;) +</span><br><span class="line">  theme_bw() +</span><br><span class="line">  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) +</span><br><span class="line">  theme(axis.text.x = element_text(size = 15, color = &quot;black&quot;, vjust = 0.5 , hjust = 0.5, angle = 0)) +</span><br><span class="line">  theme(axis.text.y = element_text(color = &quot;black&quot;, size = 15)) +</span><br><span class="line">  ylab(&quot;Copy Number&quot;) +</span><br><span class="line">  xlab(&quot;Insertion time (Myr)&quot;) +</span><br><span class="line">  #ggtitle(&quot;4DTv density of paralogs gene pairs in legumes&quot;) +</span><br><span class="line">  theme(axis.title.y = element_text(size = 18, color = &quot;black&quot;)) +</span><br><span class="line">  theme(axis.title.x = element_text(size = 18, color = &quot;black&quot;))</span><br></pre></td></tr></table></figure>
<h3 id="ltr-rts-系统发生树"><a class="markdownIt-Anchor" href="#ltr-rts-系统发生树"></a> LTR-RTs 系统发生树</h3>
<ol>
<li>genome.fasta.pass.list.gff3 文件，用bedtools提取对应的LTR-RT的完整DNA序列。</li>
<li>一个LTR-RT中有多个蛋白质domain，如何提取这些domain？用TEsorter可以轻松实现，TEsorter用conda即可安装，我在python3.7环境下安装的。得到不同功能域（GAG、INT、RT、RH……）的氨基酸序列。<br />
（一开始不知道TEsorter存在，自己用blastx和hmmer尝试，效果都不理想）</li>
<li>通过cdhit软件进行序列聚类，将高度近似或相同的序列归类，大大减少下一步比对的序列数目。我从2800聚集成400多条序列。</li>
<li>序列比对。可以用mafft或muscle。我用这windows版本的MEGA软件，MEGA X 内置muscle，，运行数秒即可得到下图。</li>
</ol>
<p><img src="https://i.imgur.com/WMphP1J.jpeg" alt="" /></p>
<ol start="5">
<li>直接在MEGA软件里面选择系统进化分析，选择ML（Maximum Likelihood），其余参数默认，运行很快就得到下图。</li>
</ol>
<p><img src="https://i.imgur.com/ksgYYlM.jpeg" alt="" /></p>
<ol start="6">
<li>
<p>上面的树，导出为Newick格式（.nwk），然后可以用其他软件来美化这个进化树。注意导出的时候可以设定是否导出树枝长度，若不选，那么出来的树就是类似二叉树的形象，树枝都是一样的长度。</p>
</li>
<li>
<p>用Figtree软件打开这个树，可以美化。参考资料 <a href="https://www.omicsclass.com/article/62">https://www.omicsclass.com/article/62</a>. 比如某个分支需要加颜色背景，就需要点击目录上方的“clade”按钮，接下来点击树枝，就能选中那个分支，再点击目录上方的“Hilight”按钮，就可以设置颜色背景，效果图像如下！</p>
</li>
</ol>
<p><img src="https://i.imgur.com/FNCS9nl.jpeg" alt="" /></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | Local BLAST search of NCBI NR database</title>
    <url>/2021/10/11/Bioinfo-Local-BLAST-search-of-NCBI-NR-database/</url>
    <content><![CDATA[<p>DIAMOND 是一种快速批量序列比对程序，可将 DNA 文件与蛋白质参考序列文件（如 NCBI-nr）进行比较。它以 C++ 实现，旨在在多核服务器上快速运行。该程序明确地设计为，利用具有大内存容量和许多内核的现代计算机体系结构。那么为什么它那么快呢，因为它使用了种子延伸方法。额外的算法成分是使用缩小的字母，间隔种子和双索引。算法简单了解一下就可以了，具体的算法的内容比较难懂就不深入讨论了。其主要的特点包括(为什么该工具那么受欢迎):在比较NCBI-nr数据库的短DNA reads时，DIAMOND比BLASTX 快4个数量级，并且在e-value &lt; 0.001 的比对上保持相当的灵敏度水平。简单一句话就是又快又准。可用于移位分析的长reads比对资源要求低，适合在标准台式机或笔记本电脑上运行(入门门槛低，适合各类的玩家)各种输出格式，包括BLAST对比格式，例如格式6的tabular分隔形式和格式5的XML格式 (很多下游分析，或者脚本都是基于BLAST的输出结果，diamond能够直接输出和Blast相同的格式不能不说是最大的优点之一)（摘自：<a href="https://www.jianshu.com/p/d2407ec4648a">lakeseafly</a></p>
<h3 id="nr-数据库下载"><a class="markdownIt-Anchor" href="#nr-数据库下载"></a> NR 数据库下载</h3>
<p>浏览器打开 <a href="https://ftp.ncbi.nlm.nih.gov/blast/db/">https://ftp.ncbi.nlm.nih.gov/blast/db/</a>。进入 fasta 目录，可以见到：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Index of /blast/db/FASTA</span><br><span class="line">Name                    Last modified      Size  </span><br><span class="line">Parent Directory                             -   </span><br><span class="line">nr.gz                   2021-10-09 19:36  111G  </span><br><span class="line">nr.gz.md5               2021-10-09 20:21   40   </span><br><span class="line">nt.gz                   2021-10-04 07:27  133G  </span><br><span class="line">nt.gz.md5               2021-10-04 08:40   40   </span><br><span class="line">pdbaa.gz                2021-10-09 11:37   32M  </span><br><span class="line">pdbaa.gz.md5            2021-10-09 11:37   43   </span><br><span class="line">swissprot.gz            2021-10-09 11:36  134M  </span><br><span class="line">swissprot.gz.md5        2021-10-09 11:36   47   </span><br></pre></td></tr></table></figure>
<p>通过 FileZilla 软件下载 nr.gz 文件，文件较大，需时较长。（备注：这个方式不推荐，我下载了两次，文件大小都不一样，均无法通过md5完整性检测，文件解压自然也是失败的。）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ wget ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz</span><br><span class="line">--2021-10-11 10:21:12--  ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz</span><br><span class="line">           =&gt; ‘nr.gz’</span><br><span class="line">Resolving ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)... 165.112.9.230, 165.112.9.228, 2607:f220:41f:250::230, ...</span><br><span class="line">Connecting to ftp.ncbi.nlm.nih.gov (ftp.ncbi.nlm.nih.gov)|165.112.9.230|:21... connected.</span><br><span class="line">Logging in as anonymous ... Logged in!</span><br><span class="line">==&gt; SYST ... done.    ==&gt; PWD ... done.</span><br><span class="line">==&gt; TYPE I ... done.  ==&gt; CWD (1) /blast/db/FASTA ... done.</span><br><span class="line">==&gt; SIZE nr.gz ... 119246586487</span><br><span class="line">==&gt; PASV ... done.    ==&gt; RETR nr.gz ... done.</span><br><span class="line">Length: 119246586487 (111G) (unauthoritative)</span><br><span class="line"></span><br><span class="line"> 3% [=====&gt;  （我的下载速度约 1 M/s，花了一个晚上下载数据集，但是数据集通不过完整性检测。）</span><br><span class="line"></span><br><span class="line">$ wget ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz.md5</span><br></pre></td></tr></table></figure>
<p>测试用 blast 自带的下载程序 update_blastdb.pl，最终也因网络中断而失败。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ perl /home/fenglei/local/app/blast-2.11.0/bin/update_blastdb.pl nr</span><br><span class="line">Connected to NCBI</span><br><span class="line">Downloading nr (56 volumes) ...</span><br><span class="line">Downloading nr.00.tar.gz...</span><br></pre></td></tr></table></figure>
<p>最后还是用 wget 工具成功下载 nr 数据集。wget 可以设置 <code>-c</code> 参数，即断点续传功能；<code>-t</code> 参数表示中断之后无限次重连。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget -c -t 0 ftp://ftp.ncbi.nlm.nih.gov/blast/db/FASTA/nr.gz</span><br></pre></td></tr></table></figure>
<p>下载完毕，用 <code>md5sum</code> 程序检测数据集完整度，通过的话就可以构建数据库索引，制作 index。<code>nr.fa.gz</code> 文件大小 120 Gb，解压成文本文件 <code>nr.fa</code> 约220 Gb，制作成索引文件 <code>nr.fa.dmnd</code> 约 220 Gb。是否可以直接以压缩格式的序列文件来制作 index 索引文件？测试发现是可以的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">md5sum -c nr.gz.md5</span><br><span class="line">#### 如果上面的文件是完整的，将看到如下信息</span><br><span class="line">#### nr.gz: OK</span><br><span class="line">diamond makedb --in nr.fa -d nr.fa</span><br><span class="line"># diamond makedb --in Araport11_genes.201606.pep.fasta.gz -d Araport11_genes.pep</span><br><span class="line"># makeblastdb -dbtype prot -input_type fasta -in nr.fa -out nr.fa</span><br><span class="line"># makeblastdb -dbtype nucl -input_type fasta -in nt.fa -out nt.fa</span><br></pre></td></tr></table></figure>
<p>注意，nr 数据库内容截取如下，有的序列名字有多个 ID，以“^A”分割。看来这几个名字就是不同的版本。我用相应的氨基酸序列去 NCBI 官网做 BLASTp，得到的结果就是排在前面的那一个 ID。将 nr 数据库在本地做 blast 比对，实际输出的也是第第一个 ID，“^A”之后的其他基因ID不会出现。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;WP_036746896.1 UxaA family hydrolase [Paenibacillus sp. UNC451MF]</span><br><span class="line">MSQSSVHSRTIWGYRRTDGRVGVRNHVLILPTIVCATQTAQRVTELVQGTVTFIHQHGCAQVGVDYEQTFRTYVGMAANP</span><br><span class="line">NVYGVIVLGLGCETHQARSVASEVRKTGKPVEVISIQDHGGTLFTVAEAARAAAKMVQEASRERRVECDFAELIVGTECG</span><br><span class="line">GSDACSGLSANPAVGVCSDKIVDHGGTSILAETTELIGAEHLLARRAVNDHVAKRVYQVIEAMEKRAFSMNVDIRTGNPS</span><br><span class="line">PGNIKGGLSSLEEKSLGASNKSGTRPLQELIDYAERPSQRGLVWMDTPGHDIEQLTGMVAGGSQIVLFTTGRGTPTGSPI</span><br><span class="line">APVIKIATNTSIFEKMNDNIDLNAGTIIEGTETIESVGDRIFEEIIEVCSGKLTKSEILKQHDFGIWRIGPTF</span><br><span class="line">&gt;WP_198710437.1 energy transducer TonB [Pseudomonas syringae]^AMBI6798472.1 TonB family protein [Pseudomonas syringae]</span><br><span class="line">MIAAALAPPVGAAEPFLVPIYTPTPVFPPELVKTRYAGKVRAQLWIKSDGQVREVRAIESGHPQLAAAVEQALRQWRYKP</span><br><span class="line">WIGTVGAPPMTTITVPVIFGSHGYRRFNTEVTVGLGNIRCGYLNHEVKSARQDYPKEPLSKVDVFWYTGQALFGSHVAHL</span><br><span class="line">RSEPQRQVLLEQLGAAIPMMVSNCRRNPDRLYGDYLPTPIKALMVGLAEQAEGSE</span><br><span class="line">&gt;WP_160354286.1 DUF1491 family protein [Sphingorhabdus profundilacus]^AMVZ98371.1 DUF1491 family protein [Sphingorhabdus profundilacus]</span><br><span class="line">MTEPRLTSQFRISALQRLTEADGGFATLLHKGDPTSGVILLVGHIRGGNPVLFERYPALDGSLTWHRITQSLVGDETEIT</span><br><span class="line">KYWKTRTQRDPDLWVLELDVASIERLDGLLATDA</span><br><span class="line">&gt;CAD7654860.1 unnamed protein product, partial [Oppiella nova]^ACAG2172047.1 unnamed protein product, partial [Oppiella nova]</span><br><span class="line">MNIEDIVALHNLVSIKIYSLQKENSNLVQQVIKFKTFYDKNKTDENETKDTESESMDTLADDKGFDKDNLLKEVERIKKK</span><br><span class="line">YSIKSKKLEQKMVSMSQRNRAHSPLLWTQIKTSKNKTDENETKDTESESMDTLADDKGFDKDNLLKEVERIKKKYSIKSK</span><br><span class="line">KLEQKMVSMSQRNRAHVRHNH</span><br></pre></td></tr></table></figure>
<h3 id="diamond-blast"><a class="markdownIt-Anchor" href="#diamond-blast"></a> Diamond BLAST</h3>
<p>普通的 BLAST 将会非常慢，所以要用到 Diamond 的 blast 功能。通过 <code>outfmt 6</code> 来控制需要输出的信息项目。参数 <code>-k</code> （–max-target-seqs）表示，针对每一个序列，仅仅输出最佳匹配的一个结果，默认是输出 25 个匹配结果。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">diamond blastp --threads 8 -d /index/nr.fa -q unkonwn_proteins_seq.fa -k 1 -e 0.0001 -o unkonwn_proteins_seq_blastp_nr_1</span><br><span class="line"># diamond blastx --threads 8 -d /index/nr.fa --outfmt 6 qseqid sallseqid pident length mismatch gapopen qstart qend sstart send evalue bitscore -q unkonwn_DNA_seq.fas -k 1 -e 0.0001 -o unkonwn_proteins_seq_blastx_nr_2</span><br><span class="line"></span><br><span class="line">##### 下面是显示tab格式的比对信息，通过-outfmt 6 参数设置将比对目标的基因名全部信息进行输出</span><br><span class="line">diamond blastp --threads 8 -d /index/nr.fa --outfmt 6 qseqid sallseqid stitle pident length mismatch gapopen qstart qend sstart send evalue bitscore -q unkonwn_proteins_seq.fas -k 1 -e 0.001 -o unkonwn_proteins_seq_blastx_nr_3</span><br><span class="line"></span><br><span class="line">##### 下面是生成 paorwise 比对信息，可以直观看到比对的区间信息</span><br><span class="line">diamond blastx --threads 16 -d ~/databases/nr/nr.fa --outfmt 0 -q Transcripts.fa -k 1 -e 0.001 -o Transcripts.fa_blastx_nr_outfmt0.tab</span><br></pre></td></tr></table></figure>
<h3 id="结果解读"><a class="markdownIt-Anchor" href="#结果解读"></a> 结果解读</h3>
<p>如下就是 tab 格式的输出。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Query_ID	gene_ID_in_NR	gene_info_in_NR	identity%	length	mismatch	gapopen	qstart	qend	sstart	send	evalue	bitscore</span><br><span class="line">TRINITY_DN69561_c0_g1_i1	SHE22971.1	SHE22971.1 Exodeoxyribonuclease III [Bathymodiolus brooksi thiotrophic gill symbiont]	41.5	82	47	1	250	5	155	235	3.95E-10	65.1</span><br><span class="line">TRINITY_DN69561_c3_g1_i1	XP_033731479.1	XP_033731479.1 uncharacterized protein LOC117321118 [Pecten maximus]	42.4	66	38	0	198	1	610	675	2.09E-06	54.3</span><br><span class="line">TRINITY_DN69557_c0_g1_i5	XP_025020276.1	XP_025020276.1 tigger transposable element-derived protein 1-like [Python bivittatus]	51.7	201	71	4	3	533	71	269	4.86E-54	183</span><br><span class="line">TRINITY_DN69557_c0_g1_i9	XP_008336686.1	XP_008336686.1 tigger transposable element-derived protein 1-like [Cynoglossus semilaevis]	60.5	114	45	0	1	342	17	130	1.86E-34	136</span><br><span class="line">TRINITY_DN69557_c0_g1_i10	XP_005003688.1	XP_005003688.1 tigger transposable element-derived protein 1-like isoform X2 [Cavia porcellus]	83.3	36	6	0	147	254	76	111	6.29E-11	67.8</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | MCScanX genome synteny blocks and 4dtv of paralogous genes</title>
    <url>/2022/03/31/Bioinfo-MCScanX-genome-synteny-blocks/</url>
    <content><![CDATA[<p>原文记录于 2019-07-05，因 2022-04-01 再次测试，遇到问题，再次编辑记录。</p>
<p>安装如果遇到下面的问题：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[fenglei@localhost MCScanX]$ make</span><br><span class="line">g++ struct.cc mcscan.cc read_data.cc out_utils.cc dagchainer.cc msa.cc permutation.cc -o MCScanX</span><br><span class="line">msa.cc: In function ‘void msa_main(const char*)’:</span><br><span class="line">msa.cc:289:22: error: ‘chdir’ was not declared in this scope</span><br><span class="line">if (chdir(html_fn)&lt;0)</span><br><span class="line">^</span><br><span class="line">make: *** [makefile:2: mcscanx] Error 1</span><br></pre></td></tr></table></figure>
<p>解决办法：</p>
<p>错误的原因是 MCScanX 不支持64位系统, 如果要在 64 位上运行, 需要在<code>msa.h</code>, <code>dissect_multiple_alignment.h</code>, and <code>detect_collinear_tandem_arrays.h</code>第一行加上</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#include &lt;unistd.h&gt;</span><br></pre></td></tr></table></figure>
<p>如果要对两个基因组（以soybean和medicago为例）进行共线性分析，需要收集两个物种的数据编码基因的gff3文件和CDS序列文件，然后进行下面的操作。</p>
<p>首先利用gff3文件，得到每一个基因的起始和终止坐标信息，注意基因有多个transcripts，只需要保留“xxxx.1”的转录本，不同物种的序列用awk等工具灵活处理。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m jcvi.formats.gff bed --type=mRNA --key=Name Gmax\_275\_Wm82.a2.v1.gene.gff3.gz -o soybean.bed</span><br><span class="line">python -m jcvi.formats.gff bed --type=mRNA --key=Name Mtruncatula\_285\_Mt4.0v1.gene.gff3 -o medicago.bed</span><br><span class="line"></span><br><span class="line">cat soybean.bed  awk &#x27;BEGIN&#123;OFS=&quot;\\t&quot;&#125;&#123;if(length($4) == 17 &amp;&amp; $4 ~ /\\.1$/)&#123;gsub(/\\.1$/,&quot;&quot;,$4);gsub(/Chr/,&quot;gm&quot;,$1); print $1,$4,$2,$3&#125;&#125;&#x27; &gt; soybean\_gff.tab</span><br><span class="line">cat medicago.bed  awk &#x27;BEGIN&#123;OFS=&quot;\\t&quot;&#125;&#123;if(length($4) == 15 &amp;&amp; $4 ~ /\\.1$/)&#123;gsub(/\\.1/,&quot;&quot;,$4);gsub(/chr/,&quot;mt&quot;,$1); print $1,$4,$2,$3&#125;&#125;&#x27; &gt; medicago\_gff.tab</span><br></pre></td></tr></table></figure>
<p>得到gff格式文件如下。 soybean.gff</p>
<p><strong>注意</strong> gff 文件中别包含 contigs 和 scaffolds，最好只包含 chromosomes。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gm01 Glyma.01G000100 27354 28320</span><br><span class="line">gm01 Glyma.01G000200 58974 67527</span><br><span class="line">gm01 Glyma.01G000300 67769 69968</span><br><span class="line">gm01 Glyma.01G000400 90151 95947</span><br><span class="line">gm01 Glyma.01G000500 90288 91197</span><br><span class="line">gm01 Glyma.01G000600 116093 127845</span><br><span class="line">gm01 Glyma.01G000700 143466 155573</span><br><span class="line">gm01 Glyma.01G000800 157029 157772</span><br><span class="line">gm01 Glyma.01G000900 170533 193342</span><br><span class="line">gm01 Glyma.01G001000 196255 201895</span><br></pre></td></tr></table></figure>
<p>medicago.gff</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mt1 Medtr1g004930 688 7332</span><br><span class="line">mt1 Medtr1g004940 6523 7366</span><br><span class="line">mt1 Medtr1g004950 14513 15729</span><br><span class="line">mt1 Medtr1g004960 16282 18382</span><br><span class="line">mt1 Medtr1g006530 28972 29214</span><br><span class="line">mt1 Medtr1g004980 31972 32344</span><br><span class="line">mt1 Medtr1g004990 35909 40554</span><br><span class="line">mt1 Medtr1g006490 44429 46280</span><br><span class="line">mt1 Medtr1g006590 46547 50437</span><br><span class="line">mt1 Medtr1g006600 51360 54977</span><br></pre></td></tr></table></figure>
<p>随后对 CDS 序列文件进行整理，保留 primary transcripts 的序列。序列名称跟上面 gff 文件里面要一致。并灵活选用工具将 CDS 序列转换成蛋白序列，或者一开始就用蛋白序列也可以。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">awk &#x27;&#123;print $1&#125;&#x27; ../jcvi\_190704/Gmax\_275\_Wm82.a2.v1.cds.fa &gt; Gmax\_275\_Wm82.a2.v1.cds.fa\_simplified</span><br><span class="line">awk &#x27;&#123;print $1&#125;&#x27; ../jcvi\_190704/Mtruncatula\_285\_Mt4.0v1.cds.fa &gt; Mtruncatula\_285\_Mt4.0v1.cds.fa\_simplified</span><br><span class="line"></span><br><span class="line">fasta\_formatter -t -i Mtruncatula\_285\_Mt4.0v1.cds.fa\_simplified -o Mtruncatula\_285\_Mt4.0v1.cds.tab</span><br><span class="line">fasta\_formatter -t -i Gmax\_275\_Wm82.a2.v1.cds.fa\_simplified -o Gmax\_275\_Wm82.a2.v1.cds.tab</span><br><span class="line"></span><br><span class="line">cat Gmax\_275\_Wm82.a2.v1.cds.tab  awk &#x27;BEGIN&#123;OFS=&quot;\\t&quot;&#125;&#123;if(length($1) == 17 &amp;&amp; $1 ~ /\\.1$/)&#123;gsub(/\\.1$/,&quot;&quot;,$1); print &quot;\\&gt;&quot;$1&quot;\\n&quot;$2&#125;&#125;&#x27; &gt; soybean\_cds.fa</span><br><span class="line">cat Mtruncatula\_285\_Mt4.0v1.cds.tab  awk &#x27;BEGIN&#123;OFS=&quot;\\t&quot;&#125;&#123;if(length($1) == 15 &amp;&amp; $1 ~ /\\.1$/)&#123;gsub(/\\.1/,&quot;&quot;,$1); print &quot;\\&gt;&quot;$1&quot;\\n&quot;$2&#125;&#125;&#x27; &gt; medicago.cds.fa</span><br><span class="line">iTools Fatools CDS2Pep -InCDS soybean\_cds.fa -OutPut soybean\_pep.fa</span><br><span class="line">iTools Fatools CDS2Pep -InCDS medicago.cds.fa -OutPut medicago.pep.fa</span><br></pre></td></tr></table></figure>
<p>然后用 blastp 对两个物种的蛋白序列进行比对，并用 MCScanX 命令检测共线性区间。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">makeblastdb -in medicago.pep.fa -dbtype prot -out index/mt -parse\_seqids</span><br><span class="line">## diamond makedb --in medicago.pep.fa --db ./diamond\_index/mt</span><br><span class="line">## diamond blastp --query soybean\_pep.fa --evalue 1e-5 --outfmt 6 --threads 24 --db ./diamond\_index/mt.dmnd --out soybean\_medicago.blast</span><br><span class="line">blastp -query soybean\_pep.fa -db index/mt -out gm\_mt.blast -evalue 1e-5 -num\_threads 24 -outfmt 6 -num\_alignments 5</span><br><span class="line">mkdir mcdata</span><br><span class="line">cp gm\_mt.blast mcdata</span><br><span class="line">cat soybean.gff medicago.gff &gt; mcdata/gm\_mt.gff</span><br><span class="line">MCScanX ./mcdata/gm\_mt</span><br></pre></td></tr></table></figure>
<p>产生的线性文件（gm_mt.collinearity）如下，可以用于下游画图。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">\[fenglei@localhost gm\_mt\_test\]$ head -n 50 gm\_mt.collinearity </span><br><span class="line">############### Parameters ###############</span><br><span class="line"># MATCH\_SCORE: 50</span><br><span class="line"># MATCH\_SIZE: 5</span><br><span class="line"># GAP\_PENALTY: -1</span><br><span class="line"># OVERLAP\_WINDOW: 5</span><br><span class="line"># E\_VALUE: 1e-05</span><br><span class="line"># MAX GAPS: 25</span><br><span class="line">############### Statistics ###############</span><br><span class="line"># Number of collinear genes: 51572, Percentage: 49.62</span><br><span class="line"># Number of all genes: 103927</span><br><span class="line">##########################################</span><br><span class="line">## Alignment 0: score=1008.0 e\_value=1.4e-69 N=23 gm01&amp;mt1 plus</span><br><span class="line">0- 0: Glyma01G232800 Medtr1g103160 0</span><br><span class="line">0- 1: Glyma01G234900 Medtr1g103450 8e-39</span><br><span class="line">0- 2: Glyma01G235100 Medtr1g103490 0.0001</span><br><span class="line">0- 3: Glyma01G236800 Medtr1g103500 2e-87</span><br><span class="line">0- 4: Glyma01G237000 Medtr1g103550 9e-47</span><br><span class="line">0- 5: Glyma01G237300 Medtr1g103570 2e-45</span><br><span class="line">0- 6: Glyma01G237400 Medtr1g103600 1e-144</span><br><span class="line">0- 7: Glyma01G237900 Medtr1g103690 9e-39</span><br><span class="line">0- 8: Glyma01G238200 Medtr1g103830 0</span><br><span class="line">0- 9: Glyma01G238400 Medtr1g104500 1e-170</span><br><span class="line">0- 10: Glyma01G238500 Medtr1g104520 6e-33</span><br><span class="line">0- 11: Glyma01G238700 Medtr1g104680 0</span><br><span class="line">0- 12: Glyma01G238800 Medtr1g104750 0</span><br><span class="line">0- 13: Glyma01G238900 Medtr1g104800 2e-80</span><br><span class="line">0- 14: Glyma01G239200 Medtr1g104870 0</span><br><span class="line">0- 15: Glyma01G239400 Medtr1g104930 1e-50</span><br><span class="line">0- 16: Glyma01G239800 Medtr1g105075 1e-32</span><br><span class="line">0- 17: Glyma01G239900 Medtr1g105305 5e-101</span><br><span class="line">0- 18: Glyma01G240000 Medtr1g105415 3e-91</span><br><span class="line">0- 19: Glyma01G240500 Medtr1g105555 5e-62</span><br><span class="line">0- 20: Glyma01G240600 Medtr1g105570 6e-06</span><br><span class="line">0- 21: Glyma01G240800 Medtr1g105650 2e-175</span><br><span class="line">0- 22: Glyma01G240900 Medtr1g105655 4e-164</span><br><span class="line">## Alignment 1: score=741.0 e\_value=1e-39 N=16 gm01&amp;mt1 plus</span><br><span class="line">1- 0: Glyma01G084800 Medtr1g093020 0</span><br><span class="line">1- 1: Glyma01G086700 Medtr1g093080 1e-138</span><br><span class="line">1- 2: Glyma01G086800 Medtr1g093095 2e-108</span><br><span class="line">1- 3: Glyma01G087500 Medtr1g093600 5e-175</span><br><span class="line">1- 4: Glyma01G087700 Medtr1g093630 0</span><br><span class="line">1- 5: Glyma01G088000 Medtr1g093650 8e-07</span><br><span class="line">1- 6: Glyma01G088200 Medtr1g093670 9e-115</span><br><span class="line">1- 7: Glyma01G088300 Medtr1g093750 1e-118</span><br><span class="line">1- 8: Glyma01G089100 Medtr1g093770 0</span><br><span class="line">1- 9: Glyma01G089300 Medtr1g093850 0</span><br><span class="line">1- 10: Glyma01G089900 Medtr1g093860 0</span><br><span class="line">1- 11: Glyma01G090200 Medtr1g093900 0</span><br><span class="line">1- 12: Glyma01G090400 Medtr1g093920 9e-22</span><br><span class="line">1- 13: Glyma01G091000 Medtr1g094010 0</span><br></pre></td></tr></table></figure>
<p>注意画图的配置文件不要出错，双斜杠（//）表示注释，注释号前面用tab符号跟染色体名称分隔，或者干脆去掉注释，我删掉注释才顺利画图，否则报错。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[fenglei@localhost gm\_mt\_test\]$ cat dot.ctl</span><br><span class="line">2000</span><br><span class="line">2000</span><br><span class="line">gm01,gm02,gm03,gm04,gm05,gm06,gm07,gm08,gm09,gm10,gm11,gm12,gm13,gm14,gm15,gm16,gm17,gm18,gm19,gm20</span><br><span class="line">mt1,mt2,mt3,mt4,mt5,mt6,mt7,mt8</span><br></pre></td></tr></table></figure>
<p>画图命令。注意 dot_plotter.java 与 dot_plotter .class 要在一个文件夹下面。其他环状图做法也类似。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /PATH_TO_MCScanX/downstream_analyses</span><br><span class="line">DATA_PATH=/xx/my/mcdata  # 根据实际情况</span><br><span class="line">java dot_plotter -g $DATA_PATH/gm_mt.gff -s $DATA_PATH/gm_mt.collinearity -c $DATA_PATH/dot.ctl -o gm_mt.test.png</span><br></pre></td></tr></table></figure>
<p>画图结果：</p>
<p><img src="https://genehub.files.wordpress.com/2019/07/gm_mt.test_.png" alt="gm_mt.test" /></p>
<p>与文献（ Wang Jinpeng et al., 2017, Plant Physiol.）中的图片对比，基本是一样的效果。</p>
<p><img src="https://genehub.files.wordpress.com/2019/07/mt4_gm.order_.png" alt="mt4_gm.order" /></p>
<p>这个 MCScanX 共线性图跟更新开发的 jcvi 相比，画质要差一些。下面是 jcvi 的结果。</p>
<p><img src="https://i.imgur.com/Ly4FSpT.png" alt="jcvi 绘制的基因组共线性图实例" /></p>
<p>MCScanX 还可以将图画成圆形。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java circle_plotter -g /home/fenglei/projects/genome_synteny_20190704/MCScanX_soybean_medicago_190705/gm_mt_test/MADS-master/MADS.gff -s /home/fenglei/projects/genome_synteny_20190704/MCScanX_soybean_medicago_190705/gm_mt_test/MADS-master/MADS.collinearity -c /home/fenglei/projects/genome_synteny_20190704/MCScanX_soybean_medicago_190705/gm_mt_test/MADS-master/circle.ctl -o MADS.png</span><br></pre></td></tr></table></figure>
<p><strong>注意</strong> circle_plotter 的 dot.ctl 文件与 dot_plotter 的 dot.ctl 文件不一样。</p>
<p>For circle_plotter , put chromosome IDs in one line in dot.ctl file.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2000</span><br><span class="line">Gm01,Gm02,Gm03,Gs01,Gs02,Gs03</span><br></pre></td></tr></table></figure>
<p>For dot_plotter, put chromosome IDs in two lines in dot.ctl file</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2000</span><br><span class="line">2000</span><br><span class="line">Gm01,Gm02,Gm03</span><br><span class="line">Gs01,Gs02,Gs03</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cat /home/fenglei/projects/genome_synteny_20190704/MCScanX_soybean_medicago_190705/gm_mt_test/MADS-master/circle.ctl</span><br><span class="line">1600    //plot width and height (in pixels)</span><br><span class="line">Chr1,Chr2,Chr3,Chr4,Chr5,Chr6,Chr7,Chr8,Chr9,Chr10,Chr11,Chr12,Chr13,Chr14,Chr15,Chr16,Chr17    //chromosomes in the circle</span><br></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/lRwZIhA.png" alt="" /></p>
<h3 id="mcscanx-与-jcvi-的比较"><a class="markdownIt-Anchor" href="#mcscanx-与-jcvi-的比较"></a> MCScanX 与 jcvi 的比较</h3>
<p>在基因组进化分析的 paralogous genes 鉴定中，MCScanX 与 jcvi 都可以用，有什么区别？从下面两幅图来看，jcvi 绘制的图片更有观赏性，而且 jcvi 能识别出这是一个物种内部（intra-genomic comparison）的 paralogous genes。</p>
<p>MCScanX：2019年基于a2v1的基因组数据。一共 1112 synteny blocks，35094 个两两配对。Number of collinear genes: 37190, Percentage: 66.90，Number of all genes: 55589。</p>
<p><img src="https://i.imgur.com/cAzbMcg.png" alt="MCScanX 分析 soybean 基因组内部的 synteny blocks" /></p>
<p>jcvi：2021年基于a4v1的基因组数据。一共 472 synteny blocks，18439个两两配对。</p>
<p><img src="https://i.imgur.com/6P2ig8r.jpeg" alt="jcvi 分析 soybean 基因组内部的 synteny blocks" /></p>
<p>看来 MCScanX 的结果更全面？以基因 <code>Glyma.01G210400</code> 为例，通过 MCScanX 可以找到另外三个旁系同源基因（paralogous），而通过 jcvi 只找到一个旁系同源基因。难怪在 2021 年的时候测试 4dtv 计算的时候，我发现 MCScanX 的结果更适合做 4dtv 计算，原因是它鉴定的 paralogous 更合理。当然，也有可能是 jcvi 的参数设计原因，我用的默认参数，没有进行额外设置。</p>
<p>MCScanX：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost mcdata]$ cat soybean.collinearity | grep &#x27;Glyma.01G210400&#x27;</span><br><span class="line"> 28- 43:        Glyma.01G210400 Glyma.05G058100       0</span><br><span class="line"> 71-432:        Glyma.01G210400 Glyma.11G031600   5e-82</span><br><span class="line"> 88-129:        Glyma.01G210400 Glyma.17G140600       0</span><br></pre></td></tr></table></figure>
<p>jcvi：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost gmo-gmo]$ cat gma.gma.anchors | grep &#x27;Glyma.01G210400&#x27;</span><br><span class="line">Glyma.01G210400.2       Glyma.17G140600.1       1030</span><br></pre></td></tr></table></figure>
<p><em>END</em></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>RNA Seq转录组测序质控工具：Kraken</title>
    <url>/2016/02/28/Bioinfo-RNA-seq-QC-by-kraken/</url>
    <content><![CDATA[<h2 id="kraken-a-set-of-tools-for-quality-control-and-analysis-of-high-throughput-sequence-data"><a class="markdownIt-Anchor" href="#kraken-a-set-of-tools-for-quality-control-and-analysis-of-high-throughput-sequence-data"></a> Kraken: A set of tools for quality control and analysis of high-throughput sequence data</h2>
<p>Matthew P.A. Davis, Stijn van Dongen, Cei Abreu-Goodger, Nenad Bartonicek and Anton J. Enright <em>Methods (2013) - Volume 63, Issue 1, 1 September 2013, Pages 41–49</em></p>
<h3 id="11-october-2013"><a class="markdownIt-Anchor" href="#11-october-2013"></a> <strong>11 October 2013</strong></h3>
<h3 id="version-13-274-of-kraken-has-been-released-in-the-form-of-seqimp-13-274tgz-and-reaper-13-274tgz-see-below-this-fixes-the-following-bugs"><a class="markdownIt-Anchor" href="#version-13-274-of-kraken-has-been-released-in-the-form-of-seqimp-13-274tgz-and-reaper-13-274tgz-see-below-this-fixes-the-following-bugs"></a> <strong>Version 13-274 of Kraken has been released, in the form of seqimp-13-274.tgz and reaper-13-274.tgz (see below). This fixes the following bugs:</strong></h3>
<ul>
<li>Versions 2.14 and 3.0 of R contain a bug in the RUtils package. This is affecting how the Kraken tools pass options to R. The R developers are aware and are fixing this bug. The previous version of Kraken (13-095) will not work with these versions of R.</li>
<li>Tally would hang indefinitely on very small input files, due to a missed check on unrealistically small hash sizes.</li>
</ul>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | Positive Selection Ka/Ks calculation</title>
    <url>/2021/10/01/Bioinfo-Positive-Selection-Ka-Ks-calculation/</url>
    <content><![CDATA[<p>总结正向选择分析的一些知识。2017 年做过一次线粒体基因的正向选择，相关内容已经<a href="https://link.springer.com/article/10.1007%2Fs00606-019-01578-2#Sec18">发表</a>，并且我在Supplementary Files 里附上了我的<a href="https://static-content.springer.com/esm/art%3A10.1007%2Fs00606-019-01578-2/MediaObjects/606_2019_1578_MOESM1_ESM.pdf">分析代码</a>。2021年再次需要做正向选择分析，再次回顾以前的工作，发现其中也有一个问题，就是没有做统计检验，推算P值，再次学习正向选择分析，并摘抄一些网络资料并整理记录。Codeml 的学习成本比较高，原理与操作都不易理解，学习的过程中发现不少好资源，比如 B 站有<a href="https://www.bilibili.com/video/BV1Qx411m7Bn?from=search&amp;seid=9774626637377853773&amp;spm_id_from=333.337.0.0">视频</a>讲解如何使用 codeml 推断特定分支的 ω 值（dN/dS），以及使用卡方检验来计算 P 值。另外有国内的团队以 codeml 为内核，用 java 编写了更友好的操作界面：<a href="http://blog.sciencenet.cn/home.php?mod=space&amp;uid=460481&amp;do=blog&amp;id=1163040">EasyCodeML</a>。</p>
<p><img src="https://d3i71xaburhd42.cloudfront.net/aac1c83c6feff2575f6296ea4751f29c0fec42a1/12-Figure8-1.png" alt="我计算 8 个物种的线粒体基因的 Ka/Ks，但是没有计算 P 值" /></p>
<h3 id="基因正选择分析原理"><a class="markdownIt-Anchor" href="#基因正选择分析原理"></a> <a href="http://www.chenlianfu.com/?p=3084">基因正选择分析原理</a></h3>
<p>下文由 <a href="http://www.chenlianfu.com/?p=3084">chenlianfu.com</a> 发表于2019 年 11 月 18 日</p>
<p><strong>一、 正选择分析的目的</strong></p>
<p>两两基因的密码子序列进行比较，从而计算 dN/dS，即 omega（ω）值。若该值 &lt; 1，则表示纯化选择；omega = 1，则中性进化；omega &gt; 1，则正选择。若分析基因在两个物种中的序列，可以计算 dN/dS 的值，若 omega &gt; 1，即表明该基因在物种进化过程中，即由其祖先物种分化成这两个物种时，基因受到了正选择。对于两个物种/序列的正选择分析，比较简单。而实际情况中，要分析的物种数量很多，包含多个类群。这个时候的正选择分析相对复杂些。</p>
<p>对多个物种的基因序列进行正选择分析，若仍然按照两个物种时的要求，即分析该基因在物种进化中是否受到了正选择？这种结果可能不好说清楚。因为该基因可能在某一类群中序列很相似，其两两比较时，omega &lt;= 1；而在另外一类群中两两比较时，很多时候 omega &gt; 1。最后软件可以从总体上给一个 omega 值，该值不可以拿来简单地评价该基因是否受到了正选择。所以，对多个物种进行正选择分析时，没法直接评价该基因是否受到了正选择。正选择只有在进行两两序列比较的时候，才能计算 omega 值，从而得到结果。</p>
<p>对基因在多个物种上的正选择分析，分析的目的则是：比较某个分枝上祖先节点和后裔节点（可以理解成，对无根树上某分枝两侧的两组物种进行比较，依然属于两两比较），从而计算该分枝的 omega 值。而在实际数据中，基因在不同的进化分枝上具有不同的 omega 值，同时在序列不同的位点也具有不同的 omega 值。目标分枝两侧的物种数量较多时，可以对序列上的每个位点进行 omega 值分析，从而鉴定正选择位点。所以，对基因在多个物种上的正选择分析，需要同时分析目标分枝的 omega 值和序列位点的 omega 值，从而判断基因是否受到正选择压。</p>
<p><strong>二、使用 PAML 对基因进行正选择分析，有三种方法</strong></p>
<p>PAML site model: 主要用于检测基因中的正选择位点。该方法分析时，认为进化树中各分枝的 omega 值是一致的，并比较两种模型：(1) 模型 m1 是 null model，认为所有位点的 omega 值&lt;1 或 =1; (2) 模型 m2 是正选择模型，存在 omega &lt;1、=1 或 &gt;1 的位点。比较两个模型的似然值（lnL）差异，利用卡方检验（自由度为2）算出 p 值。若 p 值 &lt; 0.05，则否定 null model，认为存在正选择位点。此外，推荐采用比较模型 m7 和 m8，它们将 omega 值分成了 10 类，其 p 值结果比上一种比较方法更宽松，能检测到更多的正选择基因。使用 PAML site model 方法能在整体水平上检测基因的正选择位点，而不能表明基因在某个进化分枝上是否受到正选择压。</p>
<p><font color=blue>PAML branch-site model: 主要用于检测基因在某个进化枝上是否存在正选择位点。该分析方法认为目标分化枝具有一个 omega 值，其它所有分枝具有一个相同的 omega 值，然后再检测正选择位点。同样对两种模型进行比较：（1）第一种模型为模型2，将 omega 值分成 &lt;1、=1、&gt;1 的三类，这和 site model 中的一样；（2）第二种模型和前者一致，只是将 omega 固定成 1，作为 null model。比较两种模型的似然差异，利用卡方检验（自由度为2）算 p 值（chi2 命令算出的值除以2）。若 p 值 &lt; 0.05，则能通过 Bayes Empirical Bayes (BEB) 方法计算正选择位点的后验概率</font>，若存在概率值 &gt; 0.95 正选择位点，则表示基因在目标分枝上受到正选择压。<u><font color=red>PAML 软件在 branch-site 模式下，并不给出分枝上的 omega 值。</font></u>这表示 branch-site 模式虽然考虑了目标分枝上具有不同的 omega 值，但仍然以分析位点上的 omega 为主。值得注意的是，在 branch-site 模式下可能检测到正选择位点，但在目标分枝上的 omega 值仍然可能低于 1。可能软件作者基于这点考虑，就没有给出目标分枝上的 omega 值，以免影响一些人对正选择结果的判断。</p>
<p>PAML branch model: 主要用于检测在某个分枝上，其 omega 值是否显著高于背景分枝，即基因在目标分枝上进化速度加快。该方法认为基因序列上所有位点的 omega 值是一致的，对两种模型进行比较：（1）第一种模型为 null model，所有分枝具有相同的 omega 值；（2）第二种模型认为目标分枝具有一个 omega 值，其它所有分枝具有一个相同的 omega 值。比较两种模型的似然差异，利用卡方检验（自由度为1）算 p 值。若 p 值 &lt;= 0.05，且目标分枝上的 omega 值高于背景值，则认为该基因为快速进化基因。一般情况下，该方法计算得到的 p 值会低于第二种方法的结果。</p>
<p><strong>三、其它注意事项</strong></p>
<p>Branch-site model 相比于 site model 的优点是考虑了不同的分枝具有不同的选择压，即具有不同的 omega 值。该方法让目标分枝具有一个不同的 omega 值，并没有让所有分枝的 omega 值独立进行计算（理论上这样是最好的）。这样算法很复杂，程序运行非常非常消耗时间。但其实也没必要这样做，因为正选择分析其实是两条序列比较后，分析 dN/dS，再找正选择位点，其分析结果就应该是某个分枝上基因是否受到正选择，在序列那个位点上受到正选择。</p>
<p>若在目标分枝上，其 omega 值小于 1，但是却能找到正选择位点。即该基因在该分枝上的 dN/dS &lt; 1，但是在某些位点上，dN/dS &gt; 1。那么该基因是否属于正选择基因？我认为：属于。之所以为正选择基因，主要是因为基因的个别位点或多个位点存在正选择。当只有个别位点受到正选择压力时，而其它多个位点存在纯化选择时，可能导致整体上的omega值小于1。此时，该基因也应该是属于正选择基因。</p>
<p><strong>四、参考文献中的正选择分析方法描述</strong></p>
<p>Science 文章<a href="https://science.sciencemag.org/content/364/6446/eaav6202"><em>《大规模反刍动物基因组测序与其独特性质的进化研究》</em></a> 中的正选择基因分析方法。</p>
<p>注：这篇文章做了几十个物种的从头测序与拼接，基本上由 Illumina 测序，说明该项目应该做了挺多年，基因组拼接的质量放在今天来说不算好，大部分物种的 contig N50 不到 50 Kb，后期的比较基因组学分析做的好。主要目的是研究反刍动物特性，例如用于反刍的瘤胃、可再生的骨质角、不同物种巨大的身高差异等。主要手段是研究基因的选择压力。分析思路值得学习，其<a href="https://www.science.org/doi/suppl/10.1126/science.aav6202/suppl_file/aav6202-chen-sm.pdf"><em>附件</em></a>包含大量中间数据，可作为学习参考。</p>
<p><strong>Identification of positively selected genes (PSGs).</strong> We used a conserved genome synteny methodology to establish a highconfidence orthologous gene set that included camel, cat, dog, horse, human, minke whale, killer whale, pig, and the 51 ruminant species. Briefly, pairwise WGAs were constructed for relevant genomes using LAST, with the goat genome serving as the reference genome. To minimize the effect of annotation, sequencing and assembly errors, pseudogenes, nonorthologous alignments, and non-conserved gene structures 22 on subsequent evolutionary rate analyses, a series of rigorous filtering criteria were adopted: (1) the genes mapped to the goat genome via a single chain of sequence alignments including at least 80% of its coding sequence (CDS), and met the alignment length/score thresholds required for inclusion in the MULTIZ alignments; (2) frame-shift indels in CDSs were prohibited; (3) CDSs with premature stop codons were excluded and (4) genes with Ks values (synonymous substitutions per synonymous site) between each species and cattle larger than two were excluded. As the number of available species for each gene increased, the Codeml running time dramatically increases because of the power function relation between the number of tree leaves and branches. As a trade-off, we subsampled the ruminant species by using the following criteria: (1) if an ortholog existed in more than four species in the Cervidae or Bovidae lineage, we randomly selected 4 sequences to represent either family in order to reduce computational demand; (2) genes contained in less than 4 outgroup species were excluded; (3) genes recovered in fewer than 3 ruminant families were excluded and (4) final alignments shorter than 150 bp were discarded. After these filtering steps, a total of 12,977 genes were retained, and on average ~6.6 families containing ~19.8 species were retained for each ortholog <font color=blue>(fig. S51)</font>. The tree topology shown in Fig. 1A was used as the prior tree topology, and the “<em>ape</em>” package (164) was used to estimate the unrooted tree topology for each ortholog.</p>
<p>To estimate the lineage-specific evolutionary rate for each branch, the Codeml program in the PAML package (version 4.8) (134) with the free-ratio model (model = 1) was run for each ortholog. <font color=blue>Positive selection signals on genes along specific lineages were detected using the optimized branch-site model following the author’s recommendation. A likelihood ratio test (LRT) was conducted to compare a model that allowed sites to be under positive selection on the foreground branch with the null model in which sites could evolve either neutrally and under purifying selection. The p values were computed based on Chi-square statistics, and genes with p value less than 0.05 were treated as candidates that underwent positive selection.</font> We identified PSGs at the ancestral branch of Ruminantia (table S22), the ancestral branch of Pecora (table S23), each ancestral family branch of Ruminantia (tableS24), and each ancestral subfamily branch of Bovidae (table S24). We also compared the dN/dS values of Ruminantia families with outgroup mammals <font color=blue>(fig. S52)</font>.</p>
<p><img src="https://i.imgur.com/a9XwYdx.png" alt="" /></p>
<p><img src="https://i.imgur.com/he2bRKC.png" alt="" /></p>
<p>Science 文章<a href="https://science.sciencemag.org/content/364/6446/eaav6202">《大规模反刍动物基因组测序与其独特性质的进化研究》</a> 中快速进化基因分析方法：The branch model in PAML was used, with the null model (model=0) assuming that all branches have been evolving at the same rate and the alternative model (model=2), allowing the foreground branch to evolve under a different rate. An LRT with df =1 was used to discriminate between alternative models for each ortholog in the gene set. Genes with a p value less than 0.05 and a higher ω value for the foreground than the background branches were considered as evolving with a significantly faster rate in the foreground branch.</p>
<p><a href="https://journals.plos.org/plosntds/article?id=10.1371%2Fjournal.pntd.0007463">Identification of positively selected genes in human pathogenic treponemes: Syphilis-, yaws-, and bejel-causing strains differ in sets of genes showing adaptive evolution</a> 文献中对正选择基因的分析方法：</p>
<p><img src="https://i.imgur.com/35rVAXK.png" alt="" /></p>
<p>A calculation of mutational rate ratio ω between two gene sequences was the basis for the positive selection analysis. The ω was calculated as a ratio of nonsynonymous to synonymous mutational rates. The ratio indicates negative purifying selection (0 &lt; ω &lt; 1), neutral evolution (ω = 1), and positive selection (ω &gt; 1) [54]. A set of selected genes from complete genomes was tested relative to positive selection using the maximum likelihood method using the CODEML of the PAML software package [55]. PAML version 4 [56] and its user interface PAMLX [57] were used in our study. For each analyzed gene, its maximum likelihood phylogenetic tree was used as an input tree. The CODEML offers several different codon evolutionary models, and the statistical likelihood ratio test (LRT) was used to compare the codon evolutionary model to the null model. The Bayes empirical Bayes method (BEB) [58] was then used to evaluate the posterior probability of sites considered to have been positively selected.</p>
<p>The CODEML models could produce different results (i.e., a list of sites under positive selection) since they calculate different parameter estimates. Site models allow ω to vary in each site (codon) within the gene. Statistical testing was required for sites with ω &gt; 1. Two pairs of models were predominantly used since their LRTs have low false-positive rates. M1a (nearly neutral evolution) was compared to M2a (positive selection) [58,59] and M7 (beta) was compared to M8 (beta &amp; ω) [60]. Our preliminary testing found that the two model pairs gave the same or very similar results. Therefore we chose to use the M7-M8 model pair. The M7 model is a null model that allows 10 classes of sites with a ω beta-distribution within the interval 0 ≤ ω ≤ 1. Sites with ω &gt; 1 are not allowed. The alternative M8 model adds an eleventh class of sites with ω &gt; 1. Each site was tested to determine the class to which it belongs. The LRT compares twice the log-likelihood difference 2Δl = 2(l1-l0) between the M7 model (log likelihood value l0) and the M8 model (log likelihood value l1) to the χ2 distribution [61]. If the twice log-likelihood difference is above a critical χ2 value, then the null model is rejected, and the positive selection is statistically significant.</p>
<p>A considerable disadvantage of the site models is that ω was calculated as an average over all codons of the site. Therefore, the site models are not suitable for the data where ω also varies between lineages. In contrast, the branch-site models search for positive selection in sites and pre-specifies lineages where different rates of ω may occur [62]. Sequences of lineages are a priori divided into a group of foreground lineages where positive selection may occur and group of background lineages where only purifying selection or neutral evolution occurs. We used branch-site model A, which allows four classes of sites and different setups of foreground lineages to be tested depending on the gene phylogeny. In branch-site model A, all lineages under purifying selection with a low value of ω0 belong to site class 0. Weak purifying selection and neutral evolution with ω1 near to value 1 are allowed in site class 1. In site class 2a, a proportion of class 0 sites in foreground lineages is under positive selection with ω2 &gt; 1. Similarly, site class 2b is a proportion of class 1 sites under positive selection with ω2 &gt; 1. The null model for LRT has ω2 = 1. Critical values of LRT (2Δl) are 2.71 at 5% and 5.41 at 1% [63]. The posterior probabilities of suggested sites under positive selection were calculated using the BEB method.</p>
<h3 id="基因-positive-selecetion-分析过程"><a class="markdownIt-Anchor" href="#基因-positive-selecetion-分析过程"></a> 基因 positive selecetion 分析过程</h3>
<p>PAML 软件中的 <code>codeml</code> 命令可以使用 Maxmum Likelihood 方法对密码子或氨基酸的多序列比对结果进行分析和进化参数计算 。这两种数据共用一个命令，程序运行时的参数绝大部分是公用的，但仍需要分清两种数据各自的参数意义。PAML软件中进行正选择分析的示例数据位于 <code>examples/lysozyme/</code> 目录下。</p>
<ol>
<li>基因序列准备，对于选定的若干个物种，分别准备它们的基因的 CDS 序列（DNA 格式），要注意每个基因只保留一个转录本即可；另外对序列名进行手动调整，使序列名具有独特性，易识别性，主要是为了便于后续的程序自动循环处理。并将基因 CDS 分别翻译成蛋白序列，注意这一步可能会出现的问题，比如不少物种的基因组文章即使发表在高分杂志上，它的基因集并不一定是完美的，以花生为例，我发现有数个基因CDS直接翻译之后会在序列中间出现终止密码子，这种现象可能是基因组突变，也有可能是基因注释过程中引入的小错误，还有一个我发现有些基因的CDS序列起始并不是ATG这种起始密码子（不排除是 RNA editing 现象），那用普通翻译程序可能就会出现翻译错误。所以针对各个物种，最好分别检查，灵活处理，比如移除这些包含错误的基因，或者直接使用物种自带的蛋白序列集。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#########################################################################</span><br><span class="line"># File Name: loop.sh</span><br><span class="line"># Author: fenglei</span><br><span class="line"># Mail: fengleiluck@gmail.com</span><br><span class="line"># Created Time: Fri 08 Oct 2021 04:14:35 PM CST</span><br><span class="line">#########################################################################</span><br><span class="line">#!/usr/bin/bash</span><br><span class="line">set -e</span><br><span class="line">set -u</span><br><span class="line">set -o pipefail</span><br><span class="line"></span><br><span class="line">for i in Ammopiptanthus_nanus.cds.fa Lotus_japonicus.cds.fa Glycine_max.cds.fa Medicago_truncatula.cds.fa Vigna_angularis.cds.fa Arachis_ipaensis.cds.fa Lupinus_angustifolius.cds.fa; do</span><br><span class="line">        #prefix=$&#123;i#*.cds&#125;;</span><br><span class="line">        prefix=$&#123;i%%.cds*&#125;;</span><br><span class="line">        echo [`date +&quot;%Y-%m-%d %H:%M:%S&quot;`] &quot;#&gt; Processing $prefix&quot;</span><br><span class="line">        iTools Fatools CDS2Pep -InCDS $&#123;prefix&#125;.cds.fa -OutPut  $&#123;prefix&#125;.pep_iTools.fa # 可能翻译的序列种存在终止密码子</span><br><span class="line">        gunzip *gz</span><br><span class="line">        perl pep_seq_clean.pl $&#123;prefix&#125;.pep_iTools.fa $&#123;prefix&#125;.pep.fa</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>上面的循环脚本中调用了一个序列清理程序，如下，可以去掉中间含有星号的氨基酸序列，也可以移除蛋白序列尾部的终止密码子形成的星号。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cat pep_seq_clean.pl</span><br><span class="line">#!/usr/bin/perl</span><br><span class="line"></span><br><span class="line">#/*************************************************************************</span><br><span class="line">#       &gt; File Name: seq_clean.pl</span><br><span class="line">#       &gt; Author: fenglei</span><br><span class="line">#       &gt; Mail: fengleiluck@gmail.com</span><br><span class="line">##      &gt; Created Time: Fri 08 Oct 2021 01:42:50 PM CST</span><br><span class="line"># ************************************************************************/</span><br><span class="line"></span><br><span class="line">#  如果氨基酸序列内部含有终止密码子，就去掉这个序列</span><br><span class="line">#  perl seq_clean.pl input.pep.fa output.pep.fa</span><br><span class="line"></span><br><span class="line">open INPUT, $ARGV[0] or die &quot;Can not open the file!\n $!&quot;;</span><br><span class="line">open OUTPUT, &quot;&gt;$ARGV[1]&quot; or die &quot;Can not open the file!\n $!&quot;;</span><br><span class="line">select OUTPUT;</span><br><span class="line"></span><br><span class="line">$/ = &quot;\&gt;&quot;;</span><br><span class="line">&lt;INPUT&gt;;</span><br><span class="line">while(&lt;INPUT&gt;)&#123;</span><br><span class="line">        chomp $_;</span><br><span class="line">        my $unit = $_;</span><br><span class="line">        my @array = split(/\n/, $unit);</span><br><span class="line">        my $seq_name = shift @array;</span><br><span class="line">        my $seq=&#x27;&#x27;;</span><br><span class="line">        foreach my $line (@array)&#123;</span><br><span class="line">                $seq = $seq . $line;</span><br><span class="line">        &#125;</span><br><span class="line">        #print  &quot;\&gt;$seq_name\n$seq\n&quot;; exit;</span><br><span class="line">        #print &quot;$_n&quot;; exit;</span><br><span class="line">        if($seq =~ /\*[A-Z]/i)&#123;    ### 如果中间出现终止密码子，将剔除这个序列，某物钟一共有大约100条这样的序列</span><br><span class="line">                #print &quot;\&gt;$seq_name\n$seq\n&quot;;</span><br><span class="line">        &#125;</span><br><span class="line">        else&#123;</span><br><span class="line">                #$seq =~ s/\*//;           ### 去掉尾部的星号</span><br><span class="line">                print &quot;\&gt;$seq_name\n&quot;;</span><br><span class="line">                #print &quot;\&gt;$seq_name\n$seq\n&quot;;</span><br><span class="line">                # 如何更美观的输出蛋白序列，每行100个氨基酸</span><br><span class="line">                my $len = length($seq)/100;</span><br><span class="line">                #print &quot;$len\n&quot;;</span><br><span class="line">                for(my $i=0; $i&lt;$len; $i++)&#123;</span><br><span class="line">                        my $sub_line = substr($seq, $i*100, 100);</span><br><span class="line">                        $seq =~ s/\*//;           ### 去掉尾部的可能的星号</span><br><span class="line">                        $sub_line =~ s/\*//;</span><br><span class="line">                        print &quot;$sub_line\n&quot;;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">close INPUT;</span><br><span class="line">close OUTPUT;</span><br></pre></td></tr></table></figure>
<p>用 orthofindr 程序寻找物种间的同源基因。我切换到的 Python37 环境，因为 orthofinder 是在这个环境下安装的，之前的博文有记录。</p>
<p>运行命令 <code>orthofinder -t 8 -f orthofinder_data_4 -S diamond</code> 即可进行同源基因寻找。生成的目录下会包含同源基因的列表和 Group 分组情况。下面截取的是程序刚运行的目录，所以只有部分数据呈现。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ tree orthofinder_data_4</span><br><span class="line">orthofinder_data_4</span><br><span class="line">├── XXX.fasta -&gt; ../pep_database/XXXXXXXX.pep.fa</span><br><span class="line">├── Arachis_ipaensis.pep.fa -&gt; ../pep_database/Arachis_ipaensis.pep.fa</span><br><span class="line">├── Cajanus_cajan.pep.fa -&gt; ../pep_database/Cajanus_cajan.pep.fa</span><br><span class="line">├── Lja.fasta -&gt; ../pep_database/Lotus_japonicus.pep.fa</span><br><span class="line">├── Lupinus_angustifolius.pep.fa -&gt; ../pep_database/Lupinus_angustifolius.pep.fa</span><br><span class="line">├── Mtr.fasta -&gt; ../pep_database/Medicago_truncatula.pep.fa</span><br><span class="line">├── OrthoFinder</span><br><span class="line">│   └── Results_Oct17</span><br><span class="line">│       ├── Log.txt</span><br><span class="line">│       └── WorkingDirectory</span><br><span class="line">│           ├── diamondDBSpecies0.dmnd</span><br><span class="line">│           ├── diamondDBSpecies1.dmnd</span><br><span class="line">│           ├── diamondDBSpecies2.dmnd</span><br><span class="line">│           ├── diamondDBSpecies3.dmnd</span><br><span class="line">│           ├── diamondDBSpecies4.dmnd</span><br><span class="line">│           ├── diamondDBSpecies5.dmnd</span><br><span class="line">│           ├── diamondDBSpecies6.dmnd</span><br><span class="line">│           ├── SequenceIDs.txt</span><br><span class="line">│           ├── Species0.fa</span><br><span class="line">│           ├── Species1.fa</span><br><span class="line">│           ├── Species2.fa</span><br><span class="line">│           ├── Species3.fa</span><br><span class="line">│           ├── Species4.fa</span><br><span class="line">│           ├── Species5.fa</span><br><span class="line">│           ├── Species6.fa</span><br><span class="line">│           ├── Species7.fa</span><br><span class="line">│           └── SpeciesIDs.txt</span><br><span class="line">├── Psa.fasta -&gt; ../pep_database/Pisum_sativum.pep.fa</span><br><span class="line">└── Van.fasta -&gt; ../pep_database/Vigna_angularis.pep.fa</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>序列比对，即 codon alignment，依据密码子来进行比对，比直接依据 DNA 比对更准确，比对结果存储为 paml 格式。PAL2NAL 软件可以设定输出格式，默认为 clustal 格式，需要设置为paml。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">set -e</span><br><span class="line">set -u</span><br><span class="line">set -o pipefail</span><br><span class="line">for i in `cat commn_genes_list`; do</span><br><span class="line">        echo [`date +&quot;%Y-%m-%d %H:%M:%S&quot;`] &quot;#&gt; sequence convertion and alignment: $&#123;i&#125;.fa&quot;;</span><br><span class="line">        cp ../01_fasta_files/$&#123;i&#125;.fa $&#123;i&#125;.nuc;</span><br><span class="line">        echo [`date +&quot;%Y-%m-%d %H:%M:%S&quot;`] &quot;#&gt; Proceccing $&#123;i&#125;.nuc ...&quot;;</span><br><span class="line">        iTools Fatools CDS2Pep -InCDS $&#123;i&#125;.nuc -OutPut $&#123;i&#125;.pep;</span><br><span class="line">        gunzip *gz;</span><br><span class="line">        clustalw2 -TYPE=PROTEIN -INFILE=$&#123;i&#125;.pep -ALIGN -OUTFILE=$&#123;i&#125;.pep.clustalw;</span><br><span class="line">        ~/local/app/PAL2NAL/pal2nal.pl $&#123;i&#125;.pep.clustalw $&#123;i&#125;.nuc -output paml -nogap &gt; $&#123;i&#125;.codon</span><br><span class="line">        echo;</span><br><span class="line">done</span><br></pre></td></tr></table></figure>
<p>一个基因 codon 比对的结果 paml 格式（the PHYLIP format）如下所示，首行两个数字，一个为物种数目，另一个为碱基数目。随后几行分布是物种名和去除 gap 的碱基序列。对于多个基因，可以直接用 cat 命令连接成一个文件，作为下一步 codeml 的输入。The first line contains the number of species and the sequence length (possibly followed by option characters). For codon sequences (codeml with seqtype = 1), the sequence length in the sequence file refers to the number of nucleotides rather than the number of codons.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">7  390</span><br><span class="line">Hsa_Human        AAGGTCTTTGAAAGGTGTGAGTTGGCCAGAACT...</span><br><span class="line">Hla_gibbon       AAGGTCTTTGAAAGGTGTGAGTTGGCCAGAACT...</span><br><span class="line">Cgu/Can_colobus  AAGATCTTTGAAAGGTGTGAGTTGGCCAGAACT...</span><br><span class="line">Pne_langur       AAGATCTTTGAAAGGTGTGAGTTGGCCAGAACT...</span><br><span class="line">Mmu_rhesus       AAGATCTTTGAAAGGTGTGAGTTGGCCAGAACT...</span><br><span class="line">Ssc_squirrelM    AAGGTCTTCGAAAGGTGTGAGTTGGCCAGAACT...</span><br><span class="line">Cja_marmoset     AAGGTCTTTGAAAGGTGTGAGTTGGCCAGAACT...</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>准备一个无根树</li>
</ol>
<p>我之前用过的无根树如下。newick格式，注意一定以分号结尾，否则 codeml 运行的结果中不会出现 Omema 值和 lnL 值。据我自己的经验，分析正向选择，有6~8个物种为宜，少了可能不准确，多了可能时间会很长。如果用有根树，codeml 会报错。无根树怎判断，首先可以用 Figtree 软件打开下面这个文件“unrooted_tree.txt”文件，默认的“rectangular form layput”显示下，从左侧起有 3 个分支，其实也可以直接肉眼看下面的文本内容，从最外层的括号观察，里面包含了 3 个分支。而root tree的图从最左侧开始看，只有2个分支。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$cat unrooted_tree.txt</span><br><span class="line">(((Vicia_faba, Medicago_truncatula), Lotus_japonicus),(Millettia_pinnata, ((Vigna_angularis, Vigna_radiata), Glycine_max)), Ammopiptanthus_mongolicus #1);</span><br></pre></td></tr></table></figure>
<p><a href="http://blog.sciencenet.cn/home.php?mod=space&amp;uid=1339458&amp;do=blog&amp;id=1023521"><strong>其他人的经验 1</strong></a>：制作tree文件。tree文件最简单的方法就是直接用Clustal制作，推荐 <a href="http://www.genome.jp/tools/clustalw/">http://www.genome.jp/tools/clustalw/</a>。将序列提交上去，点Execute Multiple Alignment，然后将结果里的dnd文件下载，改名为自己想要的文件+后缀名“.trees”。我这里保存为n1.trees。但是上Phylogenetics课程的时候问了老师一句关于拿Clustal建树用于PAML分析，得到的回答是:  Never, never use Clustal to build a tree。所以还是老老实实用正经的建树工具来做Newick格式的tree文件吧。</p>
<p><a href="http://www.chenlianfu.com/?p=3036"><strong>其他人的经验 2</strong></a>：输入一个树文件input.trees。该文件可以是有根树，也可以是无根树，也可以带有枝长信息。codeml命令用于分析各分枝上的omega值，若是有根树的话，对于分析root节点所在的分枝，其结果可能是不对的。因此，作者推荐使用无根树进行正选择分析。无根树是3分叉的树，最少需要3个物种；而3个物种的无根数有3个分枝（2n – 3），对其进行分析，仅能得到某个物种所对应分枝的omega值，这种情况下没太大意义；而使用4个物种的无根树进行分析，可以得到两个物种共同祖先分枝的omega值。故作者推荐使用至少4~5个物种进行分析。一个树文件内容示例。文件内容分两行：第一行表述树中有多少个物种，共计1个树，两个数值之间用任意长度的空分割。此外，Newick格式的树尾部一定要有分号，没有的话程序可能不能正常运行。</p>
<p><a href="https://www.bilibili.com/video/BV1Qx411m7Bn?from=search&amp;seid=9774626637377853773&amp;spm_id_from=333.337.0.0"><strong>其他人的经验 3</strong></a>：如果要计算某个分支，可以直接在分支后面加一个“$1”，即美元符号。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">7  1</span><br><span class="line">((Hsa_Human, Hla_gibbon) #1,((Cgu/Can_colobus, Pne_langur) #1, Mmu_rhesus), (Ssc_squirrelM, Cja_marmoset));</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">((Hsa_Human, Hla_gibbon), ((Cgu/Can_colobus, Pne_langur) $1, Mmu_rhesus), (Ssc_squirrelM, Cja_marmoset));</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>准备 codeml 的配置文件</li>
</ol>
<p>下面是从 &lt;<a href="http://chenlianfu.com">chenlianfu.com</a>&gt; 摘抄的一个配置案例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*输入输出参数：</span><br><span class="line">      seqfile = input.txt    *设置输入的多序列比对文件路径。</span><br><span class="line">     treefile = input.trees  *设置输入的树文件路径。</span><br><span class="line">      outfile = mlc          *设置输出文件路径。</span><br><span class="line">        noisy = 9            *设置输出到屏幕上的信息量等级：0，1，2，3，9。</span><br><span class="line">      verbose = 0            *设置输出到结果文件中的信息量等级：0，精简模式结果（推荐）；1，输出详细信息，包含碱基序列；2，输出更多信息。</span><br><span class="line">        getSE = 0            *设置是否计算并获得各参数的标准误：0，不需要；1，需要。</span><br><span class="line"> RateAncestor = 0            *设置是否计算序列中每个位点的替换率：0，不需要；1，需要。当设置成1时，会在结果文件rates中给出各个位点的碱基替换率；同时也会进行祖先序列的重构，在结果文件rst中有体现。</span><br><span class="line"></span><br><span class="line">*数据使用说明参数：</span><br><span class="line">      runmode = 0      *设置程序获取进化树拓扑结构的方法：0，直接从输入文件中获取进化树拓扑结构（推荐）；1，程序以输入文件中的多分叉树作为起始树，并使用星状分解法搜索最佳树；2，程序直接以星状树作为起始树，并使用星状分解法搜索最佳树；3，使用逐步添加法搜索最佳树；4，使用简约法获取起始树，再进行邻近分枝交换寻找最优树；5，以输入文件中的树作为起始树，再进行邻近分枝交换寻找最优树；-2，对密码子序列进行两两比较并使用ML方法计算DnDs，或对蛋白序列进行两两比较计算ML距离，而不进行其它参数（枝长和omega等）的计算。</span><br><span class="line">* fix_blength = 1      *设置程序处理输入树文件中枝长数据的方法：0，忽略输入树文件中的枝长信息；-1，使用一个随机起始进行进行计算；1，以输入的枝长信息作为初始值进行ML迭代分析，此时需要注意输入的枝长信息是碱基替换率，而不是碱基替换数；2，不需要使用ML迭代计算枝长，直接使用输入的枝长信息，需要注意，若枝长信息和序列信息不吻合可能导致程序崩溃；3，让ML计算出的枝长和输入的枝长呈正比。</span><br><span class="line">      seqtype = 1      *设置输入的多序列比对数据的类型：1，密码子数据；2，氨基酸数据；3，输入数据虽然为密码子序列，但先转换为氨基酸序列后再进行分析。</span><br><span class="line">    CodonFreq = 2      *设置密码子频率的计算算法：0，表示除三种终止密码子频率为0，其余密码值频率全部为1/61；1，程序分别计算三个密码子位点的四种碱基频率，再算四种碱基频率在三个位点上的算术平均值，计算61种密码子频率时，使用该均值进行计算，这61种密码子频率之和不等于1，然后对其数据标准化，使其和为1，得到所有密码子的频率；2，程序分别计算三个密码子位点的四种碱基频率，计算61种密码子频率时，使用相应位点的碱基频率进行计算，这61种密码子频率之和不等于1，然后对其数据标准化，使其和为1，得到所有密码子的频率；3，直接使用观测到的各密码子的总的频数/所有密码值的总数，得到所有密码子的频率。一般选择第三种方法，设置CodonFre的值为2。第一种方法让所有密码子频率相等，不符合实际轻卡；第二种方法没有考虑到三种位点各碱基频率的差异，得到的密码子频率不准确；第三种方法能比较准确计算出各密码子的频率；第四种方法由输入数据得到真实的各密码子频率，但有时候有些非终止密码子的频率为0，可能不利于后续的计算。</span><br><span class="line">    cleandata = 1      *设置是否移除不明确字符（N、？、W、R和Y等）或含以后gap的列后再进行数据分析：0，不需要，但在序列两两比较的时候，还是会去除后进行比较；1，需要。</span><br><span class="line">*       ndata = 1      *设置输入的多序列比对的数据个数。</span><br><span class="line">        clock = 0      *设置进化树中各分支上的变异速率是否一致，服从分子钟理论：0，变异速率不一致，不服从分子钟理论（当输入数据中物种相差较远时，各分支变异速率不一致）；1，所有分枝具有相同的变异速率，全局上服从分子钟理论；2，进化树局部符和分子钟理论，程序认为除了指定的分支具有不同的进化速率，其它分枝都具有相同的进化速率，这要求输入的进化树信息中使用#来指定分支；3，对多基因数据进行联合分析。</span><br><span class="line">        Mgene = 0      *设置是否有多个基因的多序列比对信息输入，以及多各基因之间的参数是否一致：0，输入的多序列比对文件中仅包含一个基因时，或多个基因具有相同的Kappa和Pi参数；1，输入文件包含多个基因，这些基因之间是相互独立的（这些基因之间具有不同的Kappa和Pi值，且其进化树的枝长也不相关）；2，输入文件包含多个基因，这些基因具有相同的Kappa值，不同的Pi值；3，输入文件包含多个基因，这些基因具有相同的Pi值，不同的Kappa值；4，输入文件包含多个基因，这些基因具有不同的Kappa值和不同的Pi值。当值是2、3或4时，多个基因的进化树枝长虽然长度不一样，但是呈正比关系。这点和参数值等于1是不一样的。</span><br><span class="line">        icode = 0      *设置遗传密码。其值1-10和NCBI的1-11遗传密码规则对应：0，表示通用的遗传密码。</span><br><span class="line">   Small_Diff = .5e-6  *设置一个很小的值，一般位于1e-8到1e-5之间。推荐检测设置不同的值在比较其结果，需要该参数值对结果没什么影响。</span><br><span class="line"></span><br><span class="line">*位点替换模型参数：</span><br><span class="line">        model = 1            *若输入数据是密码子序列，该参数用于设置branch models，即进化树各分枝的omega值的分布：0，进化树上所有分枝的omega值一致；1，对每个分枝单独进行omega计算；2，设置多类omega值，根据树文件中对分枝的编号信息来确定类别，具有相同编号的分枝具有相同的omega值，没有编号的分枝具有相同的omega值，程序分别计算各编号和没有编号的omega值。</span><br><span class="line">                             *若输入数据是蛋白序列，或数据是密码子序列且seqtype值是3时，该参数用于设置氨基酸替换模型：0，Poisson；1，氨基酸替换率和氨基酸的观测频率成正比；2，从aaRatefile参数指定的文件路径中读取氨基酸替换率信息，这些信息是根据经验获得，并记录到后缀为.dat的配置文件中。这些经验模型(Empirical Models)文件位于PAML软件安装目录中的dat目录下，例如，Dayhoff(dayhoff.dat)、WAG(wag.dat)、LG(lg.dat)、mtMAN(mtman.dat)和mtREV24(mtREV24.dat)等；</span><br><span class="line">   aaRatefile = dat/wag.dat  *当对蛋白数据进行分析，且model = 2时，该参数生效，用于设置氨基酸替换模型。</span><br><span class="line">       aaDist = 0            *设置氨基酸之间的距离。</span><br><span class="line">      NSsites = 0            *输入数据时密码子序列时生效，用于设置site model，即序列各位点的omega值的分布：0，所有位点具有相同的omega值；1，各位点上的omega值小于1或等于1（服从中性进化neutral）；2，各位点上的omega值小于1、等于1或大于1（选择性进化selection）；3，discrete；4，freq；5:gamma；6，2gamma；7，beta；8，beta&amp;w；9，beta&amp;gamma；10，beta&amp;gamma+1；11，beta&amp;normal&gt;1；12，0&amp;2normal&gt;1；13，3normal&gt;0。</span><br><span class="line">                             *可以一次输入多个模型进行计算并比较，其结果输出的rst文件中。</span><br><span class="line">    fix_alpha = 1            *序列中不同的位点具有不同的碱基替换率，服从discrete-gamma分布，该模型通过alpha（shape参数）和ncatG参数控制。该参数设置是否给定一个alpha值：0，使用ML方法对alpha值进行计算；1，使用下一个参数设置一个固定的alpha值。</span><br><span class="line">	                     *对于密码子序列，当NSsites参数值不为0或model不为0时，推荐设置fix_alpha = 1且alpha = 0，即不设置alpha值，认为位点间的变异速率一致，否则程序报错。若设置了alpha值，则程序认为不同密码子位点的变异速率不均匀，且同时所有位点的omega值一致，当然各分枝的omega值也会一致，这时要求NSsites和model参数值都设置为0（这一般不是我们需要的分析，它不能进行正选择分析了）。</span><br><span class="line">        alpha = 0            *设置一个固定的alpha值或初始alpha值（推荐设置为0.5）。该值小于1，表示只有少数热点位置的替换率较高；该值越小，表示位点替换率在各位点上越不均匀；若设置fix_alpha = 1且alpha = 0则表示所有位点的替换率是恒定一致的。</span><br><span class="line">       Malpha = 0            *当输入的多序列比对结果中有多基因时，设置这些基因间的alpha值是否相等：0，分别对每个基因单独计算alpha值；1，所有基因的alpha值保持一致。</span><br><span class="line">        ncatG = 5            *序列中不同位点的变异速率服从GAMMA分布的，ncatG是其一个参数，一般设置为5，4，8或10，且序列条数越多，该值设置越大。</span><br><span class="line">                             *对于密码子序列，当NSites设置为3时，ncatG设置为3；当NSites设置为4时，ncatG设置为5；当NSites值设置&gt;=5时，ncatG值设置为10。</span><br><span class="line">    fix_kappa = 0            *设置是否给定一个Kappa值：0，通过ML迭代来估算Kappa值；1，使用下一个参数设置一个固定的Kappa值。</span><br><span class="line">        kappa = 2            *设置一个固定的Kappa值，或一个初始的Kappa值。</span><br><span class="line">    fix_omega = 0            *设置是否给定一个omega值：0，通过ML迭代来估算Kappa值；1，使用下一个参数设置一个固定的omega值。 </span><br><span class="line">        omega = .4           *设置一个固定的omega值，或一个初始的omega值。</span><br><span class="line">       method = 0            *设置评估枝长的ML迭代算法：0，使用PAML的老算法同时计算所有枝长，在clock = 0下有效；1，PAML新加入的算法，一次对一个枝长进行计算，该算法仅在clock参数值为1，2或3下工作。</span><br></pre></td></tr></table></figure>
<p>下面是我自己用的一个配置</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#$ cat codeml-M0.ctl</span><br><span class="line">      seqfile = mtGenes.aligned.DNA.paml      * sequence data filename</span><br><span class="line">     treefile = unrooted_tree.txt      * tree structure file name</span><br><span class="line">      outfile = mtGenes.substitution           * main result file name</span><br><span class="line"></span><br><span class="line">      runmode = 0  * 0: user tree;  1: semi-automatic;  2: automatic</span><br><span class="line">                   * 3: StepwiseAddition; (4,5):PerturbationNNI; -2: pairwise</span><br><span class="line"></span><br><span class="line">      seqtype = 1  * 1:codons; 2:AAs; 3:codons--&gt;AAs</span><br><span class="line">    CodonFreq = 2  * 0:1/61 each, 1:F1X4, 2:F3X4, 3:codon table</span><br><span class="line"></span><br><span class="line">        ndata = 30 * number of gene alignments to be analysed</span><br><span class="line">        clock = 0  * 0:no clock, 1:clock; 2:local clock; 3:CombinedAnalysis</span><br><span class="line"></span><br><span class="line">        model = 2  * models for codons: 0:one, 1:b, 2:2 or more dN/dS ratios for branches</span><br><span class="line"></span><br><span class="line">      NSsites = 0  * 0:one w;1:neutral;2:selection; 3:discrete;4:freqs;</span><br><span class="line">                   * 5:gamma;6:2gamma;7:beta;8:beta&amp;w;9:beta&amp;gamma;</span><br><span class="line">                   * 10:beta&amp;gamma+1; 11:beta&amp;normal&gt;1; 12:0&amp;2normal&gt;1;</span><br><span class="line">                   * 13:3normal&gt;0</span><br><span class="line"></span><br><span class="line">        icode = 0  * 0:universal code; 1:mammalian mt; 2-10:see below</span><br><span class="line"></span><br><span class="line">    fix_omega = 0  * 1: omega or omega_1 fixed, 0: estimate </span><br><span class="line">        omega = .4 * initial or fixed omega, for codons or codon-based AAs</span><br><span class="line"></span><br><span class="line">    cleandata = 0  * remove sites with ambiguity data (1:yes, 0:no)?</span><br><span class="line"></span><br><span class="line">* Genetic codes: 0:universal, 1:mammalian mt., 2:yeast mt., 3:mold mt.,</span><br><span class="line">* 4: invertebrate mt., 5: ciliate nuclear, 6: echinoderm mt., </span><br><span class="line">* 7: euplotid mt., 8: alternative yeast nu. 9: ascidian mt., </span><br><span class="line">* 10: blepharisma nu.</span><br><span class="line">* These codes correspond to transl_table 1 to 11 of GENEBANK.</span><br></pre></td></tr></table></figure>
<p>下面是结果的展示。可以看到 w (dN/dS) for branches:  0.37585 0.22840，尾部的0.2284就是我们设置#1分支的ω，而第一个0.37585是其他分支的ω。由于所设定的物种的ω小于1，所以这个基因在该物种不是正向选择。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">TREE #  1:  (((8, 7), 5), (4, ((1, 2), 3)), 6);   MP score: 160</span><br><span class="line">check convergence..</span><br><span class="line">lnL(ntime: 13  np: 16):  -3122.716855      +0.000000</span><br><span class="line">   9..10   10..11   11..8    11..7    10..5     9..12   12..4    12..13   13..14   14..1    14..2    13..3     9..6  </span><br><span class="line"> 0.008466 0.038271 0.303083 0.013331 0.024760 0.007420 0.033139 0.020543 0.021931 0.003298 0.005453 0.018905 0.029024 0.643248 0.375846 0.228401</span><br><span class="line"></span><br><span class="line">Note: Branch length is defined as number of nucleotide substitutions per codon (not per neucleotide site).</span><br><span class="line"></span><br><span class="line">tree length =   0.52763</span><br><span class="line"></span><br><span class="line">(((8: 0.303083, 7: 0.013331): 0.038271, 5: 0.024760): 0.008466, (4: 0.033139, ((1: 0.003298, 2: 0.005453): 0.021931, 3: 0.018905): 0.020543): 0.007420, 6: 0.029024);</span><br><span class="line"></span><br><span class="line">(((Vicia_faba: 0.303083, Medicago_truncatula: 0.013331): 0.038271, Lotus_japonicus: 0.024760): 0.008466, (Millettia_pinnata: 0.033139, ((Vigna_angularis: 0.003298, Vigna_radiata: 0.005453): 0.021931, Glycine_max: 0.018905): 0.020543): 0.007420, Ammopiptanthus_mongolicus: 0.029024);</span><br><span class="line"></span><br><span class="line">Detailed output identifying parameters</span><br><span class="line"></span><br><span class="line">kappa (ts/tv) =  0.64325</span><br><span class="line"></span><br><span class="line">w (dN/dS) for branches:  0.37585 0.22840</span><br><span class="line"></span><br><span class="line">dN &amp; dS for each branch</span><br><span class="line"></span><br><span class="line"> branch          t       N       S   dN/dS      dN      dS  N*dN  S*dS</span><br><span class="line"></span><br><span class="line">   9..10     0.008  1077.6   338.4  0.3758  0.0020  0.0054   2.2   1.8</span><br><span class="line">  10..11     0.038  1077.6   338.4  0.3758  0.0091  0.0243   9.8   8.2</span><br><span class="line">  11..8      0.303  1077.6   338.4  0.3758  0.0723  0.1924  77.9  65.1</span><br><span class="line">  11..7      0.013  1077.6   338.4  0.3758  0.0032  0.0085   3.4   2.9</span><br><span class="line">  10..5      0.025  1077.6   338.4  0.3758  0.0059  0.0157   6.4   5.3</span><br><span class="line">   9..12     0.007  1077.6   338.4  0.3758  0.0018  0.0047   1.9   1.6</span><br><span class="line">  12..4      0.033  1077.6   338.4  0.3758  0.0079  0.0210   8.5   7.1</span><br><span class="line">  12..13     0.021  1077.6   338.4  0.3758  0.0049  0.0130   5.3   4.4</span><br><span class="line">  13..14     0.022  1077.6   338.4  0.3758  0.0052  0.0139   5.6   4.7</span><br><span class="line">  14..1      0.003  1077.6   338.4  0.3758  0.0008  0.0021   0.8   0.7</span><br><span class="line">  14..2      0.005  1077.6   338.4  0.3758  0.0013  0.0035   1.4   1.2</span><br><span class="line">  13..3      0.019  1077.6   338.4  0.3758  0.0045  0.0120   4.9   4.1</span><br><span class="line">   9..6      0.029  1077.6   338.4  0.2284  0.0054  0.0234   5.8   7.9</span><br><span class="line"></span><br><span class="line">tree length for dN:       0.1243</span><br><span class="line">tree length for dS:       0.3400</span><br><span class="line">dS tree:</span><br><span class="line">(((Vicia_faba: 0.192424, Medicago_truncatula: 0.008464): 0.024298, Lotus_japonicus: 0.015720): 0.005375, (Millettia_pinnata: 0.021039, ((Vigna_angularis: 0.002094, Vigna_radiata: 0.003462): 0.013924, Glycine_max: 0.012003): 0.013043): 0.004711, Ammopiptanthus_mongolicus: 0.023436);</span><br><span class="line">dN tree:</span><br><span class="line">(((Vicia_faba: 0.072322, Medicago_truncatula: 0.003181): 0.009132, Lotus_japonicus: 0.005908): 0.002020, (Millettia_pinnata: 0.007908, ((Vigna_angularis: 0.000787, Vigna_radiata: 0.001301): 0.005233, Glycine_max: 0.004511): 0.004902): 0.001770, Ammopiptanthus_mongolicus: 0.005353);</span><br><span class="line"></span><br><span class="line">w ratios as labels for TreeView:</span><br><span class="line">(((Vicia_faba #0.3758 , Medicago_truncatula #0.3758 ) #0.3758 , Lotus_japonicus #0.3758 ) #0.3758 , (Millettia_pinnata #0.3758 , ((Vigna_angularis #0.3758 , Vigna_radiata #0.3758 ) #0.3758 , Glycine_max #0.3758 ) #0.3758 ) #0.3758 , Ammopiptanthus_mongolicus #0.2284 );</span><br><span class="line"></span><br><span class="line">Time used:  0:05</span><br></pre></td></tr></table></figure>
<p>上述 ctl 文件中 model = 2，运行得到一个结果文件。然后将其中的 model 参数改为 0，再次运行，得到新的结果文件。那么现在有三个文件是我需要的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">all.genes.list</span><br><span class="line">result.branch_model_0.mcl</span><br><span class="line">result.branch_model_2.mcl</span><br></pre></td></tr></table></figure>
<p>我根据这三个文件，得到了下面的表格。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ perl chi2_calculator.pl </span><br><span class="line"># The number of &quot;genes, lnL0 number, lnL1 number&quot; are the same.</span><br><span class="line"># If you see this info, the data is probably OK.</span><br><span class="line">#Number Group   lnL0    lnL1    Omega_branch    Omega_controlP_value</span><br><span class="line">Number:1        atp1    lnL0:-3145.827397       lnL1:-3122.716855       Omega_branch:0.22840    Omega_control:0.37585   P_value:0.000000000</span><br><span class="line">Number:2        atp4    lnL0:-930.895378        lnL1:-930.038146        Omega_branch:0.45618    Omega_control:0.52692   P_value:0.424335018</span><br><span class="line">Number:3        atp6    lnL0:-1453.909109       lnL1:-1446.498209       Omega_branch:0.86281    Omega_control:0.37541   P_value:0.000604626</span><br><span class="line">Number:4        atp8    lnL0:-924.486129        lnL1:-914.009795        Omega_branch:1.75174    Omega_control:0.19043   P_value:0.000028196</span><br><span class="line">Number:5        atp9    lnL0:-333.236113        lnL1:-331.374307        Omega_branch:0.00010    Omega_control:0.39757   P_value:0.155391739</span><br><span class="line">Number:6        ccmB    lnL0:-1023.961013       lnL1:-1022.534291       Omega_branch:999.00000  Omega_control:0.56135   P_value:0.240094664</span><br><span class="line">Number:7        ccmC    lnL0:-1131.746218       lnL1:-1129.394721       Omega_branch:999.00000  Omega_control:0.39406   P_value:0.095226501</span><br><span class="line">Number:8        ccmFC   lnL0:-1950.197350       lnL1:-1948.956865       Omega_branch:0.42724    Omega_control:0.88398   P_value:0.289243901</span><br><span class="line">Number:9        ccmFN   lnL0:-2737.722421       lnL1:-2737.051425       Omega_branch:1.13399    Omega_control:0.65455   P_value:0.511199170</span><br><span class="line">Number:10       cob     lnL0:-1836.351940       lnL1:-1826.480046       Omega_branch:0.16318    Omega_control:0.22020   P_value:0.000051605</span><br><span class="line">Number:11       cox1    lnL0:-2381.442730       lnL1:-2354.196627       Omega_branch:0.09805    Omega_control:0.04898   P_value:0.000000000</span><br><span class="line">Number:12       cox3    lnL0:-1220.568961       lnL1:-1218.320955       Omega_branch:0.00010    Omega_control:0.53125   P_value:0.105609600</span><br><span class="line">Number:13       matR    lnL0:-3293.272506       lnL1:-3288.780620       Omega_branch:1.06998    Omega_control:0.46260   P_value:0.011199502</span><br><span class="line">Number:14       mttB    lnL0:-1110.395753       lnL1:-1109.356198       Omega_branch:1.07609    Omega_control:0.44712   P_value:0.353612004</span><br><span class="line">Number:15       nad1    lnL0:-1410.749338       lnL1:-1404.082741       Omega_branch:0.34165    Omega_control:0.13677   P_value:0.001272722</span><br><span class="line">Number:16       nad2    lnL0:-2199.786871       lnL1:-2187.259279       Omega_branch:0.80075    Omega_control:0.12534   P_value:0.000003625</span><br><span class="line">Number:17       nad3    lnL0:-537.855553        lnL1:-532.299091        Omega_branch:0.00010    Omega_control:0.27379   P_value:0.003862417</span><br><span class="line">Number:18       nad4    lnL0:-2549.647893       lnL1:-2546.428114       Omega_branch:0.25913    Omega_control:0.61043   P_value:0.039963889</span><br><span class="line">Number:19       nad4L   lnL0:-420.857873        lnL1:-413.049727        Omega_branch:0.00010    Omega_control:0.00010   P_value:0.000406411</span><br><span class="line">Number:20       nad5    lnL0:-2986.298356       lnL1:-2975.844248       Omega_branch:0.15621    Omega_control:0.26908   P_value:0.000028830</span><br><span class="line">Number:21       nad6    lnL0:-1099.896407       lnL1:-1092.361003       Omega_branch:0.54957    Omega_control:0.24816   P_value:0.000533846</span><br><span class="line">Number:22       nad7    lnL0:-1766.620230       lnL1:-1765.116602       Omega_branch:0.51002    Omega_control:0.42390   P_value:0.222322111</span><br><span class="line">Number:23       nad9    lnL0:-1032.089035       lnL1:-1031.583127       Omega_branch:999.00000  Omega_control:0.86278   P_value:0.602957841</span><br><span class="line">Number:24       rpl16   lnL0:-895.556806        lnL1:-891.758505        Omega_branch:0.27993    Omega_control:0.35303   P_value:0.022408812</span><br><span class="line">Number:25       rpl5    lnL0:-920.541028        lnL1:-919.686869        Omega_branch:0.86954    Omega_control:0.50538   P_value:0.425641005</span><br><span class="line">Number:26       rps10   lnL0:-603.758104        lnL1:-600.272712        Omega_branch:999.00000  Omega_control:0.30933   P_value:0.030641745</span><br><span class="line">Number:27       rps12   lnL0:-613.237087        lnL1:-609.335187        Omega_branch:999.00000  Omega_control:0.21780   P_value:0.020203488</span><br><span class="line">Number:28       rps14   lnL0:-493.189267        lnL1:-491.210035        Omega_branch:0.26530    Omega_control:0.31987   P_value:0.138175315</span><br><span class="line">Number:29       rps3    lnL0:-2982.678697       lnL1:-2978.575083       Omega_branch:0.54439    Omega_control:0.53311   P_value:0.016512890</span><br><span class="line">Number:30       rps4    lnL0:-1761.670696       lnL1:-1760.205396       Omega_branch:0.44191    Omega_control:0.58927   P_value:0.231008678</span><br></pre></td></tr></table></figure>
<p>附上 <code>chi2_calculator.pl</code> 程序的代码。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/usr/bin/perl</span><br><span class="line">#/*************************************************************************</span><br><span class="line">#	&gt; File Name: chi2_calculator.pl</span><br><span class="line">#	&gt; Author: fenglei</span><br><span class="line">#	&gt; Mail: fengleiluck@gmail.com</span><br><span class="line">#	&gt; Created Time: Thu 07 Oct 2021 01:26:04 PM CST</span><br><span class="line"># ************************************************************************/</span><br><span class="line"></span><br><span class="line">open GENE_LIST, &quot;&lt;30_genes.list&quot; or die &quot;Can not open the file!\n&quot;;</span><br><span class="line">open NONMODEL, &quot;&lt;mtGenes.branch_model_0.mcl&quot; or die &quot;Can not open the file!\n&quot;;  # 找到这样的行：lnL(ntime: 13  np: 16):  -3122.716855      +0.000000  </span><br><span class="line">open ALTERNATIVE, &quot;&lt;mtGenes.branch_model_2.mcl&quot; or die &quot;Can not open the file!\n&quot;;</span><br><span class="line"></span><br><span class="line">#####  perl chi2_calculator.pl &gt; out</span><br><span class="line">#####  依据上面三个文件，依次计算P值（通过似然率检验（LRT）（卡方检验）获得p值确定零假设模型和备选模型之间是否存在差异）</span><br><span class="line">#      能否同时输出 omega 值？  Alternative 文件里面有一行“w (dN/dS) for branches:  0.37585 0.22840” 第二个数字是我需要的</span><br><span class="line">my @genes;</span><br><span class="line">while(&lt;GENE_LIST&gt;)&#123;</span><br><span class="line">	chomp $_;</span><br><span class="line">	push @genes, $_;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">my @lnL0;</span><br><span class="line">while(&lt;NONMODEL&gt;)&#123;</span><br><span class="line">	chomp $_;</span><br><span class="line">	my $record = $_;</span><br><span class="line">	if($record =~ m/lnL/)&#123;</span><br><span class="line">		my @array = split(/\s+/, $record);</span><br><span class="line">		#print &quot;lnL0: $array[4]\n&quot;; exit;</span><br><span class="line">		push @lnL0, $array[4];</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">my @lnL1;</span><br><span class="line">my @omega_branch;</span><br><span class="line">my @omega_control;</span><br><span class="line">while(&lt;ALTERNATIVE&gt;)&#123;</span><br><span class="line">	chomp $_;</span><br><span class="line">	my $record = $_;</span><br><span class="line">	if($record =~ m/lnL/)&#123;   # 找到这样的行：lnL(ntime: 13  np: 16):  -3122.716855      +0.000000 </span><br><span class="line">		my @array = split(/\s+/, $record);</span><br><span class="line">		push @lnL1, $array[4];</span><br><span class="line">	&#125;</span><br><span class="line">	if($record =~ m/w\s\(dN\/dS\)\sfor\sbranches\:/)&#123;   # 找到这样的行：w (dN/dS) for branches:  0.37585 0.22840” 第二个数字是我需要的选定brach的omega</span><br><span class="line">		my @array = split(/\s+/, $record);</span><br><span class="line">		push @omega_branch,  $array[-1];</span><br><span class="line">		push @omega_control, $array[-2];</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if($#genes == $#lnL0 &amp;&amp; $#genes == $#lnL1)&#123;</span><br><span class="line">	print &quot;# The number of \&quot;genes, lnL0 number, lnL1 number\&quot; are the same.\n# If you see this info, the data is probably OK.\n&quot;;</span><br><span class="line">	#exit;</span><br><span class="line">&#125;</span><br><span class="line">else&#123;</span><br><span class="line">	print &quot;# The number of \&quot;genes, lnL0 number, lnL1 number\&quot; are NOT the same.\n# If you see this info, the data is probably NOT OK.\n# You should have a check.\n&quot;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">print &quot;#Number\tGroup\tlnL0\tlnL1\tOmega_branch\tOmega_control\tP_value\n&quot;;</span><br><span class="line"></span><br><span class="line">for(my $count=0; $count&lt;=$#genes; $count++)&#123;</span><br><span class="line">	$num = $count + 1;</span><br><span class="line">	print &quot;Number:$num\t$genes[$count]\tlnL0:$lnL0[$count]\tlnL1:$lnL1[$count]\tOmega_branch:$omega_branch[$count]\tOmega_control:$omega_control[$count]\t&quot;;</span><br><span class="line">	my $likelihood = 2 * abs( $lnL0[$count] - $lnL1[$count] );</span><br><span class="line">	my $df  = 2;  ### ??? df=1 or df=2 ???</span><br><span class="line">	system(&quot;~/local/app/PAML4.8/bin/chi2 $df $likelihood &gt; /tmp/chi2_result.txt&quot;);  # 三行的一个文件：首行空格，次行“df =  2  prob = 0.016512890 = 1.651e-02”，末行空格。需要提取P值</span><br><span class="line">	open CHISQUARE, &quot;/tmp/chi2_result.txt&quot; or die &quot;Can not open the file!\n&quot;;</span><br><span class="line">	my $p_value = 1;</span><br><span class="line">	while(&lt;CHISQUARE&gt;)&#123;</span><br><span class="line">		chomp $_;</span><br><span class="line">		my $record = $_;</span><br><span class="line">		if($record =~ m/prob/)&#123;</span><br><span class="line">			my @array = split(/\s+/, $record);</span><br><span class="line">			$p_value = $array[-3]/2;  ### PAML文档（http://abacus.gene.ucl.ac.uk/software/pamlDOC.pdf ; Page 30），p值应该是chi2程序的结果除以2。chenlianfu也有如此记录）</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">	print &quot;P_value:$p_value\n&quot;;</span><br><span class="line">	close CHISQUARE;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">=pod</span><br><span class="line">system(&quot;~/local/app/PAML4.8/bin/chi2 2 55&quot;);</span><br><span class="line">$df = 2;</span><br><span class="line">$likelihood = 23;</span><br><span class="line">system(&quot;~/local/app/PAML4.8/bin/chi2 $df $likelihood &gt;&gt; P_value.txt&quot;);</span><br><span class="line">print &quot;test\n&quot;;</span><br><span class="line"># print &quot;$a\n&quot;;  # 这命令输出的是 0，也就是 system 命令输出在屏幕的内容，不能传递给变量。</span><br><span class="line">=cut</span><br><span class="line"></span><br><span class="line">close GENE_LIST;</span><br><span class="line">close NONMODEL;</span><br><span class="line">close ALTERNATIVE;</span><br></pre></td></tr></table></figure>
<p><u><font color=blue>按照前文 Science 杂志那个反刍动物的研究论文资料，我这里的 branch model 实际上找到的是指定分支上的快速进化基因 Rapidly evolved genes。如果要做正向选择分析，要使用 branch-site mode，即参考下文的PAML四大模型之第三个模型，分别设置ModelA：“model = 2, NSsites = 2, fix_omega = 0, omega = 1.5” 和 Model A Null：“model = 2, NSsites = 2, fix_omega = 1, omega = 1”。</font></u></p>
<p>附<a href="http://www.chenlianfu.com/?m=201910">chenlianfu</a>关于正向选择分析步骤的总结：</p>
<p>(1) 收集该基因在多个物种中的 CDS 和 protein 序列（可以使用 orthoMCL 分析结果）。<br />
(2) 对该基因的蛋白序列进行多序列比对，再根据 CDS 序列转换成 Codon 序列比对结果。这个步骤需要自己编写一些程序来实现。<br />
(3) 根据 Codon 序列的比对结果构建系统发育树。推荐使用 RAxML 软件使用 ML 算法对所有的单拷贝同源基因进行物种树构建。然后，输入物种树信息、Codon 多序列比对信息，使用 codeml 进行 omega 计算和选择压模型检验。<br />
(4) 快速过滤非正选择基因：设置 runmode = -2 运行 codeml 命令对两两序列比较，使用 ML 方法计算 dNdS，若存在 omega 值大于1，则认为该基因可能属于正选择基因，进行后续分析。<br />
(5) 正选择基因的初步鉴定方法：设置 model = 0、NSsites = 1 2 运行 codeml 命令（site models）分别对正选择模型(M2a)和近中性进化模型(M1a)进行检测，若两种模型的似然值相差较大，通过自由度为 2 的卡方检验，可以确定该基因是否为正选择基因。从程序结果中（例如：lnL(ntime: 11 np: 16): -870.867266 +0.000000）可以找到 M2a 模型的似然值 l1 和 M1a 模型的似然值 l0，再计算 2Δl = 2(l1-l0)，通过命令“chi2 2 2Δl”根据卡方检验算出 p 值。此外，也可以设置 NSsites = 7 8 进行计算，则表示分别对 M8(beta &amp; omega) 和 M7(beta) 模型进行检测，和前者类似，若两种模型的似然值相差较大，通过自由度为 2 的卡方检验，可以确定该基因是否为正选择基因。根据 PAML 作者所说，M2a 和 M1a 的比较，比 M7-M8 的比较更严格。即若想得到更多的正选择基因，可以使用 M7_VS_M8 分析。此外，根据 M2 和 M8 模型的 BEB（Bayes empirical Bayes）分析结果，还可以得到在多序列比对结果中第一条序列上的正选择位点。根据 PAM L作者所说，这种 site models 之间的比较，能用于检测是否在序列上不同的位点具有不同的 omega 值，而不是用于正选择检测（We suggest that The M0-M3 comparison should be used as a test of variable ω among sites rather than a test of positive selection）。<br />
(6) <font color=blue>指定分化枝上的正选择基因鉴定方法：经过上一步初步鉴定后，设置 model = 2、NSsites = 2、fix_omega = 0、omega = 2.0 运行codeml命令（branch-site model A）；再设置 model = 2、NSsites = 2、fix_omega = 1、omega = 1 运行 codeml 命令（modified branch-site model A / null model）。进行这两种模型分析时，要求输入的树文件中对目标分化枝进行标注。对这两种模型进行 LRT 分析，计算 2Δl = 2(l1-l0)，注意是前者的似然值减后者（null model）的似然值；再使用自由度为 1 的卡方检验，通过命令“chi2 1 2Δl”计算出的值再除以 2，即得到 p 值。</font><br />
(7) <font color=blue>目标分化枝上的快速进化基因（Rapidly evolving gene）鉴定方法：设置 model = 0、NSsites = 0 运行 codeml 命令，再设置 model = 2、NSsites = 0 运行 codeml 命令（这时要求输入的树文件中对目标分化枝进行标注）</font>。然后比较两种运行模式下的似然值，通过自由度为 1 的卡方检验，可以鉴定该基因在目标分化枝的 omega 值和背景差异显著。</p>
<h3 id="一些测试与思考"><a class="markdownIt-Anchor" href="#一些测试与思考"></a> 一些测试与思考</h3>
<p>对于一个基因或者固定数目的少数基因，我按照一个参考流程 <a href="https://figshare.com/articles/journal_contribution/worked_example_pdf/3839583">https://figshare.com/articles/journal_contribution/worked_example_pdf/3839583</a>，即可计算出 omega 值。</p>
<p>该 demo 用的是 6 个物种的单拷贝 orthologous，有 3000 多个基因。而我的实验里，想用 16 个物种运行单拷贝基因鉴定，只有 322 个基因，这样范围太小，怎么改善？</p>
<p>对于无根树文件而言，如果要指定运算某个分支的进化速率，需要在那个分支上加一个“#1”。这里的意思是该物种有一个进化速率 omega，而其他物种有统一的 omega。在另一个资料中，我发现还可以在tree文件中给指定的分支设定“$1”，比如<a href="https://www.bilibili.com/video/BV1Qx411m7Bn?from=search&amp;seid=9774626637377853773&amp;spm_id_from=333.337.0.0">作者</a>用到四种海洋哺乳动物，四种陆地动物的 myoglobin 基因做的正向选择分析，把四种海洋动物标记为“$1”，这样运行结果就是指这四个鲸鱼具有统一的 omega。</p>
<p><img src="https://i.imgur.com/feqs2ew.png" alt="" /></p>
<p>比对的基因序列文件中，物种数目少于tree文件中的物种数目，似乎也可以运行得到结果？（有待确认？如果真的是这样，那我如果对若干个orthologous基因的正向选择做计算，只需要一个tree文件就可以，对于个别基因而言，确实个别物种的orthologous不会影响结果。）2021.10.08 做了一个测试，如果tree文件里面有8个物种，但是phylip格式的序列文件里面只有7个物种，codeml程序会报错的。</p>
<p>Model=0; NSsites= 7 8; 这样结果里面确实有两个 1nL 值，可以用来计算 P 值，但是没有特定 branch 的 ω，而我需要的是特定分支的 ω。这个模式确实无法实现我的目的，因为 Model=0 就表示所有分支的 Omega 都是固定的。</p>
<p>对于 codeml 的配置文件而言，里面的 model 可以设置为 0、1 或 2，这三个参数有什么区别？这个参数主要设定不同分支的ω是否一致。<font color=blue>当model=0，NSsites=0，那么表示假设所有分支、所有氨基酸位点的ω都是一致的。当 model=2, NSsites=0，即假设前景支与背景支的ω不同，出来的结果特定分支ω跟其他分支ω不同，此时其他分支的ω一致。对这两个不同的假设来做卡方检验，即可推算出前者为假的可能性（即 P 值），当 P &lt; 0.05， 可信度高。</font></p>
<p><img src="https://i.imgur.com/h89xpWB.png" alt="Model=0，假设所有分支ω一致" /></p>
<p><img src="https://i.imgur.com/64Ec8kB.png" alt="Model=2，假设前景支与背景支的ω不同" /></p>
<p><img src="https://i.imgur.com/R4qryV2.png" alt="对上述两个假设做卡方检验" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">...</span><br><span class="line">Model 7: beta (10 categories)</span><br><span class="line"></span><br><span class="line">TREE #  1:  (((8, 7), 5), (4, ((1, 2), 3)), 6);   MP score: 160</span><br><span class="line">lnL(ntime: 13  np: 16):  -3062.689720      +0.000000</span><br><span class="line">   9..10   10..11   11..8    11..7    10..5     9..12   12..4    12..13   13..14   14..1    14..2    13..3     9..6  </span><br><span class="line"> 0.007984 0.037210 0.329993 0.012402 0.023400 0.007531 0.031297 0.019721 0.020914 0.003075 0.005174 0.017900 0.027104 0.522045 0.005000 0.019948</span><br><span class="line"></span><br><span class="line">Note: Branch length is defined as number of nucleotide substitutions per codon (not per neucleotide site).</span><br><span class="line">...</span><br><span class="line">Model 8: beta&amp;w&gt;1 (11 categories)</span><br><span class="line"></span><br><span class="line">TREE #  1:  (((8, 7), 5), (4, ((1, 2), 3)), 6);   MP score: 160</span><br><span class="line">lnL(ntime: 13  np: 18):  -3041.864857      +0.000000</span><br><span class="line">   9..10   10..11   11..8    11..7    10..5     9..12   12..4    12..13   13..14   14..1    14..2    13..3     9..6  </span><br><span class="line"> 0.008053 0.038859 0.392264 0.011943 0.023468 0.008401 0.030708 0.020215 0.021091 0.002819 0.005071 0.017885 0.027144 0.504233 0.894161 0.007220 0.044307 4.278923</span><br><span class="line"></span><br><span class="line">Note: Branch length is defined as number of nucleotide substitutions per codon (not per neucleotide site).</span><br><span class="line"></span><br><span class="line">tree length =   0.60792</span><br><span class="line"></span><br><span class="line">(((8: 0.392264, 7: 0.011943): 0.038859, 5: 0.023468): 0.008053, (4: 0.030708, ((1: 0.002819, 2: 0.005071): 0.021091, 3: 0.017885): 0.020215): 0.008401, 6: 0.027144);</span><br><span class="line"></span><br><span class="line">(((Vicia_faba: 0.392264, Medicago_truncatula: 0.011943): 0.038859, Lotus_japonicus: 0.023468): 0.008053, (Millettia_pinnata: 0.030708, ((Vigna_angularis: 0.002819, Vigna_radiata: 0.005071): 0.021091, Glycine_max: 0.017885): 0.020215): 0.008401, Ammopiptanthus_mongolicus: 0.027144);</span><br><span class="line"></span><br><span class="line">Detailed output identifying parameters</span><br><span class="line"></span><br><span class="line">kappa (ts/tv) =  0.50423</span><br><span class="line"></span><br><span class="line">Parameters in M8 (beta&amp;w&gt;1):</span><br><span class="line">  p0 =   0.89416  p =   0.00722 q =   0.04431</span><br><span class="line"> (p1 =   0.10584) w =   4.27892</span><br><span class="line"> ...</span><br></pre></td></tr></table></figure>
<p>下面的方法（来自<a href="http://www.chenlianfu.com/?p=3036">chenlianfu.com</a>）可以检测指定分支的 ω, 并且计算 P 值。我查阅了 PAML 的文档，确实是这么计算 P 值。</p>
<p><font color=blue>指定分化枝上的正选择基因鉴定方法：经过上一步初步鉴定后，设置 <code>model = 2、NSsites = 2、fix_omega = 0、omega = 2.0</code> 运行 codeml 命令（branch-site model A）；再设置 <code>model = 2、NSsites = 2、fix_omega = 1、omega = 1</code> 运行 codeml 命令（modified branch-site model A / null model）。进行这两种模型分析时，要求输入的树文件中对目标分化枝进行标注。对这两种模型进行LRT分析，计算 2Δl = 2(l1-l0)，注意是前者（branch-site model A）的似然值减后者（null model）的似然值；再使用自由度为1的卡方检验，通过命令“chi2 1 2Δl”计算出的值再除以2，即得到p值。</font></p>
<p>20211011 备注：上面卡方检验直接 <code>chi2 2 2Δl</code> 即可？不需要除以二吧？—— 查阅文档之后看到，要除以二。</p>
<p><img src="https://i.imgur.com/TV6Sr9x.jpeg" alt="" /></p>
<p>上面截图中调用 <code>chi2 2 2.71</code> 命令，得到 “df =  2  prob = 0.257947294 = 2.579e-01”，再除以二就是 P 值。</p>
<p>其实也可以用 R 来做计算，在R界面输入命令 <code>pchisq(2.71, 2, lower.tail = FALSE)</code> 得到结果：“0.2579473”。跟上面调用 chi2 程序的结果是一致的。</p>
<p>卡方检验是一种用途很广的计数资料的假设检验方法，由卡尔·皮尔逊提出。它属于非参数检验的范畴，主要是比较两个及两个以上样本率( 构成比）以及两个分类变量的关联性分析。其根本思想就是在于比较理论频数和实际频数的吻合程度或拟合优度问题。比如<a href="https://zhuanlan.zhihu.com/p/42803826">我们想知道不吃晚饭对体重下降有没有影响</a>，即探讨吃晚饭与体重的关系，将一个人群分为“吃晚饭组”与“不吃晚饭组”</p>
<h3 id="学习笔记怎么通过-chi2-计算-p-值"><a class="markdownIt-Anchor" href="#学习笔记怎么通过-chi2-计算-p-值"></a> 学习笔记：怎么通过 chi2 计算 P 值？</h3>
<p>一开始接触 codeml 的时候，并不清楚怎么计算 P 值，经过阅读一些相关材料，获得 P 值计算方法，大致记录如下。</p>
<p>上面的 codeml 运行结果文件有这么一行：lnL(ntime: 13  np: 16):  -3122.716855      +0.000000</p>
<p>这个“-3122.716855”就有用，我们修改 ctl 文件的参数之后，再次运行 codeml 程序，将生成一个新的 lnL 值。依据前后两次 lnL 值，用下文提到的公式，就可以计算 P 值。</p>
<p><a href="http://blog.sina.com.cn/s/blog_65ba09d90102x4um.html">http://blog.sina.com.cn/s/blog_65ba09d90102x4um.html</a> 上回讲到了用codeml计算选择位点的时候，同时选择M7和M8模型，这两个模型的差异进近在于 M8(beta &amp; ω) 模型比 M7 （beta）多了一个参数，所以可以依靠比较这两个模型来进行LRT。公式是这个：LRT = 2dl = abs(2 X (l1-l0)) （abs=绝对值）。Step1: 打开之前用codeml生成的 mcl 文件，找到 Model7, 和 Model8。两个lnL值想减，取绝对值，乘以2，这里是：2|-10302.87869-（-10332.64273）| = 59.52 (小数点后影响不大) Step2：打开PAML程序包中的 Chi2 程序, 分别输入自由度和刚才得到的数，自由度直接取 2 就好（这个是杨子恒自己说的，在PAML的文档里有写），后面写上Step1算出来的数字，得到的 p 小于 0.05 则结果比较可靠，这里的 p 非常小。</p>
<p><a href="https://bcb.unl.edu/yyin/codeml.html">https://bcb.unl.edu/yyin/codeml.html</a> I write some simple ways to test likelihood ratio test on variable codon rates. These two models assume codon rates varied among all branchs. (1). M1a vs. M2a: M1a(model=0, NSsites=1), M2a(model=0, NSsites=2), the df = 2, LRT = 2dl = abs(2 X (l1- l0)). (2). M7 vs. M8: M1a(model=0, NSsites=7), M2a(model=0, NSsites=8), the df = 2, LRT = 2dl = abs(2 X (l1-l0)). The chi-square value can be calucated by PROGRAM CHI2.EXE in PAML.  If the p-value &lt;0.05, then we can conclude that some sites are under positive selection.</p>
<h3 id="paml-分析四大模型"><a class="markdownIt-Anchor" href="#paml-分析四大模型"></a> PAML 分析四大模型</h3>
<p>在paml分析里面，主要涉及四种模型：位点模型（site-model）、支模型（branch model）、支位点模型（branch site model）以及进化支模型。位点模型通常适用于检测某一支系普遍性、广泛性的正选择，这种正选择是由于位点持续改变所引起的，例如，适应多种病原体；支模型主要是检测某一支系是否存在快速进化、选择压力约束以及正选择，但却无法检测到正选择位点；<font color=blue>支位点模型比较准确与稳定，适用于检测某一支系断点性的正选择事件，此结果是由于适应某一时期环境改变所引起的，通常会保留在后代中</font>；进化支模型（clade model），则主要是判别不同物种之间是否存受分化选择压力作用，不局限于正选择，它一次可以标记多个分支进行比较。</p>
<ol>
<li><strong>位点模型</strong></li>
</ol>
<p>M0：假设所有位点具有相同的 dN/dS 值；<br />
M1a：假设存在两类位点—保守位点0 &lt; dN/dS &lt; 1，中性进化位点dN/dS = 1，并且估算这两类位点的比率（p0，p1）和ω值（ω0，ω1）；<br />
M2a：假设存在三类位点——纯化选择位点 dN/dS &lt; 1，中性进化位点dN/dS = 1与正选择位点dN/dS &gt; 1，并估算三类位点的比率（p0，p1，p2）；<br />
M3: 离散模型，假设所有位点的ω值呈离散分布；<br />
M7：假设所有位点0 &lt; ω &lt;1且呈现beta分布；<br />
M8：在M7模型的基础上，增加一类正选择位点（ω &gt;1）;<br />
M8a：与M8类似，只不过是将新增的ω固定为1；</p>
<p>位点模型的 Codeml.ctl 参数设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">model = 0                 </span><br><span class="line">NSsites = 0 1 2 3 7 8</span><br><span class="line">即分别比较如下模型（* 为正选择模型，前提是需要LRTs显著）：</span><br><span class="line">M3（分散比率） vs. M0（负选择）</span><br><span class="line">M2a* （正选择）vs. M1a （选择约束放松）</span><br><span class="line">M8*（正选择） vs. M7 （选择约束放松）</span><br><span class="line">M8* （正选择）vs. M8a（选择约束放松）</span><br></pre></td></tr></table></figure>
<ol start="2">
<li><strong>支模型</strong></li>
</ol>
<p>one rario：假设所有的进化谱系都具有相同的ω值；<br />
free ratio：假设所有的支系都具有独立的ω值；<br />
two ratio：假设前景支与背景支的ω不同</p>
<p>分支模型的Codeml.ctl参数设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">two ratio: model = 2, NSsites = 0  </span><br><span class="line">one ratio: model = 0, NSsites = 0</span><br><span class="line">free ratio: model = 1, NSsites = 0</span><br><span class="line">               </span><br><span class="line">one ratio（负选择） vs. free ratio（自由比率）</span><br><span class="line">one ratio（负选择） vs. two ratio （正选择）</span><br><span class="line">two ratio natural（中性进化） vs. two ratio （正选择）</span><br></pre></td></tr></table></figure>
<ol start="3">
<li><strong>支位点模型</strong></li>
</ol>
<p>假定位点间的ω值是变化的，同时也假定支系间的ω值是变化的。该模型主要用于检测前景支中正选择作用对部分位点的影响。<br />
modelA null（零假设）：ω值设定为固定值1<br />
modelA（备择假设）：估算其ω值是否大于1<br />
背景支与前景支具有相同的位点ω值：<br />
K0：前景支与背景支中的位点受到纯化选择0 &lt; ω &lt; 1；<br />
K1：前景支与背景支中的位点处于中性进化0 &lt; ω = 1;<br />
背景支与前景支具有不同的位点ω值：<br />
K2a：前景支处于中性进化，而背景支处于纯化选择；<br />
K2b：前景支受到正选择压力（ ω&gt;1 ），而背景支处于中性进化；<br />
支位点模型的的Codeml.ctl参数设置：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ModelA：</span><br><span class="line">model = 2, NSsites = 2, fix_omega = 0, omega = 1.5</span><br><span class="line">ModelAnull：</span><br><span class="line">model = 2, NSsites = 2, fix_omega = 1, omega = 1</span><br><span class="line">即比较如下模型（* 为正选择模型，前提是需要LRTs显著）：</span><br><span class="line">ModelA*（正选择） vs. ModelAnull （中性进化）</span><br></pre></td></tr></table></figure>
<ol start="4">
<li><strong>进化支模型</strong></li>
</ol>
<p>与枝位点模型类型，能同时检测多个进化枝（Clade），但是该模型并没有将背景支的dN/dS值约束在（0,1）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">M2a_model: model = 0 NSsites = 22</span><br><span class="line">Clade Model C: model = 3 NSsites = 2</span><br><span class="line">Clade Model D: model = 3 NSsites = 3</span><br><span class="line">Clade Model C vs. M2a_model</span><br></pre></td></tr></table></figure>
<h3 id="怎么区分-unrooted-tree-与-rooted-tree"><a class="markdownIt-Anchor" href="#怎么区分-unrooted-tree-与-rooted-tree"></a> 怎么区分 unrooted tree 与 rooted tree</h3>
<p>有时通过构建进化树的软件获得进化树后，软件不会对进化树是有根树，还是无根树做说明。在不做额外编写脚本的基础上，其实可以直接从newick文件的内容格式上区分有根树和无根树］</p>
<p>假设有下面三种形式的进化树：</p>
<p>[1] (a, b, c);      无根树</p>
<p>[2] (a, b, c):1;   有根树</p>
<p>[3] ((a,b),c);      有根树</p>
<p>除第一种形式的进化树外，其它两种形式的进化树都是有根树。R 语言对有根树、无根树的判断是：</p>
<p>如果最外层大括号内只有两个分枝，即为有根树，如 [3]；</p>
<p>如果最外层大括号内有三个或以上分枝，一般为无根树，如 [1]；</p>
<p>但是，如果大括号外存在枝长参数，如 [2] 中的 :1，这种情况认为三个分枝以一定的枝长连接到根上，为有根树。</p>
<p>我想通过上述三个例子，可以先看最外层是否有枝长参数，再数一下最外层括号下有几个分枝，即可简单地、直接地判断目前绝大多数获得的newick格式的进化树是有根树，还是无根树。</p>
<h3 id="实践"><a class="markdownIt-Anchor" href="#实践"></a> 实践</h3>
<p>如何收集基因？如果我想找出一个物种与相邻的若干物种相比较，有哪些基因出现了正向选择。首先，用 OrthoFinder 软件可以找出 single copy genes。这里要注意，初始的物种数目越多，single copy genes 越少，后续用于分析得到的结果越少，我看文献中有用到 7 个物种，摘录于此：“To detect genes evolving under positive selection in jujube, we used gene clustering of the seven Rosales species to identify 1,420 single-copy orthologous genes and used the optimized branch-site mode<sup>l63</sup> to identify 254 genes that are positively selected in <em>Z. jujuba</em>.” 另外，我觉得可以用 jcvi 流程，他会基于基因组位置和基因序列两个信息来做 orthologous 分析，以感兴趣物种为参考，将其他若干物种的基因集分别与之比较，就可以得这一群物种的 orthologous genes（反刍动物的进化分析其实就是类似这个策略，只不过他们用的是lastal比对软件），然后要思考的一点是，是不是必须所有物种都出现的ortholog gene，才用于后续分析。</p>
<p>2021.10.08</p>
<ol>
<li>选择7个物种，准备好CDS序列，然后翻译成pep序列，将用于orthofinder流程。注意，同时考虑jcvi流程需要的gff文件和pep文件。（别用花生。感觉序列质量不好。）</li>
<li>运行orthofinder流程，预计找到1000多个single copy genes</li>
<li>在AM与其他物种依次运行jcvi，然后整合结果，预计这种方式可以找到几千个orthologous genes</li>
<li>分别运行codeml流程，计算Ka/Ks值。并计算P值。看最终有多少个基因会出现正向选择。</li>
</ol>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p><a href="http://yuzhenpeng.github.io/2019/12/24/paml/">于振朋: Comparative Genomics and Adaptive Evolution</a><br />
<a href="https://www.bilibili.com/video/BV1Qx411m7Bn?from=search&amp;seid=9774626637377853773&amp;spm_id_from=333.337.0.0">B 站 PAML 视频教程：利用 codeml 计算 dN/dS</a><br />
<a href="http://www.chenlianfu.com/?p=3001">Chenlianfu: 使用 PAML 软件利用核酸序列进行系统发育参数分析</a><br />
<a href="http://www.chenlianfu.com/?p=3036">Chenlianfu: 使用 PAML 软件利用密码子序列进行正选择分析</a><br />
<a href="https://figshare.com/articles/journal_contribution/worked_example_pdf/3839583">A worked example of estimating ω and testing for adaptive evolution in six parasite species</a><br />
<a href="http://wap.sciencenet.cn/blog-460481-1163040.html?mobile=1">高芳銮：选择压力分析之 EasyCodeML 完整篇（By Raindy)</a><br />
<a href="https://static-content.springer.com/esm/art%3A10.1007%2Fs00606-019-01578-2/MediaObjects/606_2019_1578_MOESM1_ESM.pdf">Supplementary File 1 of “<u><em>Analyses of mitochondrial genomes of the genus Ammopiptanthus provide new insights into the evolution of legume plants</em></u>”</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | Repeat sequence analysis by RepeatExplorer2 with TAREAN (Tandem Repeat Analyzer)</title>
    <url>/2021/04/23/Bioinfo-Repeat-sequence-analysis-by-RepeatExplorer2-with-TAREAN-Tandem-Repeat-Analyzer/</url>
    <content><![CDATA[<p>学习重复序列的过程中，读到2019年发表在《Mobile DNA》杂志的文献 “Systematic survey of plant LTR-retrotransposons elucidates phylogenetic relationships of their polyprotein domains and provides a reference for element classification”。</p>
<p>文中提到 We have established an improved classification system applicable to LTR-retrotransposons from a wide range of plant species. This system reflects phylogenetic relationships as well as distinct sequence and structural features of the elements. A comprehensive database of retrotransposon protein domains (REXdb) that reflects this classification provides a reference for efficient and unified annotation of LTR-retrotransposons in plant genomes. Access to REXdb related tools is implemented in the RepeatExplorer web server (<a href="https://repeatexplorer-elixir.cerit-sc.cz/">https://repeatexplorer-elixir.cerit-sc.cz/</a>) or using a standalone version of REXdb that can be downloaded seaparately from RepeatExplorer web page (<a href="http://repeatexplorer.org/">http://repeatexplorer.org/</a>).</p>
<p>A comprehensive database of retrotransposon protein domains (REXdb) that reflects this classification provides a reference for efficient and unified annotation of LTR-retrotransposons in plant genomes.</p>
<h3 id="installation"><a class="markdownIt-Anchor" href="#installation"></a> Installation</h3>
<p>To use RepeatExplorer without installation, we recommend our freely available Galaxy server at <a href="https://repeatexplorer-elixir.cerit-sc.cz">https://repeatexplorer-elixir.cerit-sc.cz</a>. This server is provided in frame of the ELIXIR-CZ project. The Galaxy server includes also additional tools useful for data preprocessing, quality control and genome annotation.</p>
<p>For installing command-line version, follow the instruction below:</p>
<p>Download source code using git command:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://bitbucket.org/petrnovak/repex_tarean.git</span><br><span class="line">cd repex_tarean</span><br></pre></td></tr></table></figure>
<p>We recommend to install dependencies using conda (conda can be installed using miniconda). The required environment can be prepared using command:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda env create -f environment.yml</span><br></pre></td></tr></table></figure>
<p>Then activate the prepared environment using:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda activate repeatexplorer</span><br></pre></td></tr></table></figure>
<p>In the repex_tarean direcory compile the source and prepare databases using:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">make</span><br></pre></td></tr></table></figure>
<p><s>Support for 32-bit executables is required. If you are using Ubuntu distribution you can add 32-bit support by running:</s></p>
<p><s>sudo dpkg --add-architecture i386</s><br />
<s>sudo apt-get update</s><br />
<s>sudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386</s></p>
<p>To verify the installation, run RepeatExplorer clustering on the provided example data:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./seqclust -p -v tmp/clustering_output test_data/LAS_paired_10k.fas</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | 重复序列预测工具 RepeatModeler</title>
    <url>/2021/04/08/Bioinfo-RepeatModeler/</url>
    <content><![CDATA[<p>RepeatMasker是重复序列检测的常用工具，通过与参考数据库的相似性比对来准确识别或屏蔽基因组中的重复序列，属于同源预测注释的方式。基因组组装完成后，进行基因预测和注释。由于基因组中存在重复序列结构区，特别是高等真核生物，重复序列占了相当大的比例，会影响基因预测的质量，也会带来不必要的资源消耗。因此在基因预测前，首先要检测并屏蔽基因组中的重复序列（真核生物很必要，原核生物可忽略）。对于这种情况，只是为了屏蔽重复序列降低后续基因预测的压力，重复序列的检测可以不必太纠结。但有时候我们注释基因组的重复序列结构，也可能是专注于某些特定研究，例如，某些重复元件可能参与了重要功能，我们期望定位它们的位置。这种情况下，需要识别精准。</p>
<p>RepeatModeler 的识别过程是怎么样的？根据<a href="https://www.biorxiv.org/content/10.1101/856591v1.full.pdf">原始文献</a>的描述，它采用了两个不同的策略，第一个是 RepeatScout，第二个是 RECON。另外，新版的RepeatModeler2 针对 LTR 鉴定进行了功能升级，引入 LTRharvest 和 LTR_retriever 模块。RepeatScout 原理是先找出出现频率较高的“种子”序列，然后对“种子”序列进行延长来预测重复序列，这与BLAST的双序列比对过程类似，RepeatScout 能快速鉴定高频率的重复序列与出现时间比较晚的重复元件，这个过程中（Round-1），RepeatScout 从基因组随机取 40Mbp 序列，并分析其中的重复元件，通过与已知数据库进行比较能够快速鉴定已知的转座子，在 Round-1 目录下，有一个 sampleDB-1.fa 文件，这个文件对应的 blastdb 数据库文件，。对于 RECON 而言，它通过基因组之间的比较来鉴定转座子，更彻底的序列比对，也能鉴定出现时间比较早的转座子。RECON 先从基因组选取3Mbp序列作为样品，再依次增加为3倍，分别9Mbp、27Mbp、81Mbp、243Mbp，即一直从Round-2到Round-6（什么目的？）。</p>
<h3 id="软件依赖-安装"><a class="markdownIt-Anchor" href="#软件依赖-安装"></a> 软件依赖、安装</h3>
<ol>
<li><em>Perl</em> 5.8.0 or higher. 我是通过 Python3.7 的 conda 安装的：This is perl 5, version 26, subversion 2 (v5.26.2) built for x86_64-linux-thread-multi。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install perl</span><br></pre></td></tr></table></figure>
<p>在Linux命令行模式下输入“perl -MCPAN -e shell”进入perl界面，然后输入“instal module-name”安装下面的包。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">install JSON</span><br><span class="line">install File::Which</span><br><span class="line">install URI</span><br><span class="line">install LWP::UserAgent</span><br></pre></td></tr></table></figure>
<p><a href="https://metacpan.org/pod/JSON">JSON</a>自动安装失败，改成手动从cpan下载安装。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://cpan.metacpan.org/authors/id/I/IS/ISHIGAKI/JSON-4.03.tar.gz</span><br><span class="line">tar -zxvf JSON-4.03.tar.gz</span><br><span class="line">cd JSON-4.03</span><br><span class="line">perl Makefile.PL</span><br><span class="line">make</span><br><span class="line">make install Makefile</span><br><span class="line"></span><br><span class="line">wget https://cpan.metacpan.org/authors/id/P/PL/PLICEASE/File-Which-1.24.tar.gz</span><br><span class="line">wget https://cpan.metacpan.org/authors/id/O/OA/OALDERS/URI-5.09.tar.gz</span><br><span class="line">wget https://cpan.metacpan.org/authors/id/O/OA/OALDERS/libwww-perl-6.53.tar.gz</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>Python 3 and the <em>h5py</em> python library. 我电脑已经安装 Python 的管理器 Anaconda 3，然后安装Python3.7，再通过 conda 安装 h5py：</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install h5py。</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>Sequence Search Engine (RepeatMasker uses a sequence search engine to perform it’s search for repeats. Currently Cross_Match, <em>RMBlast</em> and WUBlast/ABBlast are supported. You will need to obtain one or the other of these and install them on your system.) Download Pre-compiled Package: Download the RMBlast package for your platform:</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget http://www.repeatmasker.org/rmblast-2.11.0+-x64-linux.tar.gz</span><br><span class="line">tar -zxvf rmblast-2.11.0+-x64-linux.tar.gz</span><br></pre></td></tr></table></figure>
<ol start="4">
<li><em>TRF</em> - Tandem Repeat Finder, G. Benson et al.<br />
You can obtain a free copy at <a href="http://tandem.bu.edu/trf/trf.html">http://tandem.bu.edu/trf/trf.html</a>. RepeatMasker was developed using TRF version 4.0.9</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/Benson-Genomics-Lab/TRF.git</span><br><span class="line">cd TRF</span><br><span class="line">mkdir build</span><br><span class="line">cd build</span><br><span class="line">../configure --prefix=/home/fenglei/local</span><br><span class="line">make</span><br><span class="line"># To install to user&#x27;s path</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<p>安装TRF中途报错：/home/fenglei/local/app/TRF/missing: line 81: aclocal-1.16: command not found. WARNING: ‘aclocal-1.16’ is missing on your system.<br />
通过安装 automake 解决问题。</p>
<ol start="5">
<li><em>Repeat Database</em><br />
RepeatMasker can be used with custom libraries, or with Dfam out of the box. Dfam is an open database of transposable element (TE) profile HMM models and consensus sequences. The current release (Dfam 3.2) contains 6,900 TE families spanning five organisms: human, mouse, zebrafish, fruit fly, nematode, and a growing number of additional species. To supplement this databases we recommend obtaining the RepeatMasker edition of RepBase.<br />
To update the Dfam libraries contained in this release go to <a href="http://www.dfam.org">http://www.dfam.org</a>.<br />
RepeatMasker软件自带有Dfam（RepBase数据库HMM版）的常见重复序列库，要更新完整的Dfam需去官网下载。该文件大小15G,下载时间比较久下载解压之后将Dfam文件转移到 RepeatMasker 安装目录下，替换掉RepeatMasker自带的Dfam数据集。如下方命令操作。<br />
RepeatMasker comes with a copy of the curated portion of Dfam ( Libraries/Dfam.h5 ) and will work out-of-the box with this library. This is a small library ( at this time ). There are two options for supplementing the main RepeatMasker library:<br />
The complete Dfam ( curated and uncurated families ) library may be downloaded from <a href="http://www.dfam.org">www.dfam.org</a> in famdb HDF5 format and used to replace the distributed “Libraries/dfam.h5” file. For example:</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://www.dfam.org/releases/Dfam_3.2/families/Dfam.h5.gz</span><br><span class="line">gunzip Dfam.h5.gz</span><br><span class="line"># mv Dfam.h5 /usr/local/RepeatMasker/Libraries</span><br><span class="line">NOTE: This will overwrite the distributed Dfam.h5 file.</span><br></pre></td></tr></table></figure>
<ol start="6">
<li>安装 <em>RepeatMasker</em> 按照这个网页：<a href="https://www.repeatmasker.org/RepeatMasker/">https://www.repeatmasker.org/RepeatMasker/</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://www.repeatmasker.org/RepeatMasker/RepeatMasker-4.1.2-p1.tar.gz</span><br><span class="line">tar -zxvf RepeatMasker-4.1.2-p1.tar.gz</span><br><span class="line">cd RepeatMasker</span><br><span class="line">perl ./configure</span><br><span class="line"># 输入TRF软件所在路径：/software/annotation/TRF-4.10/bin/trf</span><br><span class="line"># 选择搜索引擎：小编选的是2. RMBlast，其他搜索引擎可以根据需求选择（可多次操作），输入 RMBlast路径：/software/annotation/rmblast-2.10.0/bin 并确认默认搜索引擎</span><br></pre></td></tr></table></figure>
<ol start="7">
<li><em>RECON</em> - De Novo Repeat Finder, Bao Z. and Eddy S.R. Developed and tested with our patched version of RECON ( 1.08 ). The 1.08 version fixes problems with running RECON on 64 bit machines and supplies a workaround to a division by zero bug along with some buffer overrun fixes. The program is available at: <a href="http://www.repeatmasker.org/RepeatModeler/RECON-1.08.tar.gz">http://www.repeatmasker.org/RepeatModeler/RECON-1.08.tar.gz</a>. The original version is available at <a href="http://eddylab.org/software/recon/">http://eddylab.org/software/recon/</a>.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget http://www.repeatmasker.org/RepeatModeler/RECON-1.08.tar.gz</span><br><span class="line">tar -zxvf RECON-1.08.tar.gz</span><br><span class="line">cd RECON-1.08</span><br><span class="line">cd src</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<ol start="8">
<li><em>RepeatScout</em> - De Novo Repeat Finder, Price A.L., Jones N.C. and Pevzner P.A. Developed and tested with our multiple sequence version of RepeatScout ( 1.0.6 ). This version is available at <a href="http://www.repeatmasker.org/RepeatScout-1.0.6.tar.gz">http://www.repeatmasker.org/RepeatScout-1.0.6.tar.gz</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tar -zxvf RepeatScout-1.0.6.tar.gz</span><br><span class="line">cd RepeatScout</span><br><span class="line"># edit MakeFile:</span><br><span class="line"># INSTDIR = /home/fenglei/local/scripts/</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
<ol start="9">
<li><em>GenomeTools</em> [optional]<br />
LtrHarvest - The LtrHarvest program is part of the GenomeTools suite. We have developed this release of RepeatModeler on GenomeTools version 1.5.9 available for download from here: <a href="http://genometools.org/pub/">http://genometools.org/pub/</a> NOTE: use the “make threads=yes” build options to enable multi-threaded runs.<br />
参考 <a href="http://events.jianshu.io/p/d2fc7a1de669">CentOS 8 安装genometools</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget http://genometools.org/pub/genometools-1.6.1.tar.gz</span><br><span class="line"># make 报错：cairo.h: No such file or directory 报错，需要安装cairo</span><br><span class="line">sudo yum install cairo.x86_64 cairo-devel.x86_64 pango-devel.x86_64 pango.x86_64</span><br><span class="line">tar -zxvf genometools-1.6.1.tar.gz</span><br><span class="line">cd genometools-1.6.1</span><br><span class="line">~~make~~</span><br><span class="line"># make 的参数加上 threads=yes</span><br><span class="line"># 最开始没有加允许多线程的参数，导致程序允许时间特别长</span><br><span class="line"># 另注意，我在 Pytho3.7 环境下 make 失败，切换到系统默认的 base 环境才 make 成功</span><br><span class="line">make threads=yes</span><br></pre></td></tr></table></figure>
<ol start="10">
<li><em>Ltr_retriever</em> [optional]<br />
Ltr_retriever - A LTR discovery post-processing and filtering tool. We recommend using version 2.6 or higher from here: <a href="https://github.com/oushujun/LTR_retriever/releases">https://github.com/oushujun/LTR_retriever/releases</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># download LTR_retriever-2.9.0.tar.gz</span><br><span class="line">tar -zxvf LTR_retriever-2.9.0.tar.gz</span><br><span class="line">mv LTR_retriever-2.9.0 LTR_retriever</span><br><span class="line">/home/fenglei/local/app/LTR_retriever/LTR_retriever -h</span><br></pre></td></tr></table></figure>
<ol start="11">
<li><em>MAFFT</em> [optional]<br />
MAFFT - A multiple sequence alignment program. We developed and tested RepeatModeler using mafft version 7.407. Please use this verison or higher from here: <a href="https://mafft.cbrc.jp/alignment/software/">https://mafft.cbrc.jp/alignment/software/</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://mafft.cbrc.jp/alignment/software/mafft-7.475-with-extensions-src.tgz</span><br><span class="line">tar -zxvf mafft-7.475-with-extensions-src.tgz</span><br><span class="line">mv </span><br><span class="line">cd </span><br><span class="line">cd core</span><br><span class="line">make clean</span><br><span class="line">make</span><br><span class="line">vi Makefile</span><br><span class="line"># eidt 1st line. change &quot;/usr/local&quot; to &quot;/home/fenglei/local&quot;</span><br><span class="line">make clean</span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">cd ../extention</span><br><span class="line">vi Makefile</span><br><span class="line"># Edit the 1st line. Change &quot;/usr/local&quot; to &quot;/home/fenglei/local&quot;</span><br><span class="line">make clean</span><br><span class="line">make</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<ol start="12">
<li><em>Ninjia</em> [optional]<br />
Ninja - A tool for large-scale neighbor-joining phylogeny inference and clustering. We developed and tested RepeatModeler using Ninja version “0.95-cluster_only”. Please obtain a copy from: <a href="https://github.com/TravisWheelerLab/NINJA/releases/tag/0.95-cluster_only">https://github.com/TravisWheelerLab/NINJA/releases/tag/0.95-cluster_only</a><br />
Download source code from <a href="https://github.com/TravisWheelerLab/NINJA/releases/tag/0.95-cluster_only">https://github.com/TravisWheelerLab/NINJA/releases/tag/0.95-cluster_only</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tar -zxvf NINJA-0.95-cluster_only.tar.gz</span><br><span class="line">mv NINJA-0.95-cluster_only /home/fenglei/local/app/NINJA-0.95-cluster</span><br><span class="line">cd NINJA-0.95-cluster/NINJIA</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
<ol start="13">
<li><em>cd-hit</em> [optional]<br />
CD-HIT - A sequence clustering package. We developed and tested RepeatModeler using version 4.8.1. Please use this version or higher from: <a href="http://weizhongli-lab.org/cd-hit/">http://weizhongli-lab.org/cd-hit/</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/weizhongli/cdhit.git</span><br><span class="line">sudo yum install zlib-devel</span><br><span class="line">cd cdhit</span><br><span class="line">make</span><br></pre></td></tr></table></figure>
<ol start="14">
<li><em>RepeatModeler</em> 按照这个网页 <a href="http://www.repeatmasker.org/RepeatModeler/">http://www.repeatmasker.org/RepeatModeler/</a></li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget http://www.repeatmasker.org/RepeatModeler/RepeatModeler-2.0.1.tar.gz</span><br><span class="line">tar -zxvf RepeatModeler-2.0.1.tar.gz</span><br><span class="line">cd RepeatModeler-2.0.1</span><br><span class="line">perl ./configure</span><br></pre></td></tr></table></figure>
<p>根据程序提示，依次输入下方各个程序所在路径。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#perl</span><br><span class="line">/home/fenglei/local/app/anaconda3/envs/python37/bin/perl</span><br><span class="line">#RepeatMasker</span><br><span class="line">/home/fenglei/local/app/RepeatMasker</span><br><span class="line">#RECON</span><br><span class="line">/home/fenglei/local/app/RECON-1.08/bin</span><br><span class="line">#RepeatScount</span><br><span class="line">/home/fenglei/local/app/RepeatScout-1.0.6</span><br><span class="line">#TRF</span><br><span class="line">/home/fenglei/local/bin/trf</span><br><span class="line">#search engine: RMBlast</span><br><span class="line">/home/fenglei/local/app/rmblast-2.11.0/bin</span><br><span class="line">#genometools</span><br><span class="line">/home/fenglei/local/app/genometools-1.6.1/bin</span><br><span class="line">#Ltr_retriever</span><br><span class="line">/home/fenglei/local/app/LTR_retriever</span><br><span class="line">#MAFFT</span><br><span class="line">/home/fenglei/local/bin</span><br><span class="line">#NINJIA</span><br><span class="line">/home/fenglei/local/app/NINJA-0.95-cluster/NINJA</span><br><span class="line">#cd-hit</span><br><span class="line">/home/fenglei/local/app/cdhit</span><br><span class="line">### Congratulations!  RepeatModeler is now ready to use.</span><br></pre></td></tr></table></figure>
<h3 id="软件使用"><a class="markdownIt-Anchor" href="#软件使用"></a> 软件使用</h3>
<p>使用 REPEATMODELER 来通过基因组序列构建 LIBRARY。生成一个文件夹，名称为 RM_[PID].[DATE] ie. “RM_5098.MonMar141305172005″。该文件夹中的“consensi.fa.classified”即为 library，用于RepeatMasker的输入。值得注意的是，输入 fasta 文件序列间不能有空（空格和换行等），否则会程序出错。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##改成自己的输入fasta名称</span><br><span class="line">fasta=/home/fenglei/databases/Arabidopsis/TAIR10_chr_all.fasta</span><br><span class="line">##改成自己想要的database名称</span><br><span class="line">database_name=Arabidopsis</span><br><span class="line">##改成RepeatModeler安装目录</span><br><span class="line">RepeatModelerPath=/home/fenglei/local/app/RepeatModeler-2.0.1</span><br><span class="line">## Build database</span><br><span class="line">$&#123;RepeatModelerPath&#125;/BuildDatabase -name $&#123;database_name&#125; -engine rmblast $&#123;fasta&#125;</span><br><span class="line">## Run RepeatModeler to detect repeats</span><br><span class="line">$&#123;RepeatModelerPath&#125;/RepeatModeler -pa 10 -database $&#123;database_name&#125; -LTRStruct</span><br></pre></td></tr></table></figure>
<p>第二步就调用 RepeatMasker，依据上一步鉴定的该物种的重复序列库（Library），即 consensi.fa.classified 文件，来对基因组进行标记，输出文件夹中的“*.fasta.masked”文件就是 softmasked 文件，重复序列会被标记成小写字母。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">set -e</span><br><span class="line">set -u</span><br><span class="line">set -o pipefail</span><br><span class="line"></span><br><span class="line">refgenome=/home/fenglei/databases/Arabidopsis/TAIR10_chr_all.fasta  #改成自己的输入fasta名称 不可以用压缩文件</span><br><span class="line">database_name=Arabidopsis  #改成自己想要的database名称</span><br><span class="line">RepeatMaskerHome=/home/fenglei/local/app/RepeatMasker/</span><br><span class="line"></span><br><span class="line">$&#123;RepeatMaskerHome&#125;/RepeatMasker -pa 12 \</span><br><span class="line">        -e rmblast \</span><br><span class="line">        -lib consensi.fa.classified \</span><br><span class="line">        -dir Repeat_result \</span><br><span class="line">        -gff \</span><br><span class="line">        -xsmall \</span><br><span class="line">        $refgenome</span><br></pre></td></tr></table></figure>
<p>如何对重复序列元件进行统计？比如每种元件的数目和总长度，从而知道其在基因组所占比例，这也是一般文章需要展示的地方。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 从 RepeatMasker 分析结果找出重复元件的类别</span><br><span class="line">awk &#x27;NR&gt;3&#123;print $11&#125;&#x27; TAIR10_chr_all.fasta.out | sort | uniq -c &gt; repeat.class</span><br><span class="line"># 自编程序统计每种元件的数目和总长度</span><br><span class="line">perl ./statistics.pl  repeat.class TAIR10_chr_all.fasta.out &gt; repeat.stat</span><br><span class="line"># 调用 buildSummary.pl 对重复序列元件进行详细统计</span><br><span class="line">perl ~/local/app/RepeatMasker/util/buildSummary.pl TAIR10_chr_all.fasta.out &gt; TAIR10_chr_all.fasta.out_stat</span><br></pre></td></tr></table></figure>
<p>注：上面自编的statistics.pl程序内容如下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/home/fenglei/local/bin/perl</span><br><span class="line">use warnings;</span><br><span class="line">use strict;</span><br><span class="line"></span><br><span class="line">### usage: ./statistics.pl  repeat.class scaffold_out.final.scaffolds.fasta.out &gt; repeat.stat</span><br><span class="line"></span><br><span class="line">open REPCLASS, $ARGV[0] or die $!;</span><br><span class="line">open REPEATMASKER, $ARGV[1] or die $!;</span><br><span class="line"></span><br><span class="line">while(&lt;REPCLASS&gt;)&#123;</span><br><span class="line">        chomp $_;</span><br><span class="line">        my @reparr=split(/\s+/);</span><br><span class="line">        print &quot;$reparr[2]\t&quot;;</span><br><span class="line">        my $totallength=0;</span><br><span class="line">        my $repeatNum=0;</span><br><span class="line">        while(&lt;REPEATMASKER&gt;)&#123;</span><br><span class="line">                chomp $_;</span><br><span class="line">                $_ =~ s/^\s+//;</span><br><span class="line">                my @repeatmask=split(/\s+/);</span><br><span class="line">                my $repeatlength=0;</span><br><span class="line">#               print &quot;$repeatmask[5]\t$repeatmask[6]\t$repeatmask[10]&quot;; exit;</span><br><span class="line">                if(length($_) == 0)&#123;next;&#125;</span><br><span class="line">                if($reparr[2] eq $repeatmask[10])&#123;</span><br><span class="line">#                       print &quot;$repeatmask[5]\t$repeatmask[6]\t$repeatmask[10]&quot;; exit;</span><br><span class="line">                        $repeatNum = $repeatNum + 1;</span><br><span class="line">                        $repeatlength = $repeatmask[6] - $repeatmask[5];</span><br><span class="line">                        $totallength = $totallength + $repeatlength;</span><br><span class="line">                &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        print &quot;$repeatNum\t$totallength\n&quot;;</span><br><span class="line">        close REPEATMASKER;</span><br><span class="line">        open REPEATMASKER, $ARGV[1] or die $!;</span><br><span class="line">#       print &quot;\n&quot;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">close REPCLASS;</span><br><span class="line">close REPEATMASKER;</span><br></pre></td></tr></table></figure>
<p>以拟南芥为例，下面是输出的部分结果。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Repeat Classes</span><br><span class="line">==============</span><br><span class="line">Total Sequences: 7</span><br><span class="line">Total Length: 119667750 bp</span><br><span class="line">Class                  Count        bpMasked    %masked</span><br><span class="line">=====                  =====        ========     =======</span><br><span class="line">DNA                    --           --           --   </span><br><span class="line">    CMC-EnSpm          878          720527       0.60% </span><br><span class="line">    MULE-MuDR          1202         1171346      0.98% </span><br><span class="line">    PIF-Harbinger      150          71815        0.06% </span><br><span class="line">    TcMar-Pogo         150          31269        0.03% </span><br><span class="line">    hAT-Ac             81           28117        0.02% </span><br><span class="line">    hAT-Tip100         94           86316        0.07% </span><br><span class="line">LINE                   --           --           --   </span><br><span class="line">    L1                 2259         1292456      1.08% </span><br><span class="line">LTR                    --           --           --   </span><br><span class="line">    Copia              1251         1270535      1.06% </span><br><span class="line">    Gypsy              4058         4618620      3.86% </span><br><span class="line">    Pao                55           10627        0.01% </span><br><span class="line">RC                     --           --           --   </span><br><span class="line">    Helitron           1213         556951       0.47% </span><br><span class="line">Unknown                23305        7697251      6.43% </span><br><span class="line">                      ---------------------------------</span><br><span class="line">    total interspersed 34696        17555830     14.67%</span><br><span class="line"></span><br><span class="line">Low_complexity         8617         414746       0.35% </span><br><span class="line">Simple_repeat          34644        1364479      1.14% </span><br><span class="line">rRNA                   265          338782       0.28% </span><br><span class="line">tRNA                   289          84920        0.07% </span><br><span class="line">---------------------------------------------------------</span><br><span class="line">Total                  78511        19758757     16.51%</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">By Sequence</span><br><span class="line">===========</span><br><span class="line">Seq            Count      bpMasked</span><br><span class="line">=====          =====      ========</span><br><span class="line">               2   13984      3678725 </span><br><span class="line">    mitochondria   163        89662   </span><br><span class="line">               1   18731      4168514 </span><br><span class="line">               3   15642      4105811 </span><br><span class="line">     chloroplast   77         49506   </span><br><span class="line">               5   17313      4206310 </span><br><span class="line">               4   12601      3460229 </span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>基因组比对的SAM/BAM文件中，怎么理解MAPQ值</title>
    <url>/2020/12/28/Bioinfo-SAM-BAM-MAPQ-value-in-samtools/</url>
    <content><![CDATA[<p>关注这个问题的缘由是对转录组进行基因定量分析的过程中，发现 stringtie 和 htseq-count 产生的结果不一致。</p>
<p>stringtie 程序里面并没有提供 MAPQ 筛选的参数，也就是输入的 bam 文件中，所有 reads 都会被计数。（如果需要干预，需要提前用 samtools view -q 参数筛选 reads）</p>
<p>而 htseq-cuont 默认会使用 MAPQ&gt;10 来做筛选，即只考虑唯一比对的 reads。</p>
<p>实际上，在植物转录组测序的 reads 中，multiple mapping 的 reads 会占据很大的比例。比如有的基因会有多个拷贝，而且表达量还特别高，那么分析的时候是需要考虑这些问题的。</p>
<h3 id="sambam-文件结构简介"><a class="markdownIt-Anchor" href="#sambam-文件结构简介"></a> SAM/BAM 文件结构简介</h3>
<p><img src="https://miro.medium.com/max/875/0*CePvh8XpBcbC1HjZ.png" alt="Example of the SAM file" /></p>
<p>sam/bam文件一共12列，每列具体信息如下。第五例为MAPQ值。</p>
<p>Each alignment line has 11 mandatory fields for essential alignment information such as mapping position, and variable number of optional fields for flexible or aligner specific information:</p>
<ol>
<li>Read Name</li>
<li>SAM flag</li>
<li>chromosome (if read is has no alignment, there will be a “*” here)</li>
<li>position (1-based index, “left end of read”)</li>
<li>MAPQ (mapping quality — describes the uniqueness of the alignment, 0=non-unique, &gt;10 probably unique)</li>
<li>CIGAR string (describes the position of insertions/deletions/matches in the alignment, encodes splice junctions, for example)</li>
<li>Name of mate (mate pair information for paired-end sequencing, often “=”)</li>
<li>Position of mate (mate pair information)</li>
<li>Template length (always zero for me)</li>
<li>Read Sequence</li>
<li>Read Quality</li>
<li>Program specific Flags (i.e. AS is an alignment score, NH is a number of reported alignments that contains the query in the current record)</li>
</ol>
<h3 id="mapq是怎么定义的"><a class="markdownIt-Anchor" href="#mapq是怎么定义的"></a> MAPQ是怎么定义的？</h3>
<p>Samtools<a href="https://samtools.github.io/hts-specs/SAMv1.pdf">文档</a>中对MAPQ的定义是：</p>
<p>MAPQ: MAPping Quality. It equals −10 log10 Pr{mapping position is wrong}, rounded to the nearest<br />
integer. A value 255 indicates that the mapping quality is not available.</p>
<p>如果正确比对的可能性为 0, 那么错误率 P = 1 - 0 = 1<br />
MAPQ = -10*log10(1) = 0</p>
<p>如果正确比对的可能性为 0.9, 那么错误率 P = 1 - 0.9 = 0.1<br />
MAPQ = -10*log10(0.1) = 10</p>
<p>如果正确比对的可能性为 0.99, 那么错误率 P = 1 - 0.99 = 0.01<br />
MAPQ = -10*log10(0.01) = 20</p>
<p>如果正确比对的可能性为 0.999，那么错误率 P = 1 - 0.999 = 0.001<br />
MAPQ = -10*log10(0.001) = 30</p>
<h3 id="mapq0-的情况到底是指-unmapped-reads-还是指-non-unique-reads"><a class="markdownIt-Anchor" href="#mapq0-的情况到底是指-unmapped-reads-还是指-non-unique-reads"></a> MAPQ=0 的情况到底是指 unmapped reads 还是指 non unique reads？</h3>
<p>MAPQ=0 表示 non unique reads。我查看了 bowtie2 比对之后的 bam 文件，里面 MAPQ=0 的 reads 就是比对到了基因组的多个位置。</p>
<h3 id="mapq0-与-mapq1-有什么区别"><a class="markdownIt-Anchor" href="#mapq0-与-mapq1-有什么区别"></a> MAPQ=0 与 MAPQ=1 有什么区别？</h3>
<p>随机检查了一下 bam 文件中 MAPQ=0 与 MAPQ=1 的两个 PE reads，它们均比对到了基因组的两个不同位置。<br />
应该是比对区域的mismatch导致的MAPQ值不同。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view File1.bam | grep &#x27;V300018696L3C002R0430736588&#x27;</span><br><span class="line">V300018696L3C002R0430736588     99      Chr01   64085   0       90M     =       66302   331     CCCAGCAGTCTGAGTCCGCAGTATCCACCTTATCGGCGGCTGGACGGAACCCCTTCGCTAAGACATCTTGATACCTTAATTTTTCAATCT      FFFFFFFFFEFF@FFFFFFFFFAFFFFFFFFFFFFFFFF;EB-EC+F%6DDDF7DF&#x27;)DDCD&lt;B@D=@D0&#x27;FE(:@FAC8FF$D&lt;(;C3D     AS:i:-7 ZS:i:-7 XN:i:0  XM:i:3  XO:i:0  XG:i:0  NM:i:3  MD:Z:42A14A24A7 YS:i:-13        YT:Z:CP NH:i:2</span><br><span class="line">V300018696L3C002R0430736588     355     Chr01   66206   0       90M     =       66302   186     CCCAGCAGTCTGAGTCCGCAGTATCCACCTTATCGGCGGCTGGACGGAACCCCTTCGCTAAGACATCTTGATACCTTAATTTTTCAATCT      FFFFFFFFFEFF@FFFFFFFFFAFFFFFFFFFFFFFFFF;EB-EC+F%6DDDF7DF&#x27;)DDCD&lt;B@D=@D0&#x27;FE(:@FAC8FF$D&lt;(;C3D     AS:i:-7 ZS:i:-7 XN:i:0  XM:i:3  XO:i:0  XG:i:0  NM:i:3  MD:Z:42A14A24A7 YS:i:-13        YT:Z:CP NH:i:2</span><br><span class="line">V300018696L3C002R0430736588     147     Chr01   66302   0       19M1007N58M13S  =       64085   -331    CTTCTAGCTGTTATCACTCCATCATCCCTCTCTTGCATCTTCTGCTTTTCCTTTGGTGTGGACTTCAACTGGACAACAGGTCCCATGCTC      EFDEFFFFEFEEFEFFFEFFFBFFDFFFFFDFEEFGEEFFEFFFFDEEFFFFDFFFFFFFEEFFDFFFFFFEFFEEFFFFAFEFEFFFEF     AS:i:-13        XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:77 YS:i:-7 YT:Z:CP XS:A:-  NH:i:2</span><br><span class="line">V300018696L3C002R0430736588     403     Chr01   66302   0       19M1007N58M13S  =       66206   -186    CTTCTAGCTGTTATCACTCCATCATCCCTCTCTTGCATCTTCTGCTTTTCCTTTGGTGTGGACTTCAACTGGACAACAGGTCCCATGCTC      EFDEFFFFEFEEFEFFFEFFFBFFDFFFFFDFEEFGEEFFEFFFFDEEFFFFDFFFFFFFEEFFDFFFFFFEFFEEFFFFAFEFEFFFEF     AS:i:-13        XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:77 YS:i:-7 YT:Z:CP XS:A:-  NH:i:2</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">samtools view File1.bam | grep &#x27;V300018696L3C002R0110944536&#x27;</span><br><span class="line">V300018696L3C002R0110944536     99      Chr01   33996   1       90M     =       34061   155     GGAGAGAATTCCTATGCTGCCATATTGTAATAGATAGAGCAATCCACCACATGCCCCGCCTTCTGTGATTACTCGTGGCAACAAATCCAT      FEDFEFFFFEFFFFFDFFFFFFFFFFFCFFFFFEFFFDFEFFFEFFEFFF3FFFFFFEFFFFEFFDFDFE3AE?D6FDEFEEFEFECFFF     AS:i:0  ZS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:90 YS:i:0  YT:Z:CP NH:i:2</span><br><span class="line">V300018696L3C002R0110944536     147     Chr01   34061   1       90M     =       33996   -155    TGATTACTCGTGGCAACAAATCCATCACAGAATTGGATAAAATGGCTAGCCGGATCAGCTGAAAGAGCTCCTATACCCCGGATCCATCTC      DEBFF2E,DFED&gt;FDDFFCFDDFFEFDAFFEEEEBFCFFDEFECEFFEEFDFFFDEDFFFFEEDEFFFCEFFFFDFEBEFFECFFEEFDF     AS:i:0  ZS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:90 YS:i:0  YT:Z:CP NH:i:2</span><br><span class="line">V300018696L3C002R0110944536     355     Chr03   35175098        1       90M     =       35175163        155     GGAGAGAATTCCTATGCTGCCATATTGTAATAGATAGAGCAATCCACCACATGCCCCGCCTTCTGTGATTACTCGTGGCAACAAATCCAT      FEDFEFFFFEFFFFFDFFFFFFFFFFFCFFFFFEFFFDFEFFFEFFEFFF3FFFFFFEFFFFEFFDFDFE3AE?D6FDEFEEFEFECFFF     AS:i:0  ZS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:90 YS:i:0  YT:Z:CP NH:i:2</span><br><span class="line">V300018696L3C002R0110944536     403     Chr03   35175163        1       90M     =       35175098        -155    TGATTACTCGTGGCAACAAATCCATCACAGAATTGGATAAAATGGCTAGCCGGATCAGCTGAAAGAGCTCCTATACCCCGGATCCATCTC      DEBFF2E,DFED&gt;FDDFFCFDDFFEFDAFFEEEEBFCFFDEFECEFFEEFDFFFDEDFFFFEEDEFFFCEFFFFDFEBEFFECFFEEFDF     AS:i:0  ZS:i:0  XN:i:0  XM:i:0  XO:i:0  XG:i:0  NM:i:0  MD:Z:90 YS:i:0  YT:Z:CP NH:i:2</span><br></pre></td></tr></table></figure>
<h3 id="为什么bwa和bowtie2生成的结果中mapq不一样"><a class="markdownIt-Anchor" href="#为什么bwa和bowtie2生成的结果中mapq不一样"></a> 为什么BWA和bowtie2生成的结果中MAPQ不一样？</h3>
<p>In SAM file the quality of mapped reads is defined in by so-called MAPQ values — MAPping Quality. It equals −10 log10 Probability {mapping position is wrong}, rounded to the nearest integer. A value 255 indicates that the mapping quality is not available. Now, it is very important to remember that MAPQ values generated by different aligners (e.g. Bowtie2, TopHat, BBMap, BWA) are not exactly comparable. For example, the maximum value of MAPQ score in Bowtie2 is 42, whereas in BWA — 37. You can read a great piece about why this happens in the ACGT blog post.</p>
<p>Another important thing not everyone knows is how MAPQ value is actually calculated. In our of our previous tutorial, we mentioned that it defines how “uniquely” a particular read maps to a reference. In reality, of course, it is more complex than that and you should check out great post here here to understand the exact procedure on how score gets calculated.</p>
<p>Lastly, remember that TopHat outputs only MAPQ scores of 0, 1, 3, or 50. The first three values indicate mappings to 5 or more locations, 3–4 locations, or 2 locations, whereas a value of 50 represents a unique match. Also, in older versions of TopHat unique matches were identified with a value of 255. Therefore, you must understand that values of Bowtie and Bowtie2 (used internally by TopHat to do read mapping) produce a different range of MAPQ scores (0–42).</p>
<p>Now, as we understand a little bit better MAPQ scores, we can filter BAM/SAM files on the mapping quality. eg. getting all reads with a mapping quality larger than 30 (you could also use 49 if you wanted to:). This will remove all reads mapped the undesirable mapping qualities and will only keep uniquely mapped reads. (<a href="https://medium.com/@shilparaopradeep/samtools-guide-learning-how-to-filter-and-manipulate-with-sam-bam-files-2c28b25d29e8">source</a>)</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>使用Snakemake搭建生物信息分析流程</title>
    <url>/2020/12/28/Bioinfo-Snakemake-for-bioinfomatics-pipeline/</url>
    <content><![CDATA[<p>snakemake 简介：Snakemake is a workflow engine that provides a readable Python-based workflow definition language and a powerful execution environment that scales from single-core workstations to compute clusters without modifying the workflow. It is the first system to support the use of automatically inferred multiple named wildcards (or variables) in input and output filenames. (Johannes Köster, Sven Rahmann, 2012, Bioinformatics 28, 19:2520–2522)</p>
<h3 id="snakemake-安装"><a class="markdownIt-Anchor" href="#snakemake-安装"></a> snakemake 安装</h3>
<p>安装snakemake的方法有多种，snakemake官方推荐的是conda，安装方法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install -c bioconda snakemake</span><br></pre></td></tr></table></figure>
<p>snakemake对python版本有要求，我用python3.7就不能安装，遇到下面的错误。使用 <code>conda create --name python36 python=3.6</code> 新安装了一个python3.6。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UnsatisfiableError: The following specifications were found</span><br><span class="line">to be incompatible with the existing python installation in your environment:</span><br><span class="line"></span><br><span class="line">Specifications:</span><br><span class="line">  - snakemake -&gt; python[version=&#x27;3.4.*|3.5.*|3.6.*|&gt;=3.5,&lt;3.6.0a0|&gt;=3.6,&lt;3.7.0a0&#x27;]</span><br><span class="line"></span><br><span class="line">Your python: python=3.7</span><br></pre></td></tr></table></figure>
<h3 id="一个简单的snakemake脚本"><a class="markdownIt-Anchor" href="#一个简单的snakemake脚本"></a> 一个简单的snakemake脚本</h3>
<p>虽然snakemake广泛的应用于生物信息方面的流程编写，但是snakemake的应用并不局限于编写生物信息学的流程，这里以一个简单的合并文件的例子开始介绍snakemake的简单使用。</p>
<p>首先我们建立两个文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ echo &quot;Here is hello.&quot; &gt; hello.txt</span><br><span class="line">$ echo &quot;Here is world.&quot; &gt; world.txt</span><br></pre></td></tr></table></figure>
<p>接下来开始编写 <code>Snakefile</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rule concat:  # 这里的rule可视为snakemake定义的关键字，concat使我们自定义的这一步任务的名称</span><br><span class="line">    input:   # input同样是snakemake的关键字，定义了在这个任务中的输入文件 </span><br><span class="line">        expand(&quot;&#123;file&#125;.txt&quot;, file=[&quot;hello&quot;, &quot;world&quot;]) #expand是一个snakemake定义的替换命令</span><br><span class="line">    output:   # output也是snakemake的关键字，定义输出结果的保存文件</span><br><span class="line">        &quot;merged.txt&quot;</span><br><span class="line">    shell:  # 这里表示我们下面的命令将在命令行中执行</span><br><span class="line">        &quot;cat &#123;input&#125; &gt; &#123;output&#125;&quot;</span><br></pre></td></tr></table></figure>
<p>最后就可以在Snakefile的路径执行snakemake命令即可</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python36) [fenglei@localhost test]$ snakemake</span><br><span class="line">Provided cores: 1</span><br><span class="line">Rules claiming more threads will be scaled down.</span><br><span class="line">Job counts:</span><br><span class="line">        count   jobs</span><br><span class="line">        1       concat</span><br><span class="line">        1</span><br><span class="line"></span><br><span class="line">rule concat:</span><br><span class="line">    input: hello.txt, world.txt</span><br><span class="line">    output: merged.txt</span><br><span class="line">    jobid: 0</span><br><span class="line"></span><br><span class="line">Finished job 0.</span><br><span class="line">1 of 1 steps (100%) done</span><br><span class="line"></span><br><span class="line">$ cat merge.txt</span><br><span class="line">Here is hello.</span><br><span class="line">Here is world.</span><br></pre></td></tr></table></figure>
<p>在上面的Snakefile脚本中，rule、input、output、shell、expand均为snakemake中的关键字或者命令。同时Snakefile中的每一个rule其实都可以看作是一个简单的shell脚本，通过Snakefile将多个rule组织在一起并按照我们定义的顺序来执行。另外，在output中的结果文件可以是未存在目录中的文件,这时会自动创建不存在的目录。</p>
<h3 id="snakemake中的一些命令与规则"><a class="markdownIt-Anchor" href="#snakemake中的一些命令与规则"></a> snakemake中的一些命令与规则</h3>
<p><em>1、rule</em><br />
rule是Snakefile中最主要的部分。如上面的例子所说，每一个rule定义了一系列pipe中的一步，每一个rule都可以当作一个shell脚本来处理，一般主要包括input、output、shell3个部分。同时还有许多上面没有列出来的用法：</p>
<p>rule all。不同于其他的rule，在rule all里面一般不会去定义要执行的命令，他一般用来定义最后的输出结果文件。除了rule all中定义的文件外最后输出结果不会保存任何中间文件。例如将上面的脚本改成如下文件则没有输出结果：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rule all:</span><br><span class="line">    input:</span><br><span class="line">         #&quot;merged.txt&quot;  取消注释后，则能正常输出文件</span><br><span class="line">rule concat:</span><br><span class="line">    input:</span><br><span class="line">        expand(&quot;&#123;file&#125;.txt&quot;, file=[&quot;hello&quot;, &quot;world&quot;])</span><br><span class="line">    output:</span><br><span class="line">        &quot;merge.txt&quot;</span><br><span class="line">    shell:</span><br><span class="line">        &quot;cat &#123;input&#125; &gt; &#123;output&#125;&quot;</span><br></pre></td></tr></table></figure>
<p>wildcards。用来获取通配符匹配到的部分，例如对于通配符&quot;{dataset}/file.{group}.txt&quot;匹配到文件101/file.A.txt，则{wildcards.dataset}就是101，{wildcards.group}就是A。<br />
threads。通过在rule里面指定threads参数来指定分配给程序的线程数，egthreads: 8。<br />
resources。可用来指定程序运行的内存，eg. resources: mem_mb=800。<br />
message。使用message参数可以指定每运行到一个rule时，在终端中给出提示信息，eg.message: “starting mapping …”。<br />
priority。可用来指定程序运行的优先级，默认为0，eg.priority: 20。<br />
log。用来指定生成的日志文件，eg.log: “logs/concat.log”。<br />
params。指定程序运行的参数，eg.params: cat=“-n”,调用方法为{params.cat}。<br />
run。在run的缩进区域里面可以输入并执行python代码。<br />
scripts。用来执行指定脚本，eg.scripts: “rm_dup.py”<br />
temp。通过temp方法可以在所有rule运行完后删除指定的中间文件，eg.output: temp(“f1.bam”)。<br />
protected。用来指定某些中间文件是需要保留的，eg.output: protected(“f1.bam”)。<br />
ancient。重复运行执行某个Snakefile时，snakemake会通过比较输入文件的时间戳是否更改(比原来的新)来决定是否重新执行程序生成文件，使用ancient方法可以强制使得结果文件一旦生成就不会再次重新生成覆盖，即便输入文件时间戳已经更新，eg.input: ancient(“f1.fastq”)。<br />
Rule Dependencies。可通过快捷方式指定前一个rule的输出文件为此rule的输入文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rule a:</span><br><span class="line">    input:  &quot;path/to/input&quot;</span><br><span class="line">    output: &quot;path/to/output&quot;</span><br><span class="line">    shell:  ...</span><br><span class="line"></span><br><span class="line">rule b:</span><br><span class="line">    input:  rules.a.output   #直接通过rules.a.output 指定rule a的输出</span><br><span class="line">    output: &quot;path/to/output/of/b&quot;</span><br><span class="line">    shell:  ...</span><br></pre></td></tr></table></figure>
<p>report。使用snakemake定义的report函数可以方便的将结果嵌入到一个HTML文件中进行查看。</p>
<p><em>2. configuration</em></p>
<p>每计算一次数据都要重写一次Snakefile有时可能会显得有些繁琐，我们可以将那些改动写入配置文件，使用相同流程计算时，将输入文件的文件名写入配置文件然后通过Snakefile读入即可。<br />
配置文件有两种书写格式——json和yaml。在Snakefile中读入配置文件使用如下方式：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">configfile: &quot;path/to/config.json&quot; </span><br><span class="line">configfile: &quot;path/to/config.yaml&quot;</span><br><span class="line"></span><br><span class="line"># 也可直接在执行snakemake命令时指定配置</span><br><span class="line">$ snakemake --config yourparam=1.5</span><br></pre></td></tr></table></figure>
<p>在shell命令中直接调用config文件中的内容的话，不需要引号，如config[a]而不是config[“a”]。</p>
<h3 id="snakemake-的执行"><a class="markdownIt-Anchor" href="#snakemake-的执行"></a> snakemake 的执行</h3>
<p>一般讲所有的参数配置写入Snakefile后直接在Snakefile所在路径执行snakemake命令即可开始执行流程任务。一些常用的参数：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">--snakefile, -s 指定Snakefile，否则是当前目录下的Snakefile</span><br><span class="line">--dryrun, -n  不真正执行，一般用来查看Snakefile是否有错</span><br><span class="line">--printshellcmds, -p   输出要执行的shell命令</span><br><span class="line">--reason, -r  输出每条rule执行的原因,默认FALSE</span><br><span class="line">--cores, --jobs, -j  指定运行的核数，若不指定，则使用最大的核数</span><br><span class="line">--force, -f 重新运行第一条rule或指定的rule</span><br><span class="line">--forceall, -F 重新运行所有的rule，不管是否已经有输出结果</span><br><span class="line">--forcerun, -R 重新执行Snakefile，当更新了rule时候使用此命令</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#一些可视化命令</span><br><span class="line">$ snakemake --dag | dot -Tpdf &gt; dag.pdf</span><br><span class="line"></span><br><span class="line">#集群投递</span><br><span class="line">snakemake --cluster &quot;qsub -V -cwd -q 节点队列&quot; -j 10</span><br><span class="line"># --cluster /-c CMD: 集群运行指令</span><br><span class="line"># qusb -V -cwd -q， 表示输出当前环境变量(-V),在当前目录下运行(-cwd), 投递到指定的队列(-q), 如果不指定则使用任何可用队列</span><br><span class="line"># --local-cores N: 在每个集群中最多并行N核</span><br><span class="line"># --cluster-config/-u FILE: 集群配置文件</span><br></pre></td></tr></table></figure>
<h2 id="u"><a class="markdownIt-Anchor" href="#u"></a> <a href="https://vidotto.top/post/%E4%BD%BF%E7%94%A8-snakemake-%E7%BC%96%E5%86%99-rna-seq-%E6%B5%81%E7%A8%8B/"><u>使用 snakemake 编写 RNA seq 流程</u></a></h2>
<p>学习生信两年多了，自己也积累了一些测序数据分析流程，后来数据越来越多就有把流程自动化以方便分析工作。开始是将流程写成 shell 脚本，但是有时候还需要根据不同的数据去更改一些步骤的参数，所以每次用还是要检查一下脚本。后来发现 snakemake 流程管理工具，它完全能够满足我目前的需求。</p>
<p>我以搭建转录组流程为例子介绍如何使用 snakemake 搭建适合你的流程。</p>
<h3 id="创建一个单独的文件夹存放测序数据"><a class="markdownIt-Anchor" href="#创建一个单独的文件夹存放测序数据"></a> 创建一个单独的文件夹存放测序数据</h3>
<p>创建名为 input 的文件夹存放转录组测序数据，我使用的数据如下：</p>
<p>s1-1_RRL18212-V_1.fq.gz——Control(forward)<br />
s1-1_RRL18212-V_2.fq.gz——Control(reverse)<br />
s1-2_RRL18214-V_1.fq.gz——Treated(forward)<br />
s1-2_RRL18214-V_2.fq.gz——Treated(reverse)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">input</span><br><span class="line">├── s1-1_RRL18212-V_1.fq.gz</span><br><span class="line">├── s1-1_RRL18212-V_2.fq.gz</span><br><span class="line">├── s1-2_RRL18214-V_1.fq.gz</span><br><span class="line">└── s1-2_RRL18214-V_2.fq.gz</span><br></pre></td></tr></table></figure>
<h3 id="为-star-比对步骤准备-index"><a class="markdownIt-Anchor" href="#为-star-比对步骤准备-index"></a> 为 STAR 比对步骤准备 index</h3>
<p>我们需要把测序数据比对到小鼠参考基因组上，需要先下载小鼠（GRCm38.p6）参考基因组文件并使用 STAR 的 genomeGenerate 创建 index 。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir genome</span><br><span class="line">wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M20/GRCm38.p6.genome.fa.gz</span><br><span class="line">wget ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_mouse/release_M20/gencode.vM20.annotation.gtf.gz</span><br><span class="line">pigz -d GRCm38.p6.genome.fa.gz gencode.vM20.annotation.gtf.gz</span><br><span class="line"></span><br><span class="line">STAR \</span><br><span class="line">--runMode genomeGenerate \</span><br><span class="line">--genomeDir star_index \</span><br><span class="line">--genomeFastaFiles genome/GRCm38.p6.genome.fa \</span><br><span class="line">--sjdbGTFfile annotation/gencode.vM20.annotation.gtf \</span><br><span class="line">--runThreadN 4</span><br></pre></td></tr></table></figure>
<h3 id="编写-snakefile"><a class="markdownIt-Anchor" href="#编写-snakefile"></a> 编写 snakefile</h3>
<p>创建一个文件名为 snakefile 的文件，我们的流程主要编写在这个文件里。</p>
<p>我们先看一个基础 snakefile 是什么样子的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rule bwa_map:</span><br><span class="line">    input:</span><br><span class="line">        &quot;data/genome.fa&quot;,</span><br><span class="line">        &quot;data/samples/A.fastq&quot;</span><br><span class="line">    output:</span><br><span class="line">        &quot;mapped_reads/A.bam&quot;</span><br><span class="line">    shell:</span><br><span class="line">        &quot;bwa mem &#123;input&#125; | samtools view -Sb - &gt; &#123;output&#125;&quot;</span><br></pre></td></tr></table></figure>
<p>每一个 rule 表示不同的任务，需要通过 input 和 output 指定任务需要的输入文件和会产生的输出文件，run 就指明该任务的将要运行的命令行。</p>
<h3 id="第一个任务fastqc"><a class="markdownIt-Anchor" href="#第一个任务fastqc"></a> 第一个任务：fastqc</h3>
<p>第一个任务我们检测测序数据质量，按照 snakemake 规则如下写法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rule fastqc:</span><br><span class="line">    input:</span><br><span class="line">        &quot;input/&#123;sample&#125;_1.fq.gz&quot;,</span><br><span class="line">        &quot;input/&#123;sample&#125;_2.fq.gz&quot;</span><br><span class="line">    output:</span><br><span class="line">        &quot;results/1_initial_qc/&#123;sample&#125;/&#123;sample&#125;_1_fastqc.zip&quot;,</span><br><span class="line">        &quot;results/1_initial_qc/&#123;sample&#125;/&#123;sample&#125;_2_fastqc.zip&quot;,</span><br><span class="line">        &quot;results/1_initial_qc/&#123;sample&#125;/&#123;sample&#125;_1_fastqc.html&quot;,</span><br><span class="line">        &quot;results/1_initial_qc/&#123;sample&#125;/&#123;sample&#125;_2_fastqc.html&quot;</span><br><span class="line">    log:</span><br><span class="line">        &quot;log/&#123;sample&#125;_fastqc&quot;</span><br><span class="line">    shell:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        fastqc -o results/1_initial_qc/&#123;wildcards.sample&#125; --noextract &#123;input[0]&#125; &#123;input[1]&#125; 2&gt; &#123;log&#125;</span><br><span class="line">        &quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<p>因为是双端测序数据，我每次运行将一个样品的两端数据同时检测。可以发现在 input 和 output 里我都使用了 {sample} 字样，这是snakemake 中的通配方式，比如 input/{sample}_1.fq.gz 就可以通配到：s1-1_RRL18212-V_1.fq.gz 和 s1-2_RRL18214-V_1.fq.gz 两个文件，这一点是 snakemake 的精髓，这样我们一行命令就能把所以样品都跑完流程。</p>
<h3 id="第二个任务fastp"><a class="markdownIt-Anchor" href="#第二个任务fastp"></a> 第二个任务：fastp</h3>
<p>对测序数据进行质量控制步骤，主要修剪一些接头序列和去除低质量 reads 。这里我一般使用 fastp 自动化完成这一步。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rule fastp:</span><br><span class="line">    input:</span><br><span class="line">        &quot;input/&#123;sample&#125;_1.fq.gz&quot;,</span><br><span class="line">        &quot;input/&#123;sample&#125;_2.fq.gz&quot;</span><br><span class="line">    output:</span><br><span class="line">        &quot;results/2_fastp_output/&#123;sample&#125;_1_good.fq.gz&quot;,</span><br><span class="line">        &quot;results/2_fastp_output/&#123;sample&#125;_2_good.fq.gz&quot;,</span><br><span class="line">        &quot;results/2_fastp_output/&#123;sample&#125;.html&quot;,</span><br><span class="line">        &quot;results/2_fastp_output/&#123;sample&#125;.json&quot;</span><br><span class="line">    log:</span><br><span class="line">        &quot;log/&#123;sample&#125;_fastp&quot;</span><br><span class="line">    shell:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        fastp -w 10 -h results/2_fastp_output/&#123;wildcards.sample&#125;.html -j results/2_fastp_output/&#123;wildcards.sample&#125;.json -i &#123;input[0]&#125; -I &#123;input[1]&#125; -o &#123;output[0]&#125; -O &#123;output[1]&#125; 2&gt; &#123;log&#125;</span><br><span class="line">        &quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<p>仔细阅读 snakemake 的文档之后就会发现它的语法非常简单，并且有很强的阅读性。这个任务中需要对 shell 部分做一点解释。<br />
首先，我想每个样品都设置有样品名的结果文件（html 和json），我使用 {wildcards.sample} 获得通配名。<br />
其二，shell 命令里面需要两个设定两个输入和输出，这里和 python 中的切片类似，或者我们可以在 input 和 output 这一步骤就对文件进行命令，这样可读性更好，比如：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rule fastp:</span><br><span class="line">    input:</span><br><span class="line">        fwd:&quot;input/&#123;sample&#125;_1.fq.gz&quot;,</span><br><span class="line">        rev:&quot;input/&#123;sample&#125;_2.fq.gz&quot;</span><br><span class="line">    output:</span><br><span class="line">        fwwd:&quot;results/2_fastp_output/&#123;sample&#125;_1_good.fq.gz&quot;,</span><br><span class="line">        rev:&quot;results/2_fastp_output/&#123;sample&#125;_2_good.fq.gz&quot;,</span><br><span class="line">        &quot;results/2_fastp_output/&#123;sample&#125;.html&quot;,</span><br><span class="line">        &quot;results/2_fastp_output/&#123;sample&#125;.json&quot;</span><br><span class="line">    log:</span><br><span class="line">        &quot;log/&#123;sample&#125;_fastp&quot;</span><br><span class="line">    shell:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        fastp -w 10 -h results/2_fastp_output/&#123;wildcards.sample&#125;.html -j results/2_fastp_output/&#123;wildcards.sample&#125;.json -i &#123;input[fwd]&#125; -I &#123;input[rev]&#125; -o &#123;output[fwd]&#125; -O &#123;output[rev]&#125; 2&gt; &#123;log&#125;</span><br><span class="line">        &quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<h3 id="第三个任务star"><a class="markdownIt-Anchor" href="#第三个任务star"></a> 第三个任务：STAR</h3>
<p>完成质量控制部分后就可以进行数据比对这一步骤了，上一任务的输出文件是这一任务的输入文件，snakemake 利用不同任务之间文件的关系来自动理顺任务关系。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rule STAR:</span><br><span class="line">    input:</span><br><span class="line">        &quot;results/2_fastp_output/&#123;sample&#125;_1_good.fq.gz&quot;,</span><br><span class="line">        &quot;results/2_fastp_output/&#123;sample&#125;_2_good.fq.gz&quot;</span><br><span class="line">    output:</span><br><span class="line">        &quot;results/3_aligned_sequences/&#123;sample&#125;Aligned.sortedByCoord.out.bam&quot;,</span><br><span class="line">        &quot;results/3_aligned_sequences/&#123;sample&#125;Log.final.out&quot;,</span><br><span class="line">        &quot;results/3_aligned_sequences/&#123;sample&#125;Log.out&quot;</span><br><span class="line">    params:&quot;&#123;sample&#125;&quot;</span><br><span class="line">    log:</span><br><span class="line">        &quot;log/&#123;sample&#125;_STAR&quot;</span><br><span class="line">    shell:</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">        STAR --genomeDir &#123;config[star_index]&#125;  --readFilesCommand zcat --readFilesIn &#123;input[0]&#125; &#123;input[1]&#125; --runThreadN 10 \</span><br><span class="line">        --outSAMtype BAM SortedByCoordinate --quantMode GeneCounts --outFileNamePrefix results/3_aligned_sequences/&#123;params&#125; 2&gt; &#123;log&#125;</span><br><span class="line">        &quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<p>我在这个任务中使用了配置文件中的参数，在开始我没有说明这点，我们可以将软件运行参数单独存放在配置文件里，每次使用 snakemake 的时候只需要修改配置文件而不需要对主流程进行修改。<br />
在snakefile 的开始要对配置文件进行声明configfile:“config.yaml”。<br />
在这个任务中我还设置了 params ，我们可以将命令中的一些静态参数写在这里以提高易读性。在 rule 中的 params 可以直接在shell 中调用。</p>
<h3 id="第四个任务featurecounts"><a class="markdownIt-Anchor" href="#第四个任务featurecounts"></a> 第四个任务：featureCounts</h3>
<p>最后就要对各个样品进行定量了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rule featureCounts:</span><br><span class="line">    input:</span><br><span class="line">        expand(&quot;results/3_aligned_sequences/&#123;sample&#125;Aligned.sortedByCoord.out.bam&quot;, sample=SAMPLES)</span><br><span class="line">    output:</span><br><span class="line">        &quot;results/4_final_counts/final_counts.txt&quot;,</span><br><span class="line">        &quot;results/4_final_counts/final_counts.txt.summary&quot;</span><br><span class="line">    log:</span><br><span class="line">        &quot;log/featurecounts.log&quot;</span><br><span class="line">    shell:</span><br><span class="line">        &quot;&quot;&quot; </span><br><span class="line">        ls results/3_aligned_sequences/*bam | xargs featureCounts -a &#123;config[gtf]&#125; -o &#123;output[0]&#125; \</span><br><span class="line">        -T 5 -t exon -g gene_id 2&gt; &#123;log&#125;</span><br><span class="line">        &quot;&quot;&quot;</span><br></pre></td></tr></table></figure>
<p>snakemake 另外一个很简便的地方就在于它将列表推导式简化为 expand 函数，比如这个任务中的 input 就会生成所有符合条件的 bam 文件。</p>
<h3 id="总结"><a class="markdownIt-Anchor" href="#总结"></a> 总结</h3>
<p>这只是使用 snakemake 编写的简单的流程，主要想记录下在学习 snakemake 中的几个知识点，snakemake 还有其他的一些使用技巧我会在日后其他的流程中慢慢总结。如果你有写生信分析流程的需要还是非常推荐这个工具，它还有很多高级技巧有待我细细挖掘。</p>
<p><strong>全文来源</strong><br />
<a href="https://www.jianshu.com/p/14b9eccc0c0e"><u>井底蛙蛙呱呱呱</u></a><br />
<a href="https://vidotto.top/post/%E4%BD%BF%E7%94%A8-snakemake-%E7%BC%96%E5%86%99-rna-seq-%E6%B5%81%E7%A8%8B/"><u>Vidotto’s blog：使用 snakemake 编写 RNA seq 流程</u></a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | TCseq Time Course sequencing data analysis</title>
    <url>/2021/09/16/Bioinfo-TCseq-Time-Course-sequencing-data-analysis/</url>
    <content><![CDATA[<p>转录组测序如果有多个时间点，可以做表达趋势分析，即基因表达模式聚类分析，可以用 STEM、Mfuzz、TCseq 软件等工具。</p>
<p>Mfuzz 采用了一种新的聚类算法 fuzzy c-means algorithm，在文献中称这种聚类算法为 soft clustering 算法，相比 K-means 等 hard clustering 算法，一定程度上降低了噪声对聚类结果的干扰，而且这种算法有效的定义了基因和 cluster 之间的关系，即基因是否属于某个 cluster, 对应的值为 memebership。</p>
<p>对于分析而言，我们只需要提供基因表达量的数据就可以了，需要注意的是，Mfuzz 默认你提供的数据是归一化之后的表达量，这意味着表达量必须可以直接在样本间进行比较，对于 FPKM, TPM 这两种定量方式而言，是可以直接在样本间进行比较的，但是对于 count 的定量结果，我们必须先进行归一化，可以使用 edgeR 或者 DESeq 先得到归一化之后的数据再进行后续分析。Mfuzz 的使用可参考：<a href="https://cloud.tencent.com/developer/article/1625288">生信修炼手册：使用 Mfuzz 进行时间序列表达模式聚类分析</a></p>
<p>TCseq 则可以用 count 定量来做输入，他自己会调用 edgeR 来做样品之间的归一化。分析之前准备三个文件：（1）基因表达矩阵文件，可以直接拿原始 read count 数据；（2）样品分组情况的文件；（3）基因坐标文件。</p>
<p>下面列出文件内容：</p>
<p>（1）基因表达矩阵文件，可以直接拿原始 read count 数据。我是用 htseq-count 工具来做的每个基因的 read count 统计，这里按下不表。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gene-id	L1-1A	L1-2A	L1-3A	L2-1A	L2-2A	L2-3A	L3-1A	L3-2A	L3-3A	L4-1A	L4-2A	L4-3A</span><br><span class="line">Chr01.g00016	72	74	30	16	95	134	100	10	57	95	78	5</span><br><span class="line">Chr01.g00017	1645	2072	2672	791	1105	1726	3060	947	882	1576	2414	466</span><br><span class="line">Chr01.g00018	8	3	59	6	16	16	19	6	0	12	3	1</span><br><span class="line">Chr01.g00019	1	14	26	2	5	7	15	0	0	8	6	0</span><br><span class="line">Chr01.g00020	0	0	0	0	0	0	0	0	0	0	0	0</span><br><span class="line">Chr01.g00021	0	0	0	0	0	0	0	0	0	0	0	0</span><br><span class="line">Chr01.g00022	1744	1912	2568	1549	2708	1966	2198	2308	1995	1789	2255	1697</span><br><span class="line">Chr01.g00023	8	1	3	8	14	3	6	3	6	0	7	1</span><br><span class="line">Chr01.g00024	39	25	69	127	103	8	43	170	167	89	89	67</span><br><span class="line">Chr01.g00025	0	0	0	0	0	0	0	0	0	0	0	0</span><br><span class="line">Chr01.g00026	0	1	0	6	2	1	17	30	8	2	5	94</span><br><span class="line">Chr01.g00027	748	794	808	370	640	805	886	1169	786	677	864	817</span><br><span class="line">... ... (其余省略)</span><br></pre></td></tr></table></figure>
<p>（2）样品分组文件 (样品，时间点，分组三列)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sampleid	timepoint	group</span><br><span class="line">L1-1A	0h	1</span><br><span class="line">L1-2A	0h	1</span><br><span class="line">L1-3A	0h	1</span><br><span class="line">L2-1A	2h	2</span><br><span class="line">L2-2A	2h	2</span><br><span class="line">L2-3A	2h	2</span><br><span class="line">L3-2A	24h	3</span><br><span class="line">L3-3A	24h	3</span><br><span class="line">L4-1A	48h	4</span><br><span class="line">L4-2A	48h	4</span><br><span class="line">L4-3A	48h	4</span><br></pre></td></tr></table></figure>
<p>（3）基因坐标文件 (染色体，起始及终止位点，基因id四列)</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chr	start	end	id</span><br><span class="line">scaffold_1	760	5575	scaffold_1.g00001</span><br><span class="line">scaffold_1	81403	85562	scaffold_1.g00002</span><br><span class="line">scaffold_1	122872	124937	scaffold_1.g00003</span><br><span class="line">scaffold_1	138239	140514	scaffold_1.g00004</span><br><span class="line">scaffold_1	156823	159196	scaffold_1.g00005</span><br><span class="line">scaffold_1	160925	162845	scaffold_1.g00006</span><br><span class="line">scaffold_1	195980	199165	scaffold_1.g00007</span><br><span class="line">scaffold_1	199535	200289	scaffold_1.g00008</span><br></pre></td></tr></table></figure>
<h3 id="读取输入基因表达量与分组数据"><a class="markdownIt-Anchor" href="#读取输入基因表达量与分组数据"></a> 读取输入基因表达量与分组数据</h3>
<p>准备好上述三个文件，就可以在 Rstudio 界面开始加载 TCseq 包，读取上述三个数据文件，开始分析。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">setwd(&quot;C:/R-data&quot;)</span><br><span class="line"></span><br><span class="line">#To install this package, start R (version &quot;4.1&quot;) and enter:</span><br><span class="line">  </span><br><span class="line"> if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE))</span><br><span class="line">    install.packages(&quot;BiocManager&quot;)</span><br><span class="line"></span><br><span class="line">BiocManager::install(&quot;TCseq&quot;)</span><br><span class="line">library(TCseq)</span><br><span class="line"></span><br><span class="line">BiocManager::install(&quot;topGO&quot;)   ## 画GO树状图需要用</span><br><span class="line">library(topGO)</span><br><span class="line"></span><br><span class="line">library(dplyr)</span><br><span class="line"></span><br><span class="line"># To view documentation for the version of this package installed in your system, start R and enter:</span><br><span class="line">browseVignettes(&quot;TCseq&quot;)</span><br><span class="line"></span><br><span class="line">rm(list = ls())  # 清除 Rstudio 里面旧的变量</span><br><span class="line">ls()</span><br><span class="line"># 位置信息文件</span><br><span class="line">genomicIntervals &lt;- read.delim(&#x27;AMO.intervial.txt&#x27;, stringsAsFactors = FALSE)</span><br><span class="line">genomicIntervals$chr &lt;- as.factor(genomicIntervals$chr)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">## 表达量矩阵文件</span><br><span class="line">#count &lt;- read.delim(&#x27;all_read_count.txt&#x27;,header = T,row.names = 1) ### read count table</span><br><span class="line"></span><br><span class="line">count &lt;- read.delim(&#x27;all_read_count.txt&#x27;,header = T,row.names = 1) ### read count table</span><br><span class="line">count &lt;- count[,-7]   ### L3-1A 样品数据有问题，剔除  # Optional</span><br><span class="line"></span><br><span class="line"># as.integer 转换为整数型</span><br><span class="line">countsTable &lt;- count %&gt;%  mutate(across(where(is.numeric), as.integer))   # 依赖 dplyr 包</span><br><span class="line"># or</span><br><span class="line">#count1 &lt;- apply(count, 2, as.integer)</span><br><span class="line">rownames(countsTable) &lt;- rownames(count)</span><br><span class="line">##矩阵形式</span><br><span class="line">countsTable &lt;- as.matrix(countsTable)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 分组文件</span><br><span class="line">experiment &lt;- read.delim(&#x27;leaf_group.txt&#x27;,header = T,stringsAsFactors = FALSE)</span><br><span class="line">experiment$sampleid &lt;- as.factor(experiment$sampleid)</span><br></pre></td></tr></table></figure>
<h3 id="创建tca对象"><a class="markdownIt-Anchor" href="#创建tca对象"></a> 创建TCA对象</h3>
<p>TCseq 使用 S4 类 TCA 存储所有输入数据以进行后续分析。根据以上三个文件创造即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tca &lt;- TCA(design = experiment, genomicFeature = genomicIntervals, counts = countsTable)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tca  # 此次摘抄自 凯凯何_Boy 链接：https://www.jianshu.com/p/26332e4da742</span><br><span class="line">  ##############</span><br><span class="line">  An object of class &quot;TCA&quot;</span><br><span class="line">@design</span><br><span class="line">  sampleid timepoint group</span><br><span class="line">1       s1        0h     1</span><br><span class="line">2       s2        0h     1</span><br><span class="line">3       s3        0h     1</span><br><span class="line">4       s4       24h     2</span><br><span class="line">5       s5       24h     2</span><br><span class="line">6       s6       24h     2</span><br><span class="line">7       s7       48h     3</span><br><span class="line">8       s8       48h     3</span><br><span class="line">9       s9       48h     3</span><br><span class="line"></span><br><span class="line">@counts</span><br><span class="line">                    s1  s2  s3  s4  s5  s6  s7  s8  s9</span><br><span class="line">ENSBTAG00000000005  60  58  70  64  60  74  53  55  50</span><br><span class="line">ENSBTAG00000000008   0   0   0   1   0   1   2   0   0</span><br><span class="line">ENSBTAG00000000009   0   1   3   0   1   0  11   9   9</span><br><span class="line">ENSBTAG00000000010 341 300 341 170 216 214 150 236 199</span><br><span class="line">ENSBTAG00000000011   4   2   3   5   3   1   6   2   3</span><br><span class="line">29749 more rows ...</span><br><span class="line"></span><br><span class="line">@genomicFeature</span><br><span class="line">   chr     start       end                 id</span><br><span class="line">1 chr1 100098899 100161382 ENSBTAG00000035710</span><br><span class="line">2 chr1 100754351 100754458 ENSBTAG00000043293</span><br><span class="line">3 chr1 101522743 101601659 ENSBTAG00000011139</span><br><span class="line">4 chr1 101619573 101646742 ENSBTAG00000053582</span><br><span class="line">5 chr1 101776678 101776956          MSTRG.445</span><br><span class="line">29749 more rows ...</span><br><span class="line"></span><br><span class="line">@clusterRes</span><br><span class="line">An object of class &quot;clust&quot;</span><br><span class="line">另一种创建的方式,是通过SummarizedExperiment对象：</span><br><span class="line"></span><br><span class="line">suppressWarnings(library(SummarizedExperiment))</span><br><span class="line">se &lt;- SummarizedExperiment(assays=list(counts = countsTable), colData = experiment)</span><br><span class="line">tca &lt;- TCAFromSummarizedExperiment(se = se, genomicFeature = genomicIntervals)</span><br></pre></td></tr></table></figure>
<p>现在已经基于这三个文件得到了TCA对象</p>
<h3 id="差异分析"><a class="markdownIt-Anchor" href="#差异分析"></a> 差异分析</h3>
<p>该包内置了我们常用的差异分析 R 包 edgeR，通过使用广义线性模型 (GLM) 方法去鉴定差异基因。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tca &lt;- DBanalysis(tca）</span><br><span class="line">## 我们也可以增添一些参数进行过滤</span><br><span class="line">tca &lt;- DBanalysis(tca, filter.type = &quot;raw&quot;, filter.value = 10, samplePassfilter = 2)</span><br><span class="line">#比如上述步骤保留具有两个或多个已读取样本的基因表达量超过10的基因组区域</span><br><span class="line"></span><br><span class="line">tca &lt;- DBanalysis(tca, filter.type = &quot;raw&quot;, filter.value = 10, samplePassfilter = 2)  # 与上面的选一个即可，这个命令是加了筛选参数的。</span><br><span class="line">#比如上述步骤保留具有两个或多个已读取样本的基因表达量超过10的基因组区域</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="提取差异分析结果"><a class="markdownIt-Anchor" href="#提取差异分析结果"></a> 提取差异分析结果</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#####################</span><br><span class="line">####提取差异分析结果</span><br><span class="line">#####################</span><br><span class="line"># 通过DBresult函数可以直接提取我们差异分析的结果，并通过$去查看各个组的内容。</span><br><span class="line">DBres &lt;- DBresult(tca, group1 = &quot;0h&quot;, group2 = c(&quot;2h&quot;,&quot;24h&quot;,&quot;48h&quot;))</span><br><span class="line">str(DBres, strict.width =  &quot;cut&quot;)</span><br><span class="line">head(DBres$`24hvs0h`)</span><br><span class="line"># 若只想提取满足显著差异的结果(一般abs(log2-fold &gt; 2)且adjust p-value&lt;0.05)，只需要加上top.sig = TRUE函数即可。</span><br><span class="line">## 显著差异</span><br><span class="line">DBres.sig &lt;- DBresult(tca, group1 = &quot;0h&quot;, group2 = c(&quot;2h&quot;,&quot;24h&quot;,&quot;48h&quot;), top.sig = TRUE)</span><br><span class="line">str(DBres.sig, strict.width =  &quot;cut&quot;)</span><br><span class="line">#############</span><br></pre></td></tr></table></figure>
<p>下面是摘抄他人的案例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">通过DBresult函数可以直接提取我们差异分析的结果，在通过$去查看各个组的内容。</span><br><span class="line"></span><br><span class="line">DBres &lt;- DBresult(tca, group1 = &quot;0h&quot;, group2 = c(&quot;24h&quot;,&quot;48h&quot;))</span><br><span class="line">str(DBres, strict.width =  &quot;cut&quot;)</span><br><span class="line">head(DBres$`24hvs0h`)</span><br><span class="line">############</span><br><span class="line">GRanges object with 6 ranges and 4 metadata columns:</span><br><span class="line">                     seqnames              ranges strand |     logFC      PValue         paj</span><br><span class="line">                        &lt;Rle&gt;           &lt;IRanges&gt;  &lt;Rle&gt; | &lt;numeric&gt;   &lt;numeric&gt;   &lt;numeric&gt;</span><br><span class="line">  ENSBTAG00000000005     chr1 100098899-100161382      * |  0.274010 1.35162e-01 2.81082e-01</span><br><span class="line">  ENSBTAG00000000009     chr1 101522743-101601659      * | -1.501457 2.26674e-01 4.03419e-01</span><br><span class="line">  ENSBTAG00000000010     chr1 101776678-101776956      * | -0.513593 3.36326e-06 3.80124e-05</span><br><span class="line">  ENSBTAG00000000011     chr1   10231295-10543983      * |  0.198446 7.93039e-01 8.90540e-01</span><br><span class="line">  ENSBTAG00000000012     chr1 102768932-102769966      * | -0.300941 5.04886e-03 2.18330e-02</span><br><span class="line">  ENSBTAG00000000013     chr1 105069395-105069910      * |  0.140489 1.63446e-01 3.21469e-01</span><br><span class="line">                                     id</span><br><span class="line">                            &lt;character&gt;</span><br><span class="line">  ENSBTAG00000000005 ENSBTAG00000035710</span><br><span class="line">  ENSBTAG00000000009 ENSBTAG00000011139</span><br><span class="line">  ENSBTAG00000000010          MSTRG.445</span><br><span class="line">  ENSBTAG00000000011 ENSBTAG00000017753</span><br><span class="line">  ENSBTAG00000000012 ENSBTAG00000048551</span><br><span class="line">  ENSBTAG00000000013          MSTRG.449</span><br><span class="line">  -------</span><br><span class="line">  seqinfo: 206 sequences from an unspecified genome; no seqlengths</span><br><span class="line"></span><br><span class="line"># 作者：凯凯何_Boy https://www.jianshu.com/p/26332e4da742</span><br></pre></td></tr></table></figure>
<h3 id="时间趋势分析"><a class="markdownIt-Anchor" href="#时间趋势分析"></a> 时间趋势分析</h3>
<p>接下来就到了趋势分析的换件了，为了检测数据的时序模式，TCseq包使用了非监督聚类的方法,首先通过聚类创建一个时程表，行为基因组区域信息，列为时间点，表中的数值可以选择标准化后的表达量值或者是基于初始时间点所有样品点的LogFC值，代码中通过value参数来调整，另外若设置filter = TRUE时候，将自动过滤在任何两个时间段都没有显著差异的基因组区域，结果通过tcTable函数进行查看</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##通过标准化后的表达量来做聚类</span><br><span class="line"># tca &lt;- timecourseTable(tca, value = &quot;expression&quot;, norm.method = &quot;rpkm&quot;, filter = TRUE)  # Aug 9 用的这个</span><br><span class="line">tca &lt;- timecourseTable(tca, value = &quot;expression&quot;, lib.norm = TRUE, norm.method = &quot;rpkm&quot;, filter = TRUE, pvalue.threshold =  0.1, abs.fold = 1.5)</span><br><span class="line">#tca &lt;- timecourseTable(tca, value = &quot;expression&quot;, norm.method = &quot;rpkm&quot;, filter = FALSE)</span><br><span class="line"></span><br><span class="line">## 通过LogFC值来做聚类</span><br><span class="line">#tca &lt;- timecourseTable(tca, value = &quot;FC&quot;, norm.method = &quot;rpkm&quot;, filter = TRUE)</span><br><span class="line"></span><br><span class="line">## 查看生成结果</span><br><span class="line">t &lt;- tcTable(tca)</span><br><span class="line">head(t)</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## 通过LogFC值</span><br><span class="line">tca &lt;- timecourseTable(tca, value = &quot;FC&quot;, norm.method = &quot;rpkm&quot;, filter = TRUE)</span><br><span class="line"></span><br><span class="line">##通过标准化后的表达量</span><br><span class="line">tca &lt;- timecourseTable(tca, value = &quot;expression&quot;, norm.method = &quot;rpkm&quot;, filter = TRUE)</span><br><span class="line"></span><br><span class="line">## 查看生成结果</span><br><span class="line">t &lt;- tcTable(tca)</span><br><span class="line">head(t)</span><br><span class="line">                             0h          24h          48h</span><br><span class="line">ENSBTAG00000000425 0.0000000000  0.030165698 0.0075187827</span><br><span class="line">ENSBTAG00000000706 2.6013480888 11.521986790 1.7768887654</span><br><span class="line">ENSBTAG00000000936 0.0007283438  0.003506178 0.0003475789</span><br><span class="line">ENSBTAG00000001325 0.0002585125  0.001290036 0.0001705818</span><br><span class="line">ENSBTAG00000001687 0.3065966903  2.485377556 2.6233245852</span><br><span class="line">ENSBTAG00000001745 0.2496824763  2.120932031 4.7101417152</span><br></pre></td></tr></table></figure>
<h3 id="聚类分析"><a class="markdownIt-Anchor" href="#聚类分析"></a> 聚类分析</h3>
<p>两种聚类算法可供选择: hard clustering（包含hierachical,pam,kmeans） 及 soft clustering (fuzzy cmeans)，算法的选择大家自己参考文献选择，这里就拿文档中cmeans算法进行分析聚类。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tca &lt;- timeclust(tca, algo = &quot;cm&quot;, k = 6, standardize = TRUE)</span><br><span class="line"></span><br><span class="line">###################################################</span><br><span class="line">p &lt;- timeclustplot(tca, value = &quot;z-score(RPKM)&quot;, cols = 3)</span><br></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/PVjl6Hy.jpeg" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 若是想查看某个聚类有哪些基因参与，使用tca@clusterRes查看聚类结果即可</span><br><span class="line"></span><br><span class="line">a &lt;- as.data.frame(tca@clusterRes@cluster)</span><br><span class="line">names(a) &lt;- &#x27;Cluster&#x27;</span><br><span class="line">## 查看各个聚类中的基因数目</span><br><span class="line">table(a)</span><br><span class="line">dim(a)</span><br><span class="line">table(a)</span><br><span class="line"></span><br><span class="line">#&gt; table(a)</span><br><span class="line">#### 过滤标准： tca &lt;- DBanalysis(tca, filter.type = &quot;raw&quot;, filter.value = 10, samplePassfilter = 2)</span><br><span class="line"># 1    2    3    4    5    6 </span><br><span class="line"># 1751  380 1122  599  905  554   # Aug 11 基于read count。过滤了一部分数据：</span><br><span class="line"></span><br><span class="line">#--- 过往记录：</span><br><span class="line"># 1    2    3    4    5    6 </span><br><span class="line"># 418 1397  993  602 1033 1042    ### Aug 10 </span><br><span class="line"># table(a)</span><br><span class="line"># filter.value = 1, samplePassfilter = 2) # Aug 9 用的这个 筛选条件之后，基因数目少了很多</span><br><span class="line">#1   2   3   4   5   6 </span><br><span class="line">#736 222 569 810 812 452 </span><br><span class="line"># 干旱处理 叶片的基因分组情况。没有设置筛选的情况下，基因数目多很多，但是手动查询发现有的基因并不明显</span><br><span class="line">#1    2    3    4    5    6 </span><br><span class="line">#3431 2156 3690 5167 2368 3566 </span><br><span class="line">##1   2   3   4   5   6 </span><br><span class="line">##511 147 165 292 180 255 </span><br><span class="line">##筛选 。可以分别导出每个cluster的基因列表 </span><br><span class="line"></span><br><span class="line">Cluster1 &lt;- subset(a,Cluster == 1)</span><br><span class="line">Cluster2 &lt;- subset(a,Cluster == 2)</span><br><span class="line">Cluster3 &lt;- subset(a,Cluster == 3)</span><br><span class="line">Cluster4 &lt;- subset(a,Cluster == 4)</span><br><span class="line">Cluster5 &lt;- subset(a,Cluster == 5)</span><br><span class="line">Cluster6 &lt;- subset(a,Cluster == 6)</span><br><span class="line">#Cluster7 &lt;- subset(a,Cluster == 7)</span><br><span class="line"></span><br><span class="line">write.csv(as.data.frame( tca@clusterRes@cluster ), file=&quot;6_clusters.csv&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#上面分6次执行提取cluster命令比较繁琐，另一个方法是批量导出每个聚类所包含的基因，上面这种重复写6次的命令太繁复，尝试用for循环来解决</span><br><span class="line">dir.create(path=&quot;tcseq_cluster&quot;,recursive = TRUE)  # 在工作目录下新建一个文件夹</span><br><span class="line">for(i in 1:6)&#123;</span><br><span class="line">  assign(paste(&quot;Cluster&quot;,i,sep=&quot;&quot;),subset(a,Cluster == i)) # Cluster2 &lt;- subset(a,Cluster == 2)</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="对个别-cluster-进行功能富集分析"><a class="markdownIt-Anchor" href="#对个别-cluster-进行功能富集分析"></a> 对个别 Cluster 进行功能富集分析</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">library(clusterProfiler)</span><br><span class="line">library(org.XXXX.eg.db)</span><br><span class="line">library(stringr)</span><br><span class="line">library(topGO)</span><br><span class="line">org &lt;- org.XXXX.eg.db</span><br><span class="line"></span><br><span class="line">geneList=rownames(Cluster1)  # Cluster 1</span><br><span class="line">bp1 &lt;-enrichGO(gene = geneList, OrgDb = org, keyType = &quot;GID&quot;, ont = &quot;BP&quot;)</span><br><span class="line">pdf(&quot;TCseq_Cluster1_GO_BP.pdf&quot;)</span><br><span class="line">barplot(bp1, drop=TRUE, showCategory=30)</span><br><span class="line">dev.off()</span><br><span class="line">write.csv(as.data.frame( bp1@result ), file=&quot;TCseq_Cluster1_GO_BP.csv&quot;)</span><br><span class="line"></span><br><span class="line">geneList=rownames(Cluster2)  # Cluster 2</span><br><span class="line">bp2 &lt;-enrichGO(gene = geneList, OrgDb = org, keyType = &quot;GID&quot;, ont = &quot;BP&quot;)</span><br><span class="line">pdf(&quot;TCseq_Cluster2_GO_BP.pdf&quot;)</span><br><span class="line">barplot(bp2, drop=TRUE, showCategory=30)</span><br><span class="line">dev.off()</span><br><span class="line">write.csv(as.data.frame( bp2@result ), file=&quot;TCseq_Cluster2_GO_BP.csv&quot;)</span><br><span class="line">#----- 上面采用默认参数，得到的GO条目太少，于是放松筛选标准，画的图更好看</span><br><span class="line">bp2 &lt;-enrichGO(gene = geneList, OrgDb = org, keyType = &quot;GID&quot;, ont = &quot;BP&quot;, pvalueCutoff = 0.5, qvalueCutoff = 0.9)</span><br><span class="line">pdf(&quot;TCseq_Cluster2_GO_BP_low_standard.pdf&quot;)</span><br><span class="line">barplot(bp2, drop=TRUE, showCategory=30)</span><br><span class="line">dev.off()</span><br><span class="line">#------</span><br></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/CUmLAMP.jpeg" alt="" /></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | Using Circos for genome visualization</title>
    <url>/2021/05/28/Bioinfo-Using-Circos-for-genome-visualization/</url>
    <content><![CDATA[<p>circos 是以环形展示基因组序列和注释信息的工具，我首先按照 circos 官网的指引进行手动安装，即手动逐个安装 Perl 模块，最后再安装 circos 文件，但是卡在 GD 库，没法成功运行 circos。但是换了一台服务器，进入 anaconda3 下面的 python3.7 环境，直接用 conda 不到一分钟就成功安装 circos。</p>
<p>First, understand the <a href="http://circos.ca/software/requirements">requirements</a>. If you are a Windows user, read about pertinent differences between UNIX and Windows.</p>
<p><a href="http://circos.ca/software/download">Download</a> and <a href="http://circos.ca/software/install">install</a> the software, then follow the <a href="http://circos.ca/documentation/tutorials">tutorials</a>.</p>
<h3 id="installing-perl-modules"><a class="markdownIt-Anchor" href="#installing-perl-modules"></a> Installing Perl modules</h3>
<p>安装 Circos 的第一步，安装 Perl 以及相关的若干 Perl 模块。我 Linux 系统自带的 Perl，进入命令行界面时报错（<code>perl -MCPAN -e shell</code> Can’t locate <a href="http://CPAN.pm">CPAN.pm</a> in @INC），所以我先尝试自己安装的 Perl，即 anaconda3/python37 里面的 Perl v5.26.2，但是在安装 Params::Validate 包时候无法通过。我再次尝试系统默认的 Perl v5.16.3，先安装 CPAN，再逐个安装包，成功安装 Params::Validate。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source activate python37</span><br><span class="line">perl --version</span><br><span class="line"># This is perl 5, version 26, subversion 2 (v5.26.2) built for x86_64-linux-thread-multi</span><br><span class="line">perl --version</span><br><span class="line">This is perl 5, version 16, subversion 3 (v5.16.3) built for x86_64-linux-thread-multi</span><br><span class="line">perl -MCPAN -e shell</span><br><span class="line"></span><br><span class="line">Config::General (v2.50 or later)</span><br><span class="line">Font::TTF</span><br><span class="line">GD</span><br><span class="line">List::MoreUtils</span><br><span class="line">Math::Bezier</span><br><span class="line">Math::Round</span><br><span class="line">Math::VecStat</span><br><span class="line">Params::Validate (自动安装失败，尝试手动安装)</span><br><span class="line">Readonly</span><br><span class="line">Regexp::Common</span><br><span class="line">Set::IntSpan (v1.16 or later)</span><br><span class="line">Text::Format</span><br></pre></td></tr></table></figure>
<p>安装 Params::Validate 的过程中，同时安装了下列 Perl 模块。均是模块安装包下载之后解压，进入模块目录后依次运行 <code>perl Makefile.PL</code>，<code>make Makefile</code>，<code>make install Makefile</code> 即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://cpan.metacpan.org/authors/id/D/DR/DROLSKY/Params-Validate-1.30.tar.gz</span><br><span class="line"># wget http://search.cpan.org/CPAN/authors/id/D/DR/DROLSKY/Params-Validate-0.95.tar.gz</span><br><span class="line">wget https://cpan.metacpan.org/authors/id/E/ET/ETHER/Module-Metadata-1.000037.tar.gz</span><br><span class="line">wget https://cpan.metacpan.org/authors/id/L/LE/LEONT/version-0.9929.tar.gz</span><br><span class="line">wget https://cpan.metacpan.org/authors/id/B/BI/BINGOS/IPC-Cmd-1.04.tar.gz</span><br><span class="line">wget https://cpan.metacpan.org/authors/id/B/BI/BINGOS/Params-Check-0.38.tar.gz</span><br><span class="line">wget https://cpan.metacpan.org/authors/id/J/JE/JESSE/Locale-Maketext-Simple-0.21.tar.gz</span><br><span class="line">wget https://cpan.metacpan.org/authors/id/B/BI/BINGOS/Module-Load-Conditional-0.74.tar.gz</span><br><span class="line">wget https://cpan.metacpan.org/authors/id/B/BI/BINGOS/Module-Load-0.36.tar.gz</span><br></pre></td></tr></table></figure>
<h3 id="installing-libpng-freetype-libgd-and-gd"><a class="markdownIt-Anchor" href="#installing-libpng-freetype-libgd-and-gd"></a> INSTALLING libpng, freetype, libgd AND gd</h3>
<p>About half of the support questions in the Google Group are about installing Perl’s GD module, which is the interface to the libgd system graphics library.</p>
<p>The installation process is not robust because of dependencies and the possibility of their being different versions of these dependencies on your system. Below I show the process of installing GD on a new Mac OS Mavericks system (10.9.4).</p>
<p>Below I link to my local copies of the versions of each library that I installed. These are mature libraries and newer versions are likely to be minor bug releases. The exception is GD—I was unable to successfully compile v2.56 (boot_GD symbol warning which I could not fix). However v2.53 worked.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; tar xvfz libpng-1.6.14.tar.gz</span><br><span class="line">&gt; cd libpng-1.6.14</span><br><span class="line">&gt; ./configure —prefix=/usr/local</span><br><span class="line">&gt; make</span><br><span class="line">&gt; make install</span><br><span class="line"></span><br><span class="line">&gt; tar xvfz jpegsrc.v9.tar.gz</span><br><span class="line">&gt; cd jpeg-9</span><br><span class="line">&gt; ./configure —prefix=/usr/local</span><br><span class="line">&gt; make</span><br><span class="line">&gt; make install</span><br><span class="line"></span><br><span class="line">&gt; tar xvfz freetype-2.4.0.tar.gz</span><br><span class="line">&gt; cd freetype-2.4.0</span><br><span class="line">&gt; ./configure —prefix=/usr/local</span><br><span class="line">&gt; make</span><br><span class="line">&gt; make install</span><br></pre></td></tr></table></figure>
<p>You should now have libraries in /usr/local/lib as we as some header files in /usr/local/include.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-rwxr-xr-x  1 root  wheel   650336 21 Nov 11:15 libfreetype.6.dylib</span><br><span class="line">-rw-r--r--  1 root  wheel  3676456 21 Nov 11:15 libfreetype.a</span><br><span class="line">lrwxr-xr-x  1 root  wheel       19 21 Nov 11:15 libfreetype.dylib -&gt; libfreetype.6.dylib</span><br><span class="line">-rwxr-xr-x  1 root  wheel      957 21 Nov 11:15 libfreetype.la</span><br><span class="line">-rwxr-xr-x  1 root  wheel   275736 21 Nov 11:14 libjpeg.9.dylib</span><br><span class="line">-rw-r--r--  1 root  wheel  1492952 21 Nov 11:14 libjpeg.a</span><br><span class="line">lrwxr-xr-x  1 root  wheel       15 21 Nov 11:14 libjpeg.dylib -&gt; libjpeg.9.dylib</span><br><span class="line">-rwxr-xr-x  1 root  wheel      920 21 Nov 11:14 libjpeg.la</span><br><span class="line">lrwxr-xr-x  1 root  wheel       10 21 Nov 11:13 libpng.a -&gt; libpng16.a</span><br><span class="line">lrwxr-xr-x  1 root  wheel       14 21 Nov 11:13 libpng.dylib -&gt; libpng16.dylib</span><br><span class="line">lrwxr-xr-x  1 root  wheel       11 21 Nov 11:13 libpng.la -&gt; libpng16.la</span><br><span class="line">-rwxr-xr-x  1 root  wheel   240580 21 Nov 11:13 libpng16.16.dylib</span><br><span class="line">-rw-r--r--  1 root  wheel  1077240 21 Nov 11:13 libpng16.a</span><br><span class="line">lrwxr-xr-x  1 root  wheel       17 21 Nov 11:13 libpng16.dylib -&gt; libpng16.16.dylib</span><br><span class="line">-rwxr-xr-x  1 root  wheel      924 21 Nov 11:13 libpng16.la</span><br><span class="line">drwxr-xr-x  6 root  wheel      204 21 Nov 11:15 pkgconfig/</span><br></pre></td></tr></table></figure>
<p>Now install libgd, linking to the libraries installed above</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; tar xvfz libgd-2.1.0.tar.gz</span><br><span class="line">&gt; cd libgd-2.1.0</span><br><span class="line">&gt; ./configure --with-png=/usr/local --with-freetype=/usr/local --with-jpeg=/usr/local --prefix=/usr/local</span><br><span class="line">./configure --with-png=/home/fenglei/local --with-freetype=/home/fenglei/local --with-jpeg=/home/fenglei/local --prefix=/home/fenglei/local</span><br><span class="line">…</span><br><span class="line">** Configuration summary for libgd 2.1.0:</span><br><span class="line"></span><br><span class="line">   Support for Zlib:                 yes</span><br><span class="line">   Support for PNG library:          yes</span><br><span class="line">   Support for JPEG library:         yes</span><br><span class="line">   Support for VPX library:          no</span><br><span class="line">   Support for TIFF library:         no</span><br><span class="line">   Support for Freetype 2.x library: yes</span><br><span class="line">   Support for Fontconfig library:   no</span><br><span class="line">   Support for Xpm library:          no</span><br><span class="line">   Support for pthreads:             yes</span><br><span class="line">…</span><br><span class="line"></span><br><span class="line">&gt; make</span><br><span class="line">&gt; make install</span><br></pre></td></tr></table></figure>
<p>You now have libgd in /usr/local/lib</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-rwxr-xr-x  1 root  wheel   389372 19 Nov 14:47 libgd.3.dylib</span><br><span class="line">-rw-r--r--  1 root  wheel  1217200 19 Nov 14:47 libgd.a</span><br><span class="line">lrwxr-xr-x  1 root  wheel       13 19 Nov 14:47 libgd.dylib -&gt; libgd.3.dylib</span><br><span class="line">-rwxr-xr-x  1 root  wheel     1139 19 Nov 14:47 libgd.la</span><br></pre></td></tr></table></figure>
<p>as well as some binaries in /usr/local/bin. In particular, you have /usr/local/bin/glib-config, which provides the configuration for your libgd installation</p>
<p>The --with-* parameters during the configure stage of gdlib installation sets the sources of the dependencies that will be build into gdlib. If you used a different -prefix in compiling these dependencies (see above), adjust these parameters accordingly. For example, if you compiled libpng with -prefix=/my/path then use --with-png=/my/path/.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/usr/local/bin/gdlib-config --all</span><br><span class="line"></span><br><span class="line">GD library  2.1.0</span><br><span class="line">includedir: /usr/local/include</span><br><span class="line">cflags:     -I/usr/local/include</span><br><span class="line">ldflags:     -L/usr/local/lib</span><br><span class="line">libs:       -ljpeg -lz  -L/usr/local/lib -lpng16 -L/usr/local/lib -lfreetype -lz -liconv</span><br><span class="line">libdir:     /usr/local/lib</span><br><span class="line">features:   GD_JPEG GD_FREETYPE GD_PNG GD_GIF GD_GIFANIM GD_OPENPOLYGON</span><br></pre></td></tr></table></figure>
<p>由于我安装的 gd 时候是配置到了用户目录下，所以得到下面的信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">GD library  2.1.0</span><br><span class="line">includedir: /home/fenglei/local/include</span><br><span class="line">cflags:     -I/home/fenglei/local/include</span><br><span class="line">ldflags:     -L/home/fenglei/local/lib</span><br><span class="line">libs:       -ljpeg -lz -lm  -L/home/fenglei/local/lib -lpng16 -L/home/fenglei/local/lib -lfreetype -lz -lfontconfig -lfreetype   -lfontconfig -lXpm -lX11   /home/fenglei/local/lib/libiconv.so -Wl,-rpath -Wl,/home/fenglei/local/lib</span><br><span class="line">libdir:     /home/fenglei/local/lib</span><br><span class="line">features:   GD_XPM GD_JPEG GD_FONTCONFIG GD_FREETYPE GD_PNG GD_GIF GD_GIFANIM GD_OPENPOLYGON</span><br></pre></td></tr></table></figure>
<p>You must have GD_FREETYPE and GD_PNG for Circos to run. The other features, such as support for JPEG and TIFF are optional. In this example, I’ve included the JPEG library in the installation.</p>
<p>Now, install the Perl interface to libgd — the GD module.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; tar xvfz GD-2.53.tar.gz</span><br><span class="line">&gt; perl Makefile.PL</span><br><span class="line"></span><br><span class="line">Configuring for libgd version 2.1.0.</span><br><span class="line">Checking for stray libgd header files...none found.</span><br><span class="line"></span><br><span class="line">Included Features:          GD_JPEG GD_FREETYPE GD_PNG GD_GIF GD_GIFANIM GD_OPENPOLYGON</span><br><span class="line">GD library used from:       /usr/local</span><br><span class="line">Checking if your kit is complete...</span><br><span class="line">Looks good</span><br><span class="line">Writing Makefile for GD</span><br><span class="line">Writing MYMETA.yml and MYMETA.json</span><br><span class="line"></span><br><span class="line">During the installation GD will look for libgd-config (see above) for libgd configuration. </span><br><span class="line"></span><br><span class="line">&gt; make</span><br><span class="line">&gt; make install</span><br><span class="line"></span><br><span class="line">&gt; perl -MGD -e &#x27;print $GD::VERSION,”\n”’</span><br><span class="line">&gt; 2.53</span><br></pre></td></tr></table></figure>
<p>Test that the modules are installed using</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; circos --modules</span><br><span class="line">…</span><br><span class="line">ok       0.39 Font::TTF::Font</span><br><span class="line">ok       2.53 GD</span><br><span class="line">ok        0.2 GD::Polyline</span><br><span class="line">ok       2.39 Getopt::Long</span><br><span class="line">ok       1.16 IO::File</span><br><span class="line">…</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget http://circos.ca/distribution/circos-0.69-9.tgz</span><br><span class="line">tar -zxvf circos-0.69-9.tgz</span><br><span class="line">./bin/circos --modules</span><br><span class="line"></span><br><span class="line">ok       1.26 Carp</span><br><span class="line">missing            Clone</span><br><span class="line">ok       2.63 Config::General</span><br><span class="line">ok       3.40 Cwd</span><br><span class="line">ok      2.145 Data::Dumper</span><br><span class="line">ok       2.52 Digest::MD5</span><br><span class="line">ok       2.84 File::Basename</span><br><span class="line">ok       3.40 File::Spec::Functions</span><br><span class="line">ok     0.2301 File::Temp</span><br><span class="line">ok       1.51 FindBin</span><br><span class="line">ok       0.39 Font::TTF::Font</span><br><span class="line">missing            GD</span><br><span class="line">missing            GD::Polyline</span><br><span class="line">ok        2.4 Getopt::Long</span><br><span class="line">ok       1.16 IO::File</span><br><span class="line">ok      0.430 List::MoreUtils</span><br><span class="line">ok       1.27 List::Util</span><br><span class="line">ok       0.01 Math::Bezier</span><br><span class="line">ok      1.997 Math::BigFloat</span><br><span class="line">ok       0.07 Math::Round</span><br><span class="line">ok       0.08 Math::VecStat</span><br><span class="line">ok       1.02 Memoize</span><br><span class="line">ok       1.30 POSIX</span><br><span class="line">ok       1.30 Params::Validate</span><br><span class="line">ok       1.63 Pod::Usage</span><br><span class="line">ok       2.05 Readonly</span><br><span class="line">ok 2017060201 Regexp::Common</span><br><span class="line">missing            SVG</span><br><span class="line">ok       1.19 Set::IntSpan</span><br><span class="line">missing            Statistics::Basic</span><br><span class="line">ok       2.45 Storable</span><br><span class="line">ok       1.16 Sys::Hostname</span><br><span class="line">ok       2.02 Text::Balanced</span><br><span class="line">ok       0.62 Text::Format</span><br><span class="line">ok     1.9725 Time::HiRes</span><br></pre></td></tr></table></figure>
<p>Install missing packages</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cpan -i SVG</span><br><span class="line">cpan -i Clone</span><br><span class="line">cpan -i Statistics::Basic</span><br></pre></td></tr></table></figure>
<h3 id="以上做完依然报错"><a class="markdownIt-Anchor" href="#以上做完依然报错"></a> 以上做完依然报错</h3>
<p>运行 <code>circos --mudules</code> 显示 GD 模块缺失。（已经分别安装 libgd 和 Perl 的 GD 模块，为什么circos还是显示没有 GD 模块？）</p>
<h3 id="使用-conda-安装-circos"><a class="markdownIt-Anchor" href="#使用-conda-安装-circos"></a> 使用 conda 安装 circos</h3>
<p>换一台服务器，<code>source activate python37</code> 切换成 python3.7 环境。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; which perl</span><br><span class="line">~/local/app/anaconda3/envs/python37/bin/perl</span><br><span class="line">&gt; perl --version</span><br><span class="line">This is perl 5, version 26, subversion 2 (v5.26.2) built for x86_64-linux-thread-multi</span><br></pre></td></tr></table></figure>
<p>再运行 <code>conda install -c bioconda circos</code> 顺利安装！下面是模块测试。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost ~]$ circos --modules</span><br><span class="line">ok       1.38 Carp</span><br><span class="line">ok       0.42 Clone</span><br><span class="line">ok       2.63 Config::General</span><br><span class="line">ok       3.75 Cwd</span><br><span class="line">ok      2.167 Data::Dumper</span><br><span class="line">ok       2.55 Digest::MD5</span><br><span class="line">ok       2.85 File::Basename</span><br><span class="line">ok       3.67 File::Spec::Functions</span><br><span class="line">ok     0.2304 File::Temp</span><br><span class="line">ok       1.51 FindBin</span><br><span class="line">ok       0.39 Font::TTF::Font</span><br><span class="line">ok       2.71 GD</span><br><span class="line">ok        0.2 GD::Polyline</span><br><span class="line">ok       2.49 Getopt::Long</span><br><span class="line">ok       1.16 IO::File</span><br><span class="line">ok      0.428 List::MoreUtils</span><br><span class="line">ok     1.4602 List::Util</span><br><span class="line">ok       0.01 Math::Bezier</span><br><span class="line">ok   1.999806 Math::BigFloat</span><br><span class="line">ok       0.07 Math::Round</span><br><span class="line">ok       0.08 Math::VecStat</span><br><span class="line">ok    1.03_01 Memoize</span><br><span class="line">ok       1.76 POSIX</span><br><span class="line">ok       1.29 Params::Validate</span><br><span class="line">ok       1.69 Pod::Usage</span><br><span class="line">ok       2.05 Readonly</span><br><span class="line">ok 2017060201 Regexp::Common</span><br><span class="line">ok       2.84 SVG</span><br><span class="line">ok       1.19 Set::IntSpan</span><br><span class="line">ok     1.6611 Statistics::Basic</span><br><span class="line">ok       2.62 Storable</span><br><span class="line">ok       1.20 Sys::Hostname</span><br><span class="line">ok       2.03 Text::Balanced</span><br><span class="line">ok       0.59 Text::Format</span><br><span class="line">ok     1.9741 Time::HiRes</span><br></pre></td></tr></table></figure>
<p>再以 circos 自带的案例做画图测试。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget http://circos.ca/distribution/circos-0.69-9.tgz</span><br><span class="line">tar -zxvf circos-0.69-9.tgz</span><br><span class="line">cd circos-0.69-9</span><br><span class="line">cd example</span><br><span class="line"># 在 example 目录下有名为 run 的脚本：../bin/circos -conf etc/circos.conf -debug_group summary,timer &gt; run.out</span><br><span class="line"># 由于我调用的是 anaconda3 里面的 circos，所以用下面的命令，几秒钟即可运行完毕，顺利得到 circos.svg &amp; circos.png 图。</span><br><span class="line">circos -conf etc/circos.conf -debug_group summary,timer &gt; run.out</span><br></pre></td></tr></table></figure>
<p><img src="http://i.imgur.com/ZkOgjPN.jpg" alt="example/circos.png" /></p>
<p>注：<br />
另一台服务器上，通过 conda 可以安装 circos，但是运行的时候报错：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; circos</span><br><span class="line">perl: symbol lookup error: /home/fenglei/perl5/lib/perl5/x86_64-linux-thread-multi/auto/Clone/Clone.so: undefined symbol: Perl_xs_apiversion_bootcheck</span><br></pre></td></tr></table></figure>
<p>看来是 Perl 环境变量的问题。</p>
<p>Circos 的文件结构如下图所示，conf 文件即图片属性设置，txt 文件就是统计数据，circos 将二者的结合就是图片。</p>
<p><img src="http://qiubio.com/wp-content/uploads/2011/11/circos-architecture.png" alt="" /></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>转录组数据分析之nr数据库注释</title>
    <url>/2015/12/14/Bioinfo-annotate-RNA-seq-by-NR-database/</url>
    <content><![CDATA[<p>如果分析的对象是植物，如何只对nr数据库中的植物序列进行检索？</p>
<span id="more"></span>
<ol>
<li>Go to NCBI Entrez Protein search</li>
<li>Search with <code>all [filter]</code> query. This will give you all protein entries</li>
<li>Locate “Taxonomic Groups” box on the right. Display tree and locate “Green plants”. Click and wait a moment. You should now see proteins from green plants. The query in the Search box should change to (all [filter]) AND “green plants”[porgn:__txid33090].</li>
<li>Download everything as GI list. This is your “Plant GI list”</li>
</ol>
<p>Now you can:</p>
<ol>
<li>Download full nr database in FASTA format</li>
<li>Using a custom script select from the nr database only those entries that have a GI from the “Plant GI list”</li>
<li>Create the final plant_nr using formatdb</li>
</ol>
<p>OR: use new blast where apparently you can filter the nr database based on gi list using ‘-gilist’ option of blast itself! (<a href="http://www.ncbi.nlm.nih.gov/books/NBK1763/">http://www.ncbi.nlm.nih.gov/books/NBK1763/</a>). But I haven’t used that yet. Ref: <a href="https://www.biostars.org/p/8443/">https://www.biostars.org/p/8443/</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Augustus-3.3的安装</title>
    <url>/2018/05/16/Bioinfo-augustus-3-3-installation/</url>
    <content><![CDATA[<p>Augustus 是流行的基因预测软件。在安装的过程中，遇到了 make 报错的问题，查询资料之后成功安装。错误信息提示 Augustus 在 bam2hints 编译的时候不通过，导致 make 失败。原来是bam2hints、filterBam 和 bam2wig 这三个目录下的 Makefile 中对其依赖程序的调用需要手动更改。下面部分文字摘抄自 <a href="http://iamphioxus.org">iamphioxus.org</a> 。 Augustus is a very popular tool for gene annotation, however its installation process can be a bit tricky. For example, if we just download and install <em>Augustus</em> like below, it will not work.</p>
<p>wget <a href="http://bioinf.uni-greifswald.de/augustus/binaries/augustus-3.3.1.tar.gz">http://bioinf.uni-greifswald.de/augustus/binaries/augustus-3.3.1.tar.gz</a><br />
tar xvzf augustus-3.3.1.tar.gz<br />
cd augustus-3.3.1<br />
make</p>
<p>You will probably get these errors:</p>
<p>cd auxprogs &amp;&amp; make<br />
make[1]: Entering directory ‘/home/jxyue/Tools/augustus-3.2.3/auxprogs’<br />
cd bam2hints; make;<br />
make[2]: Entering directory ‘/home/jxyue/Tools/augustus-3.2.3/auxprogs/bam2hints’<br />
g++ -Wall -O2 -c <a href="http://bam2hints.cc">bam2hints.cc</a> -o bam2hints.o -I/usr/include/bamtools<br />
bam2hints.cc:16:27: fatal error: api/BamReader.h: No such file or directory<br />
#include &lt;api/BamReader.h&gt;<br />
^<br />
compilation terminated.<br />
Makefile:29: recipe for target ‘bam2hints.o’ failed<br />
make[2]: *** [bam2hints.o] Error 1<br />
make[2]: Leaving directory ‘/home/jxyue/Tools/augustus-3.2.3/auxprogs/bam2hints’<br />
Makefile:7: recipe for target ‘all’ failed<br />
make[1]: *** [all] Error 2<br />
make[1]: Leaving directory ‘/home/jxyue/Tools/augustus-3.2.3/auxprogs’<br />
Makefile:7: recipe for target ‘all’ failed<br />
make: *** [all] Error 2<br />
This is because the auxiliary tools, bam2hints and filterBam, depend on the pre-installation of bamtools with proper library path configured.</p>
<p>Therefore, let’s install bamtools first. It will be much easier if we just do system-wide installation like: 首先安装 bamtools，我在使用 redhat 系统，安装 bamtools-2.4.1 要用到 cmake 3.0以上版本。我尝试安装了 cmake 3.0 的源码，但是编译失败，于是下载了二进制文件，cmake 可以运行，随后顺利编译 bamtools 2.4.1。</p>
<p>tar -zxvf bamtools-2.4.1.tar.gz<br />
cd bamtools-2.4.1<br />
mkdir build<br />
cd build<br />
cmake -DCMAKE_INSTALL_PREFIX=/home/fenglei/local …<br />
make<br />
make install</p>
<h1 id="此时运行-bamtools-发现报错提示无法用-libbamtoolsso241于是在下载目录把该文件拷贝到了安装目录下的-lib-和-lib64-中再运行bamtools就成了"><a class="markdownIt-Anchor" href="#此时运行-bamtools-发现报错提示无法用-libbamtoolsso241于是在下载目录把该文件拷贝到了安装目录下的-lib-和-lib64-中再运行bamtools就成了"></a> 此时运行 bamtools 发现报错，提示无法用 libbamtools.so.2.4.1，于是在下载目录把该文件拷贝到了安装目录下的 lib 和 lib64 中，再运行bamtools就成了。</h1>
<h1 id="find-~local-name-libbamtoolsso241"><a class="markdownIt-Anchor" href="#find-~local-name-libbamtoolsso241"></a> find ~/local -name libbamtools.so.2.4.1</h1>
<p>cp /home/fenglei/local/app/bamtools-2.4.1/lib/libbamtools.so.2.4.1 /home/fenglei/local/lib/<br />
cp /home/fenglei/local/app/bamtools-2.4.1/lib/libbamtools.so.2.4.1  /home/fenglei/local/lib64</p>
<p>Now bamtools should have been correctly installed. Next, we need to modify the Makefiles of bam2hints and filterBam to adapt them with our manually installed bamtools.</p>
<p>First, go to the “./auxprogs/bam2hints” directory and make the following changes for the Makefile:</p>
<p>Add:<br />
BAMTOOLS = /home/fenglei/local</p>
<p>Replace:<br />
INCLUDES = /usr/include/bamtools<br />
By:<br />
INCLUDES = $(BAMTOOLS)/include</p>
<p>Replace:<br />
LIBS = -lbamtools -lz<br />
By:<br />
LIBS = $(BAMTOOLS)/lib64/libbamtools.a -lz</p>
<h1 id="注意-libs-中-lib64-也可能是-lib要通过搜索-libbamtoolsa-查看其实际位置"><a class="markdownIt-Anchor" href="#注意-libs-中-lib64-也可能是-lib要通过搜索-libbamtoolsa-查看其实际位置"></a> 注意 LIBS 中 lib64 也可能是 lib，要通过搜索 libbamtools.a 查看其实际位置。</h1>
<p>Then, go to the “augustus-3.2.3/auxprogs/filterBam/src” directory and make the following changes for the Makefile:</p>
<p>Replace:</p>
<p>BAMTOOLS = /usr/include/bamtools<br />
By:<br />
BAMTOOLS = /home/fenglei/local</p>
<p>Replace:<br />
INCLUDES = -I<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>B</mi><mi>A</mi><mi>M</mi><mi>T</mi><mi>O</mi><mi>O</mi><mi>L</mi><mi>S</mi><mo stretchy="false">)</mo><mo>−</mo><mi>I</mi><mi>h</mi><mi>e</mi><mi>a</mi><mi>d</mi><mi>e</mi><mi>r</mi><mi>s</mi><mo>−</mo><mi>I</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">/</mi><mi>b</mi><mi>a</mi><mi>m</mi><mi>t</mi><mi>o</mi><mi>o</mi><mi>l</mi><mi>s</mi><mi>B</mi><mi>y</mi><mo>:</mo><mi>I</mi><mi>N</mi><mi>C</mi><mi>L</mi><mi>U</mi><mi>D</mi><mi>E</mi><mi>S</mi><mo>=</mo><mo>−</mo><mi>I</mi></mrow><annotation encoding="application/x-tex">(BAMTOOLS) -Iheaders -I./bamtools
By:
INCLUDES = -I</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal">a</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">s</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord">.</span><span class="mord">/</span><span class="mord mathnormal">b</span><span class="mord mathnormal">a</span><span class="mord mathnormal">m</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">s</span><span class="mord mathnormal" style="margin-right:0.05017em;">B</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.10903em;">N</span><span class="mord mathnormal" style="margin-right:0.07153em;">C</span><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.10903em;">U</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.76666em;vertical-align:-0.08333em;"></span><span class="mord">−</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span></span></span></span>(BAMTOOLS)/include -Iheaders -I./bamtools</p>
<p>Replace:<br />
LIBS = -lbamtools -lz<br />
By:<br />
LIBS = $(BAMTOOLS)/lib64/libbamtools.a -lz</p>
<p>进入 augustus-3.3.1/auxprogs/bam2wig，编辑 Makefile。</p>
<p># SAMTOOLS=$(TOOLDIR)/samtools/<br />
SAMTOOLS=/home/fenglei/local/app/samtools</p>
<p>#HTSLIB=$(TOOLDIR)/htslib/<br />
HTSLIB=/home/fenglei/local/app/htslib</p>
<h1 id="bcftoolstooldirbcftools"><a class="markdownIt-Anchor" href="#bcftoolstooldirbcftools"></a> BCFTOOLS=$(TOOLDIR)/bcftools/</h1>
<p>BCFTOOLS=/home/fenglei/local/app/bcftools</p>
<h1 id="tabixtooldirtabix"><a class="markdownIt-Anchor" href="#tabixtooldirtabix"></a> TABIX=$(TOOLDIR)/tabix/</h1>
<p>TABIX=/home/fenglei/local/app/htslib</p>
<h2 id="上述注释掉的内容是-makefile-中的原始设置分别改一下就行了-tabix-是-htslib-下的一程序"><a class="markdownIt-Anchor" href="#上述注释掉的内容是-makefile-中的原始设置分别改一下就行了-tabix-是-htslib-下的一程序"></a> 上述注释掉的内容是 Makefile 中的原始设置，分别改一下就行了。tabix 是 htslib 下的一程序。</h2>
<p>[20201027 update] 在新的机器上重新安装Augustus，虽然按照上述步骤修改MakeFile，但是bam2wig还是无法make成功。于是将这个文件夹改掉，单独下载bam2wig程序（<a href="https://github.com/MikeAxtell/bam2wig%EF%BC%89%EF%BC%8C%E5%B7%B2%E7%BB%8F%E6%98%AF%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%96%87%E4%BB%B6%EF%BC%8C%E4%B8%8D%E9%9C%80%E8%A6%81%E7%BC%96%E8%AF%91%EF%BC%8C%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E4%BD%BF%E7%94%A8%EF%BC%81%E7%84%B6%E5%90%8E%E8%BF%9B%E5%85%A5auxprogs%E7%9B%AE%E5%BD%95%EF%BC%8C%E4%BF%AE%E6%94%B9MakeFile%E6%96%87%E4%BB%B6%EF%BC%8C%E5%B0%B1%E5%B0%86bam2wig%E5%AD%97%E7%AC%A6%E9%82%A3%E4%B8%A4%E8%A1%8C%E6%B3%A8%E9%87%8A%E6%8E%89%E3%80%82%E7%84%B6%E5%90%8E%E5%9B%9E%E5%88%B0Augustus%E7%9B%AE%E5%BD%95%E4%B8%8BMake%E5%B0%B1OK%E4%BA%86%E3%80%82">https://github.com/MikeAxtell/bam2wig），已经是二进制文件，不需要编译，可以直接使用！然后进入auxprogs目录，修改MakeFile文件，就将bam2wig字符那两行注释掉。然后回到Augustus目录下Make就OK了。</a> Now, we are finally ready to compile Augustus. Get back to the “augustus-3.3.1” directory and type “make”, 成功! References <a href="https://github.com/pezmaster31/bamtools/wiki/Building-and-installing">https://github.com/pezmaster31/bamtools/wiki/Building-and-installing</a> <a href="https://www.biostars.org/p/189048/">https://www.biostars.org/p/189048/</a> <a href="http://tiramisutes.github.io/2017/01/06/GLIBC.html">http://tiramisutes.github.io/2017/01/06/GLIBC.html</a> <a href="https://iamphioxus.org/2017/05/08/installing-augustus-with-manual-bamtools-installation/">https://iamphioxus.org/2017/05/08/installing-augustus-with-manual-bamtools-installation/</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>ChipSeeker的安装</title>
    <url>/2020/03/02/Bioinfo-chipseeker-installation/</url>
    <content><![CDATA[<p>我使用Linux CentOS 7系统，在ChipSeeker的安装过程中遇到了许多问题，这里做个记录。 <img src="https://genehub.files.wordpress.com/2020/03/e688aae5b18f2020-03-02e4b88be58d887.59.11.png" alt="截屏2020-03-02下午7.59.11" /> 在R （version 3.6）输入如下命令开始自动安装。安装命令：</p>
<p>if (!requireNamespace(“BiocManager”, quietly = TRUE))<br />
install.packages(“BiocManager”)</p>
<p>BiocManager::install(“ChIPseeker”)</p>
<p>部分报错信息：</p>
<p>make：gfortran：命令未找到 │*** moving datasets to lazyload DB<br />
ERROR: compilation failed for package ‘igraph’<br />
installation of package ‘igraph’ had non-zero exit status<br />
installation of package ‘tidygraph’ had non-zero exit status<br />
installation of package ‘graphlayouts’ had non-zero exit status<br />
installation of package ‘ggraph’ had non-zero exit status <br />
installation of package ‘enrichplot’ had non-zero exit status<br />
installation of package ‘ChIPseeker’ had non-zero exit status</p>
<p>解决办法，先给centOS 7系统安装gfortran：</p>
<p>yum install gcc-gfortran</p>
<p>继续安装R包，遇到 libgfortran.so.4 文件缺失的问题。解决办法：用find命令在linux系统里面找，在anaconda 3.7的安装目录下找到一个，所以就用这个文件，做一个软链接到系统库（我是/home/xxx/local/lib），然后igraph这些包就安装好了。 后续还遇到了R packages无法下载的问题：</p>
<p>package ‘xxxx-package’ is not available (for R version 3.6.0)</p>
<p>直接在R的cran里面搜索包，手动下载之后，在R界面用下面的命令即可安装：</p>
<p>install.packages(“/xxx/yy/xx/xxpackage.1.xx.0.tar.gz”)</p>
<p>这些包也有可能在编译的过程遇到问题，我尝试过下载旧版本的包，有时候可以解决问题；也有更换不同版本的gcc才能编译成功的情况。 对于功能高级、复杂的R包的安装，有时候真的麻烦，花掉我不止一天时间。一个R包依赖其他多个不同R包，不一定每个R包都能顺利安装；具体到各个R包，他们有不同的版本，不是每个版本都能安装，可能要换不同的gcc来做编译；还有就是linux下面安装软件很多时候都是环境变量的问题，要根据具体情况做修改和调整。 终于安装成功： <img src="https://genehub.files.wordpress.com/2020/03/e688aae5b18f2020-03-02e4b88be58d888.00.55.png" alt="截屏2020-03-02下午8.00.55" /></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>转：大样本RNA-seq数据的共表达网络分析</title>
    <url>/2015/11/21/Bioinfo-coexpression-network-analysis/</url>
    <content><![CDATA[<p></p>
<p><strong>大样本RNA-seq数据的救星——共表达网络分析</strong></p>
<p></p>
<p><strong>什么是共表达网络分析?</strong></p>
<p>基因共表达网络分析（Gene Co-expression Network Analysis）是根据基因表达信号值的动态变化，计算基因间的共表达关系，来建立基因转录调控模型，得到基因间的表达调控关系及调控方向，从而寻找一个或多个物种在不同发育阶段、不同组织在不同条件或处理时的全部基因表达调控网络模型以及关键基因，从而系统的研究生物体复杂的生命现象。最典型的方法就是WGCNA（Weighted Correlation Network analysis），基于基因表达网络权重构建，描述基因表达的关联模式的R程序包。简单点说就是，根据基因的表达量可以计算相关性，但是加入一些新的权重，比如处理条件等，就可以把基因表达与条件相互结合来分析两者之间的相关性或者关联性啦。</p>
<p><img src="http://www.seq.cn/data/attachment/forum/201511/20/171402vxwez00ajes3x3hd.png.thumb.jpg" alt="" /></p>
<p><img src="http://www.seq.cn/data/attachment/forum/201511/20/171403sygryfqqqfy2zci2.png.thumb.jpg" alt="" /></p>
<p>参考文献：Xue Z, Huang K, Cai C, et al. Genetic programs in human and mouse early embryos revealed by single-cell RNA [thinsp] sequencing[J]. Nature, 2013, 500(7464): 593-597.  <strong>当大样本量遇上WGCNA</strong> 如果我们的表达量数据是两组或者少数几组数据，相关性分析不准确，使用组间差异表达分析，聚类分析就可以了。如果我们想研究同一个组织不同的发育阶段、处理条件下不同时间点的应答或者不同器官/组织类型的发育调控，并且样本数目比较多的情况下（非重复样本数目5个以上，注意：是非重复哦~），想通过两两之间的相互比较，明显是行不通的。而WGCNA刚好适用于大规模的数据分析。  <strong>WGCNA构建方法</strong> WGCNA是从大规模数据中挖掘模块（module）信息的算法，在该方法中模块被定义为一组具有类似表达谱的基因，如果某些基因在一个生理过程或不同组织中总是具有相类似的表达变化，那么我们有理由认为这些基因在功能上是相关的，可以把他们定义为一个模块。比如上图a聚类树的不同分支就代表不同的基因模块。 下一步就需要研究模块与关注性状的相关性（WGCNA会使用不同的颜色对模块进行命名区分），如下图所示：</p>
<p><img src="http://www.seq.cn/data/attachment/forum/201511/20/171403cq9uer9xaxum7twz.png.thumb.jpg" alt="" /></p>
<p>各基因模块与组织的相关性分析</p>
<p>之后可以通过功能注释鉴定模块的功能，通过模块内部基因的关联网络，找到该模块的关键基因，如下图所示。</p>
<p><img src="http://www.seq.cn/data/attachment/forum/201511/20/171403zpympkja8mb4jtod.png.thumb.jpg" alt="" /></p>
<p>参考文献：Hollender C A, Kang C, Darwish O, et al. Floral transcriptomes in woodland strawberry uncover developing receptacle and anther gene networks[J]. Plant physiology, 2014, 165(3): 1062-1075. 转录调控类文章，一般最终都会落实到某个或某些关键基因的讨论，所以共表达网络分析有助于从复杂的数据整理中筛选出关键的基因。那么，就让我们来看看WGCNA的效果吧。  <strong>WGCNA效果</strong> 下表所列的就是部分基于WGCNA所发表的文章</p>
<p>Years</p>
<p>Species</p>
<p>Publication</p>
<p>IF</p>
<p>Article</p>
<p>2015</p>
<p>Human</p>
<p>Nature neuroscience</p>
<p>16.059</p>
<p>Coexpression networks identify brain region-specific enhancer RNAs in the human brain</p>
<p>2015</p>
<p>Maize</p>
<p>Plant cell</p>
<p>9.338</p>
<p>RNA Sequencing of Laser-Capture Microdissected Compartments of the Maize Kernel Identifies Regulatory Modules Associated with Endosperm Cell Differentiation</p>
<p>2015</p>
<p>Maize</p>
<p>PNAS</p>
<p>9.674</p>
<p>Transcriptome dynamics of developing maize leaves and genomewide prediction of cis elements and their cognate transcription factors</p>
<p>2014</p>
<p>Human</p>
<p>Nature communications</p>
<p>11.47</p>
<p>Gene co-expression network analysis reveals common system-level properties of prognostic genes across cancer types</p>
<p>2014</p>
<p>Human</p>
<p>Cell reports</p>
<p>8.358</p>
<p>MicroRNAs establish robustness and adaptability of a critical gene network to regulate progenitor fate decisions during cortical neurogenesis</p>
<p>2013</p>
<p>Human and mouse</p>
<p>Nature</p>
<p>41.456</p>
<p>Genetic programs in human and mouse early embryos revealed by single-cell RNA sequencing</p>
<p>2013</p>
<p>Human</p>
<p>Cell</p>
<p>32.242</p>
<p>Integrative functional genomic analyses implicate specific molecular pathways and circuits in autism</p>
<p><a href="http://www.seq.cn/forum.php?mod=viewthread&amp;tid=5414967">http://www.seq.cn/forum.php?mod=viewthread&amp;tid=5414967</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>两个基因组序列相互比较：Mummer</title>
    <url>/2020/12/05/Bioinfo-compare-two-genome-sequences-by-mummer/</url>
    <content><![CDATA[<p>直接对两个基因组进行比较，用Mummer：</p>
<p>例如，将细菌1（H_pyloriJ99_Eslice.fasta）与细菌2（H_pylori26695_Eslice.fasta）进行比较：</p>
<p>mummer -mum -b -c H_pylori26695_Eslice.fasta H_pyloriJ99_Eslice.fasta &gt; mummer.mums<br />
mummerplot -x [0,275287] -y [0,265111] -postscript -p mummer mummer.mums</p>
<p>结果：</p>
<p><img src="https://genehub.files.wordpress.com/2019/07/mummer.png" alt="mummer.png" /></p>
<p>如果换成两个大基因组呢？800M以上的基因组，结果报错了，尺寸太大，程序默认不支持这么多，只允许400M。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># reading input file &quot;Jxxx.fasta&quot; of length 854295539</span><br><span class="line"># construct suffix tree for sequence of length 854295539</span><br><span class="line"># (maximum reference length is 536870908)</span><br><span class="line"># (maximum query length is 4294967295)</span><br><span class="line"># process 8542955 characters per dot</span><br><span class="line">mummer: suffix tree construction failed: textlen=854295539 larger than maximal textlen=536870908</span><br></pre></td></tr></table></figure>
<p>我的版本是：MUMmer3.23</p>
<p>需要对mummer添加参数重新编译：</p>
<p>The size of your reference sequence is larger than is supported by default.<br />
You can either break your reference into multiple files and run each<br />
individually, or recompile the mummer package with:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">make clean</span><br><span class="line">make CPPFLAGS=&quot;-O3 -DSIXTYFOURBITS&quot;</span><br></pre></td></tr></table></figure>
<p><strong>20201204 更新</strong></p>
<p>MUMMER v4 可以直接对大型基因组进行比较，他的功能已经升级了。<a href="https://github.com/mummer4/mummer/releases/download/v4.0.0rc1/mummer-4.0.0rc1.tar.gz">mummer-4.0.0rc1.tar.gz下载链接</a></p>
<p>如何对同一个物种的不同版本基因组序列比较？</p>
<p>以大豆<em>Glycine max</em>为例，大豆20条染色体，基因组尺寸约1 Gb，最新基因组版本Gmax_508_a4.v1，上一个版本是Gmax_275_a2.v1。</p>
<p><strong>一、先用nucmer对两个genome序列进行比较，生成delta文件。</strong><br />
我设定的最小匹配单元长度是1 kb，也就是1 kb内不允许错配。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nucmer --prefix=GM508_GM275_genome --minmatch=1000 --threads=12 ~/databases/Glycine_max/508_Wm82.a4.v1/assembly/Gmax_508_v4.0.softmasked.fa ~/databases/Glycine_max/phytozome.12/Gmax_275_v2.0.softmasked.fa</span><br></pre></td></tr></table></figure>
<p><strong>二、然后可以delta-filter自定义筛选。</strong><br />
比如说我只想看contig和reference两者唯一匹配，并且长度在1000，相似度大于90.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">delta-filter -i 89 -l 1000 -1 GM508_GM275_genome.delta &gt;GM508_GM275_genome_i89_l1000_1.delta</span><br></pre></td></tr></table></figure>
<p><strong>三、再用mummerplot命令画图。</strong><br />
注意Rfile和Qfile主要功能是提供两个基因组各自包含的若干染色体（或者scaffold、contig）序列，不加这个参数，出来的图片没有染色体名称标记的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mummerplot -Rfile ~/databases/Glycine_max/508_Wm82.a4.v1/assembly/Gmax_508_v4.0.softmasked.fa -Qfile ~/databases/Glycine_max/phytozome.12/Gmax_275_v2.0.softmasked.fa -postscript -p GM508_GM275_genome_i89_l1000_1 GM508_GM275_genome_i89_l1000_1.delta</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># `gnuplot 5.4 patchlevel 1  </span><br><span class="line"># Reading delta file GM508_GM275_genome_i89_l1000_1.delta  </span><br><span class="line"># Writing plot files GM508_GM275_genome_i89_l1000_1.fplot, GM508_GM275_genome_i89_l1000_1.rplot  </span><br><span class="line"># Writing gnuplot script GM508_GM275_genome_i89_l1000_1.gp  </span><br><span class="line"># Rendering plot GM508_GM275_genome_i89_l1000_1.ps`</span><br></pre></td></tr></table></figure>
<p><strong>20201230 备注</strong></p>
<p>更换一台机器之后，运行画图遇到错误。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ mummerplot -Rfile ./AM_genome_V5_20201211.fa -Qfile ./20201228_3ddna.fa -postscript -p plot_test V5_vs_3dV1_genome_i89_l1000_1.delta </span><br><span class="line">gnuplot 4.6 patchlevel 2</span><br><span class="line">Reading delta file V5_vs_3dV1_genome_i89_l1000_1.delta</span><br><span class="line">Writing plot files plot_test.fplot, plot_test.rplot</span><br><span class="line">Writing gnuplot script plot_test.gp</span><br><span class="line">Rendering plot plot_test.ps</span><br><span class="line">WARNING: Unable to run &#x27;false plot_test.gp&#x27;, Inappropriate ioctl for device</span><br></pre></td></tr></table></figure>
<p>切换到 python37 或者 python27 环境，用conda安装了更高版本的 gnuplot ，再安装 libjpeg-turbo 就可以运行 gnuplot 了。但是仍然无法运行mummerplot。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 用conda安装gnuplot</span><br><span class="line">conda install -c bioconda gnuplot</span><br><span class="line"></span><br><span class="line"># 启动gnuplot遇到错误</span><br><span class="line">$ gnuplot --version</span><br><span class="line">gnuplot: error while loading shared libraries: libjpeg.so.8: cannot open shared object file: No such file or directory</span><br><span class="line"></span><br><span class="line"># 安装 libjpeg-turbo，就可以运行gnuplot了</span><br><span class="line">$ conda install -c conda-forge libjpeg-turbo</span><br><span class="line"></span><br><span class="line"># 成功运行gnuplot</span><br><span class="line">(python27) [fenglei@localhost ~]$ gnuplot --version</span><br><span class="line">gnuplot 5.0 patchlevel 3</span><br></pre></td></tr></table></figure>
<p><strong>四、生成比对图片</strong><br />
把ps文件放到windows系统，用Photoshop软件打开上面生成的ps文件即可看到图。当然也可以直接在linux里面用convert命令将ps文件转换为pdf/png文件，但是我的linux系统没有convert命令。如图可以见到两个版本基因组的差异。11和14号染色体有明显的结构差异。</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/gm508_gm275_genome_i89_l1000_1.jpg"><img src="https://genehub.files.wordpress.com/2020/12/gm508_gm275_genome_i89_l1000_1.jpg?w=1024" alt="" /></a></p>
<p><strong>五、如果不对delta文件做自定义筛选呢？</strong><br />
可见到大量的点，浅蓝色是反向匹配，深蓝色是正向匹配。</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/gm508_gm275_genome.jpg"><img src="https://genehub.files.wordpress.com/2020/12/gm508_gm275_genome.jpg?w=1024" alt="" /></a></p>
<p><strong>六、如果两个物种相比较呢？</strong><br />
要注意minmatch参数不能设太大，我把两个物种（Glycine max and Glycine soja）的minmatch设置为1000000，虽然运行时间比较短，但是结果输出一个空白delta文件。设置为minmatch=100测试，需要的时间更长，得到一个满屏铺满蓝点的图，根本看不清。设置minmatch=1000，并用delta-filter对比对的序列做筛选，进而得到下图。可见到11和13号染色体的区别。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">nucmer --prefix=GM508_Gsoja_genome --minmatch=1000 --threads=12 ~/databases/Glycine_max/508_Wm82.a4.v1/assembly/Gmax_508_v4.0.softmasked.fa ~/databases/03_Glycine_soja_W05_2019/Gsoja.W05.genome.fadelta-filter -i 89 -l 1000 -1 GM508_Gsoja_genome.delta &gt; GM508_Gsoja_genome_i89_l1000_1.deltamummerplot -Rfile ~/databases/Glycine_max/508_Wm82.a4.v1/assembly/Gmax_508_v4.0.softmasked.fa -Qfile ~/databases/03_Glycine_soja_W05_2019/Gsoja.W05.genome.fa -postscript -p GM508_Gsoja_genome_i89_l1000_1 GM508_Gsoja_genome_i89_l1000_1.delta</span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/12/gm508_gsoja_genome_i89_l1000_1.jpg"><img src="https://genehub.files.wordpress.com/2020/12/gm508_gsoja_genome_i89_l1000_1.jpg?w=1024" alt="" /></a></p>
<p>补充：画图可以用dotPlotly包，参考 <a href="https://github.com/tpoorten/dotPlotly/tree/master/example">https://github.com/tpoorten/dotPlotly/tree/master/example</a></p>
<p>主要是R语言：<a href="https://github.com/tpoorten/dotPlotly/blob/master/mummerCoordsDotPlotly.R">https://github.com/tpoorten/dotPlotly/blob/master/mummerCoordsDotPlotly.R</a></p>
<p>补充：如何理解上述作图过程中的几个文件呢？</p>
<p>delta文件（在<a href="http://mummer.sourceforge.net/manual/#HumanCompare">http://mummer.sourceforge.net/manual/#HumanCompare</a> 页面的The delta format section下面有详细解释）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/path/Gmax_508_v4.0.softmasked.fa /path/G.max-mitochondrion.fasta</span><br><span class="line"> NUCMER</span><br><span class="line">   Gm13 ChrM 45225048 402558     # 匹配区段所在的染色体</span><br><span class="line">   21773198 21776178 114322 117301 3 3 0   # 前四个数字：两个染色体上面的区段坐标。后三个数字：错误数(不相同碱基+indel碱基数)，相似错误(非正匹配得分) 终止密码子(NUCMER为0)。 如果结束大于起始，表示在负链。英文版解释：The three digits following the location coordinates are the number of errors (non-identities + indels), similarity errors (non-positive match scores), and stop codons (does not apply to DNA alignments, will be &quot;0&quot;)</span><br><span class="line">   8  # query的8位置有“缺失”？？？如果前面有负号，则表示此处为“插入”？相对ref序列而言。</span><br><span class="line">   0  # 表示当前匹配结束</span><br><span class="line">   Gm20 ChrM 47846026 402558</span><br><span class="line">   14299558 14301282 188578 190302 3 3 0</span><br><span class="line">   0 </span><br><span class="line">   Gm17 ChrM 41740656 402558</span><br><span class="line">   23669908 23674616 270387 265667 78 78 0</span><br><span class="line">   -499</span><br><span class="line">   -1   # 这连续的“-1”是什么意思？</span><br><span class="line">   -1</span><br><span class="line">   -1</span><br><span class="line">   -1</span><br><span class="line">   -1</span><br><span class="line">   -106</span><br><span class="line">   -2</span><br><span class="line">   -1</span><br><span class="line">   -1</span><br><span class="line">   -2</span><br><span class="line">   -2182</span><br><span class="line">   1263</span><br><span class="line">   -230</span><br><span class="line">   0 </span><br><span class="line">(output continues ...)</span><br></pre></td></tr></table></figure>
<p><strong>七、输出适合肉眼观察的Tabular格式比对结果</strong><br />
上面的delta文件不便于我们肉眼阅读，可用show-coords -r ${prefix}.delta &gt; ${prefix}.coords命令之后得到更适合阅读的格式（coords文件）。<br />
有点类似BLAST的“-outfmt 6”参数输出的Tabular格式<br />
如下，以ref序列的染色体排序的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">   [S1]     [E1]       [S2]     [E2]    [LEN 1]  [LEN 2]    [% IDY]   [TAGS]</span><br><span class="line">41311147 41314402     161362   158107       3256     3256      99.91   Gm08 ChrM</span><br><span class="line">24034371 24036869     210827   213325       2499     2499      99.88   Gm12 ChrM</span><br><span class="line">24038545 24043058      13087     8578       4514     4510      99.78   Gm12 ChrM</span><br><span class="line">21773198 21776178     114322   117301       2981     2980      99.90   Gm13 ChrM</span><br><span class="line">23669908 23674616     270387   265667       4709     4721      98.35   Gm17 ChrM</span><br><span class="line">14299558 14301282     188578   190302       1725     1725      99.83   Gm20 ChrM</span><br></pre></td></tr></table></figure>
<p><strong>八、输出适合肉眼观察的Pairwise格式比对结果</strong><br />
可指定特定的染色体或scaffold用于输出到屏幕，输出格式类似BLAST的“-outfmt 1”参数。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">show-aligns seqA_vs_seqB_genome_i89_l1000_1.delta Chrxxx Chryyy | less</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">============================================================</span><br><span class="line">-- Alignments between xxx and yyy</span><br><span class="line"></span><br><span class="line">-- BEGIN alignment [ +1 1 - 245034 | -1 94962171 - 94717077 ]</span><br><span class="line"></span><br><span class="line">                  10|       20|       30|       40|</span><br><span class="line">1          cccaaccccgagccctaaaccctaaaccccaaacccccaaccctgagcc</span><br><span class="line">94962171   cccaaccccgagccctaaaccctaaaccccaaacccccaaccctgagcc</span><br><span class="line">                                                            </span><br><span class="line">                  10|       20|       30|       40|</span><br><span class="line">50         tcgagccctaagccttgagcccgagccctaagccccgatccctaagccc</span><br><span class="line">94962122   tcgagccctaagccttgagcccgagccctaagccccgatccctaagccc</span><br><span class="line">                                                            </span><br><span class="line">                  10|       20|       30|       40|</span><br><span class="line">99         tgaaccccgaaccctcaaccccgaaccccaaaccctcaaccccaaaccc</span><br><span class="line">94962073   tgaaccccgaaccctcaaccccgaaccccaaaccctcaaccccaaaccc</span><br></pre></td></tr></table></figure>
<p>参考：</p>
<ol>
<li>MUMMER 两个基因组间比较 <a href="https://www.jianshu.com/p/c12f2a117892">https://www.jianshu.com/p/c12f2a117892</a></li>
<li>MUMMER 两个基因组间比较 <a href="https://www.jianshu.com/p/9701c9add82d">https://www.jianshu.com/p/9701c9add82d</a></li>
<li>最详细的MUMMER中文文档 <a href="https://www.jianshu.com/p/2e184e5c15b7">https://www.jianshu.com/p/2e184e5c15b7</a></li>
<li>How to understand MUMMER delta format？<a href="http://mummer.sourceforge.net/manual/#HumanCompare">http://mummer.sourceforge.net/manual/#HumanCompare</a></li>
<li>用R绘制点状图：<a href="https://github.com/tpoorten/dotPlotly">https://github.com/tpoorten/dotPlotly</a></li>
<li>用R绘制mummer的结果图 <a href="https://blog.csdn.net/u012110870/article/details/102492711?utm%5C_medium=distribute.pc%5C_relevant.none-task-blog-title-3&amp;spm=1001.2101.3001.4242">https://blog.csdn.net/u012110870/article/details/102492711?utm\_medium=distribute.pc\_relevant.none-task-blog-title-3&amp;spm=1001.2101.3001.4242</a></li>
</ol>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>cufflinks安装前提之一：安装boost</title>
    <url>/2014/09/08/Bioinfo-cufflinks-boost/</url>
    <content><![CDATA[<p>转录组数据分析软件cufflinks的安装，前提是linux平台必须装有boost 1.47以上的版本！安装步骤如下：</p>
<span id="more"></span>
<p>linux平台下要编译安装除gcc和gcc-c<ins>之外，还需要两个开发库：bzip2-devel 和python-devel，因此在安装前应该先保证这两个库已经安装： #yum install gcc gcc-c</ins> bzip2 bzip2-devel bzip2-libs python-devel -y 然后是去官网下载源码包，<a href="http://www.boost.org/users/download/">地址</a> 下载，解压，按照如下步骤： #tar xvzf boost_1_50_0.tar.gz 进入boost_1_50_0目录： #cd boost_1_50_0 然后是编译安装，boost源码包中有配置脚本，直接用就可以： <strong>#sh ./bootstrap.sh</strong> Building Boost.Build engine with toolset gcc… tools/build/v2/engine/bin.linuxx86_64/b2 Detecting Python version… 2.6 Detecting Python root… /usr Unicode/ICU support for Boost.Regex?.. not found. Generating Boost.Build configuration in project-config.jam… Bootstrapping is done. To build, run: ./b2 To adjust configuration, edit ‘project-config.jam’. Further information: - Command line help: ./b2 --help - Getting started guide: <a href="http://www.boost.org/more/getting%5C_started/unix-variants.html">http://www.boost.org/more/getting\_started/unix-variants.html</a> - Boost.Build documentation: <a href="http://www.boost.org/boost-build2/doc/html/index.html">http://www.boost.org/boost-build2/doc/html/index.html</a> 接下来就是编译，重点关注是否编译成功： <strong>#./b2</strong> 然后就是漫长的等待，如果最后出现： The Boost C++ Libraries were successfully built! The following directory should be added to compiler include paths: /home/fenglei/local/app/boost_1_50_0 The following directory should be added to linker library paths: /home/fenglei/local/app/boost_1_50_0/stage/lib 表示编译成功，如果没有成功，就需要回查看哪里出现error，再安装相应的库， 最后就是安装： <strong>#./b2 install --prefix=/usr/local</strong> 安装后的头文件在/usr/local/include/boost里面，而相应的库在/usr/local/lib/libboost_*</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>cuffmerge的结果中将相邻的基因merge成一个“基因”</title>
    <url>/2016/02/28/Bioinfo-cuffmerge-merge-genes/</url>
    <content><![CDATA[<p>cuffmerge combining genes from adjacent loci?? <a href="https://www.biostars.org/p/104551/">https://www.biostars.org/p/104551/</a> <a href="http://seqanswers.com/forums/showthread.php?t=19772">http://seqanswers.com/forums/showthread.php?t=19772</a> <a href="http://seqanswers.com/forums/showthread.php?t=48571">http://seqanswers.com/forums/showthread.php?t=48571</a> <a href="https://groups.google.com/forum/#!searchin/tuxedo-tools-users/cuffmerge/tuxedo-tools-users/HSZmU%5C_KDflo/Zz5mMtZkW6wJ">https://groups.google.com/forum/#!searchin/tuxedo-tools-users/cuffmerge/tuxedo-tools-users/HSZmU\_KDflo/Zz5mMtZkW6wJ</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>多个样品的denovo RNA Seq组装</title>
    <url>/2016/04/08/Bioinfo-denovo-rna-seq-assembly/</url>
    <content><![CDATA[<p>问题：先各自组装，然后合并组装的结果；还是先合并reads，再一起组装？ 应该是合并Reads再进行组装能得到更好的结果。 参考资料：<a href="http://seqanswers.com/forums/showthread.php?t=33452">http://seqanswers.com/forums/showthread.php?t=33452</a> #9： I’ve tried assembling combined reads vs. assembling separate reads for several species, and combining reads has always given a more contiguous and accurate assembly. If you have &gt; 200 million combined reads, I strongly recommend using Trinity In-Silico Normalization, which will give a good assembly in much shorter run time when compared to non-normalized assembly. 也有人分开组装，然后合并。 合并方法： TGICL CAP3 CD-HIT</p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>Diamond: 比BLAST更快速的比对工具</title>
    <url>/2018/07/09/Bioinfo-diamond-vs-blast/</url>
    <content><![CDATA[<p><strong>Diamond简介</strong> 序列比对软件，能输出与BLAST类似的结果，但是速度快了数百倍。 <strong>安装</strong> 二进制可以直接解压使用：</p>
<p>wget <a href="http://github.com/bbuchfink/diamond/releases/download/v0.9.22/diamond-linux64.tar.gz">http://github.com/bbuchfink/diamond/releases/download/v0.9.22/diamond-linux64.tar.gz</a><br />
tar xzf diamond-linux64.tar.gz</p>
<p>源码则用cmake安装：</p>
<p>wget <a href="http://github.com/bbuchfink/diamond/archive/v0.9.22.tar.gz">http://github.com/bbuchfink/diamond/archive/v0.9.22.tar.gz</a><br />
tar xzf v0.9.22.tar.gz<br />
cd diamond-0.9.22<br />
mkdir bin<br />
cd bin<br />
cmake …<br />
make install</p>
<p><strong>使用</strong> 1 建立index</p>
<p>diamond makedb --in swissprot.fasta -d swissprot</p>
<p>2 比对</p>
<p>diamond blastp --db ./index/swissprot --query putative_proteins.fa --threads 10 --out proteins-BLASTP-swissprot.m8 -e 0.00001 --max-target-seqs 1</p>
<p>建立index的过程就6秒钟（Processed 557491 sequences, 199978344 letters. Total time = 6.64576s）。比对过程也极快，几分钟跑完了。 <strong>与其他软件的比较</strong> “生信技能树”论坛有人讲Diamond与BLAST进行比较，26740个蛋白序列与NR的蛋白库（animal）作比对，运行DIAMOND仅需要3小时，运行BLASTP则需要2周。存在的问题是同一个蛋白序列在两个比对软件下得到的最高分比对结果通常不一样（可能跟参数设置有关？）。第二个问题是输出的tabular格式结果不能被blast2go识别（可能需要调整输出格式的参数）。 <strong>参考资料</strong> [1] <a href="https://github.com/bbuchfink/diamond/releases/">https://github.com/bbuchfink/diamond/releases/</a> [2] <a href="http://www.biotrainee.com/thread-1465-1-1.html">http://www.biotrainee.com/thread-1465-1-1.html</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>使用DOGMA对Chloroplast genome注释并用Sequin提交到GenBank</title>
    <url>/2016/05/26/Bioinfo-dogma-chloroplast-genome-annotation/</url>
    <content><![CDATA[<h2 id="dogma可以对叶绿体基因组进行注释并可以生成直接导入sequin软件的注释信息从而生成genbank格式的注释可提交ncbi也可在ogdraw进行绘图"><a class="markdownIt-Anchor" href="#dogma可以对叶绿体基因组进行注释并可以生成直接导入sequin软件的注释信息从而生成genbank格式的注释可提交ncbi也可在ogdraw进行绘图"></a> DOGMA可以对叶绿体基因组进行注释，并可以生成直接导入sequin软件的注释信息，从而生成Genbank格式的注释，可提交NCBI，也可在OGDRAW进行绘图。</h2>
<h2 id="dogma-help"><a class="markdownIt-Anchor" href="#dogma-help"></a> DOGMA Help</h2>
<ol>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#assumptions">Platforms/Browsers</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#userids">Userids/Passwords</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#unique">Unique IDs</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#retrieving">Retrieving or removing an existing annotation</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#input_file">Input file format</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#input_file_problems">Input file problems</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#gapped">Gapped alignment</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#rna_per">Percent identity cutoffs</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#gcode">Genetic code</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#evalue">E-values</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#reorient">Reorienting genomes</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#cutoff">COVE threshold</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#dogbase">Databases</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#numberline">Numberline panel</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#extract">Extracting sequences</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#summaries">Displaying summaries</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#annotation_panel">Annotation panel</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#sequin_input">Sequin input window</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#delete_gene">Deleting a gene</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#sequin_files">Using Sequin to submit files to GenBank</a></p>
</li>
<li>
<p><a href="http://dogma.ccbb.utexas.edu/html/dirs.html#misc">Misc. data files</a></p>
</li>
<li>
<p><strong>Platforms/Browsers</strong></p>
<ul>
<li>DOGMA was developed using Safari (Mac’s <a href="http://www.apple.com/safari">browser</a> for OS X) under Panther (10.3.2) so these are the conditions under which DOGMA works best. It seems to run fine under Tiger, however there are some issues with the middle panel refreshing. When you originally retrieve an annotation you have been working on, you must hit the refresh button in the lower right-hand corner. DOGMA may be functional with Internet Explorer for the Mac running OS X, but Microsoft is no longer supporting IE on the Mac and there are no gaurantees with DOGMA under IE.</li>
<li>You should set your font to size 14 (or smaller) in the browser Preferences (having a larger size may cause DOGMA windows to display incorrectly) .</li>
<li>You should also set your monitor resolution to at least 1152 x 768.</li>
<li>For Safari, make sure you don’t have pop-up windows blocked (under the Safari menu).</li>
</ul>
</li>
<li>
<p><strong>Userids</strong> Your userid gives you access to the your own data files. Your userid will give you access only to your own data. Because this site is not encrypted, the passwords are not secure and you should use a password that is not used for secure purposes. Userid and passwords are <em>case sensitive</em>. Userids should be alpha-numeric (no spaces!). If you are having trouble logging in, make sure you are typing with proper capitalization. If you forget your userid or password, send email to <a href="mailto:staciakwyman@gmail.com">staciakwyman@gmail.com</a></p>
</li>
<li>
<p><strong>Unique IDs</strong> Unique IDs are how you identify and distinguish between your different annotations. When you are retrieving an existing ID, your will be given a list of annotations by unique ID. It is best to name the annotation with the genome name and perhaps the DOGMA settings that the annotation is created with. Unique IDs should be alpha-numeric (no spaces!). It’s a good idea to identify them by taxon and their settings. For example, if you had several nicotiana annotations, you might name them this way:</p>
<ul>
<li>nicotianaGap50</li>
<li>nicotianaUngap60</li>
<li>etc…</li>
</ul>
</li>
<li>
<p><strong>Retrieving or removing an existing annotation</strong> When you enter your userid and then hit submit in the retrieve section, you will be presented with a list of the annotations that exist in your data directory and the date that it was last edited. You may remove obsolete annotations here, or view and edit unfinished annotations. If you remove an annotation, it <em>can</em> be retrieved, but not quickly or easily and perhaps not the most recent copy, so be sure you want to delete it.</p>
</li>
<li>
<p><strong>Input file format</strong> The input file should be in FASTA format. The first line should begin with a “&gt;” followed immediately by the SeqID and then the nucleotide sequence beginning on the next line. In order for a feature table to be imported into Sequin, the SeqId of the FASTA file (the first word immediately after &gt; ), must match the SeqId of the feature table. So be aware that the first word (after the &gt;) on the first line of the FASTA file will be used as the SeqId in Sequin.For example, in the following file, the SeqId is Sc_16:</p>
<p>&gt;Sc_16 [organism=Saccharomyces cerevisiae] [strain=S288C]<br />
CGACCACAATGGTACGATTGTTCATAAATCAGGAGATGTTCCTATTCATATAAAGATACC<br />
AAACAGATCTCTAATACATGACCAGGATATCAACTTCTATAATGGTTCCGAAAACGAAAG<br />
AAAACCAAATCTAGAGCGTAGAGACGTCGACCGTGTTGGTGATCCAATGAGGATGGATAG<br />
[etc.]</p>
<p>And the first line of the feature table file would look like:</p>
<p>&gt;Features Sc_16</p>
<p>More information is available at <a href="http://www.ncbi.nlm.nih.gov/Sequin/table.html">the NCBI site.</a> Sequence data may contain any of the characters from the IUPAC code:</p>
<p><strong>A</strong></p>
<p>adenosine</p>
<p><strong>M</strong></p>
<p>A or C (amino)</p>
<p><strong>C</strong></p>
<p>cytidine</p>
<p><strong>S</strong></p>
<p>G or C (strong)</p>
<p><strong>G</strong></p>
<p>guanine</p>
<p><strong>W</strong></p>
<p>A or T (weak)</p>
<p><strong>T</strong></p>
<p>thymidine</p>
<p><strong>B</strong></p>
<p>G or T or C</p>
<p><strong>U</strong></p>
<p>uridine</p>
<p><strong>D</strong></p>
<p>G or A or T</p>
<p><strong>R</strong></p>
<p>G or A (purine)</p>
<p><strong>H</strong></p>
<p>A or C or T</p>
<p><strong>Y</strong></p>
<p>T or C (pyrimidine)</p>
<p><strong>V</strong></p>
<p>G or C or A</p>
<p><strong>K</strong></p>
<p>G or T (keto)</p>
<p><strong>N</strong></p>
<p>A G C T (any)</p>
</li>
<li>
<p>Problems? Read below <strong>IF YOU GET OUTPUT WITH NO GENES:</strong> This usually means your input file had the wrong kind of line breaks. Follow the directions below and try uploading your file again. If you have a situation not covered in the instructions below, send <a href="mailto:staciakwyman@gmail.com">staciakwyman@gmail.com</a> email.<strong>Creating an input file:</strong> To prepare your file for uploading to DOGMA, several steps may be required depending on which program (Sequencher, MacVector, Consed, Word, etc.) you used to save your data. Different programs save files with different kinds of line breaks, and it must be a specific kind for uploading to DOGMA. In the instructions below, I am assuming you are using a Mac running OS X.</p>
<ul>
<li><strong>To save from Sequencer or MacVector:</strong> If you have a Sequencher (or MacVector) file, you’ll need to execute several steps to get it ready to input to DOGMA. Save the file as Pearson/FASTA format from the export menu (FASTA text in MacVector).Then you have two options to convert it to a file which may be uploaded through the browser to DOGMA (if you are you Mac OS X):
<ol>
<li>Using a terminal window.
<ul>
<li>Open a terminal window (the terminal application is in the Utilities folder under Applications).</li>
<li>cd to the directory with the file in it (if the file is on the Desktop, open the terminal window and then type “cd Desktop” at the prompt).</li>
<li>At the prompt, type: native2ascii filename filename</li>
<li>Then try uploading the file to DOGMA</li>
</ul>
</li>
<li>Using MS Word.
<ul>
<li>Open the file in MS Word, then save as MS-DOS Text. NOT TEXT ONLY.</li>
</ul>
</li>
</ol>
</li>
<li><strong>To save from MS Word</strong> Save the file as MS-DOS text. NOT TEXT ONLY.</li>
<li><strong>Other:</strong>
<ul>
<li>If you aren’t sure what program the file came from and it isn’t uploading correctly to DOGMA, try running native2ascii on it (as in the directions for saving from Sequencher above. Doing this to a file will do no harm if it’s already in ASCII format). The symptom of not uploading correctly is that DOGMA finds no genes in input sequence.</li>
<li>Files saved from Consed should be OK for uploading to DOGMA.</li>
<li>Files downloaded through the browser from GenBank (as in the tutorial) should be OK for uploading.</li>
</ul>
</li>
</ul>
</li>
<li>
<p><strong>To gap or not to gap</strong> <strong>MT Genomes</strong> For mitchondrial genomes, we have not found any genomes for which ungapped BLAST finds something that gapped BLAST misses, so gapped BLAST should be used for mt genomes. You could also run both and compare the results.<strong>CP Genomes</strong> The option for gapped and ungapped alignment may give slightly different results for chloroplast genomes. The ungapped option will generally generate shorter BLASTX matches with higher percent identity scores. This will result in some genes appearing as multiple, contiguous pieces in the annotation window. The gapped alignment will generate longer BLASTX matches but for genomes with some protein coding genes that are quite divergent from the ones in the database, these genes may be missed. The more divergent genes can be found by either running an ungapped alignment or by running a gapped alignment with a lower percent identity cutoff than the 60% default value. The best thing to do is run it both gapped (with and without lowering the percent identity cutoff) and ungapped alignment and compare the results. We also recommend that users examine the BLASTX results before deciding if a gene is present when there are differences between gapped and ungapped annotations (BLAST results for a gene can be viewed by clicking on the gene name in the top panel). We have evaluated the differences between these two options for several genomes but we would be interested in hearing about any differences you detect. I suggest that when you are annotating a complete cp genome, keep one of the runs as the “master” copy to which you can add genes which are found with difference settings.</p>
</li>
<li>
<p><strong>Percent identity cutoffs</strong> <strong>Protein coding gene cutoffs</strong> In the first run, try the default values for the percent identity cutoff and if you are missing genes, lower the value and run it again. If your genome is only distantly related to the other genomes in the database (see <a href="http://dogma.ccbb.utexas.edu/html/cp_taxa">cp taxa</a> or <a href="http://dogma.ccbb.utexas.edu/html/mt_taxa">mt taxa</a> for a list of genomes in the database).<strong>Chloroplast tRNA cutoffs</strong> Chloroplast tRNAs are identified by BLASTN searches against a data base of 15 chloroplast genomes. The high level of nucleotide sequence conservation among the same tRNAs in different genomes enables accurate identification of chloroplast tRNAs by this method. When selecting the percent identity cutoff for RNAs in cp genomes, we recommend using a high cutoff (85-90%) to avoid spurious trna matches. The optimum percent identity may vary some depending on how divergent the genome you are annotating is relative to the sequences in the database. Thus, it may be necessary to do multiple runs with different percent identity settings. Furthermore, putatively identified tRNAs could be confirmed with other available programs for identifying tRNAs.</p>
</li>
<li>
<p><strong>Which genetic code do I use?</strong> For chloroplast annotations, use number 11 (Bacterial and Plant Plastid), which is identical to the standard genetic code, but has more start codons. The standard genetic code has just ATG, TTG, CTG, number 11 also has ATT, ATC, ATA and GTG. Using Genetic Code 11 instead of the Standard Genetic Code for chloroplast genomes only has the effect of highlighting more potential start codons, but should have no other effect.</p>
</li>
<li>
<p><strong>BLAST E-values</strong> Blast e-values tell you approximately how many sequences with that score you would expect to find in the database by chance. Therefore, a higher number (i.e. 1e-5) indicates that the sequence is more likely to appear by chance, and is therefore a <em>less</em> stringent cutoff. A lower number (i.e. 1e-30) indicates the sequence is less likely to appear by chance, and is therefore a more stringent cutoff. Note, however, that these scores are based on the length of the match and the length of the database and can be misleading at times.</p>
</li>
<li>
<p><strong>Reorienting mitochondrial genomes</strong> If you want your fasta file to be reoriented so that the cox1 gene turns up as the first gene in the annotation, select Yes here. This is to provide consistency in finished genomes. Cox1 was chosen as a reliable starting place because it tends to be the most conserved gene for mitochondrial genomes.</p>
</li>
<li>
<p><strong>COVE threshold</strong> Only tRNAs scoring above this value are reported. This cuts down on the number of spurius tRNAs that are found. If many tRNAs are found which overlap with protein coding genes, set this value higher to screen out some of the lower-scoring tRNAs.</p>
</li>
<li>
<p><strong>Database taxa</strong> Click <a href="http://dogma.ccbb.utexas.edu/html/cp_taxa">here</a> for a list of taxa in the chloroplast database. Click <a href="http://dogma.ccbb.utexas.edu/html/mt_taxa">here</a> for a list of taxa in the mitochondrial database.</p>
</li>
<li>
<p><strong>Numberline panel</strong> This panel displays all the genes graphically on a numberline. When the colored block representing the gene is clicked, that gene is displayed in the top panel. When you mouse over the gene block and hold the mouse still, information about that gene will appear in a yellow box. It gives the gene name, gene start, gene end, and strand of the gene. Protein coding genes are light purple on the forward strand, and dark striped purple on the reverse. Transfer RNAs are light blue on the forward strand, and dark striped blue on the reverse. Ribosomal RNAs are light green on the forward strand, and dark striped green on the reverse. After a gene has been annotated, it shows up in the middle panel with a black border. For genes with introns, the black border connects the exons.</p>
</li>
<li>
<p><strong>Extracting sequences</strong> There are several kinds of sequences which can be extracted from the annotation. All of the sequences are generated from the text summary file, so if genes are not yet annotated, the sequences generated may not be correct.<br />
*   <strong>Intergenic sequences</strong> This will return the set of nucleotide sequences between all the genes in the input.<br />
*   <strong>Introns</strong> This will return the nucleotide sequences of all the introns for annotated genes with more than one exon.<br />
*   <strong>Protein coding aa sequences</strong> This will return the set of sequences for all the genes in the text summary, translated to amino acids. For genes with introns, the intron sequences are not returned and the translated exons are each given on a separate line.<br />
*   <strong>Protein coding nt sequences</strong> This will return the set of nucleotide sequences for all the genes in the text summary. For genes with introns, the intron sequences are not returned and the exons are each given on a separate line.<br />
*   <strong>tRNAs</strong>The nucleotide sequence for the tRNA is returned.<br />
*   <strong>rRNAs</strong>The nucleotide sequence for the rRNA is returned.</p>
</li>
<li>
<p><strong>Displaying summaries</strong> Clicking on the Show Sequin Format button brings up the Sequin input file. If no genes have been annotated, it will be empty. Clicking on the Show Text Summary button brings up the list of genes produced by BLASTing against the database. This list is modified as the genes are annotated. It does not represent a correct list until all genes have been annotated. (For example, the BLAST hits don’t contain stop codons, so all the protein coding genes are initially 3 nucleotides short.) Once a gene has been annotated, it is shown labelled “Annotated” in the text summary. Exons are listed separately, one after another in the text summary.</p>
</li>
<li>
<p><strong>Annotating genes</strong> <strong>Protein coding genes</strong> When you click on a gene in the numberline panel, information about that gene appears in the top panel. Both the forward and reverse strands of the DNA sequence containing that gene plus 60 basepairs up and down stream of the gene are shown. The amino acid sequence for the input genome is shown directly adjacent (above for genes on the forward strand, below for genes on the reverse strand) to the nucleotide sequence. The amino acid sequences for the closest BLAST hits (how many is a setting the user can change on the first form page) are show next. The user needs to pick a start and stop codon for the gene based on these BLAST hits.<strong>Protein coding genes with introns</strong> For a gene with an intron, it will likely show up as two adjacent genes on the number line. When annotating a gene with an intron, the start and stop codons of the first and last exons must first be annotated, and then the exons can be joined (using the button on the Sequin window) in the annotation.<strong>Example:</strong> When nicotiana is run through DOGMA, the gene atpF has an intron and shows up on the numberline in two pieces: from 12206 12673 and 13294 13452 on the reverse strand. Before the exons can be joined, the start codon must be chosen by clicking on the second exon (since it is on the reverse strand). Then the first exon can be selected and the stop codon picked and then the “Add an exon” button in the Sequin window can be selected. This will bring up a list of all the potential exons for that gene.</p>
</li>
<li>
<p><strong>Sequin input window</strong> The Sequin Window appears when a gene block is clicked on in the numberline panel. It appears with all of the required information already filled in when the window appears, but the user needs to verify the beginning and end of the gene. When a link for a potential start and stop codon is click in the top panel of the Annotation Window, the values are automatically updated in the Sequin Window. Values in the Sequin Window may also be manually updated.</p>
</li>
<li>
<p><strong>Deleting a gene</strong> There are two ways to remove a gene. One is to, select the “Delete Gene” button from the bottom panel in DOGMA and then type in the name of the gene exactly as it appears in the text summary. You will be asked to confirm the gene you want to remove. The other way to delete a gene is to click the delete button next to the gene you want to remove in the text summary for the annotation. Once a gene is deleted, it can’t be undone. You can, however, add a gene using the “Add Gene” button in the bottom panel.</p>
</li>
<li>
<p><strong>Preparing files to input to Sequin program</strong> In order for a feature table to be imported into Sequin, the SeqId of the FASTA file (the first word after &gt; ), must match the SeqId of the feature table. So be aware that the first word (after the &gt;) on the first line of the FASTA file will be used as the SeqId in Sequin.Example: In the following file, the SeqId is Sc_16:</p>
</li>
</ol>
<pre><code>\&gt;Sc\_16 \[organism=Saccharomyces cerevisiae\] \[strain=S288C\] 
CGACCACAATGGTACGATTGTTCATAAATCAGGAGATGTTCCTATTCATATAAAGATACC
AAACAGATCTCTAATACATGACCAGGATATCAACTTCTATAATGGTTCCGAAAACGAAAG
AAAACCAAATCTAGAGCGTAGAGACGTCGACCGTGTTGGTGATCCAATGAGGATGGATAG
\[etc.\]

More information is available at [the NCBI site.](http://www.ncbi.nlm.nih.gov/Sequin/table.html) When preparing a Sequin submission, you'll need two files: the FASTA file containing the genome sequence, and the feature table file created by DOGMA. To prepare the feature table file after annotating all the genes:

1.  Click on the \`\`Show Sequin Format'' button.
2.  Copy and paste the contents of the file as into Word.
3.  Save the Word file as \`\`Text only.''

The Sequin page at NCBI is [Sequin](http://www.ncbi.nlm.nih.gov/Sequin/). You can download the Sequin stand-alone application from this [page](http://www.ncbi.nlm.nih.gov/Sequin/download/seq_mac_download.html). Click on the sequin.Mac.hqx link on the page to download a file called Sequin Folder.sit. This should automagically uncompress and inside that folder, you should double-click on the SequinOSX application. You should read through the Sequin documentation on the NCBI site to familiarize yourself with it, but you can also pretty much ignore it.
1.  Choose Start New Submission
2.  Enter the information for the 4 tabs: Submission, Contact, Authors, and Affiliation. It won't let you proceed until it has this information.
3.  You can save and re-use this information by going back to the Submission tab and selecting Export Submitter Info from the File menu (convention is to name it with a .sbt extension). Then, for your next submission, when you are on the Submission tab, select Import Submitter Info from the File menu and load the saved file.
4.  The next form you typically won't need to change, just select Next Form.
5.  Now fill out the organism information under the Organism tab. For chloroplasts, you should change Location of Sequence to Chloroplast. Sequin will then fill in the genetic code for you.
6.  Under the Nucleotide tab, you should import your import your fasta file. For chloroplasts, change topology to circular.
7.  Click next page, do nothing on this tab, then click Next Form. When it says &quot;You have not entered proteins. Is this correct?&quot; say OK.
8.  Next you get a window with the GenBank format, and now you import your feature table file by choosing \`\`File&gt;Open'' and selecting the feature table file. The GenBank format should then include all your annotations and the protein sequences for all your protein coding genes.
9.  You should then select &quot;Search&gt;Validate&quot; to see any errors that you might need to fix.
10.  When you save the Sequin file and quit, Sequin will tell you to email the file to gb-sub@ncbi.nlm.nih.gov. You can also save the GenBank flat file.
</code></pre>
<ol start="21">
<li><strong>Misc. data files</strong> For each annotation, there are many files which are stored with it. These can be accessed by giving the URL prefix for the annotation:<a href="http://dogma.ccbb.utexas.edu/data/USERID/UNIQUE/FILENAMESome">http://dogma.ccbb.utexas.edu/data/USERID/UNIQUE/FILENAMESome</a> files you might be interested in looking at are:</li>
</ol>
<pre><code>*   **missed.txt** If DOGMA missed any genes, they will be listed in this file.
*   **cm\_out** (for mt data) This is the raw cove output. It gives the cove score and the coordinates of putative tRNAs.
*   **cm\_strings** This is the sequences that COVE identified as potential tRNAs. It may have putative tRNAs which are not in DOGMA because the folding program wansn't able to fold the string of nucleotides.
*   **blast\_output** this is a directory containing the BLAST output for each of the genes.

**Sorry, for security reasons, directory listing has been turned off for this server so some of the files are no longer available.**
</code></pre>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>基因名称在Excel中显示成了日期的问题</title>
    <url>/2017/05/12/Bioinfo-gene-names-were-converted-to-dates-in-excel/</url>
    <content><![CDATA[<p>Excel会自动把基因名称纠正为日期或者数字，这些错误很难被修正。例如，名为SEPT2和MARCH1的基因就会被Excel自动纠正为‘2-Sep ’和‘1-Mar’。此外，Excel还会自动将RIKEN标识符转化为浮点数字(比如将‘ 2310009E13’变成‘2.31E+13’)。 解决办法： 1 不要用excel直接打开文件，而是用导入数据功能。 启动Excel，在Excel功能栏里选择“数据”，然后点击“自文本”，选择目的文本文件。 <img src="https://genehub.files.wordpress.com/2017/05/qqe688aae59c9620170512181102.jpg" alt="QQ截圖20170512181102" /> 2选择文本文件，就会出来“文本导入向导”，点击有基因名称的那一列，数据格式选择“文本”即可。 <img src="https://genehub.files.wordpress.com/2017/05/qqe688aae59c9620170512181305.jpg" alt="QQ截圖20170512181305" />   <sub>END</sub></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Gene Ontology analysis for DEGs of Arabidopsis</title>
    <url>/2018/01/02/Bioinfo-gene-ontology-analysis-for-degs-of-arabidopsis/</url>
    <content><![CDATA[<blockquote>
<p>try http:// if https:// URLs are not supported<br />
source(“<a href="https://bioconductor.org/biocLite.R">https://bioconductor.org/biocLite.R</a>”)<br />
biocLite(“clusterProfiler”)<br />
biocLite(“DOSE”)<br />
biocLite(“tibble”)<br />
library(clusterProfiler)<br />
biocLite(“topGO”)<br />
library(topGO)<br />
biocLite(“org.At.tair.db”)<br />
library(org.At.tair.db)</p>
<p>a=read.table(“diff.gene.table”, head=T, sep=“\t”)a=read.table(“diff.gene.table”, head=T, sep=“\t”)b=a[,1]<br />
keytypes(org.At.tair.db)  ## 看该数据库支持哪些基因名称类型，例如拟南芥支持AT1G01110 就是keytype=“TAIR”<br />
ego &lt;- enrichGO(gene          = b, keyType = “TAIR”,                OrgDb         = org.At.tair.db,                ont           = “CC”,                pAdjustMethod = “BH”,                pvalueCutoff  = 0.05,                qvalueCutoff  = 0.05, readable      = TRUE)<br />
barplot(ggo, drop=TRUE, showCategory=12)dotplot(ego)<br />
write.table(as.data.frame( ego@result), file=“test_CC.txt”)</p>
<h1 id="kegg-over-representation-testkk-enrichkegggene-b-organism-ath-pvaluecutoff-005"><a class="markdownIt-Anchor" href="#kegg-over-representation-testkk-enrichkegggene-b-organism-ath-pvaluecutoff-005"></a> KEGG over-representation testkk &lt;- enrichKEGG(gene         = b,                 organism     = ‘ath’,                 pvalueCutoff = 0.05)</h1>
<p>write.table(as.data.frame(kk@result), file=“test_kk.txt”)</p>
<h1 id="kegg-gene-set-enrichment-analysiskk2-gsekegggenelist-b-organism-ath-nperm-1000-mingssize-120-pvaluecutoff-005-verbose-falseheadkk2"><a class="markdownIt-Anchor" href="#kegg-gene-set-enrichment-analysiskk2-gsekegggenelist-b-organism-ath-nperm-1000-mingssize-120-pvaluecutoff-005-verbose-falseheadkk2"></a> KEGG Gene Set Enrichment Analysiskk2 &lt;- gseKEGG(geneList     = b,               organism     = ‘ath’,               nPerm        = 1000,               minGSSize    = 120,               pvalueCutoff = 0.05,               verbose      = FALSE)head(kk2)</h1>
<p>mkk &lt;- enrichMKEGG(gene = b,                   organism = ‘ath’)</p>
</blockquote>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>How to use DESeq2 to analyse RNAseq data</title>
    <url>/2016/03/01/Bioinfo-how-to-use-deseq2-to-analyse-rnaseq-data/</url>
    <content><![CDATA[<h1 id="how-to-use-deseq2-to-analyse-rnaseq-data"><a class="markdownIt-Anchor" href="#how-to-use-deseq2-to-analyse-rnaseq-data"></a> How to use DESeq2 to analyse RNAseq data</h1>
<p>（<a href="http://dwheelerau.com/2014/02/17/how-to-use-deseq2-to-analyse-rnaseq-data/%EF%BC%89">http://dwheelerau.com/2014/02/17/how-to-use-deseq2-to-analyse-rnaseq-data/）</a></p>
<p>Posted on <a href="http://dwheelerau.com/2014/02/17/how-to-use-deseq2-to-analyse-rnaseq-data/" title="8:29 pm">February 17, 2014</a></p>
<p><strong>News:</strong> <em>My colleagues at NZGL have developed an open source R based GUI for generating plots using cuffdiff data. One for deseq2 will be available soon! Feel free to<a href="https://github.com/NZGL/shiny_cuffdiff">check it out</a> and get back to us with any <a href="https://github.com/NZGL/shiny_cuffdiff/issues">suggestions</a></em>. <em>Only requires <a href="https://github.com/NZGL/shiny_cuffdiff">R-studio</a></em>. There is only one thing better than DESeq and thats DESeq2! The <a href="http://www.bioconductor.org/packages/2.13/bioc/html/DESeq2.html">updated version</a> is out and I’m keen to give it a whirl. Like with my old <a href="http://dwheelerau.com/2013/04/15/how-to-use-deseq-to-analyse-rnaseq-data/">DESeq post</a>, once again I am really just following the excellent <a href="http://www.bioconductor.org/packages/2.13/bioc/vignettes/DESeq2/inst/doc/DESeq2.pdf">DESeq2 manual</a>, thanks again to the authors for the great documentation! Just a quick warning that I haven’t tested this workflow extensively, let me know if things don’t work. Also, DESeq2 is new so some of the function might have changed, so if you have problems makes sure you check what version you are using versus what I used (see sessionInfo below). The files I used for this are found <a href="https://drive.google.com/file/d/0B6eVTdUN1IlwdnNiMkpvV1FWMUk/edit?usp=sharing">here</a> if you want to give them a go or follow along. I’ve already got a <a href="http://dwheelerau.com/2013/04/15/how-to-use-deseq-to-analyse-rnaseq-data/">blow by blow run through on how to do use DESeq</a> and much of that applies to the new package, so here I’ll just concentrate on some DESeq2 specific stuff as well as all the graphs. I’ve included some side by side comparisons between DESeq and DESeq2. Installing is easy:</p>
<p>1</p>
<p>2</p>
<p><code>source``(``'[http://bioconductor.org/biocLite.R](http://bioconductor.org/biocLite.R)'``)</code></p>
<p><code>biocLite``(``'DESeq2'``)</code></p>
<p>One important change is that now you can directly create the count table using raw <a href="http://www-huber.embl.de/users/anders/HTSeq/doc/count.html">HT-Seq-count</a> output, and I’ll show you how to do that below. Remember HT-Seq-count will create a single file for each replicate of a condition (based on an SAM alignment file), so in my case with two conditions (control and treatment) and 3 reps each, that makes a total of 6 files. I called these files treated1.txt, treated2.txt, treated3.txt, untreated1 untreated2, untreated3 so that i can use grep to import them (explained below). Previously i would use a script to merge them all together, now DESeq2 allows you to import these files directory. Below I set the directory where the files are located; use grep to catch all these files based on the string match “treated” that they all share (be carefully it doesn’t catch anything else), this is stored in sampleFiles. If you like you could just directly specify the files using “sampleFiles&lt;-c(“treated1.txt”,…etc…”untreated3.txt”). Importantly, we need to setup the sampleConditions, with the same order as that found for the file names in sampleFiles (so it knows what each files represents). Finally we make a dataframe that becomes a deseq table. Note my “#” lines are just nonfunctional comment lines that I am using to print out the output from the screen!</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p>22</p>
<p>23</p>
<p>24</p>
<p>25</p>
<p>26</p>
<p>27</p>
<p>28</p>
<p>29</p>
<p>30</p>
<p>31</p>
<p>32</p>
<p>33</p>
<p>34</p>
<p>35</p>
<p><code>library``(``'DESeq2'``)</code></p>
<p><code>directory&lt;-``'/home/dwheeler/Desktop/BLOG/Dec_post2'</code></p>
<p><code>#use grep to search for the 'treated' part of filename to collect files</code></p>
<p><code>sampleFiles&lt;-``grep``(``'treated'``,``list.files``(directory),value=``TRUE``)</code></p>
<p><code># sampleFiles</code></p>
<p><code>#[1] 'treated1.txt'   'treated2.txt' 'treated3.txt'  'untreated1.txt'</code></p>
<p><code>#[5] 'untreated2.txt' 'untreated3.txt'</code></p>
<p><code>sampleCondition&lt;-``c``(``'treated'``,``'treated'``,``'treated'``,``'untreated'``,``'untreated'``,``'untreated'``)</code></p>
<p><code>sampleTable&lt;-``data.frame``(sampleName=sampleFiles, fileName=sampleFiles, condition=sampleCondition)</code></p>
<p><code>####</code></p>
<p><code>#sampleTable</code></p>
<p><code>#     sampleName       fileName condition</code></p>
<p><code>#1   treated1.txt   treated1.txt   treated</code></p>
<p><code>#2   treated2.txt   treated2.txt   treated</code></p>
<p><code>#3   treated3.txt   treated3.txt   treated</code></p>
<p><code>#4 untreated1.txt untreated1.txt untreated</code></p>
<p><code>#5 untreated2.txt untreated2.txt untreated</code></p>
<p><code>#6 untreated3.txt untreated3.txt untreated</code></p>
<p><code>######</code></p>
<p><code>ddsHTSeq&lt;-``DESeqDataSetFromHTSeqCount``(sampleTable=sampleTable, directory=directory, design=~condition)</code></p>
<p><code>#####</code></p>
<p><code>#ddsHTSeq</code></p>
<p><code>#class: DESeqDataSet</code></p>
<p><code>#dim: 7921 6</code></p>
<p><code>#exptData(0):</code></p>
<p><code>#assays(1): counts</code></p>
<p><code>#rownames(7921): seq_1 seq_2 ... seq_7920 seq_7921</code></p>
<p><code>#rowData metadata column names(0):</code></p>
<p><code>#colnames(6): treated1.txt treated2.txt ... untreated2.txt</code></p>
<p><code>#  untreated3.txt</code></p>
<p><code>#colData names(1): condition</code></p>
<p><code>#######</code></p>
<p><code>colData``(ddsHTSeq)$condition&lt;-``factor``(``colData``(ddsHTSeq)$condition, levels=``c``(``'untreated'``,``'treated'``))</code></p>
<p>The levels in colData are important because they are used in the log calculations; it makes sense to set untreated or control first so that the direction of the logs fold changes doesn’t confuse everyone (typically we do comparisons to the control)! Now for the guts of the DEseq2 analysis.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p><code>dds&lt;-``DESeq``(ddsHTSeq)</code></p>
<p><code>res&lt;-``results``(dds)</code></p>
<p><code>res&lt;-res[``order``(res$padj),]</code></p>
<p><code>head``(res)</code></p>
<p><code>#DataFrame with 6 rows and 6 columns</code></p>
<p><code>#          baseMean log2FoldChange      lfcSE      stat       pvalue</code></p>
<p><code>#</code></p>
<p><code>#seq_3146  997.5419      0.7894523 0.08297687  9.514125 1.832488e-21</code></p>
<p><code>#seq_1802  746.3972      0.5685789 0.08533961  6.662544 2.691282e-11</code></p>
<p><code>#seq_2146  406.1395      0.9424543 0.14108613  6.679993 2.389544e-11</code></p>
<p><code>#seq_7548  466.5453      0.6036683 0.10178158  5.931017 3.010637e-09</code></p>
<p><code>#seq_3240 1569.6556      0.6132326 0.11145966  5.501835 3.758596e-08</code></p>
<p><code>#seq_958   149.6504      0.7398193 0.14154162  5.226868 1.724055e-07</code></p>
<p><code>#                 padj</code></p>
<p><code>#</code></p>
<p><code>#seq_3146 1.299050e-17</code></p>
<p><code>#seq_1802 6.359498e-08</code></p>
<p><code>#seq_2146 6.359498e-08</code></p>
<p><code>#seq_7548 5.335601e-06</code></p>
<p><code>#seq_3240 5.328937e-05</code></p>
<p><code>#seq_958  2.036971e-04</code></p>
<p>Looking good, time for some plots. BTW I’m using the same dataset I used for the original DESeq blog post (links to data and that blog at top of page).</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p><code>plotMA``(dds,ylim=``c``(-2,2),main=``'DESeq2'``)</code></p>
<p><code>dev.copy``(png,``'deseq2_MAplot.png'``)</code></p>
<p><code>dev.off``()</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/deseq1_deseq2_maplot2.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/deseq1_deseq2_maplot2.png?w=584&amp;h=297" alt="MAPlot of DESeq1 (left) and DESeq2  (right) for the same data" /></a> As expected for this dataset there are not many differentially expressed genes (red). There certainly is a difference in the level of scatter with this dataset using DESeq and DESeq2. Also note that there is good reduction in scatter for low count reads (left hand side of the graph) in DESeq2 versus the original version. DESeq tends to be a conservative approach, I like that, and with that in mind the update uses a test called cooks distance to remove outliers from the analysis. <a href="http://en.wikipedia.org/wiki/Cook's_distance">Cooks distance</a> looks to see how much each sample contributes to a genes overall value fold change, with samples that cause extreme effects removed. To be specific, the gene will not be analysed for differential expression if one of its samples is considered an outlier. The idea being here that we want to see only DE genes that show a consistent pattern. The draw back of this approach is that there is a loss of power, as some genes that are truly DE will be removed before the statistical tests are performed. We can save the table, and also print out some information on what the columns mean.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p><code>mcols``(res,use.names=``TRUE``)</code></p>
<p><code>#DataFrame with 6 rows and 2 columns</code></p>
<p><code>#                       type</code></p>
<p><code>#baseMean       intermediate</code></p>
<p><code>#log2FoldChange      results</code></p>
<p><code>#lfcSE               results</code></p>
<p><code>#stat                results</code></p>
<p><code>#pvalue              results</code></p>
<p><code>#padj                results</code></p>
<p><code>#description</code></p>
<p><code>#baseMean                        the base mean over all rows</code></p>
<p><code>#log2FoldChange log2 fold change (MAP): condition treated vs untreated</code></p>
<p><code>#lfcSE           standard error: condition treated vs untreated</code></p>
<p><code>#stat            Wald statistic: condition treated vs untreated</code></p>
<p><code>#pvalue          Wald test p-value: condition treated vs untreated</code></p>
<p><code>#padj            BH adjusted p-values</code></p>
<p><code>#write the table to a csv file</code></p>
<p><code>write.csv``(``as.data.frame``(res),file=``'sim_condition_treated_results_deseq2.csv'``)</code></p>
<p>BTW take this with a pinch of salt because its only a simple sample dataset, but the difference in gene counts is that deseq only found a single differentially expressed gene (at padj 0.1), whilst deseq2 called this same gene plus 23 others.  Also, reducing the cut-off multiple testing correction to 0.05 only removes 3 genes from the list with DESeq2. Now we want to transform the raw discretely distributed counts so that we can do clustering.</p>
<p>1</p>
<p>2</p>
<p><code>rld&lt;-</code> <code>rlogTransformation``(dds, blind=``TRUE``)</code></p>
<p><code>vsd&lt;-``varianceStabilizingTransformation``(dds, blind=``TRUE``)</code></p>
<p>Here we choose blind so that the initial conditions setting does not influence the outcome, ie we want to see if the conditions cluster based purely on the individual datasets, in an unbiased way. According to the documentation, the rlogTransformation method that converts counts to log2 values is apparently better than the old varienceStabilisation method when the data size factors vary by large amounts. The code and plot below shows the [nice] effect of the transformation.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p><code>par``(mai=``ifelse``(1:4 &lt;= 2,</code> <code>par``(``'mai'``), 0))</code></p>
<p><code>px     &lt;-</code> <code>counts``(dds)[,1] /</code> <code>sizeFactors``(dds)[1]</code></p>
<p><code>ord    &lt;-</code> <code>order``(px)</code></p>
<p><code>ord    &lt;- ord[px[ord]&lt;150]</code></p>
<p><code>ord    &lt;- ord[``seq``(1,</code> <code>length``(ord), length=50)]</code></p>
<p><code>last   &lt;- ord[``length``(ord)]</code></p>
<p><code>vstcol &lt;-</code> <code>c``(``'blue'``,</code> <code>'black'``)</code></p>
<p><code>matplot``(px[ord],</code> <code>cbind``(``assay``(vsd)[, 1],</code> <code>log2``(px))[ord, ], type=l, lty=1, col=vstcol, xlab=``'n'``, ylab=``'f(n)'``)</code></p>
<p><code>legend``(``'bottomright'``, legend =</code> <code>c``(``expression``(``'variance stabilizing transformation'``),</code> <code>expression``(log[2](n/s[1]))), fill=vstcol)</code></p>
<p><code>dev.copy``(png,``'DESeq2_VST_and_log2.png'``)</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/deseq2_vst_and_log21.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/deseq2_vst_and_log21.png?w=300&amp;h=300" alt="Graph showing variance stabilizing transformation for sample 1 (blue) and of the transformation f (n) = log2 (n/s1 ) (black)" /></a> The x axis is the square root of variance over the mean for all samples, so this will naturally included variance due to the treatment. The goal here is to flattern the curve so that there is consistent variance across the read counts, and that is what we got.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p><code>library``(``'vsn'``)</code></p>
<p><code>par``(mfrow=``c``(1,3))</code></p>
<p><code>notAllZero &lt;- (``rowSums``(``counts``(dds))&gt;0)</code></p>
<p><code>meanSdPlot``(``log2``(``counts``(dds,normalized=``TRUE``)[notAllZero,] + 1), ylim =</code> <code>c``(0,2.5))</code></p>
<p><code>meanSdPlot``(``assay``(rld[notAllZero,]), ylim =</code> <code>c``(0,2.5))</code></p>
<p><code>meanSdPlot``(``assay``(vsd[notAllZero,]), ylim =</code> <code>c``(0,2.5))</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/deseq2_stabilizing_comp1.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/deseq2_stabilizing_comp1.png?w=584" alt="deseq2_stabilizing_comp" /></a> This interesting plot shows the standard deviation across all samples against the mean counts using three different methods of transformation. With this data you can see that the shifted logarithm method (left) seems to do pretty badly at for low count genes, with both regularized log (center) and DESeqs variance stabilisation (right) doing a much better job across the entire dynamic range of counts. For some reason, everyone loves a good heat map!</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p><code>library``(``'RColorBrewer'``)</code></p>
<p><code>library``(``'gplots'``)</code></p>
<p><code>select &lt;-</code> <code>order``(``rowMeans``(``counts``(dds,normalized=``TRUE``)),decreasing=``TRUE``)[1:30]</code></p>
<p><code>hmcol&lt;-</code> <code>colorRampPalette``(``brewer.pal``(9,</code> <code>'GnBu'``))(100)</code></p>
<p><code>heatmap.2``(``counts``(dds,normalized=``TRUE``)[select,], col = hmcol,</code></p>
<p><code>Rowv =</code> <code>FALSE``, Colv =</code> <code>FALSE``, scale=``'none'``,</code></p>
<p><code>dendrogram=``'none'``, trace=``'none'``, margin=``c``(10,6))</code></p>
<p><code>dev.copy``(png,``'DESeq2_heatmap1'``)</code></p>
<p><code>dev.off``()</code></p>
<p><code>heatmap.2``(``assay``(rld)[select,], col = hmcol,</code></p>
<p><code>Rowv =</code> <code>FALSE``, Colv =</code> <code>FALSE``, scale=``'none'``,</code></p>
<p><code>dendrogram=``'none'``, trace=``'none'``, margin=``c``(10, 6))</code></p>
<p><code>dev.copy``(png,``'DESeq2_heatmap2'``)</code></p>
<p><code>dev.off``()</code></p>
<p><code>heatmap.2``(``assay``(vsd)[select,], col = hmcol,</code></p>
<p><code>Rowv =</code> <code>FALSE``, Colv =</code> <code>FALSE``, scale=``'none'``,</code></p>
<p><code>dendrogram=``'none'``, trace=``'none'``, margin=``c``(10, 6))</code></p>
<p><code>dev.copy``(png,``'DESeq2_heatmap3'``)</code></p>
<p><code>dev.off``()</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/deseq2_heatmaps.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/deseq2_heatmaps.png?w=584&amp;h=261" alt="heatmaps" /></a> The above shows heatmaps for 30 most highly expressed genes (not necessarily the biggest fold change). The data is of raw counts (left), regularized log transformation (center) and from variance stabilizing transformation (right) and you can clearly see the effect of the transformation has by shrinking the variance so that we don’t get the squish effect shown in the left hand graph. Now we calculate sample to sample distances so we can make a dendrogram to look at the clustering of samples.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p><code>distsRL &lt;-</code> <code>dist``(``t``(``assay``(rld)))</code></p>
<p><code>mat&lt;-</code> <code>as.matrix``(distsRL)</code></p>
<p><code>rownames``(mat) &lt;-</code> <code>colnames``(mat) &lt;-</code> <code>with``(``colData``(dds),</code></p>
<p><code>paste``(condition,sampleFiles , sep=``' : '``))</code></p>
<p><code>#updated in latest vignette (See comment by Michael Love)</code></p>
<p><code>#this line was incorrect</code></p>
<p><code>#heatmap.2(mat, trace='none', col = rev(hmcol), margin=c(16, 16))</code></p>
<p><code>#From the Apr 2015 vignette</code></p>
<p><code>hc &lt;-</code> <code>hclust``(distsRL)</code></p>
<p><code>heatmap.2``(mat, Rowv=``as.dendrogram``(hc),</code></p>
<p><code>symm=``TRUE``, trace=``'none'``,</code></p>
<p><code>col =</code> <code>rev``(hmcol), margin=``c``(13, 13))</code></p>
<p><code>dev.copy``(png,``'deseq2_heatmaps_samplebysample.png'``)</code></p>
<p><code>dev.off``()</code></p>
<p><a href="https://dwheelerau.files.wordpress.com/2014/02/dist_matrix.png"><img src="http://dwheelerau.files.wordpress.com/2014/02/dist_matrix.png?w=584" alt="dist_matrix" /></a> Although this result looks terrible, as we would expect samples to cluster by treatment, in this case I’m actually happy by this result. Why? Well this was actually a control experiment to show that slightly different (and unavoidable) experimental setup for the different samples, wasn’t responsible for the observed expression differences, so seeing that there is little treatment effect makes me happy. Remember, always <em>try</em> and do what Fisher tells us to, <a href="http://en.wikipedia.org/wiki/Design_of_experiments">replicate, randomised, block</a>. Similarly the pca.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p><code>print``(``plotPCA``(rld, intgroup=``c``(``'condition'``)))</code></p>
<p><code>dev.copy``(png,``'deseq2_pca.png'``)</code></p>
<p><code>dev.off``()</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/deseq2_pca.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/deseq2_pca.png?w=300&amp;h=247" alt="deseq2_pca" /></a> I hope your’s looks better! Previously we talked about the cooks distance treatment of outliers, in that a gene is thrown away if one of its samples is deemed to be an outlier. You may not want this to happen so DESeq2 we can take a different approach by replacing the outlier value with one estimated value as predicted by the distribution using the <a href="http://en.wikipedia.org/wiki/Truncated_mean">trimmed mean</a> approach. DESeq2 recomends you only do this if you have several replicates per treatment, and indeed it automatically uses this feature if you have 7 or more replicates in your datatable.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p><code>ddsClean &lt;-</code> <code>replaceOutliersWithTrimmedMean``(dds)</code></p>
<p><code>ddsClean &lt;-</code> <code>DESeq``(ddsClean)</code></p>
<p><code>tab &lt;-</code> <code>table``(initial =</code> <code>results``(dds)$padj &lt; .1,</code></p>
<p><code>cleaned =</code> <code>results``(ddsClean)$padj &lt; .1)</code></p>
<p><code>addmargins``(tab)</code></p>
<p><code>write.csv``(``as.data.frame``(tab),file=``'sim_condition_treated_results_cleaned_summary_deseq2.csv'``)</code></p>
<p><code>resClean &lt;-</code> <code>results``(ddsClean)</code></p>
<p><code>write.csv``(``as.data.frame``(resClean),file=``'sim_condition_treated_results_cleaned_deseq2.csv'``)</code></p>
<p>In my case it didn’t really make much difference. Dispersion plot shows how the estimates are shrunk from the gene wise values (black dots) toward the fitted estimates, with the final values used in testing being the blue dots.</p>
<p>1</p>
<p><code>plotDispEsts``(dds)</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/deseq2_dispersion_plot.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/deseq2_dispersion_plot.png?w=584" alt="Dispersion plots deseq and deseq2 (right)" /></a> and compared DESeq1 and 2. <a href="http://dwheelerau.files.wordpress.com/2013/12/dispersion_estimages.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/dispersion_estimages.png?w=584&amp;h=437" alt="dispersion plots Deseq1 Left and right deseq2" /></a> Now independent filtering to remove any tests that have little chance of pass to reduce the number of tests we have to perform, thus reducing the effects of multiple testing error. (false discovery). You can see how many genes are rejected based on different values of alpha (FDR)</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p><code>#filtering threashold</code></p>
<p><code>attr``(res,``'filterThreshold'``)</code></p>
<p><code>#     10%</code></p>
<p><code>#91.48005</code></p>
<p><code>plot``(``attr``(res,``'filterNumRej'``),type=``'b'``, ylab=``'number of rejections'``)</code></p>
<p><code>dev.copy``(png,``'deseq2_filtering_treshold.png'``)</code></p>
<p><code>dev.off``()</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/deseq2_filtering-threashold_ed.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/deseq2_filtering-threashold_ed.png?w=584" alt="deseq2_filtering threashold_Ed" /></a></p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p><code>W &lt;- res$stat</code></p>
<p><code>maxCooks &lt;-</code> <code>apply``(``assays``(dds)[[``'cooks'``]],1,max)</code></p>
<p><code>idx &lt;- !``is.na``(W)</code></p>
<p><code>plot``(``rank``(W[idx]), maxCooks[idx], xlab=``'rank of Wald statistic'``,</code></p>
<p><code>ylab=``'maximum Cook'``s distance per gene',</code></p>
<p><code>ylim=``c``(0,5), cex=.4, col=``rgb``(0,0,0,.3))</code></p>
<p><code>m &lt;-</code> <code>ncol``(dds)</code></p>
<p><code>p &lt;- 3</code></p>
<p><code>abline``(h=``qf``(.99, p, m - p))</code></p>
<p><code>dev.copy``(png,``'deseq2_cooksdist.png'``)</code></p>
<p><code>dev.off``()</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/cooks-distance.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/cooks-distance.png?w=300&amp;h=270" alt="cooks distance" /></a> Plot of the maximum Cook’s distance per gene over the rank of the Wald statistics for the condition. Here more about independent filtering. What it shows in genes with very low counts are unlikely to have a significant p-value due to excessive dispersion at the left side of the dynamic range of counts. The y-axis here is -log10, so bigger numbers are smaller p-values (better).</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p><code>plot``(res$baseMean+1, -``log10``(res$pvalue),</code></p>
<p><code>log=``'x'``, xlab=``'mean of normalized counts'``,</code></p>
<p><code>ylab=``expression``(-log[10](pvalue)),</code></p>
<p><code>ylim=``c``(0,30),</code></p>
<p><code>cex=.4, col=``rgb``(0,0,0,.3))</code></p>
<p><code>dev.copy``(png,``'deseq2_indep_filt.png'``)</code></p>
<p><code>dev.off``()</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/deseq2_indep_filtering.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/deseq2_indep_filtering.png?w=300&amp;h=270" alt="deseq2_indep_filtering" /></a> All those dots on the left hand side the graph represent failed tests due to very low count values, thus we can really just get rid of them to reduce our chance of making a type I error. And again, you can see that only a few small (or no) p-values are discarded by the filtering. NOTE: You might only see blue lines [I’ve broken something??]</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p><code>use &lt;- res$baseMean &gt;</code> <code>attr``(res,``'filterThreshold'``)</code></p>
<p><code>table``(use)</code></p>
<p><code>h1 &lt;-</code> <code>hist``(res$pvalue[!use], breaks=0:50/50, plot=``FALSE``)</code></p>
<p><code>h2 &lt;-</code> <code>hist``(res$pvalue[use], breaks=0:50/50, plot=``FALSE``)</code></p>
<p><code>colori &lt;-</code> <code>c``(``'do not pass'``=``'khaki'``,</code> <code>'pass'``=``'powderblue'``)</code></p>
<p><code>barplot``(height =</code> <code>rbind``(h1$counts, h2$counts), beside =</code> <code>FALSE``,</code></p>
<p><code>col = colori, space = 0, main =</code> <code>''``, ylab=``'frequency'``)</code></p>
<p><code>text``(x =</code> <code>c``(0,</code> <code>length``(h1$counts)), y = 0, label =</code> <code>paste``(``c``(0,1)),</code></p>
<p><code>adj =</code> <code>c``(0.5,1.7), xpd=``NA``)</code></p>
<p><code>legend``(``'topright'``, fill=``rev``(colori), legend=``rev``(``names``(colori)))</code></p>
<p><a href="http://dwheelerau.files.wordpress.com/2013/12/deseq2-pvals-and-mulittest.png"><img src="http://dwheelerau.files.wordpress.com/2013/12/deseq2-pvals-and-mulittest.png?w=584&amp;h=282" alt="deseq2 pvals and mulittest" /></a> The graph on the left ranks the p-values from smallest to biggest (x-axis) and plots them. The black line is the actual p-value numbers (remember only about 23 genes had a p-value lower than 0.05). The red line has a slope that represents the number of tests divided by the false discovery rate (0.1). The idea here is the FDR is controlled at the 0.1% value for all tests that occur to the left of the right-most intersection of the black and red line. The code for the right hand plot above.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p><code>resFilt &lt;- res[use &amp; !``is.na``(res$pvalue),]</code></p>
<p><code>orderInPlot &lt;-</code> <code>order``(resFilt$pvalue)</code></p>
<p><code>showInPlot &lt;- (resFilt$pvalue[orderInPlot] &lt;= 0.08)</code></p>
<p><code>alpha &lt;- 0.1</code></p>
<p><code>plot``(``seq``(along=``which``(showInPlot)), resFilt$pvalue[orderInPlot][showInPlot],</code></p>
<p><code>pch=``'.'``, xlab =</code> <code>expression``(``rank``(p[i])), ylab=``expression``(p[i]))</code></p>
<p><code>abline``(a=0, b=alpha/``length``(resFilt$pvalue), col=``'red3'``, lwd=2)</code></p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p>22</p>
<p>23</p>
<p>24</p>
<p>25</p>
<p>26</p>
<p>27</p>
<p>28</p>
<p>29</p>
<p>30</p>
<p>31</p>
<p>32</p>
<p>33</p>
<p><code>sessionInfo``()</code></p>
<p><code>R version</code> <code>3.0.2</code> <code>(2013-09-25)</code></p>
<p><code>Platform: x86_64-pc-linux-``gnu</code> <code>(64-bit)</code></p>
<p><code>locale:</code></p>
<p><code>[1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C</code></p>
<p><code>[3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8</code></p>
<p><code>[5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8</code></p>
<p><code>[7] LC_PAPER=en_US.UTF-8 LC_NAME=C</code></p>
<p><code>[9] LC_ADDRESS=C LC_TELEPHONE=C</code></p>
<p><code>[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C</code></p>
<p><code>attached base packages:</code></p>
<p><code>[1] parallel stats graphics grDevices utils datasets methods</code></p>
<p><code>[8] base</code></p>
<p><code>other attached packages:</code></p>
<p><code>[1] gplots_2.12.1 RColorBrewer_1.0-5 BiocInstaller_1.12.0</code></p>
<p><code>[4] DESeq2_1.2.8 RcppArmadillo_0.3.920.3 Rcpp_0.10.6</code></p>
<p><code>[7] GenomicRanges_1.14.3 XVector_0.2.0 IRanges_1.20.6</code></p>
<p><code>[10] BiocGenerics_0.8.0</code></p>
<p><code>loaded via a</code> <code>namespace</code> <code>(and not attached):</code></p>
<p><code>[1] affy_1.40.0 affyio_1.30.0 annotate_1.40.0</code></p>
<p><code>[4] AnnotationDbi_1.24.0 Biobase_2.22.0 bitops_1.0-6</code></p>
<p><code>[7] caTools_1.16 DBI_0.2-7 DESeq_1.14.0</code></p>
<p><code>[10] gdata_2.13.2 genefilter_1.44.0 geneplotter_1.40.0</code></p>
<p><code>[13] grid_3.0.2 gtools_3.1.1 KernSmooth_2.23-10</code></p>
<p><code>[16] lattice_0.20-24 limma_3.18.5 locfit_1.5-9.1</code></p>
<p><code>[19] preprocessCore_1.24.0 RSQLite_0.11.4 splines_3.0.2</code></p>
<p><code>[22] stats4_3.0.2 survival_2.37-4 tools_3.0.2</code></p>
<p><code>[25] vsn_3.30.0 XML_3.98-1.1 xtable_1.7-1</code></p>
<p><code>[28] zlibb</code></p>
<p>[Updated July ’14: to fix errors with distance matrix plot, cooks distance, and the Benjamini-Hochberg multiple testing adjustment procedure (props to Stefan for pointing them out]</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Infernal和hmmer程序的安装</title>
    <url>/2017/08/07/Bioinfo-infernal-and-hmmer-installation/</url>
    <content><![CDATA[<p>再Rfam数据库对small RNA进行注释的过程中需要用到Infernal，但是安装遇到问题。configure之后，make不成功，报错“fatal error: config.h: No such file”，下面是解决方案。 hmmer就是一款比对软件，类似于blast等，它使用马尔可夫概率模型的方法。HMMER的目的是更准确的探测到远程同源序列，它提供的比对结果要比blast更加精确，相应的速度也要慢。在功能基因研究中需要使用到序列搜索，比如从序列数据库中，找同源的序列，或者对一个新的基因功能进行鉴定，使用hmmer比使用blast有着更高的灵敏度以及更高的搜索速度，但其应用还远没有blast普及。 hmmer安装的参考资料是：</p>
<p>curl -O <a href="ftp://selab.janelia.org/pub/software/hmmer3/3.1b1/hmmer%5C-3.1b1.tar.gz">ftp://selab.janelia.org/pub/software/hmmer3/3.1b1/hmmer\-3.1b1.tar.gz</a><br />
tar xzf hmmer-3.1b1.tar.gz<br />
cd hmmer-3.1b1/<br />
./configure --prefix=/usr &amp;&amp; make &amp;&amp; make install</p>
<p>但是我安装过程中报错：</p>
<p>make[2]: Entering directory ‘/home/fenglei/local/app/infernal/easel/miniapps’<br />
CC esl-afetch.o<br />
GEN esl-afetch<br />
CC esl-alimanip.o<br />
In file included from /home/fenglei/local/include/assert.h:5:0,<br />
from esl-alimanip.c:8:<br />
/home/fenglei/local/include/except.h:5:44: fatal error: config.h: No such file or directory<br />
#include  /* For HAVE_PTHREAD */<br />
^<br />
compilation terminated.<br />
make[2]: *** [Makefile:123: esl-alimanip.o] Error 1<br />
make[2]: Leaving directory ‘/home/fenglei/local/app/infernal/easel/miniapps’<br />
make[1]: *** [Makefile:377: all] Error 2<br />
make[1]: Leaving directory ‘/home/fenglei/local/app/infernal/easel’<br />
make: *** [Makefile:103: all] Error 2</p>
<p>原因： 现在较新的内核已经弃用了config.h，把这个文件新建上去即可。 解决办法：执行命令（注意路径的不同）：</p>
<p>cd easel<br />
vi config.h</p>
<p>在vi界面输入下述内容，随后保存退出。</p>
<p>#ifndef _LINUX_CONFIG_H<br />
 #define _LINUX_CONFIG_H<br />
 #endif</p>
<p>随后成功安装。</p>
<p>make &amp;&amp; make install</p>
<p>参考资料 <a href="http://2013-caltech-workshop.readthedocs.io/en/latest/prokka-annotation.html">http://2013-caltech-workshop.readthedocs.io/en/latest/prokka-annotation.html</a> <a href="https://lzw.me/a/linux-config-no-such-file-or-directory.html/comment-page-1#comment-80998">https://lzw.me/a/linux-config-no-such-file-or-directory.html/comment-page-1#comment-80998</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>安装LASTZ</title>
    <url>/2019/02/28/Bioinfo-install-lastz/</url>
    <content><![CDATA[<p>LASTZ是序列比对工具，可以生成AXT格式的比对文件。 安装LASTZ方法如下 下载地址：<a href="http://www.bx.psu.edu/~rsharris/lastz/">http://www.bx.psu.edu/~rsharris/lastz/</a> If you have received the distribution as a packed archive, unpack it by whatever means are appropriate for your computer. The result should be a directory <code>/lastz‑distrib‑X.XX.XX</code> that contains a <code>src</code> subdirectory (and some others). You may find it convenient to remove the revision number (<code>‑X.XX.XX</code>) from the directory name. Before building or installing any of the programs, you will need to tell the installer where to put the executable, either by setting the shell variable<code>$LASTZ_INSTALL</code>, or by editing the <code>make‑include.mak</code> file to set the definition of <code>installDir</code>. Also, be sure to add the directory you choose to your <code>$PATH</code>. Then to build the LASTZ executable, enter the following commands from bash or a similar command-line shell (Solaris users should substitute <code>gmake</code> for <code>make</code>). This will build two executables (<code>lastz</code> and <code>lastz_D</code>) and copy them into your <code>installDir</code>.</p>
<pre><code>cd /lastz-distrib-X.XX.XX/src
make
make install
</code></pre>
<p>The two executables are basically the same program; the only difference is that <code>lastz</code> uses integer scores, while <code>lastz_D</code> uses floating-point scores. The build process should not report any warnings or errors. Because of this, the Makefile is set up so that warnings are considered errors and will stop the build. If you encounter this situation, you can modify the Makefile, removing “-Werror” from the variable definedForAll. This should allow the build to complete, while still reporting the warnings. You’ll need to decide whether the warnings indicate something is really wrong. Usually they don’t, but please report them to the author regardless. A simple self test is included so you can test whether the build succeeded. To run it, enter the following command:</p>
<pre><code>make test
</code></pre>
<p>If the test is successful, you will see no output from this command. Otherwise, you will see the differences between the expected output and the output of your build, plus a line that looks like this:</p>
<pre><code>make: \*\*\* \[test\] Error 1
</code></pre>
<p>我在安装的过程中遇到下面的问题</p>
<p>cd src &amp;&amp; make lastz lastz_D<br />
make[1]: Entering directory ‘/home/david/src/lastz/src’<br />
gcc -c -O3 -Wall -Wextra -Werror -D_FILE_OFFSET_BITS=64 -D_LARGEFILE_SOURCE -DVERSION_MAJOR=“\“1”\” -DVERSION_MINOR=“\“04”\” -DVERSION_SUBMINOR=“\“00”\” -DREVISION_DATE=“\“20170312”\” -DSUBVERSION_REV=“\“1881:1893M”\” -Dscore_type=\‘I\’ lastz.c -o lastz.o<br />
lastz.c: In function ‘parse_options_loop’:<br />
lastz.c:6525:6: error: this ‘if’ clause does not guard… [-Werror=misleading-indentation]<br />
if (*scan != ‘.’) goto cant_understand; scan++;<br />
^~<br />
lastz.c:6525:47: note: …this statement, but the latter is misleadingly indented as if it is guarded by the ‘if’<br />
if (*scan != ‘.’) goto cant_understand; scan++;<br />
^~~~<br />
lastz.c:6585:6: error: this ‘if’ clause does not guard… [-Werror=misleading-indentation]<br />
if (*scan != ‘.’) goto cant_understand; scan++;<br />
^~<br />
lastz.c:6585:47: note: …this statement, but the latter is misleadingly indented as if it is guarded by the ‘if’<br />
if (*scan != ‘.’) goto cant_understand; scan++;<br />
^~~~<br />
lastz.c:6644:6: error: this ‘if’ clause does not guard… [-Werror=misleading-indentation]<br />
if (*scan != ‘.’) goto cant_understand; scan++;<br />
^~<br />
lastz.c:6644:47: note: …this statement, but the latter is misleadingly indented as if it is guarded by the ‘if’<br />
if (*scan != ‘.’) goto cant_understand; scan++;<br />
^~~~<br />
cc1: all warnings being treated as errors<br />
Makefile:94: recipe for target ‘lastz.o’ failed<br />
make[1]: *** [lastz.o] Error 1<br />
make[1]: Leaving directory ‘/home/david/src/lastz/src’<br />
Makefile:14: recipe for target ‘build_lastz’ failed<br />
make: *** [build_lastz] Error 2</p>
<p>解决办法 You can get around this by deleting “<em>-Werror</em>” from the CFLAGS listed in <em>definedForAll</em> in src/Makefile (overriding CFLAGS from the command line just causing new errors). 参考资料 <a href="https://github.com/lastz/lastz/issues/5">https://github.com/lastz/lastz/issues/5</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>安装vcftools</title>
    <url>/2018/01/09/Bioinfo-install-vcftools/</url>
    <content><![CDATA[<p>configure的过程报错：Zlib找不到。 实际上已经安装zlib。 解决办法</p>
<p>export ZLIB_LIBS=‘-L/home/fenglei/local/lib -lz’<br />
export ZLIB_CFLAGS=-I/home/fenglei/local/include<br />
echo $ZLIB_LIBS $ZLIB_CFLAGS<br />
./configure --prefix=/home/fenglei/local/<br />
make<br />
make install</p>
<p>成功安装。 参考资料：<a href="https://github.com/vcftools/vcftools/issues/29">https://github.com/vcftools/vcftools/issues/29</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>jcvi 安装与使用，报错以及解决办法</title>
    <url>/2021/06/03/Bioinfo-jcvi-installation/</url>
    <content><![CDATA[<p>jcvi 是 Haibao Tang 开发的基因组组装注释与比较基因组分析工具，比如可以用于可视化 synteny blocks。原理是依据物种之间基因编码序列相似性比较，如果若干个连续的基因在两个基因组之间都有出现，那这若干个基因就是一个 synteny block，可能是从祖先染色体上继承下来的，物种之间的亲缘关系越近，synteny blocks 数目越多。</p>
<p>之前<a href="https://genehub.wordpress.com/2019/07/05/mcscanx-%e6%b5%8b%e8%af%95/">测试过 MCScanX</a>，其实 jcvi 和 MCScanX 就是一回事，是同一个作者开发的，jcvi 是升级版，操作更加便利，生成的图片更加精美。回去 <a href="https://github.com/wyp1125/MCScanX#installation">MCScanX</a> 看了一下开发时间，最后更新大约是 2014 年，但是里面有的程序还是很实用的，比如可以计算共线性区块之间的基因对的 Ka/Ks value（add_kaks_to_synteny.pl）.</p>
<h3 id="安装-jcvi"><a class="markdownIt-Anchor" href="#安装-jcvi"></a> 安装 jcvi</h3>
<p>jcvi 软件推荐使用 pip 安装，也可以选择使用 conda 安装。我是 anaconda3 下面建立了 python 2.7 和 python 3.7 两个环境，分别进行了测试，最后发现 python2.7 环境下 jcvi 可以正常运行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source activate python27</span><br><span class="line">conda install -c bioconda jcvi</span><br><span class="line">conda install -c bioconda last</span><br><span class="line">conda install scipy</span><br><span class="line"># 但是运行序列比对时候报错！--&gt; 经过查询是 lastal 的问题，也就是别用 conda 安装的 last，自己去 last 网站下载源码，安装到用户目录下，然后将其bin路径写入环境变量bashrc文件，然后就可以解决比对报错的问题。</span><br></pre></td></tr></table></figure>
<h3 id="安装-lastal"><a class="markdownIt-Anchor" href="#安装-lastal"></a> 安装 lastal</h3>
<p>手动安装 last 软件，并将其路径写入环境变量。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://gitlab.com/mcfrith/last.git</span><br><span class="line">cd last</span><br><span class="line">mdke</span><br><span class="line"># then we can see lastal in ./last/bin/</span><br><span class="line"># put /PATH/TO/last/bin into ~/.bashrc</span><br><span class="line">which lastal</span><br><span class="line">(python37) [fenglei@localhost cds]$ which lastal</span><br><span class="line">~/local/app/anaconda3/envs/python37/bin/lastal</span><br><span class="line">(python37) [fenglei@localhost cds]$ source ~/.bashrc</span><br><span class="line">(base) [fenglei@localhost cds]$ which lastal</span><br><span class="line">~/local/app/last/bin/lastal</span><br></pre></td></tr></table></figure>
<p>下面开始做一个数据测试，参考：<a href="https://github.com/tanghaibao/jcvi/wiki/MCscan-(Python-version)">https://github.com/tanghaibao/jcvi/wiki/MCscan-(Python-version)</a></p>
<h3 id="基因坐标与基因序列数据准备"><a class="markdownIt-Anchor" href="#基因坐标与基因序列数据准备"></a> 基因坐标与基因序列数据准备</h3>
<p>原始数据：（1）gff3 格式的基因坐标；（2）fasta 格式的基因 CDS 序列。使用 jcvi 内置程序对这两个文件做格式整理。以大豆（Glycine max）和野生豆（Glycine soja）为例，这一步需要得到四个文件：gma.bed gma.cds gso.bed gso.cds</p>
<p>如下图所示，要注意同一个物种的 bed 文件和 cds 文件的基因 ID 要相互匹配。由于基因 ID 通常带有“.1”或“.2p”这样的后缀，需要注意，必要的时候自己写脚本处理数据。</p>
<p><img src="https://i.imgur.com/RYAdtK3.jpg" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">### BED FORMAT FILES FOR GENES</span><br><span class="line"></span><br><span class="line">python -m jcvi.formats.gff bed --type=mRNA --key=transcript_id Gmax_508_Wm82.a4.v1.gene.gff3.gz &gt; gma.bed</span><br><span class="line">11:12:31 [base] Load file `Gmax_508_Wm82.a4.v1.gene.gff3.gz`</span><br><span class="line">11:13:30 [gff] Extracted 86256 features (type=mRNA id=transcript_id)</span><br><span class="line"></span><br><span class="line">python -m jcvi.formats.gff bed --type=mRNA --key=Name Gmax_508_Wm82.a4.v1.gene.gff3.gz &gt; gma.bed2</span><br><span class="line">11:20:14 [base] Load file `Gmax_508_Wm82.a4.v1.gene.gff3.gz`</span><br><span class="line">11:21:13 [gff] Extracted 86256 features (type=mRNA id=Name)</span><br><span class="line"></span><br><span class="line">python -m jcvi.formats.gff bed --type=mRNA --key=transcript_id Gsoja.W05.gene.gff.gz &gt; gso.bed</span><br><span class="line">11:14:15 [base] Load file `Gsoja.W05.gene.gff.gz`</span><br><span class="line">11:15:31 [gff] Extracted 89477 features (type=mRNA id=transcript_id)</span><br><span class="line"></span><br><span class="line">python -m jcvi.formats.gff bed --type=mRNA --key=Name Gsoja.W05.gene.gff.gz &gt; gso.bed2             </span><br><span class="line">11:22:16 [base] Load file `Gsoja.W05.gene.gff.gz`</span><br><span class="line">11:23:32 [gff] Extracted 89477 features (type=mRNA id=Name)</span><br><span class="line"></span><br><span class="line">python -m jcvi.formats.gff bed --type=mRNA --key=ID Gsoja.W05.gene.gff.gz &gt; gso.bed3    </span><br><span class="line">11:27:42 [base] Load file `Gsoja.W05.gene.gff.gz`</span><br><span class="line">11:28:58 [gff] Extracted 89477 features (type=mRNA id=ID)</span><br><span class="line"></span><br><span class="line">### REMOVE DUPLICATIONS</span><br><span class="line"></span><br><span class="line">python -m jcvi.formats.bed uniq gma.bed2 </span><br><span class="line">11:35:34 [base] Load file `gma.bed2`</span><br><span class="line">11:35:37 [bed] Imported: 86256, Exported: 51013</span><br><span class="line"></span><br><span class="line">python -m jcvi.formats.bed uniq gso.bed3</span><br><span class="line">11:37:25 [base] Load file `gso.bed3`</span><br><span class="line">11:37:29 [bed] Imported: 89477, Exported: 55103</span><br><span class="line"></span><br><span class="line">### CDS FORMAT FILE FOR UNIQ GENES</span><br><span class="line"></span><br><span class="line">seqkit grep -f &lt;(cut -f 4 gma.uniq.bed ) Gmax_508_Wm82.a4.v1.cds.fa.gz |  seqkit seq -i &gt; gma.cds</span><br><span class="line">seqkit grep -f &lt;(cut -f 4 gso.uniq.bed ) Gsoja.W05.gene.cds.fa.gz |  seqkit seq -i &gt; gso.cds</span><br><span class="line"></span><br><span class="line">seqkit grep -f &lt;(cut -f 4 gma.uniq.bed ) Gmax_508_Wm82.a4.v1.protein.fa |  seqkit seq -i &gt; gma.pep  # ERROR due to id isuues</span><br><span class="line">seqkit grep -f &lt;(cut -f 4 gso.uniq.bed ) Gsoja.W05.gene.protein.fa.gz |  seqkit seq -i &gt; gso.pep</span><br><span class="line"></span><br><span class="line"># TROUBLESHOOTING</span><br><span class="line">awk &#x27;&#123;if($0~/&gt;/)&#123;gsub(/\.p/,&quot;&quot;,$1)&#125;; &#123;print&#125;&#125;&#x27; Gmax_508_Wm82.a4.v1.protein.fa &gt; Gmax_508_Wm82.a4.v1.protein.new.fa</span><br><span class="line">seqkit grep -f &lt;(cut -f 4 gma.uniq.bed ) Gmax_508_Wm82.a4.v1.protein.new.fa |  seqkit seq -i &gt; gma.pep</span><br></pre></td></tr></table></figure>
<h3 id="apairwise_synteny_searchsh"><a class="markdownIt-Anchor" href="#apairwise_synteny_searchsh"></a> a.pairwise_synteny_search.sh</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/local/app/anaconda3/envs/python27/bin/python -m jcvi.compara.catalog ortholog gma gso --no_strip_names</span><br></pre></td></tr></table></figure>
<p>该命令直接对物种间基因序列进行比较，将生成一个 gma.gso.pdf 文件，打开如下。</p>
<p><img src="https://i.imgur.com/Ly4FSpT.png" alt="" /></p>
<p>同时生成一堆文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-rw-rw-r-- 1 fenglei fenglei    139507 Jun  3 12:09 gma.gso.pdf</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   5333469 Jun  3 12:09 gma.gso.lifted.anchors</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   2931001 Jun  3 12:08 gma.gso.anchors</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   5953786 Jun  3 12:08 gma.gso.last.filtered</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  97488440 Jun  3 12:08 gma.gso.last</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  58121140 Jun  3 12:08 gso.bck</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei       515 Jun  3 12:08 gso.prj</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 264000792 Jun  3 12:08 gso.suf</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   1101303 Jun  3 12:07 gso.des</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei    220416 Jun  3 12:07 gso.sds</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei    220416 Jun  3 12:07 gso.ssp</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  66055302 Jun  3 12:07 gso.tis</span><br></pre></td></tr></table></figure>
<p>The <code>.last</code> file is raw LAST output, <code>.last.filtered</code> is filtered LAST output, <code>.anchors</code> is the seed synteny blocks (high quality), <code>.lifted.anchors</code> recruits additional anchors to form the final synteny blocks.</p>
<p>查看了一下 .lifted.anchors 与 .anchors 的区别，如下看到两个文件都有 551 个 synteny blocks，只是 blocks 内部的基因配对数目不同，应该就是后者有更严格的筛选条件。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python27) [fenglei@localhost gma-gso]$ cat gma.gso.lifted.anchors | grep -v &#x27;###&#x27; | wc -l</span><br><span class="line">124133</span><br><span class="line">(python27) [fenglei@localhost gma-gso]$ cat gma.gso.lifted.anchors | grep &#x27;###&#x27; | wc -l   </span><br><span class="line">551</span><br><span class="line">(python27) [fenglei@localhost gma-gso]$ cat gma.gso.anchors | grep -v &#x27;###&#x27; | wc -l        </span><br><span class="line">68549</span><br><span class="line">(python27) [fenglei@localhost gma-gso]$ cat gma.gso.anchors | grep &#x27;###&#x27; | wc -l   </span><br><span class="line">551</span><br></pre></td></tr></table></figure>
<h3 id="bdepth_visualiztionsh"><a class="markdownIt-Anchor" href="#bdepth_visualiztionsh"></a> b.depth_visualiztion.sh</h3>
<p>We could also quick test if the synteny pattern is indeed 1:1, by running:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m jcvi.compara.synteny depth --histogram gma.gso.anchors</span><br></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/BB2UsVk.jpg" alt="" /></p>
<h3 id="canchorssimple_file_generationsh"><a class="markdownIt-Anchor" href="#canchorssimple_file_generationsh"></a> c.anchors.simple_file_generation.sh</h3>
<p>This command generates a .simple file which is a more succinct form than the .anchors file.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m jcvi.compara.synteny screen --minspan=30 --simple gma.gso.anchors gma.gso.anchors.new</span><br></pre></td></tr></table></figure>
<p>将 <code>gma.gso.anchors</code> 文件转化成 <code>gma.gso.anchors.simple</code> 文件。有什么不同？见下面的文本框。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python27) [fenglei@localhost gma-gso]$ head gma.gso.anchors</span><br><span class="line">###</span><br><span class="line">Glyma.01G000100.1       Glysoja.01G000001.1     496</span><br><span class="line">Glyma.01G000322.1       Glysoja.01G000002.1     775</span><br><span class="line">Glyma.01G000400.1       Glysoja.01G000003.1     2600</span><br><span class="line">Glyma.01G001000.2       Glysoja.01G000010.2     984</span><br><span class="line">Glyma.01G001100.3       Glysoja.01G000011.2     1490</span><br><span class="line">Glyma.01G001300.3       Glysoja.01G000013.2     3560</span><br><span class="line">Glyma.01G001350.1       Glysoja.01G000014.1     381</span><br><span class="line">Glyma.01G001500.1       Glysoja.01G000015.3     2880</span><br><span class="line">Glyma.01G001700.1       Glysoja.01G000017.1     1650</span><br><span class="line">(python27) [fenglei@localhost gma-gso]$ head gma.gso.anchors.simple</span><br><span class="line">Glyma.01G000100.1       Glyma.01G245700.6       Glysoja.01G000001.1     Glysoja.01G002529.1     2354    +</span><br><span class="line">Glyma.01G023500.1       Glyma.01G044800.1       Glysoja.02G002717.1     Glysoja.02G002929.1     209     -</span><br><span class="line">Glyma.01G045100.2       Glyma.01G071700.1       Glysoja.02G003545.1     Glysoja.02G003757.1     210     +</span><br><span class="line">Glyma.01G083700.1       Glyma.01G090200.1       Glysoja.02G003470.1     Glysoja.02G003510.1     46      +</span><br><span class="line">Glyma.01G098400.6       Glyma.01G106600.2       Glysoja.03G006294.1     Glysoja.03G006391.1     76      +</span><br><span class="line">Glyma.01G125600.2       Glyma.01G145000.1       Glysoja.03G005845.1     Glysoja.03G006096.1     198     -</span><br><span class="line">Glyma.01G118000.1       Glyma.01G122800.1       Glysoja.03G006181.1     Glysoja.03G006214.2     37      +</span><br><span class="line">Glyma.01G107000.1       Glyma.01G113400.1       Glysoja.03G006412.2     Glysoja.03G006472.1     56      +</span><br><span class="line">Glyma.01G003900.1       Glyma.01G008500.1       Glysoja.05G013057.1     Glysoja.05G013097.1     40      +</span><br><span class="line">Glyma.01G001900.2       Glyma.01G007300.1       Glysoja.07G017673.1     Glysoja.07G017734.1     56      -</span><br></pre></td></tr></table></figure>
<h3 id="dmacrosynteny_visualizationsh"><a class="markdownIt-Anchor" href="#dmacrosynteny_visualizationsh"></a> d.Macrosynteny_visualization.sh</h3>
<p>准备一个 <code>seqids</code> 文件，定义哪些染色体需要展示出来。文件内容是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Gm01,Gm02,Gm03,Gm04,Gm05,Gm06,Gm07,Gm08,Gm09,Gm10,Gm11,Gm12,Gm13,Gm14,Gm15,Gm16,Gm17,Gm18,Gm19,Gm20</span><br><span class="line">Chr01,Chr02,Chr03,Chr04,Chr05,Chr06,Chr07,Chr08,Chr09,Chr10,Chr11,Chr12,Chr13,Chr14,Chr15,Chr16,Chr17,Chr18,Chr19,Chr20</span><br></pre></td></tr></table></figure>
<p>可以用 shell 代码生成上面的文件，我的命令如下。注意 seqids 内容上下行代表两个物种，跟下文出现的 layout 文件要顺序对应。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">for i in $(seq 1 20); do printf &quot;Gm&quot;%02d&quot;,&quot; $i ; done; echo </span><br><span class="line">for i in $(seq 1 20); do printf &quot;Chr&quot;%02d&quot;,&quot; $i ; done; echo</span><br></pre></td></tr></table></figure>
<p>再准备一个 <code>layout</code> 文件。定义染色体出现的位置，角度。文件内容是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># y, xstart, xend, rotation, color, label, va,  bed</span><br><span class="line"> .6,     .1,    .8,       0,      , gma, top, gma.bed</span><br><span class="line"> .4,     .1,    .8,       0,      , gso, top, gso.bed</span><br><span class="line"># edges</span><br><span class="line">e, 0, 1, gma.gso.anchors.simple</span><br></pre></td></tr></table></figure>
<h3 id="ekaryotypesh"><a class="markdownIt-Anchor" href="#ekaryotypesh"></a> <a href="http://e.karyotype.sh">e.karyotype.sh</a></h3>
<p>画图文件准备完毕，运行画图命令：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python -m jcvi.graphics.karyotype seqids layout</span><br></pre></td></tr></table></figure>
<p>将生成一个 karyotype.pdf 文件，打开如下。</p>
<p><img src="https://i.imgur.com/Bugyz9W.jpeg" alt="" /></p>
<p>以上就是两个物种间的共线性比较分析。</p>
<h3 id="同一个物种内部的-synteny-呢"><a class="markdownIt-Anchor" href="#同一个物种内部的-synteny-呢"></a> 同一个物种内部的 synteny 呢？</h3>
<p>由于大豆在近期经历了 WGD 事件，导致很多基因都有双拷贝，所以内部就有 synteny，我做了测试分析，用与上文相同的代码，得到图片如下。看来 jcvi 程序会自动滤掉基因的自我比较，而是做 paralog 的比较。</p>
<p><img src="https://i.imgur.com/9QhsL89.jpg" alt="" /></p>
<h3 id="其他案例"><a class="markdownIt-Anchor" href="#其他案例"></a> 其他案例</h3>
<p>软件的文档里面还列出了三个物种的比较、对某些 synteny 区段进行高亮、只展示特定染色体区间的方法。下面直接摘抄原作者的图片，留作参考。</p>
<p><img src="https://camo.githubusercontent.com/833e373b369f1c221132d729e1cf0128a8cd638fc04c90782ad7d5e9d30867db/68747470733a2f2f7777772e64726f70626f782e636f6d2f732f39766c337973336e6476696d6734632f67726170652d70656163682d636163616f2e706e673f7261773d31" alt="" /></p>
<p><img src="https://camo.githubusercontent.com/5b300c541bd65669e40cf15f7e496fd0a63a0a47ecb4c80a8f5641e9253c9981/68747470733a2f2f7777772e64726f70626f782e636f6d2f732f736f3274643065716b6c626b6c6e6c2f67726170652e70656163682e6b6172796f747970652d677265656e2e706e673f7261773d31" alt="" /></p>
<p><img src="https://camo.githubusercontent.com/7a878ab0e1aa1221d9c4af36a4d0f131eb43f8ddb10caea79e53366d6797cd92/68747470733a2f2f7777772e64726f70626f782e636f6d2f732f696d646f7539756b6e74743474616d2f67726170652d70656163682d636163616f2d626c6f636b732e706e673f7261773d31" alt="" /></p>
<h3 id="其他笔记"><a class="markdownIt-Anchor" href="#其他笔记"></a> 其他笔记</h3>
<p>下面是软件安装调试的一些笔记。python3.7 环境我也测试了，可以安装 jcvi，而且我发现 python3.7 的 jcvi 与 python2.7 下面的 jcvi 的屏幕输出不同。但是 pyton2.7 jcvi 运行过程中有些步骤报错（[Errno 13] Permission denied: ‘dvipng’）导致缺失一些数据结果，所以我放弃了python3.7 jcvi，转而用 python2.7 jcvi 来做分析。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">source activate python37</span><br><span class="line">conda install scipy</span><br><span class="line">conda install -c bioconda last</span><br><span class="line">conda install -c bioconda jcvi  # 这一条就报错！</span><br><span class="line"># 于是从github手动下载软件尝试</span><br><span class="line">cd ~/local/app  # or any directory of your choice</span><br><span class="line">git clone git://github.com/tanghaibao/jcvi.git</span><br><span class="line">pip install -e .</span><br><span class="line"># 安装成功。能否运行数据比对？</span><br><span class="line"># 依然不能，经查是 lastal 的问题！！！</span><br><span class="line">## lastal: I was installed here with multi-threading disabled  # 运行到lastal就报错，根本没有比对结果输出。</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create -n jcvi python=2.7</span><br><span class="line">source activate jcvi</span><br><span class="line"># 安装前需要确认存在bioconda和r channel，安装前先更新conda</span><br><span class="line"># conda --add-channel r</span><br><span class="line"># conda install jcvi last</span><br><span class="line">conda install -c bioconda last</span><br></pre></td></tr></table></figure>
<p>后续还可能会由于缺少 scipy 在绘图时报错 ImportError: No module named scipy.spatial ，因此可提<br />
前安装</p>
<p><strong>安装scipy</strong><br />
#conda-forge scipy-1.2.0<br />
conda install scipy</p>
<p><strong>问题一</strong></p>
<p>File “/biosoft/python/Python-v2.7.11/lib/python2.7/site-packages/subprocess32.py”, line 1393, in _execute_child<br />
    raise child_exception_type(errno_num, err_msg)<br />
OSError: [Errno 2] No such file or directory: ‘kpsewhich’</p>
<p>解决办法：linux中缺少kpsewhich命令导致的，于是安装该命令，CentOS系统方法如下：</p>
<p>sudo yum install tetex-latex tetex-doc tetex-fonts<br />
sudo yum install texlive tex-live-latex</p>
<p>安装好后再次运行，顺利通过。</p>
<p>我的系统是redhat，没有安yum，所以下载了textlive的源码编译，但是一直不能通过，后来重装了一个centOS系统才可以用。</p>
<p><strong>问题二</strong></p>
<p>原来在用户目录下安装了GCC-6.5.0，可以正常使用jcvi的；但是昨天升级到了GCC-9.2.0之后，今天用jcvi 画synteny图的时候遇到下面的问题。</p>
<p>ImportError: /home/fenglei/local/lib64/libstdc++.so.6: undefined symbol: libiconv</p>
<p>将libstdc++.so.6这个软连接重新指向旧版GCC对应的libstdc++.so.6.0.22，然后jcvi就没有报错了。</p>
<p><img src="https://genehub.files.wordpress.com/2019/09/e5beaee4bfa1e688aae59bbe_20190906173207.png" alt="微信截图_20190906173207" /></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>基因组|N50与N90的统计</title>
    <url>/2017/07/18/Bioinfo-n50-n90-length/</url>
    <content><![CDATA[<h3 id="背景"><a class="markdownIt-Anchor" href="#背景"></a> 背景</h3>
<p>基因组组装的过程中，N50与N90是常用的评价指标。</p>
<h3 id="方法"><a class="markdownIt-Anchor" href="#方法"></a> 方法</h3>
<p>可以使用NGS QC Toolkit实现统计。 下载地址： <a href="http://59.163.192.90:8080/ngsqctoolkit/">http://59.163.192.90:8080/ngsqctoolkit/</a> <code>perl N50Stat.pl -i in.fa -o out.stat</code> <a href="http://N50Stat.pl">N50Stat.pl</a></p>
<p>Tool to generate statistics for read/sequence data given in FASTA format (total number of reads/sequences, total bases and minimum, maximum, average, median, N25, N50, N75, N90 and N95 read/sequence length)</p>
<p>Citation Patel RK, Jain M (2012). NGS QC Toolkit: A toolkit for quality control of next generation sequencing data. PLoS ONE, 7(2): e30619.</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>PacBio测序：专有名词的定义</title>
    <url>/2016/02/25/Bioinfo-pacbio-sequencing/</url>
    <content><![CDATA[<p><a href="http://files.pacb.com/software/smrtanalysis/2.2.0/doc/smrtportal/help/!SSL!/Webhelp/Portal%5C_PacBio%5C_Glossary.htm">http://files.pacb.com/software/smrtanalysis/2.2.0/doc/smrtportal/help/!SSL!/Webhelp/Portal\_PacBio\_Glossary.htm</a></p>
<h2 id="smrt-portal-help"><a class="markdownIt-Anchor" href="#smrt-portal-help"></a> SMRT® Portal Help</h2>
<h1 id="pacific-biosciences-terminology"><a class="markdownIt-Anchor" href="#pacific-biosciences-terminology"></a> Pacific Biosciences Terminology</h1>
<h2 id="general-terminology"><a class="markdownIt-Anchor" href="#general-terminology"></a> General Terminology</h2>
<ul>
<li>SMRT® Cell: Consumable substrates comprising arrays of zero-mode waveguide nanostructures.</li>
<li>Adapters: Exogenous nucleic acids that are ligated to a nucleic acid molecule to be sequenced. For example, SMRTbell™ adapters are hairpin loops that are ligated to both ends of the double stranded DNA insert to produce a SMRTbell™ sequencing template. When adapter sequences are removed from a CCS read, the read is split into multiple subreads.</li>
<li>Movie: Real-time observation of a SMRT® Cell.</li>
<li>zero-mode waveguide (ZMW): A nanophotonic device for confining light to a small observation volume. This can be, for example, a small hole in a conductive layer whose diameter is too small to permit the propagation of light in the wavelength range used for detection. Physically part of a SMRT® Cell.</li>
<li>Sequencing ZMW: A ZMW (zero-mode waveguide) that is expected to be able to produce a sequence if it is populated with a polymerase. ZMWs used for automated SMRT Cell alignment are not considered sequencing ZMWs.</li>
<li>Run: Specifies</li>
<li>The wells and SMRT Cells to include in the sequencing run.</li>
<li>The collection and analysis protocols to use for the selected wells and cells.</li>
</ul>
<h2 id="read-terminology"><a class="markdownIt-Anchor" href="#read-terminology"></a> Read Terminology</h2>
<p><img src="http://files.pacb.com/software/smrtanalysis/2.2.0/doc/smrtportal/help/!SSL!/Webhelp/3Part_Reads_Def.png" alt="" /></p>
<ul>
<li>polymerase read (formerly called “read”): A sequence of nucleotides incorporated by the DNA polymerase while reading a template, such as a circular SMRTbell™ template. Polymerase reads are most useful for quality control of the instrument run. Polymerase read metrics primarily reflect movie length and other run parameters rather than insert size distribution. Polymerase reads are trimmed to include only the high quality region; they include sequences from adapters; and can further include sequence from multiple passes around a circular template.</li>
<li>subread: Each polymerase read is partitioned to form one or more subreads, which contain sequence from a single pass of a polymerase on a single strand of an insert within a SMRTbell™ template and no adapter sequences. The subreads contain the full set of quality values and kinetic measurements. Subreads are useful for applications like <em>de novo</em> assembly, resequencing, base modification analysis, and so on.</li>
<li>circular consensus (CCS) read: The consensus sequence determined using subreads taken from a single ZMW. This is not aligned against a reference sequence. In contrast to Reads of Insert, CCS reads require at least two full-pass subreads from the insert.</li>
<li>read of insert: Represents the highest quality single sequence for an insert, regardless of the number of passes. For example, if your template received one-and-a-half subreads, that information will be combined into a Read of Insert. CCS is an example of a special case where at least two full subreads are collected for an insert. Reads of Insert give the most accurate estimate of the length of the insert sequence loaded onto a SMRT® Cell. For long templates, Reads of Insert may be the same as Polymerase Reads.</li>
</ul>
<h2 id="read-length-terminology"><a class="markdownIt-Anchor" href="#read-length-terminology"></a> Read Length Terminology</h2>
<p><img src="http://files.pacb.com/software/smrtanalysis/2.2.0/doc/smrtportal/help/!SSL!/Webhelp/Mapped_Length.png" alt="" /></p>
<ul>
<li>mapped polymerase read length: The total number of bases along a read from the first adapter or aligned subread to the last adapter or aligned subread. Approximates the sequence produced by a polymerase in a ZMW.</li>
<li>mapped subread length: The length of the subread alignment to a target reference sequence. This does not include the adapter sequence.</li>
<li>polymerase read length: The total number of bases produced from a ZMW after trimming. This may include the adapter sequence.</li>
</ul>
<h2 id="primary-analysis-terminology"><a class="markdownIt-Anchor" href="#primary-analysis-terminology"></a> Primary Analysis Terminology</h2>
<ul>
<li>
<p>Primary analysis protocol: Specifies signal processing of the movie, base calling of the traces/pulses, and quality assessment of the base calls. Primary analysis is always performed on the instrument.</p>
</li>
<li>
<p>Adapter Screening: Annotates adapter read locations. Used to break a read into subreads during secondary analysis mapping and Circular Consensus.</p>
</li>
<li>
<p>High Quality Region Screening: Annotates the high quality sequencing regions of a read to be used during Raw Read Trimming.</p>
</li>
<li>
<p>Insert Screening: Annotates insert DNA regions in the Polymerase Read.</p>
</li>
<li>
<p>Quality Value Assignment: A prediction of the error probability of a basecall.</p>
</li>
<li>
<p>Quality Value (QV): The total probability that the basecall is an insertion or substitution or is preceded by a deletion. QV = -10 * log10(p). For example, QV 20 is 99% accurate, QV 30 is 99.9% accurate, and QV 50 is 99.999% accurate.</p>
</li>
<li>
<p>Insertion QV: The probability that the basecall is an insertion with respect to the true sequence.</p>
</li>
<li>
<p>Deletion QV: The probability that a deletion error occurred before the current base.</p>
</li>
<li>
<p>Substitution QV: The probability that the basecall is a substitution.</p>
</li>
<li>
<p>raw read trimming: Extraction of high quality regions from an unfiltered read. Trimming of an unfiltered read produces a polymerase read.</p>
</li>
<li>
<p>Read Quality Assignment: A trained prediction of a read’s mapped accuracy based on its pulse and base file characteristics (peak signal-to-noise ratio, average base QV, interpulse distance, and so on). This is used during secondary analysis filtering.</p>
</li>
</ul>
<h2 id="secondary-analysis-terminology"><a class="markdownIt-Anchor" href="#secondary-analysis-terminology"></a> Secondary Analysis Terminology</h2>
<ul>
<li>
<p>Secondary analysis protocol: Specifies how to</p>
</li>
<li>
<p>Align a group of reads to a reference sequence to produce a consensus sequence.</p>
</li>
<li>
<p>Assemble a set of reads into contigs to produce a <em>de novo</em> sequence.</p>
</li>
<li>
<p>Identify insertions, deletions, and SNPs.</p>
</li>
<li>
<p>Evaluate consensus quality and quality of the instrument run.</p>
</li>
<li>
<p>Consensus: Generation of a consensus sequence from multiple-sequence alignment.</p>
</li>
<li>
<p><em>De Novo</em> Assembly: Assembly of all subreads without a reference sequence.</p>
</li>
<li>
<p>Filtering: Removes reads that do not meet the Read Quality and Read Length parameters set by the user. The current default filtering parameters defined by Pacific Biosciences are:</p>
</li>
<li>
<p>Read Quality ≥ .75 (as of SMRT Analysis v2.1)</p>
</li>
<li>
<p>Read Length ≥ 50 bases</p>
</li>
<li>
<p>Mapping: Local alignment of a read or subread to a reference sequence.</p>
</li>
</ul>
<h2 id="accuracy-terminology"><a class="markdownIt-Anchor" href="#accuracy-terminology"></a> Accuracy Terminology</h2>
<ul>
<li>circular consensus accuracy: Accuracy based on multiple sequencing passes around a single circular template molecule.</li>
<li>consensus accuracy: Accuracy based on aligning multiple sequencing reads or subreads together, optionally with a reference sequence.</li>
<li>polymerase read quality: A trained prediction of a read’s mapped accuracy based on its pulse and base file characteristics (peak signal-to-noise ratio, average base QV, inter-pulse distance, and so on).</li>
<li>Subread Accuracy: The post-mapping accuracy of the basecalls.</li>
<li>Formula: [1 - (errors/subread length)], where errors = number of deletions + insertions + substitutions.</li>
</ul>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>安装PacBio数据分析工具包SMRT Analysis</title>
    <url>/2016/03/07/Bioinfo-pacbio-smrt-analysis/</url>
    <content><![CDATA[<h2 id="download-smrt-analysis"><a class="markdownIt-Anchor" href="#download-smrt-analysis"></a> Download SMRT Analysis</h2>
<p>Download SMRT Analysis from PacBio DevNet (<a href="http://www.pacbiodevnet.com/">http://www.pacbiodevnet.com</a>):</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://s3.amazonaws.com/files.pacb.com/software/smrtanalysis/2.2.0/smrtanalysis-2.2.0.133377.run</span><br><span class="line">wget https://s3.amazonaws.com/files.pacb.com/software/smrtanalysis/2.2.0/smrtanalysis-2.2.0.133377-patch-3.run</span><br></pre></td></tr></table></figure>
<h2 id=""><a class="markdownIt-Anchor" href="#"></a> <a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/SMRT-Analysis-Software-Installation-v2.2.0#installation-summary"></a>Installation Summary</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SMRT_ROOT=/opt/smrtanalysis</span><br><span class="line">sudo mkdir $SMRT_ROOT</span><br><span class="line">sudo chown smrtanalysis:smrtanalysis $SMRT_ROOT</span><br><span class="line"></span><br><span class="line">su -l smrtanalysis</span><br><span class="line">smrtanalysis-2.2.0.133377.run -p smrtanalysis-2.2.0.133377-patch-3.run --rootdir $SMRT_ROOT</span><br><span class="line"></span><br><span class="line">$SMRT_ROOT/admin/bin/smrtportald-initd start</span><br><span class="line">$SMRT_ROOT/admin/bin/kodosd start</span><br></pre></td></tr></table></figure>
<h2 id="-2"><a class="markdownIt-Anchor" href="#-2"></a> <a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/SMRT-Analysis-Software-Installation-v2.2.0#upgrade-summary"></a>Upgrade Summary</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">su -l smrtanalysis</span><br><span class="line">SMRT_ROOT=/opt/smrtanalysis</span><br><span class="line">$SMRT_ROOT/admin/bin/smrtportald-initd stop </span><br><span class="line">$SMRT_ROOT/admin/bin/smrtupdater -- -p smrtanalysis-2.2.0.133377-patch-3.run smrtanalysis-2.2.0.133377.run</span><br><span class="line">$SMRT_ROOT/admin/bin/smrtportald-initd start</span><br></pre></td></tr></table></figure>
<p>Once SMRT Portal is installed, proceed to the following sections to complete setup:</p>
<ol>
<li><a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/SMRT-Analysis-Software-Installation-v2.2.0#set-up-smrt-portal">Set up SMRT Portal</a> (for new installations only)</li>
<li><a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/SMRT-Analysis-Software-Installation-v2.2.0#verify-the-installation">Verify the Installation</a> (for new installations <strong>and</strong> upgrades)</li>
</ol>
<h2 id="-3"><a class="markdownIt-Anchor" href="#-3"></a> <a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/SMRT-Analysis-Software-Installation-v2.2.0#patch-summary"></a>Patch Summary</h2>
<p><strong>These two commands must be run as <code>smrtanalysis</code> user.</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">SMRT_ROOT=/opt/smrtanalysis</span><br><span class="line">$SMRT_ROOT/admin/bin/smrtportald-initd stop</span><br></pre></td></tr></table></figure>
<p><strong>These two commands must be run as <code>root</code> (e.x. using <code>sudo</code>). Skip these commands if the files do not exist.</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo rm /tmp/mysql_XXXXX.sock </span><br><span class="line">sudo rm $SMRT_ROOT/userdata/database/../../error.log </span><br></pre></td></tr></table></figure>
<p><strong>These two commands must be run as <code>smrtanalysis</code> user.</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$SMRT_ROOT/admin/bin/smrtupdater smrtanalysis-2.2.0.133377-patch-3.run</span><br><span class="line">$SMRT_ROOT/admin/bin/smrtportald-initd start</span><br></pre></td></tr></table></figure>
<p>Note： [20180704]使用的过程中发现 SMRT analysis 还是会依赖系统的一些程序的，之前系统用的是 Python 2.7，运行SMRTanalysis中的甲基化分析流程没问题，前段时间将默认的 Python 换成了 Python 3.6（Anaconda），结果遇到甲基化分析中断，报错信息: <code>Exiting smrtpipe last error: SmrtExit task://016448/P_Mapping/covGFF Failed</code> 在bashrc中将默认的 Python 设置为 Python 2.7，然后甲基化分析就可以正常运行了。</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Preqc of SGA</title>
    <url>/2016/06/27/Bioinfo-preqc-of-sga/</url>
    <content><![CDATA[<p>[Copied from <a href="https://groups.google.com/forum/#!msg/sga-users/95dTwpJCARU/oKoq54EZqKwJ%5C">https://groups.google.com/forum/#!msg/sga-users/95dTwpJCARU/oKoq54EZqKwJ\</a>]</p>
<p>For the past few months I (jtsimpson) have been working on a new component of SGA to assist users with their assembly. This program, called ‘preqc’, attempts to measure the quality of the input data and how easy or difficult assembling it will be. The output of the pipeline is a PDF containing plots. I’ve uploaded an example report here: <a href="https://dl.dropboxusercontent.com/u/8813551/preqc_report.pdf">https://dl.dropboxusercontent.com/u/8813551/preqc_report.pdf</a> My hope is that this report will help you explore your data, select an assembly strategy (ie a program and its parameters) and troubleshoot when things go wrong. The report contains plots that attempt to capture the structure of the underlying genome (for example how repetitive it is) and also capture data quality (for example the sequencing error rate). At the end of this email is a brief description of each plot. I hope to get the manuscript up on arXiv this week which contains much more information. Feel free to ask questions if anything is unclear. Here are the instructions to run this on your data: 1) update to latest sga on github 2) preprocess the data: sga preprocess --pe-mode 1 input_1.fastq input_2.fastq &gt; my_genome.fastq 3) index the data sga index -a ropebwt -t 8 --no-reverse my_genome.fastq 4) run preqc sga preqc -t 8 my_genome.fastq &gt; my_genome.preqc 5) make the report /path/to/sga/src/bin/sga-preqc-report.py my_genome.preqc /path/to/sga/src/examples/preqc/*.preqc The preqc step only takes a few hours to run on very large genomes so it should not be a burden to generate this report at the start of a project. The goal of this project is to make assembly an easier and more predictable process. I hope you all find this to be useful, even if you prefer to use a different assembler. Please let me know if you have any comments or suggestions! Cheers, Jared Description of plots in the report: - Genome Size This plot contains an estimate of the genome size based on k-mer count statistics - Frequency of Variant Branches in the k-de Bruijn graph This shows how often a de Bruijn graph branches due to sequence variation (ie a SNP or indel) as a function of k. Most assemblers contain ‘bubble popping’ algorithms to resolve sequence variants in the graph. These algorithms often work well but a high branch rate makes assembly more difficult. The oyster data branches very frequently due to variants making it difficult to assemble. - Frequency of Repeat Branches in the k-de Bruijn graph This measures how often a de Bruijn graph branches due to repeats in the genome. Repeat branches tend to be difficult to resolve. This is a key indicator of how difficult the assembly will be. - Frequency of Error Branches in the k-de Bruijn graph Like the above two plots, except it measures how often branches caused by sequencing errors are encountered. These branches tend to be easier to get handle during assembly. - Mean quality score by position - Fraction of bases at least Q30 These plots measure quality scores along the length of the read. The first plot calculates the mean quality score at each base. The second calculates the fraction of reads with quality &gt;= Q30 at the base position. - k-mer position of first error This measures sequencing error rate by looking for rare k-mers in the reads. It is similar to how ‘sga correct’ finds and corrects errors. The plot shows how often putatively incorrect k-mers are found at each position in the reads. - Per-position error rate This directly measures the sequencing error rate along the read by counting mismatches in groups of overlapping reads. - Duplicate proportion This plot attempts to infer the proportion of read pairs that are PCR duplicates. - Estimated fragment size histogram This plot shows the distribution of paired-end fragment sizes. - 51-mer count distribution For an assembly to be successful, it is important to have high coverage data. This plot attempts to capture sequence coverage by plotting a histogram of 51-mer counts. Most data sets are bimodal with a sharp peak at low count for k-mers with sequencing errors and a wider distribution of true genomic k-mers. If these two distributions (true k-mers and k-mers with errors) are well-separated, it makes assembly easier. The Snake data is ideal in this regard. The yeast data is acceptable but would benefit from higher coverage. - GC Bias plots This series of plots (one per data set) shows k-mer counts as function of GC content in the read. Ideally, there would be no dependence between GC content and k-mer count. The yeast data shows some bias, while the fish data is less biased. - Simulated contig lengths in k-de Bruijn graph The last plot shows a simulated assembly of the data by finding contig paths in the graph. The simulator will extend contigs by ignoring sequencing errors and resolving sequence variants, only stopping when a repeat is found or there is no coverage. This plot can help predict if your data is easy to assemble or hard. For example the yeast data is easy to assemble (very good N50) but the oyster data, which has many sequence variant branches and many repeats, is very hard (low N50).</p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>根据参考基因组对contigs进行排列</title>
    <url>/2017/09/20/Bioinfo-sort-contigs-based-on-chromosomes/</url>
    <content><![CDATA[<p>Multiple programs have been developed for reference-assisted chromosome assembly: Bambus [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR10">10</a>], BACCardI [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR11">11</a>], Projector2 [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR12">12</a>], OSLay [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR13">13</a>], ABACAS [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR14">14</a>], MeDuSa [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR15">15</a>], AlignGraph [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR16">16</a>], Ragout [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR17">17</a>], SyMap [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR18">18</a>] and RACA [<a href="https://gigascience.biomedcentral.com/articles/10.1186/s13742-016-0141-6#CR19">19</a>]. Most of the listed tools were designed for bacterial or small genomes. For example, ABACAS is a convenient bacterial genome contiguation tool that may also be used for small eukaryotic genomes such as <em>Saccharomyces cerevisiae</em> (12.1 mega base pairs). However, ABACAS is not efficiently scaled to use with the large genomes typical of vertebrate species. ABACAS对小型基因组很实用。但是注意：contig连接处是由99个N连接起来的，实际上contig的末端室友重叠关系的。 针对大型基因组，可以使用Chromosomer: a reference-based genome arrangement tool for producing draft chromosome sequences</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>T检验中，单尾和双尾，成对、等方差和异方差的差异</title>
    <url>/2016/06/14/Bioinfo-t-test/</url>
    <content><![CDATA[<p>在做数据检验的时候，通常先要检验数据是否正态，因为正态分布下有非常详尽的理论基础，用起来非常方便，如果数据不服从正态分布怎么办呢？此时就可以用非参数检验，是基于秩（其实就是序号啦）的，也有很多种方法。你可能会问：不管数据是否正态，是否都能用非参数检验呢，其实也是可以的，不过正态下用非参数检验的话，检验功效就不如参数方法了。如果你不知道什么是检验功效的话就去查一查概率统计的课本。为了有较高的检验功效，非正态数据就用非参数方法，正态数据就用参数方法。 至于该做双尾还是单尾检验，是可以根据问题的实际意义进行判断的，如果不好判断就画画散点图，看一个是否明显在另一个之上或之下。 至于方差的要求那是因为在正态分布下，等方差会省去很多麻烦，所以通常假定方差相等，相关的检验理论也非常完善。如果你不知道方差到底是否相等，可以做检验，最直观的方法就是绘制箱线图，或计算样本标准差。</p>
<p>实际上是： 当所要比较的两个样本统计量的总体参数事先无法肯定哪个大或者哪个小时，就要用双尾检验，所得到的检验结果取P双尾值。否则就取P单尾值。单尾检验强调的是方向性。 举个例子： 例子1：在甲、乙两地随机抽取两个样本，他们的身高平均数分别为x1和x2，现在要对x1和x2进行检验，由于事先无法确定两个样本均数所在的总体样本均数哪个大哪个小，所以要用双尾检验。 例子2：一批17岁男生测验的身高平均数x1,到18岁时再进行测验得到平均数x2，若要对x1和x2进行检验，因为同一批人的18岁身高平均值不可能比17岁的还低，所以这里要用单尾检验。 实际上我们前面所说的T检验的例子都是无法确定两样本总体参数谁大谁小，所以都取P双尾值 上面是一个找到的资料，不知道对不对。 ********************** 还有一个百度上面的： 单尾和双尾取决于你的H0。设两个样本是X1，X2，如果H0是X1=X2，那么做双尾检验，因为不确定X1比X2大还是小。如果如果H0是X1&gt;X2或X1&lt;X2，那么做的是单尾，因为有先验的假设。 ************************ 还有一个相关的： 通常假设检验的目的是两总体参数是否相等，以两样本均数比较为例， 无效假设为两样本所代表的总体均数相等； 备择假设为不相等（有可能甲大于乙，也有可能甲小于乙）既两种情况都有可能发生． 而研究者做这样的假设说明（１）他没有充分的理由判断甲所代表的总体均数会大于乙的或甲的会小于乙的；（２）他只关心甲乙两个样本各自所代表的总体均数是否相等？至于哪个大不是他关心的问题．这时研究者往往会采用双侧检验． 如果研究者从专业知识的角度判断甲所代表的总体均数不可能大于（或小于）乙的，这时一般就采用单侧检验． 例如：要比较经常参加体育锻炼的中学男生心率是否低于一般中学男生的心率，就属于单侧检验．因为根据医学知识知道经常锻炼的中学男生心率不会高于一般中学男生，因此在进行假设检验时应使用单侧检验． 单尾检验和双尾检验的区别在于他们拒绝H0的标准。单尾检验允许你在差异相对较小时拒绝H0，这个差异被规定了方向。另一方面，双尾检验需要相对较大的差异，这个差异不依赖于方向。 所有的研究者都同意单尾检验与双尾检验不同。一些研究者认为，双尾检验更为严格，比单尾检验更令人信服。因为双尾检验要求更多的证据来拒绝H0，因此提供了更强的证据说明处理存在效应。另一些研究者倾向于使用单尾检验，因为它更为敏感，即在单尾检验中相对较小的处理效应也可能是显著的，但是，它可能不能达到双尾检验的显著性要求。 那么我们是应该使用单尾检验还是双尾检验？？通常，双尾检验被用于没有强烈方向性期望的实验研究中，或是存在两个可竞争的预测时。例如，当一种理论预测分数增加，而另一种理论预测分数减少时，应当使用双尾检验。应当使用单尾检验的情况包括在进行实验前已经有方向性预测，或强烈需要做出方向性预测时。   参考资料：</p>
<p><a href="http://www.ilovematlab.cn/thread-162174-1-1.html">http://www.ilovematlab.cn/thread-162174-1-1.html</a><br />
<a href="http://wiki.mbalib.com/wiki/%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E9%AA%8C">http://wiki.mbalib.com/wiki/显著性检验</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>PacBio测序数据格式释义</title>
    <url>/2016/04/19/Bioinfo-understanding-pacbio-format/</url>
    <content><![CDATA[<p>本文摘抄/参考自：<a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/Data-files-you-received-from-your-service-provider">https://github.com/PacificBiosciences/SMRT-Analysis/wiki/Data-files-you-received-from-your-service-provider</a> 为什么原始数据中有三个“.bas.h5”文件？原因：实际上在PacBio早期的测序原始数据里，只有一个bas.h5文件，因为后来单个SMRT Cell的数据通量有所提高，从而增加了bas.h5文件用以存储base calling数据。 This page describes some of the data files you received from your service provider.</p>
<h2 id=""><a class="markdownIt-Anchor" href="#"></a> <a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/Data-files-you-received-from-your-service-provider#primary-analysis-data"></a>Primary Analysis Data</h2>
<p>This is data <strong>directly</strong> generated by a PacBio RS II run.</p>
<ul>
<li>The <code>Primary</code> directory includes one subdirectory for <strong>each</strong> run.</li>
<li>Each run directory includes a subdirectory for <strong>each</strong> SMRT Cell used in the run.</li>
<li>Each SMRT Cell directory includes an <code>Analysis_Results</code> subdirectory, which contains output files of interest. <strong>Example:</strong></li>
</ul>
<p>/path/to/secondary/storage/2420294/0011<br />
├── Analysis_Results<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.1.bax.h5<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.1.log<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.1.subreads.fasta<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.1.subreads.fastq<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.2.bax.h5<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.2.log<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.2.subreads.fasta<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.2.subreads.fastq<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.3.bax.h5<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.3.log<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.3.subreads.fasta<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.3.subreads.fastq<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.bas.h5<br />
│   ├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.sts.csv<br />
│   └── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.sts.xml<br />
├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.1.xfer.xml<br />
├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.2.xfer.xml<br />
├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.3.xfer.xml<br />
├── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.mcd.h5<br />
└── m140415_143853_42175_c100635972550000001823121909121417_s1_p0.metadata.xml</p>
<h3 id="-2"><a class="markdownIt-Anchor" href="#-2"></a> <a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/Data-files-you-received-from-your-service-provider#pacbio-file-naming-convention"></a>PacBio File Naming Convention</h3>
<p>Many files and sequences used in primary and secondary analysis contain a long string identifier. Below is a typical ID string from a subread with fields defined:</p>
<blockquote>
<p>m140415_143853_42175_c100635972550000001823121909121417_s1_p0/553/3100_11230<br />
└1┘└────2─────┘ └─3─┘ └────────────────4────────────────┘└5┘└6┘└7┘ └───8────┘</p>
</blockquote>
<ol>
<li>“m” = movie</li>
<li>Time of Run Start (yymmdd_hhmmss)</li>
<li>Instrument Serial Number</li>
<li>SMRT Cell Barcode</li>
<li>Set Number (a.k.a. “Look Number”. Deprecated field, used in earlier version of RS)</li>
<li>Part Number (usually “p0”, “X0” when using expired reagents)</li>
<li>ZMW hole number †</li>
<li>Subread Region (start_stop using polymerase read coordinates) †</li>
</ol>
<blockquote>
<p>† Note that Fields 7 and 8 are used as sequence IDs in FASTAFASTQ files. They are not used in filenames.</p>
</blockquote>
<p>For information on the main files of interest, see:</p>
<ul>
<li><a href="https://s3.amazonaws.com/files.pacb.com/software/instrument/2.0.0/bas.h5+Reference+Guide.pdf">bas.h5 Reference Guide</a> <strong>(PDF)</strong>: Describes the main output files produced by the primary analysis pipeline: <code>bas.h5</code>,<code>.1.bax.h5</code>, <code>.2.bax.h5</code>, and <code>.3.bax.h5</code>. The <code>bax.h5</code> files contain base call information from the sequencing run. The <code>bas.h5</code> file is essentially a pointer to the three <code>bax.h5</code> files.</li>
<li><a href="https://s3.amazonaws.com/files.pacb.com/software/instrument/2.0.0/Metadata+Output+Guide.pdf">Metadata Output Guide</a> <strong>(PDF)</strong>: Describes the file <code>metadata.xml</code>, which contains top-level information about the data, including what sequencing enzyme and chemistry were used, sample name, and other metadata.</li>
<li><a href="https://s3.amazonaws.com/files.pacb.com/software/instrument/1.3.1/Statistics+Output+Guide.pdf">Statistics Output Guide</a> <strong>(PDF)</strong>: Describes the file <code>sts.xml</code>, which includes summary statistics from a single movie acquisition.</li>
</ul>
<h2 id="-3"><a class="markdownIt-Anchor" href="#-3"></a> <a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/Data-files-you-received-from-your-service-provider#secondary-analysis-data"></a>Secondary Analysis Data</h2>
<p>This is data produced by secondary analysis, which is performed on the primary analysis data generated by the instrument.</p>
<blockquote>
<ul>
<li>
<p>All files for a specific job reside in <strong>one</strong> directory that is named according to the job ID number</p>
</li>
<li>
<p>Every SMRT Portal job has the following structure. <strong>Example:</strong></p>
<p>/path/to/smrtanalysis/userdata/jobs/016/016234<br />
├── data/<br />
├── results/<br />
├── log/<br />
├── workflow/<br />
├── <a href="http://job.sh">job.sh</a><br />
├── input.xml<br />
└── settings.xml</p>
<ul>
<li><code>data</code> is a <strong>directory</strong> that contains intermediate and final data files for the analysis job</li>
<li><code>results</code> is a <strong>directory</strong> that contains summary statistics and plots for the analysis job</li>
<li><code>log</code> is a <strong>directory</strong> that contains all log files for the analysis job</li>
<li><code>workflow</code> is a <strong>directory</strong> that contains all the executables for the analysis job</li>
<li><code>job.sh</code> is an executable file used by SMRT Portal to run the <code>smrtpipe.py</code> analysis job</li>
<li><code>input.xml</code> is a .xml file containing a list of input <code>bax.h5</code> files used to run the analysis job</li>
<li><code>settings.xml</code> is a .xml file containing the parameters needed to perform the analysis job</li>
</ul>
</li>
<li>
<p>For more detail on specific protocol outputs, see <a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/Navigating-the-SMRT-Pipe-Job-Directory">Navigating the SMRT Pipe Job Directory</a>.</p>
</li>
</ul>
</blockquote>
<p>Within the <code>data</code> directory are several types of output files. You can use these data files as input for further downstream processing, pass on to collaborators, or upload to public genome sites. Depending on the protocol being performed, the <code>data</code> directory contain files in the following formats:</p>
<ul>
<li><strong>cmp.h5:</strong> The primary sequence alignment file for SMRT sequencing data. (Click <a href="https://s3.amazonaws.com/files.pacb.com/software/smrtanalysis/1.4/doc/cmp.h5+Reference+Guide.pdf">here</a> **(PDF)**for further details.)</li>
<li><strong>H5:</strong> <code>Hierarchical Data Format</code>; a file-system-like data format. (Click <a href="http://www.hdfgroup.org/HDF5/doc/H5.intro.html">here</a> for further details.)</li>
<li><strong>SAM:</strong> <code>Sequence Alignment Map</code> is a generic nucleotide alignment format that describes the alignment of query sequences or sequencing reads to a reference sequence or assembly. (Click <a href="http://samtools.sourceforge.net/">here</a> for further details.)</li>
<li><strong>BAM:</strong> Binary version of the <code>Sequence Alignment Map (SAM)</code> format. (Click <a href="http://genome.ucsc.edu/goldenPath/help/bam.html">here</a> for further details.)</li>
<li><strong>BAI:</strong> The index file for a file generated in the BAM format. (This is a non-standard file type.)</li>
<li><strong>FASTA:</strong> FASTA-formatted sequence files contains either nucleic acid sequence (such as DNA) or protein sequence information. FASTA files store multiple sequences in a single file. (Click <a href="http://en.wikipedia.org/wiki/FASTA_format">here</a> for further details.)</li>
<li><strong>GFF:</strong> <code>General Feature Format</code>, used for describing genes and other features associated with DNA, RNA and Protein sequences. (Click <a href="http://genome.ucsc.edu/FAQ/FAQformat#format3">here</a> for further details.)</li>
<li><strong>VCF:</strong> <code>Variant Call Format</code>, for use with the molecular visualization and analysis program VMD. (Click <a href="http://en.wikipedia.org/wiki/Variant_Call_Format">here</a> for further details.)</li>
<li><strong>BED:</strong> Format that defines the data lines displayed in an annotation track. (Click <a href="http://genome.ucsc.edu/FAQ/FAQformat#format1">here</a> for further details.)</li>
<li><strong>CSV:</strong> Comma-Separated Values file. Can be viewed using Microsoft Excel or a text editor.</li>
<li><strong>GML:</strong> An XML representation of the scaffold graph that results from scaffolding contigs using the AHA hybrid assembly algorithm.</li>
</ul>
<h2 id="-4"><a class="markdownIt-Anchor" href="#-4"></a> <a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/Data-files-you-received-from-your-service-provider#smrt-portal-reports"></a>SMRT Portal Reports</h2>
<p>Your service provider included secondary analysis reports generated using SMRT Portal.</p>
<ul>
<li>For an explanation of the report fields, click <a href="https://s3.amazonaws.com/files.pacb.com/software/smrtanalysis/2.2.0/Reports+-+Terminology.pdf">here</a> <strong>(PDF)</strong>.</li>
</ul>
<h2 id="-5"><a class="markdownIt-Anchor" href="#-5"></a> <a href="https://github.com/PacificBiosciences/SMRT-Analysis/wiki/Data-files-you-received-from-your-service-provider#downloading-smrt-analysis-software"></a>Downloading SMRT Analysis Software</h2>
<ul>
<li>The latest version of the SMRT Analysis software is available <a href="http://www.pacb.com/devnet/">here</a>.</li>
<li>Pacific Biosciences provides a free Amazon Machine Image that you can use to run SMRT Portal in the cloud. See <a href="https://github.com/PacificBiosciences/Bioinformatics-Training/wiki/%22Installing%22-SMRT-Portal-the-easy-way---Launching-A-SMRT-Portal-AMI">here</a> for details.</li>
</ul>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | 怎么理解序列一致性（Sequence identity）</title>
    <url>/2021/03/16/Bioinfo-understanding-sequence-identity/</url>
    <content><![CDATA[<p>序列一致性（Sequence identity）是评估两个序列相似度的一个参考值，不同的软件可能会有不通过的计算方法。下面的案例摘抄自 <a href="http://lh3.github.io/2018/11/25/on-the-definition-of-sequence-identity">Heng Li’s blog</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">CCAGTGTGGCCGATACCCCAGGTTGGCACGCATCGTTGCCTTGGTAAGC</span><br><span class="line">CCAGTGTGGCCGATGCCCGTGCTACGCATCGTTGCCTTGGTAAGC</span><br></pre></td></tr></table></figure>
<p>经典的方法是先对两个序列做比对，并且设置打分规则：匹配 match=1，错配 mismatch=-2，缺失 gapOpen=-2，缺失延伸 gapExt=-1。依据这个打分规则，上述两条序列的最佳比对结果如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Ref+:  1 CCAGTGTGGCCGATaCCCcagGTtgGC-ACGCATCGTTGCCTTGGTAAGC 49</span><br><span class="line">         |||||||||||||| |||   ||  || ||||||||||||||||||||||</span><br><span class="line">Qry+:  1 CCAGTGTGGCCGATgCCC---GT--GCtACGCATCGTTGCCTTGGTAAGC 45</span><br></pre></td></tr></table></figure>
<p>Here we have 43 matching bases, 1 mismatch, 5 deletions and 1 insertion to the first/Ref sequence. The <a href="https://www.drive5.com/usearch/manual/cigar.html">CIGAR</a> is 18M3D2M2D2M1I22M. CIGAR 的定义： Concise Idiosyncratic Gapped Alignment Report，上面的CIGAR值可翻译为：18 matches，3 deletions，2 matches，2 matches，1 deletions，22 mathces。</p>
<h3 id="不考虑-gap-的序列一致性"><a class="markdownIt-Anchor" href="#不考虑-gap-的序列一致性"></a> 不考虑 Gap 的“序列一致性”</h3>
<p>如果不考虑 Gap，则只考虑匹配 Match 和错配 Mismatch。序列一致性等于 “#matches / (#matches + #mismatches)” = 43/(43+1) = 97.7%。这里的序列一致性并没有考虑 Gap，有一定局限性，早期基因组相关报道中提到的“大猩猩基因组与人类基因组的相似程度为98%”应该就是这种情况。摘抄：An obvious problem with this definition is that it doesn’t count gaps. However, it is an often used definition. We may hear that the chimpanzee and human genome differ by a couple of percent. Here we are referring to such gap-excluded identity. The exact sentence in the first chimpanzee genome paper is “Single-nucleotide substitutions occur at a mean rate of 1.23% between copies of the human and chimpanzee genome”.</p>
<h3 id="考虑-gap-的序列一致性以-blast-为例"><a class="markdownIt-Anchor" href="#考虑-gap-的序列一致性以-blast-为例"></a> 考虑 Gap 的“序列一致性”（以 BLAST 为例）</h3>
<p>BLAST 中对序列一致性的算法是最常见的算法，序列一致性等于匹配数 43（matchings bases）除以比对区间总长度 50，得到 86%。需要指出，虽然 Ref 序列的长度是 49，但是总比对长度却是 50（就是要多加 1 个插入碱基的长度）。局限在于，虽然考虑的 Gap 的存在，但是没有考虑 Gap 是否连续。一个连续的 Gap，与若干个分散的 Gap，如果总长度一样，计算得到的序列一致性也一样，这种计算方法就有不够科学的地方。原作者举例，如果一个 query 序列长度为 1000bp，比对到参考序列上面发现中间有连续 300bp 是 insertion 导致的 Gap，这个情况下序列一致性为 (1000-300)/1000 = 70%，这个结果会被过滤掉，而在进化（evolution）的过程中，这个连续的 300bp 可能只是一次序列插入事件，而非 300 次独立的单碱基插入事件。BLAST identity is defined as the number of matching bases over the number of alignment columns. In this example, there are 50 columns, so the identity is 43/50=86%. In a SAM file, the number of columns can be calculated by summing over the lengths of M/I/D CIGAR operators. The number of matching bases equals the column length minus the NM tag. Here is a Perl one-liner to calculate BLAST identity:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">perl -ane &#x27;if(/NM:i:(\d+)/)&#123;$n=$1; $l=0; $l+=$1 while/(\d+)[MID]/g; print(($l-$n)/$l,&quot;\n&quot;)&#125;&#x27;</span><br><span class="line"># Where variable $n is the sum of mismatches and gaps and $l is the alignment length. </span><br><span class="line">#In the PAF format, column 10 divived by column 11 gives the BLAST identity.</span><br></pre></td></tr></table></figure>
<p>核酸序列比对程序 BLASTN 可以输出 SAM 格式结果，如下所示。上面的 Perl 命令行即可以读取包含“NM:i:[\d+]”的行，NM即$1=17；识别M、I、D 字符对应的数字，相同字母对应的数值分别累加，累加之后分别为 match，M=551；insertion，I=5；deletion，D=9。那么序列一致性等于 (M+I+D-NM)/(M+I+D)=(565-17)/565=97%。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@HD     VN:1.2  SO:coordinate   GO:reference</span><br><span class="line">@SQ     SN:Query_1      LN:916</span><br><span class="line">@PG     ID:0    VN:2.9.0+       CL:blastn -db /home/fenglei/database/Glycine_max/Gmax_275_Wm82_a2.v1/index/genome.fa -query GNAT_mutate.fa -out GNAT_mutate.fa-BLASTN-Wm82-275.m17 -outfmt 17 -window_size 10 -word_size 10     PN:blastn</span><br><span class="line">Chr02   0       Query_1 1       255     2929886H24M3D83M3D83M3D83M3D291M3I13M2I57M45646980H     *       0       0       *       *       AS:i:591        EV:f:0  NM:i:17 PI:f:100.00     BS:f:1092.49</span><br></pre></td></tr></table></figure>
<h3 id="压缩-gap-的序列一致性以-minimap2-为例"><a class="markdownIt-Anchor" href="#压缩-gap-的序列一致性以-minimap2-为例"></a> 压缩 Gap 的“序列一致性”（以 minimap2 为例）</h3>
<p>上文提到，连续若干个碱基的 Gap 可能是进化过程中单次插入导致的，那么可以通过压缩 Gap 将上述序列比对转化成下面的情形。Gap 的数目没有变化，但是长度全部变为 1，这样总长度也发生了变化。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Ref+:  CCAGTGTGGCCGATaCCCcGTtGCTACGCATC-TTGCCTTGGTAAGC</span><br><span class="line">       |||||||||||||| ||| || |||||||||| ||||||||||||||</span><br><span class="line">Qry+:  CCAGTGTGGCCGATgCCC-GT-GCTACGCATCgTTGCCTTGGTAAGC</span><br></pre></td></tr></table></figure>
<p>Gap 压缩之后的序列一致性为 43/(50-2-1)=91.5%。对于比对软件 minimap2，即是采用这种算法。下面是Perl 命令计算一致性数值的例子。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">perl -ane &#x27;if(/NM:i:(\d+)/)&#123;$n=$1; $m=$g=$o=0; $m+=$1 while/(\d+)M/g; $g+=$1,++$o while/(\d+)[ID]/g; print(1-($n-$g+$o)/($m+$o),&quot;\n&quot;)&#125;&#x27;</span><br><span class="line">#where $m is the sum of M operations, $g the sum of I and D operations and $o the number of gap opens.</span><br></pre></td></tr></table></figure>
<p>参考资料</p>
<ol>
<li><a href="http://lh3.github.io/2018/11/25/on-the-definition-of-sequence-identity">On the definition of sequence identity</a></li>
<li><a href="https://www.jianshu.com/p/9539f44ecf61">怎样定义 sequences 比对的相似度</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/55324279">知乎专栏：序列一致性</a></li>
</ol>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | DOS 界面下的基本操作命令</title>
    <url>/2022/05/05/DOS-usual-commands/</url>
    <content><![CDATA[<p>偶尔需要用到 DOS 界面下调用软件来做数据处理，现对场用的命令行做一个记录。</p>
<ol>
<li>从默认 C 盘切换磁盘到 D 盘，直接输入 <code>d:</code>。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Microsoft Windows [版本 10.0.19044.1645]</span><br><span class="line">(c) Microsoft Corporation。保留所有权利。</span><br><span class="line"></span><br><span class="line">C:\Users\fengl&gt;d:</span><br><span class="line"></span><br><span class="line">D:\&gt;</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>
<p>显示当前目录下的文件列表：<code>dir</code>。</p>
</li>
<li>
<p>进入目录，输入 <code>cd folder_name/sub_folder</code>。</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd    #显示当前目录</span><br><span class="line">cd\   #返回根目录</span><br><span class="line">cd..  #返回上一级目录</span><br></pre></td></tr></table></figure>
<ol start="4">
<li>
<p>运行 exe 程序，直接输入 <code>D:\path\to\xxx.exe</code> 或 <code>xxx.exe</code>。如果路径中有空格怎么办？用双引号处理：<code>&quot;D:\Program Files\path\to\xxx.exe&quot;</code>。</p>
</li>
<li>
<p>清理当前界面：<code>cls</code>。</p>
</li>
<li>
<p>在当前路径下创建新目录：<code>md folder_name</code>。</p>
</li>
<li>
<p>删除目录：<code>rd /s /q folder_name</code>。</p>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rd folder_name  #rd 的另外一个写法是 rmdir。使用的方法也很简单：rd 文件夹名 即可，例如：rd test。</span><br><span class="line">rd /s folder_name #如果要删除的文件夹下面还有子文件，你得给rd加个 /s 参数，它才会执行，所以，正确的写法是：rd /s test。</span><br><span class="line">rd /s /q folder_name #当删除带子文件的文件夹的时候，CMD总是殷勤地问你：是否确认(Y/N)? 参数 /q ，取自 quiet，安静模式，带 /S 删除目录树时不要求确认</span><br></pre></td></tr></table></figure>
<ol start="8">
<li>
<p>在当前目录下删除特定的文件：<code>del file.txt</code>。删除指定的一个或多个文件，不能用于删除子目录。参数 /P 的功能是使 DOS 在删除每个文件之前，要求用户先认可，这样使得用户可以有选择地删除一些文件。</p>
</li>
<li>
<p>批处理，批处理文件（.bat）</p>
</li>
</ol>
<p>以 for 循环为例：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@echo off</span><br><span class="line">for %%I in (ABC) do echo %%I</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>
<p>批处理文件的for循环就是这样简单，下面来看看for语句的注意事项，并运行更复杂的for循环实例。<br />
for语句的形式变量I，可以换成26个字母中的任意一个，这些字母会区分大小写，也就是说，%%I和%%i会被认为不是同一个变量；形式变量I还可以换成其他的字符，但是，为了不与批处理中的%0～%9这10个形式变量发生冲突，请不要随意把%%I替换为%%0～%%9中的任意一个；<br />
in和do之间的command1表示的字符串或变量可以是一个，也可以是多个，每一个字符串或变量，我们称之为一个元素，每个元素之间，用空格键、跳格键、逗号、分号或等号分隔；<br />
for语句依次提取command1中的每一个元素，把它的值赋予形式变量I，带到do后的command2中参与命令的执行；并且每次只提取一个元素，然后执行一次do后的命令语句，而无论这个元素是否被带到command2中参与了command2的运行；当执行完一次do后的语句之后，再提取command1中的下一个元素，再执行一次command2，如此循环，直到command1中的所有元素都已经被提取完毕，该for语句才宣告执行结束。</p>
<p>有了以上的基础，我们再来看下面这个例子，这个例子修改了demo1中的部分内容(记为demo2)，结果将大不一样：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">@echo off</span><br><span class="line">for  %%I in (A,B,C) do echo %%I</span><br><span class="line">pause</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p>追梦菜鸟：<a href="https://blog.csdn.net/u013514928/article/details/79629937">https://blog.csdn.net/u013514928/article/details/79629937</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>恒生银行信用卡Cash Dollar优惠登记</title>
    <url>/2017/08/10/Life-cash-dollar-of-HANGSANG/</url>
    <content><![CDATA[<p>由2017年7月1日至2018年6月30日，憑大學/大專聯營信用卡只需登記1次^，由登記月份起作以下簽賬交易，均可賺取<strong>高達5倍Cash Dollars</strong>:</p>
<p>1）拨打29986038，选择语言，点3选英语；<br />
2）选3，教育优惠Cash Dollar登记；<br />
3）输入16位信用卡账户，以“#”（pound）结束;<br />
4）收到语音提示之后，按“1”确认；<br />
5）收到语音播报七位数Reference Number，然后会提示是否结束服务，按“9”即结束服务。</p>
<p>参考：<br />
<a href="http://www.hangseng.com/cms/emkt/pmo/grp05/p10/chi/index.html">http://www.hangseng.com/cms/emkt/pmo/grp05/p10/chi/index.html</a></p>
<p>细则</p>
<p>大 學 / 大 專 聯 營 信 用 卡 「 高 達 5x Cash Dollars 自 我 增 值 獎 賞 」</p>
<p>優惠期由2017年7月1日至2018年6月30日(「優惠期」)。</p>
<p>客戶於優惠期內致電2998 6038登記1次，成功登記後，憑大學/大專聯營信用卡於登記之月份至2018年6月30日內之合資格交易均可享有高達5倍恒生信用卡Cash Dollars(包括原有之基本Cash Dollars)。[案:去年登記過的，今年需要重新登記。</p>
<p>適用於5倍恒生信用卡Cash Dollars之合資格交易包括：(i)於本地或網上書店購物及/或(ii)支付本地及海外公開考試費用；適用於3倍恒生信用卡Cash Dollars之合資格交易包括：報讀本地及海外各大院校辦學機構舉辦之課程，根據持續進修基金可獲發還款項課程名單為準，並成功於2018年7月16日或之前誌賬於信用卡戶口內之簽賬。</p>
<p>每個成功登記之信用卡戶口於優惠期內最多只可額外獲享合共$300 Cash Dollars，包括(i)於本地或網上書店購物及/或(ii)支付本地及海外公開考試費用而額外獲享之$200 Cash Dollars及報讀本地及海外各大院校辦學機構舉辦之課程，根據持續進修基金可獲發還款項課程名單為準，而額外獲享之簽賬以同一信用卡戶口計算，包括以同一主卡戶口過賬之附屬卡之簽賬。</p>
<p>以每次單一簽賬計算及所獲取之Cash Dollars以整數為單位，不足$1 Cash Dollar則不獲計算。</p>
<p>附：CUHK缴学费的流程。</p>
<p>第一，先去登记3X cash dollar，如上文。<br />
第二，登入你的恒生e-banking，点账户服务→缴付账单→缴帐→新增；商户<br />
商户类别：Education Institutions<br />
商户：The Chinese University of Hong Kong<br />
账单户口号码：进入中大CUSIS→make a payment→pay amount→next，之后有一个Payment Reference，就是这个。<br />
账单类别：01 Tuition,Hostel…<br />
金额：xxx（学费金额）<br />
支账户口：选择信用卡户口，会有信用卡号码，别点成储蓄卡户口。<br />
点击付款确认就ok了。</p>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
  </entry>
  <entry>
    <title>My Fast HexoPages</title>
    <url>/2020/12/07/Life-initial-demo-page/</url>
    <content><![CDATA[<p>abstract</p>
<span id="more"></span>
<p>This is the main text<br />
中文测试<br />
End of document</p>
<p>MarkDown的使用参考 <a href="https://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/_Rbook/markdown.html">北京大学李东风《R语言教程》</a><br />
MarkDown的使用参考 <a href="https://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/_Rbook/markdown.html">https://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/_Rbook/markdown.html</a></p>
<p>以一个井号#开始的行是一级标题， 以两个井号#开始的行是二级标题， …………， 以六个井号#开始的行是六级标题。 标题行前面应该空一行， 否则可能把某些偶然出现在行首的#号误认为标题行的标志。<br />
#井号起始，但不是标题<br />
# 井号显示测试</p>
<p>对一级标题， 也可以用标题内容下面输入一行等于号=表示上一行内容是一级标题。 对二级标题， 可以用标题内容下面输入一行减号-表示上一行内容是二级标题。 等于号和减号的个数不限。</p>
<p>用三个或三个以上连续的星号组成的行， 可以转换成分隔线。下面是一个分隔线：</p>
<hr />
<h3 id="小标题测试"><a class="markdownIt-Anchor" href="#小标题测试"></a> 小标题测试</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ <span class="comment"># 代码框测试（用三个连续的反向单撇号表示代码开头与代码结束， 中间就会当作源程序代码处理。）</span></span><br><span class="line">$ perl script.pl</span><br><span class="line">$ python3 xxxx</span><br></pre></td></tr></table></figure>
<h3 id="引用测试"><a class="markdownIt-Anchor" href="#引用测试"></a> 引用测试</h3>
<blockquote>
<p>白日依山尽，黄河入海流。<br />
欲穷千里目，更上一层楼。</p>
</blockquote>
<h3 id="网络图片测试"><a class="markdownIt-Anchor" href="#网络图片测试"></a> 网络图片测试</h3>
<p><img src="https://genehub.files.wordpress.com/2020/12/gm508_gm275_genome.jpg" alt="" /></p>
<h3 id="本地图片测试"><a class="markdownIt-Anchor" href="#本地图片测试"></a> 本地图片测试</h3>
<p><img src="/images/figure-0001.png" alt="这是一个本地图片测试" /></p>
<p><img src="/images/geom_encircle_demo.pdf" alt="这是PDF格式的图片" /></p>
<p>\begin{center} <br> \includegraphics[width=8in]{/images/geom_encircle_demo.pdf} <br> \end{center}</p>
<p><img src="/images/geom_encircle_demo.pdf" alt="Alt" /></p>
<h3 id="表格测试"><a class="markdownIt-Anchor" href="#表格测试"></a> 表格测试</h3>
<hr />
<table>
<thead>
<tr>
<th style="text-align:left">姓名</th>
<th style="text-align:right">收入</th>
<th style="text-align:center">职业</th>
<th>颜色偏好</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">赵四海</td>
<td style="text-align:right">123456</td>
<td style="text-align:center">业务经理</td>
<td>红</td>
</tr>
<tr>
<td style="text-align:left">刘英</td>
<td style="text-align:right">50</td>
<td style="text-align:center">无</td>
<td>蓝</td>
</tr>
<tr>
<td style="text-align:left">钱德里</td>
<td style="text-align:right">3200</td>
<td style="text-align:center">保洁</td>
<td>灰</td>
</tr>
</tbody>
</table>
<h2 id="table管道表示例"><a class="markdownIt-Anchor" href="#table管道表示例"></a> Table:管道表示例</h2>
<p><strong>视频测试</strong></p>
<p>&lt;video src=“<a href="https://youtu.be/zJagpUbnv-Y">https://youtu.be/zJagpUbnv-Y</a>” controls=“controls” width:100% height:auto&gt;</video></p>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
      <tags>
        <tag>Tag</tag>
      </tags>
  </entry>
  <entry>
    <title>Bioinfo | Gene Ontology - GOMAP</title>
    <url>/2021/06/17/Linux-Gene-Ontology-GOMAP/</url>
    <content><![CDATA[<p>Gene Ontology Meta Annotator for Plants</p>
<p>GOMAP 主要是给植物基因集做 Gene Ontology 注释信息匹配，它综合了多个数据库，所以得到的信息会全面一些。早年将基因对应到GO用的工具是Blast2GO，这个软件linux版本安装比较麻烦，基于mysql数据库，而且后面它商业化之后要收费。后来的策略是用diamond的快速blastp将基因集与SwissProt数据库进行比较，得到每个基因最相近的Uniprot ID，再依靠id-mapping文件将基因与GO对应起来，本文最后有简单介绍基于SwissProt做GO注释的流程。</p>
<p>What is GOMAP-Singularity? GOMAP-Singularity is the containerized version of the Gene Ontology Meta Annotator for Plants (GOMAP) pipeline. GOMAP is a high-throughput pipeline to annotate GO terms to plant protein sequences. The pipeline uses three different approaches to annotate GO terms to plant protein sequences, and compile the annotations together to generate an aggregated dataset. GOMAP uses Python code to run the component tools to generate the GO annotations, and R code to clean and aggregate the GO annotations from the component tools.</p>
<p>How do I use GOMAP-Singularity?</p>
<p>Please check &lt;<a href="http://bioinformapping.com/gomap">bioinformapping.com/gomap</a>&gt; for detailed documentation on how to use the container.</p>
<h3 id="install-system-dependencies"><a class="markdownIt-Anchor" href="#install-system-dependencies"></a> Install system dependencies</h3>
<p>You must first install development tools and libraries to your host.<br />
On Debian-based systems:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get update &amp;&amp; \</span><br><span class="line">  sudo apt-get install -y build-essential \</span><br><span class="line">  libseccomp-dev pkg-config squashfs-tools cryptsetup</span><br></pre></td></tr></table></figure>
<p>On CentOS/RHEL:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo yum groupinstall -y &#x27;Development Tools&#x27; &amp;&amp; \</span><br><span class="line">  sudo yum install -y epel-release &amp;&amp; \</span><br><span class="line">  sudo yum install -y golang libseccomp-devel \  </span><br><span class="line">  squashfs-tools cryptsetup</span><br><span class="line">  yum remove golang # 后面手动安装</span><br></pre></td></tr></table></figure>
<h3 id="install-golang"><a class="markdownIt-Anchor" href="#install-golang"></a> Install Golang</h3>
<p>Golang 有多种安装方法，我是在其官网(<a href="https://golang.org/doc/install#download">https://golang.org/doc/install#download</a>)下载<a href="https://golang.org/dl/go1.16.5.linux-amd64.tar.gz">源文件</a>到本地，然后安装到用户目录。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://golang.org/dl/go1.16.5.linux-amd64.tar.gz</span><br><span class="line">tar -zxvf go1.16.5.linux-amd64.tar.gz</span><br><span class="line"></span><br><span class="line"># 将 “export PATH=&quot;/home/fenglei/local/app/go/bin&quot;:$PATH” 写入bashrc</span><br><span class="line">source ~/.bashrc</span><br><span class="line">which go</span><br><span class="line"># ~/local/app/go/bin/go</span><br><span class="line"></span><br><span class="line"># Verify that you&#x27;ve installed Go by opening a command prompt and typing the following command:</span><br><span class="line">go version</span><br><span class="line"># go version go1.16.5 linux/amd64</span><br></pre></td></tr></table></figure>
<h3 id="compiling-singularityce"><a class="markdownIt-Anchor" href="#compiling-singularityce"></a> Compiling SingularityCE</h3>
<p>参考安装方法如下</p>
<p>You can build SingularityCE using the following commands:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cd $&#123;GOPATH&#125;/src/github.com/sylabs/singularity &amp;&amp; \</span><br><span class="line">  ./mconfig &amp;&amp; \</span><br><span class="line">  cd ./builddir &amp;&amp; \</span><br><span class="line">  make &amp;&amp; \</span><br><span class="line">  sudo make install</span><br></pre></td></tr></table></figure>
<p>And that’s it! Now you can check your SingularityCE version by running:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ singularity version</span><br></pre></td></tr></table></figure>
<p>To build in a different folder and to set the install prefix to a different path:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ./mconfig -b ./buildtree -p /usr/local</span><br></pre></td></tr></table></figure>
<p>我的安装如下。</p>
<p>系统自带的gcc（版本4.8.5）编译报错，提示找不到config.c文件。我切换成用户的gcc（版本10.2.0），就可以安装。<br />
启动用户gcc的办法，修改bashrc文件，将下面三行的注释符号去掉，然后source ~/.bashrc即可。以后有必要再回来将这几行注释掉，就恢复系统自带的老版本gcc。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PATH=/home/fenglei/local/gcc-10.2.0/bin/:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=/home/fenglei/local/gcc-10.2.0/lib/:/home/fenglei/local/gcc-10.2.0/lib64/:$LD_LIBRARY_PATH</span><br><span class="line">export LD_LIBRARY_PATH=/home/fenglei/local/lib/:/home/fenglei/local/lib64/:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ git clone https://github.com/sylabs/singularity.git</span><br><span class="line">$ cd singularity  # 该目录下有一个 mconfig 文件</span><br><span class="line"># ./mconfig -b ./buildtree -p /home/fenglei/local</span><br><span class="line"># ./mconfig -b ./buildtree -p /home/fenglei/local --without-suid</span><br><span class="line">$ ./mconfig    # 默认的安装位置是 /usr/local</span><br><span class="line">$ cd /home/fenglei/local/app/singularity/buildtree</span><br><span class="line">$ make</span><br><span class="line"># make install</span><br><span class="line">$ sudo make install</span><br><span class="line"></span><br><span class="line">$ which singularity</span><br><span class="line">/usr/local/bin/singularity</span><br></pre></td></tr></table></figure>
<p>测试：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ singularity version                                                                                        </span><br><span class="line">3.8.0-rc.1+107-g8b21e5a16</span><br></pre></td></tr></table></figure>
<h3 id="gomap-singularity"><a class="markdownIt-Anchor" href="#gomap-singularity"></a> GOMAP-singularity</h3>
<ol>
<li>Singularity 安装</li>
</ol>
<p>上面已经完成。也可参考：<a href="https://bioinformapping.com/gomap/master/RUNNING.html">https://bioinformapping.com/gomap/master/RUNNING.html</a></p>
<ol start="2">
<li>从 git 下载 GOMAP-singularity</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/Dill-PICL/GOMAP-singularity.git</span><br><span class="line">cd GOMAP-singularity</span><br></pre></td></tr></table></figure>
<ol start="3">
<li>配置并下载相关参考数据集</li>
</ol>
<p>Run the setup step to make necessary directories and download data files from CyVerse. The pipeline download is large and would require ~40GB of free hard drive space during the setup step.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ./setup.sh </span><br><span class="line"># 由于GO没安好，导致这一步报错，后面重新安装了GO，并重装singularity</span><br><span class="line"># ERROR  : No setuid installation found, for unprivileged installation use: ./mconfig --without-suid</span><br><span class="line"></span><br><span class="line">$ ./setup.sh </span><br><span class="line">0/1 -  0.00% of files done   0.000/39254.793 MB -  0.00% of file sizes done</span><br><span class="line">Processing GOMAP.sif - 39254.793 MB   2021-06-17.15:58:52</span><br><span class="line">GOMAP.sif - 40.000/39254.793 MB -  0.10% done   2021-06-17.16:00:53</span><br><span class="line">GOMAP.sif - 680.000/39254.793 MB -  1.73% done   2021-06-17.16:02:47</span><br><span class="line">GOMAP.sif - 1360.000/39254.793 MB -  3.46% done   2021-06-17.16:04:49</span><br><span class="line">GOMAP.sif - 2000.000/39254.793 MB -  5.09% done   2021-06-17.16:06:40</span><br><span class="line">GOMAP.sif - 2400.000/39254.793 MB -  6.11% done   2021-06-17.16:08:32</span><br><span class="line">cliReconnManager: Reconnecting clientState = 0</span><br><span class="line">...</span><br><span class="line">cliReconnManager: Reconnecting clientState = 0</span><br><span class="line">The client/server socket connection has been renewed</span><br><span class="line">GOMAP.sif - 30880.000/39254.793 MB - 78.67% done   2021-06-17.17:59:30</span><br><span class="line">GOMAP.sif - 31520.000/39254.793 MB - 80.30% done   2021-06-17.18:01:43</span><br><span class="line">GOMAP.sif - 32040.000/39254.793 MB - 81.62% done   2021-06-17.18:03:45</span><br><span class="line">GOMAP.sif - 32640.000/39254.793 MB - 83.15% done   2021-06-17.18:05:31</span><br><span class="line">GOMAP.sif - 33200.000/39254.793 MB - 84.58% done   2021-06-17.18:07:27</span><br><span class="line">GOMAP.sif - 33373.426/39254.793 MB - 85.02% done   2021-06-17.18:08:24</span><br><span class="line">cliReconnManager: Reconnecting clientState = 0</span><br><span class="line">The client/server socket connection has been renewed</span><br><span class="line">cliReconnManager: Reconnecting clientState = 0</span><br><span class="line">The client/server socket connection has been renewed</span><br><span class="line">cliReconnManager: Reconnecting clientState = 0</span><br><span class="line">The client/server socket connection has been renewed</span><br><span class="line">cliReconnManager: Reconnecting clientState = 0</span><br><span class="line">The client/server socket connection has been renewed</span><br><span class="line">GOMAP.sif - 39254.793/39254.793 MB - 100.00% done   2021-06-17.18:45:46</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol start="4">
<li>测试 GOMAP 注释流程</li>
</ol>
<p>[optional]: Test whether the container and the data files are working as intended.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ./test.sh</span><br><span class="line"></span><br><span class="line">Running Sequence-similarity based Annotation Step</span><br><span class="line">/usr/local/lib/python2.7/dist-packages/Bio/SearchIO/__init__.py:211: BiopythonExperimentalWarning: Bio.SearchIO is an experimental submodule which may undergo significant changes prior to its future official release.</span><br><span class="line">  BiopythonExperimentalWarning)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Building a new DB, current time: 06/17/2021 20:59:09</span><br><span class="line">New DB name:   /workdir/test/GOMAP-0.3_GOMAP-input/input/0.3_GOMAP-input.fa</span><br><span class="line">New DB title:  /workdir/test/GOMAP-0.3_GOMAP-input/input/0.3_GOMAP-input.fa</span><br><span class="line">Sequence type: Protein</span><br><span class="line">...</span><br><span class="line">Checking gaf file for simple errors and fixing them</span><br><span class="line">There were 34 warnings (use warnings() to see them)</span><br><span class="line">[1] &quot;Checking if data/data/go/go.obo.data exists&quot;</span><br><span class="line">[1] &quot;data/data/go/go.obo.data exists so loading R object&quot;</span><br><span class="line">   user  system elapsed </span><br><span class="line">  2.547   0.078   2.624 </span><br><span class="line">[1] &quot;Reading All Datasets&quot;</span><br><span class="line">Checking gaf file for simple errors and fixing them</span><br><span class="line">[1] 1714</span><br><span class="line">[1] &quot;Removing Redundancy&quot;</span><br><span class="line">[1] 18</span><br><span class="line">Compiling Non-Redundant Comprehensive Data</span><br><span class="line">There were 50 or more warnings (use warnings() to see the first 50)</span><br></pre></td></tr></table></figure>
<ol start="5">
<li>实战篇：学习自定义配置文件 Edit the config file</li>
</ol>
<p>a. Declare export GOMAP_LOC environment variable. Edit <code>~/.bashrc</code> as below:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export GOPATH=&quot;/home/fenglei/local/app/go&quot;</span><br><span class="line">export GOMAP_LOC=&quot;/home/fenglei/local/app/GOMAP-singularity/install/location&quot;</span><br></pre></td></tr></table></figure>
<p>b. Download the <a href="https://bioinformapping.com/gomap/master/_static/min-config.yml">config.yml</a> file and make necessary changes. Change the highlighted lines to fit your input data.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#Input section </span><br><span class="line">input:</span><br><span class="line">  #input fasta file name</span><br><span class="line">  fasta: GOMAP-input.fa</span><br><span class="line">  # output file basename</span><br><span class="line">  basename: GOMAP_output</span><br><span class="line">  #input NCBI taxonomy id</span><br><span class="line">  taxon: &quot;123456&quot;</span><br><span class="line">  # Name of the species</span><br><span class="line">  species: &quot;Glycine max&quot;</span><br><span class="line">  # Email is mandatory</span><br><span class="line">  email: myname#gmail.com</span><br><span class="line">  #Number of CPUs used for tools</span><br><span class="line">  cpus: 4</span><br><span class="line">  #Whether openmpi should be used</span><br><span class="line">  mpi: False</span><br><span class="line">  #what the name of the temporary directory is</span><br><span class="line">  tmpdir: &quot;/tmpdir&quot;</span><br></pre></td></tr></table></figure>
<ol start="6">
<li>Run pipeline</li>
</ol>
<p>可直接修改 <a href="http://test.sh">test.sh</a> 并运行该脚本。也可参考软件手册分步骤运行。<br />
下面摘抄的是在单机（SINGLE）运行的模式，软件手册里也有在集群（MPI）运行的示范代码。<br />
<a href="http://test.sh">test.sh</a> 与 test目录在同一个路径。GOMAP-input.fa 与 config.yml 都在test目录下。输入的蛋白序列，其尾部如果有表示stop codon的星号，要移除星号。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># seqsim</span><br><span class="line">./run-GOMAP-SINGLE.sh --step=seqsim --config=test/config.yml</span><br><span class="line"># domain</span><br><span class="line">./run-GOMAP-SINGLE.sh --step=domain --config=test/config.yml</span><br><span class="line"># fanngo</span><br><span class="line">./run-GOMAP-SINGLE.sh --step=fanngo --config=test/config.yml</span><br><span class="line"># mixmeth-blast</span><br><span class="line">./run-GOMAP-SINGLE.sh --step=mixmeth-blast --config=test/config.yml</span><br><span class="line"># mixmeth-preproc</span><br><span class="line">./run-GOMAP-SINGLE.sh --step=mixmeth-preproc --config=test/config.yml</span><br><span class="line"># mixmeth</span><br><span class="line">./run-GOMAP-SINGLE.sh --step=mixmeth --config=test/config.yml</span><br><span class="line"># aggregate</span><br><span class="line"># Attention: Please wait for all your Argot2.5 jobs to finish before running this step. You will get emails from Argot2.5 when your jobs are submitted and when they are finished. You can also check the status of all current jobs from all users here.</span><br><span class="line">./run-GOMAP-SINGLE.sh --step=aggregate --config=test/config.yml</span><br></pre></td></tr></table></figure>
<h3 id="附注用-swissprot-与-idmapping-来做-go"><a class="markdownIt-Anchor" href="#附注用-swissprot-与-idmapping-来做-go"></a> 附注：用 SwissProt 与 idmapping 来做 GO</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">## SwissProt 文件是氨基酸序列，比较大</span><br><span class="line">wget ftp://ftp.ncbi.nih.gov/blast/db/FASTA/swissprot.gz</span><br><span class="line">## idmapping.tb.gz 文件可能下载链接有变化</span><br><span class="line">wget ftp://ftp.pir.georgetown.edu/databases/idmapping/idmapping.tb.gz</span><br><span class="line">## swissprot index 建立</span><br><span class="line">diamond makedb --in swissprot -d swissprot</span><br><span class="line">## 序列比对</span><br><span class="line">diamond blastp -d /PATH/TO/index/swissprot -q input.proteins.fa -k 1 -e 0.00001 -o swissprot_blastp.out</span><br><span class="line">## idmapping 文件整理，下文有摘抄文件具体内容</span><br><span class="line">awk -F &quot;\t&quot;  &#x27;&#123;print $1&quot;\t&quot;$8&#125;&#x27; idmapping.tb &gt; uniprotID-GOnumber.tab</span><br><span class="line">## 将“基因-Uniprot-GO”的关系建立起来</span><br><span class="line">perl UniProt2GO_annotate.pl uniprotID-GOnumber.tab swiss_dia_matches.m8 swiss_GO_matches.tab</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ head idmapping.tb </span><br><span class="line">Q6GZX4  001R_FRG3G      2947773 YP_031579.1     81941549; 49237298              PF04947 GO:0006355; GO:0046782; GO:0006351                      UniRef100_Q6GZX4        UniRef90_Q6GZX4 UniRef50_Q6GZX4 UPI00003B0FD4           65492415165820 AY548484        AAT09660.1</span><br><span class="line">Q6GZX3  002L_FRG3G      2947774 YP_031580.1     49237299; 81941548; 47060117            PF03003 GO:0033644; GO:0016021                  UniRef100_Q6GZX3        UniRef90_Q6GZX3 UniRef50_Q6GZX3 UPI00003B0FD5           654924        15165820 AY548484        AAT09661.1</span><br><span class="line">Q197F8  002R_IIV3       4156251 YP_654574.1     109287880; 123808694; 106073503                                         UniRef100_Q197F8        UniRef90_Q197F8 UniRef50_Q197F8 UPI0000D83464           345201                        16912294 DQ643392        ABF82032.1</span><br><span class="line">Q197F7  003L_IIV3       4156252 YP_654575.1     106073504; 109287881; 123808693                                         UniRef100_Q197F7        UniRef90_Q197F7 UniRef50_Q197F7 UPI0000D83465           345201                        16912294 DQ643392        ABF82033.1</span><br><span class="line">Q6GZX2  003R_FRG3G      2947775 YP_031581.1     81941547; 49237300                                              UniRef100_Q6GZX2        UniRef90_Q6GZX2 UniRef50_Q6GZX2 UPI00003B0FD6           654924                          15165820       AY548484        AAT09662.1</span><br><span class="line">Q6GZX1  004R_FRG3G      2947776 YP_031582.1     49237301; 81941546                      GO:0033644; GO:0016021                  UniRef100_Q6GZX1        UniRef90_Q6GZX1 UniRef50_Q6GZX1 UPI00003B0FD7           654924                15165820 AY548484        AAT09663.1</span><br><span class="line">Q197F5  005L_IIV3       4156254 YP_654577.1     123808691; 109287883; 106073506                                         UniRef100_Q197F5        UniRef90_Q197F5 UniRef50_Q197F5 UPI0000D83467           345201                        16912294 DQ643392        ABF82035.1</span><br><span class="line">Q6GZX0  005R_FRG3G      2947777 YP_031583.1     47060120; 49237302; 81941545            PF02393                         UniRef100_Q6GZX0        UniRef90_Q6GZX0 UniRef50_Q6GZX0 UPI00003B0FD8           654924                        15165820 AY548484        AAT09664.1</span><br><span class="line">Q91G88  006L_IIV6       1733056 NP_149469.1     82012333; 15078718; 15042163            PF04383; PF12299                                UniRef100_Q91G88        UniRef90_Q91G88 UniRef50_Q91G88 UPI00000F3D32           176652        2820141; 3959991; 7698884; 8492091; 17239238; 8021587; 10456793; 8121799; 9926400; 16789247; 11448171; 1475907; 3201750; 9482589; 1549908; 8073636       AF303741        AAK81943.1</span><br><span class="line">Q6GZW9  006R_FRG3G      2947778 YP_031584.1     81941544; 49237303                                              UniRef100_Q6GZW9        UniRef90_Q6GZW9 UniRef50_Q6GZW9 UPI00003B0FD9           654924                          15165820       AY548484        AAT09665.1</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ head swiss_GO_matches.tab</span><br><span class="line">Q6GZX4  GO:0006355; GO:0046782; GO:0006351</span><br><span class="line">Q6GZX3  GO:0033644; GO:0016021</span><br><span class="line">Q197F8</span><br><span class="line">Q197F7</span><br><span class="line">Q6GZX2</span><br><span class="line">Q6GZX1  GO:0033644; GO:0016021</span><br><span class="line">Q197F5</span><br><span class="line">Q6GZX0</span><br><span class="line">Q91G88</span><br><span class="line">Q6GZW9</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ head swiss_GO_matches.tab</span><br><span class="line">gene1 Q9M9M9  GO:0050897; GO:0009055; GO:0008137; GO:0009735; GO:0006979; GO:0005747; GO:0005739</span><br><span class="line">gene2 Q9LP77  GO:0005524; GO:0004672; GO:0016021; GO:0005886; GO:0009506; GO:0005774</span><br><span class="line">gene3 Q9CAL2  GO:0005524; GO:0004674; GO:0016021; GO:0005886</span><br><span class="line">gene4 A4FLF6</span><br><span class="line">gene5 Q8RY67  GO:0005524; GO:0004674; GO:0007166; GO:0016021; GO:0005886</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cat UniProt2GO_annotate.pl</span><br><span class="line">#!/usr/bin/perl</span><br><span class="line">use warnings;</span><br><span class="line">use strict;</span><br><span class="line"></span><br><span class="line">open IDMAPPING, $ARGV[0] or die $!;</span><br><span class="line">open BLASTOUT, $ARGV[1] or die $!;</span><br><span class="line">open OUT, &quot;&gt;$ARGV[2]&quot; or die $!;</span><br><span class="line">select OUT;</span><br><span class="line"></span><br><span class="line">my %id2go;</span><br><span class="line"></span><br><span class="line">while(&lt;IDMAPPING&gt;)&#123;</span><br><span class="line">        chomp $_;</span><br><span class="line">        my @array1=split(/\t/);</span><br><span class="line">        $id2go&#123;$array1[0]&#125;=$array1[1];</span><br><span class="line">#       print &quot;$array1[1]\n&quot;; exit;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">while(&lt;BLASTOUT&gt;)&#123;</span><br><span class="line">        chomp $_;</span><br><span class="line">        my @array2=split(/\t/);</span><br><span class="line">        my $geneid=$array2[0];</span><br><span class="line">        my $UniprotID=$array2[1];</span><br><span class="line">#       print &quot;$UniprotID\n&quot;;</span><br><span class="line">        $UniprotID =~ s/\.[0-9]$//;</span><br><span class="line">#       print &quot;$geneid\t$&#123;UniprotID&#125;test\n&quot;; exit;</span><br><span class="line">        if(exists $id2go&#123;$UniprotID&#125;)&#123; print &quot;$geneid\t$UniprotID\t$id2go&#123;$UniprotID&#125;\n&quot;;&#125;</span><br><span class="line">        else&#123;print &quot;$geneid\t$UniprotID\n&quot;;&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">close IDMAPPING;</span><br><span class="line">close BLASTOUT;</span><br><span class="line">close OUT;</span><br></pre></td></tr></table></figure>
<p>经过一系列的转换，得到下面格式的文件，就可以在R程序里面用于GO数据库的构建。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ zcat GMA_GO_TERM.txt.gz | head</span><br><span class="line">GID     GO      ONTOLOGY        EVIDENCE</span><br><span class="line">Glyma.01G000100 GO:0006412      P       IEA</span><br><span class="line">Glyma.01G000100 GO:0009063      P       IEA</span><br><span class="line">Glyma.01G000100 GO:0009234      P       IEA</span><br><span class="line">Glyma.01G000100 GO:0016021      C       IEA</span><br><span class="line">Glyma.01G000100 GO:0031969      C       IEA</span><br><span class="line">Glyma.01G000100 GO:0016835      F       IEA</span><br><span class="line">Glyma.01G000100 GO:0030976      F       IEA</span><br><span class="line">Glyma.01G000100 GO:0070204      F       IEA</span><br><span class="line">Glyma.01G000137 GO:0016043      P       IEA</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Linux编辑器vim配置：spf13-vim</title>
    <url>/2020/04/24/Linux-How-to-set-vim-by-spf13-vim/</url>
    <content><![CDATA[<p>spf13懒人工具（<a href="http://vim.spf13.com/%EF%BC%89%E6%98%AF%E4%B8%80%E5%A5%97vim%E6%8F%92%E4%BB%B6%E7%BB%84%E6%88%90%E7%9A%84%E6%8F%92%E4%BB%B6%E9%9B%86%EF%BC%8C%E5%AE%89%E8%A3%85spf13%E5%8D%B3%E6%98%AF%E5%AE%89%E8%A3%85%E4%B8%80%E5%A5%97%E6%8F%92%E4%BB%B6">http://vim.spf13.com/）是一套vim插件组成的插件集，安装spf13即是安装一套插件</a>. 安装过程：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">curl https://j.mp/spf13-vim3 -L &gt; spf13-vim.sh &amp;&amp; sh spf13-vim.sh</span><br></pre></td></tr></table></figure>
<p>安装之后，home目录下会多出一系列文件 <img src="https://genehub.files.wordpress.com/2020/04/e5beaee4bfa1e688aae59bbe_20200424171301.png" alt="微信截图_20200424171301" /> 安装完毕之后，我使用vim编辑脚本，发现并没有语法高亮，我用的两个系统分别是CentOS7和Ubuntu。于是参考资料，在home目录新增了一 <code>.vimrc.local</code> 文件，写入个性化设置的内容，然后打开编辑器就可以看到语法高亮了！</p>
<h2 id="customization"><a class="markdownIt-Anchor" href="#customization"></a> Customization</h2>
<p>Create <code>~/.vimrc.local</code> and <code>~/.gvimrc.local</code> for any local customizations. For example, to override the default color schemes，新建 <code>~/.vimrc.local</code> 文件并写入以下内容。</p>
<p>set t_Co=256 &quot; required&quot;<br />
colorscheme desert</p>
<p>[caption id=“attachment_1091” align=“alignleft” width=“403”]<img src="https://genehub.files.wordpress.com/2020/04/e5beaee4bfa1e688aae59bbe_20200424171937.png" alt="微信截图_20200424171937" /> 个性化配置之前[/caption]                     [caption id=“attachment_1092” align=“alignleft” width=“399”]<img src="https://genehub.files.wordpress.com/2020/04/e5beaee4bfa1e688aae59bbe_20200424172602.png" alt="微信截图_20200424172602" /> 个性化配置之后[/caption]                     其实有多种配色主题可以选择，我直接用了desert测试就很满意，所以没有测试其他的。 参考资料： <a href="https://blog.csdn.net/simple%5C_the%5C_best/article/details/51901361">https://blog.csdn.net/simple\_the\_best/article/details/51901361</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Tmux的使用</title>
    <url>/2016/01/28/Linux-How-to-use-tmux-in-Linux/</url>
    <content><![CDATA[<p>介绍 <a href="https://wiki.freebsdchina.org/software/t/tmux">tmux</a>是一个优秀的终端复用软件，即使非正常掉线，也能保证当前的任务运行，这一点对于 远程SSH访问特别有用，网络不好的情况下仍然能保证工作现场不丢失!此外，tmux完全使用键盘 控制窗口，实现窗口的切换功能。 简单地说，tmux对于我主要有两个功能（这应该也是tmux的主要功能）:</p>
<ol>
<li>split窗口。可以在一个terminal下打开多个终端，也可以对当前屏幕进行各种split，即可以 同时打开多个显示范围更小的终端。</li>
<li>在使用SSH的环境下，避免网络不稳定，导致工作现场的丢失。想象以下场景， 你在执行一条命令的过程中，由于网络不稳定，SSH连接断开了。这个时候，你就不知道之前 的那条命令是否执行成功。如果此时你打开了很多文件，进入了较深层次的目录，由于网络 不稳定，SSH连接断开。重新连接以后，你又不得不重新打开那些文件，进入那个深层次的 目录。如果使用了tmux，重新连接以后，就可以直接回到原来的工作环境，不但提高了工作 效率，还降低了风险，增加了安全性。</li>
</ol>
<h3 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install tmux</span><br></pre></td></tr></table></figure>
<p>安装完成后输入命令tmux即可打开软件，界面十分简单，类似一个下方带有状态栏的终端控制台； 不出意外，这时候你会跟我第一次一样，觉得tmux没什么牛逼的。</p>
<h3 id="会话窗口面板"><a class="markdownIt-Anchor" href="#会话窗口面板"></a> 会话，窗口，面板</h3>
<p>根据tmux的定义，在开启了tmux服务器后，会首先创建一个会话，而这个会话则会首先创建一个 窗口，其中仅包含一个面板；也就是说，这里看到的所谓终端控制台应该称作tmux的一个面板， 虽然其使用方法与终端控制台完全相同。 tmux使用C/S模型构建，主要包括以下单元模块：</p>
<ul>
<li>server服务器。输入tmux命令时就开启了一个服务器。</li>
<li>session会话。一个服务器可以包含多个会话</li>
<li>window窗口。一个会话可以包含多个窗口。</li>
<li>pane面板。一个窗口可以包含多个面板。</li>
</ul>
<h3 id="初体验"><a class="markdownIt-Anchor" href="#初体验"></a> 初体验</h3>
<p>我们先来看一张效果图，再来学习tmux的配置和使用我一般都是这么用，因为我的笔记本 只有13寸:-) <img src="http://mingxinglai.com/cn/image/tmux-small.jpg" alt="tmux-small" /> 当然，做为一个准IT男，我还有一个很大的屏幕，所以我偶尔也这么用： <img src="http://mingxinglai.com/cn/image/tmux-large.jpg" alt="tmux-large" /> 你所看到的只是X个会话中的一个会话，且是该会话下面的Y个窗口中的一个窗口。是的，你在一 个窗口里就可以拥有这么多个终端，这就是tmux的主要功能。好了，下面是tmux的常用按键，你 先自己玩一下再往下看吧。</p>
<h3 id="常用按键"><a class="markdownIt-Anchor" href="#常用按键"></a> 常用按键</h3>
<p>这里需要说明一点的是，tmux的任何指令，都包含一个前缀，也就是说，你按了前缀(一组按键， 默认是Ctrl+b)以后，系统才知道你接下来的指令是发送给tmux的。</p>
<ul>
<li>C-b ? 显示快捷键帮助</li>
<li>C-b C-o 调换窗口位置，类似与vim 里的C-w</li>
<li>C-b 空格键 采用下一个内置布局</li>
<li>C-b ! 把当前窗口变为新窗口</li>
<li>C-b &quot; 横向分隔窗口</li>
<li>C-b % 纵向分隔窗口</li>
<li>C-b q 显示分隔窗口的编号</li>
<li>C-b o 跳到下一个分隔窗口</li>
<li>C-b 上下键 上一个及下一个分隔窗口</li>
<li>C-b C-方向键 调整分隔窗口大小</li>
<li>C-b c 创建新窗口</li>
<li>C-b 0~9 选择几号窗口</li>
<li>C-b c 创建新窗口</li>
<li>C-b n 选择下一个窗口</li>
<li>C-b l 切换到最后使用的窗口</li>
<li>C-b p 选择前一个窗口</li>
<li>C-b w 以菜单方式显示及选择窗口</li>
<li>C-b t 显示时钟</li>
<li>C-b ; 切换到最后一个使用的面板</li>
<li>C-b x 关闭面板</li>
<li>C-b &amp; 关闭窗口</li>
<li>C-b s 以菜单方式显示和选择会话</li>
<li>C-b d 退出tumx，并保存当前会话，这时，tmux仍在后台运行，可以通过tmux attach进入 到指定的会话</li>
</ul>
<h3 id="配置"><a class="markdownIt-Anchor" href="#配置"></a> 配置</h3>
<p>参考：<a href="http://mingxinglai.com/cn/2012/09/tmux/">http://mingxinglai.com/cn/2012/09/tmux/</a></p>
<h3 id="附安装记录"><a class="markdownIt-Anchor" href="#附安装记录"></a> 附安装记录。</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo yum install tmux</span><br><span class="line">[sudo] password for user: </span><br><span class="line">Loaded plugins: fastestmirror</span><br><span class="line">Determining fastest mirrors</span><br><span class="line">epel/x86_64/metalink                                                                                                                                                                                            | 9.1 kB  00:00:00     </span><br><span class="line"> * base: ftp.cuhk.edu.hk</span><br><span class="line"> * epel: hkg.mirror.rackspace.com</span><br><span class="line"> * extras: ftp.cuhk.edu.hk</span><br><span class="line"> * updates: mirrors.icidc.com</span><br><span class="line">base                                                                                                                                                                                                            | 3.6 kB  00:00:00     </span><br><span class="line">epel                                                                                                                                                                                                            | 4.7 kB  00:00:00     </span><br><span class="line">extras                                                                                                                                                                                                          | 2.9 kB  00:00:00     </span><br><span class="line">ius                                                                                                                                                                                                             | 1.3 kB  00:00:00     </span><br><span class="line">ius-testing                                                                                                                                                                                                     | 1.3 kB  00:00:00     </span><br><span class="line">updates                                                                                                                                                                                                         | 2.9 kB  00:00:00     </span><br><span class="line">(1/5): updates/7/x86_64/primary_db                                                                                                                                                                              | 4.0 MB  00:00:00     </span><br><span class="line">(2/5): epel/x86_64/updateinfo                                                                                                                                                                                   | 1.0 MB  00:00:00     </span><br><span class="line">(3/5): ius-testing/x86_64/primary                                                                                                                                                                               | 1.4 kB  00:00:01     </span><br><span class="line">(4/5): epel/x86_64/primary_db                                                                                                                                                                                   | 6.9 MB  00:00:02     </span><br><span class="line">(5/5): ius/x86_64/primary                                                                                                                                                                                       | 129 kB  00:00:02     </span><br><span class="line">ius                                                                                                                                                                                                                            584/584</span><br><span class="line">ius-testing                                                                                                                                                                                                                        2/2</span><br><span class="line">Resolving Dependencies</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package tmux.x86_64 0:1.8-4.el7 will be installed</span><br><span class="line">--&gt; Processing Dependency: libevent-2.0.so.5()(64bit) for package: tmux-1.8-4.el7.x86_64</span><br><span class="line">--&gt; Running transaction check</span><br><span class="line">---&gt; Package libevent.x86_64 0:2.0.21-4.el7 will be installed</span><br><span class="line">--&gt; Finished Dependency Resolution</span><br><span class="line"></span><br><span class="line">Dependencies Resolved</span><br><span class="line"></span><br><span class="line">=======================================================================================================================================================================================================================================</span><br><span class="line"> Package                                                 Arch                                                  Version                                                       Repository                                           Size</span><br><span class="line">=======================================================================================================================================================================================================================================</span><br><span class="line">Installing:</span><br><span class="line"> tmux                                                    x86_64                                                1.8-4.el7                                                     base                                                243 k</span><br><span class="line">Installing for dependencies:</span><br><span class="line"> libevent                                                x86_64                                                2.0.21-4.el7                                                  base                                                214 k</span><br><span class="line"></span><br><span class="line">Transaction Summary</span><br><span class="line">=======================================================================================================================================================================================================================================</span><br><span class="line">Install  1 Package (+1 Dependent package)</span><br><span class="line"></span><br><span class="line">Total download size: 457 k</span><br><span class="line">Installed size: 1.3 M</span><br><span class="line">Is this ok [y/d/N]: y</span><br><span class="line">Downloading packages:</span><br><span class="line">(1/2): libevent-2.0.21-4.el7.x86_64.rpm                                                                                                                                                                         | 214 kB  00:00:00     </span><br><span class="line">(2/2): tmux-1.8-4.el7.x86_64.rpm                                                                                                                                                                                | 243 kB  00:00:00     </span><br><span class="line">---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------</span><br><span class="line">Total                                                                                                                                                                                                  1.1 MB/s | 457 kB  00:00:00     </span><br><span class="line">Running transaction check</span><br><span class="line">Running transaction test</span><br><span class="line">Transaction test succeeded</span><br><span class="line">Running transaction</span><br><span class="line">  Installing : libevent-2.0.21-4.el7.x86_64                                                                                                                                                                                        1/2 </span><br><span class="line">  Installing : tmux-1.8-4.el7.x86_64                                                                                                                                                                                               2/2 </span><br><span class="line">  Verifying  : tmux-1.8-4.el7.x86_64                                                                                                                                                                                               1/2 </span><br><span class="line">  Verifying  : libevent-2.0.21-4.el7.x86_64                                                                                                                                                                                        2/2 </span><br><span class="line"></span><br><span class="line">Installed:</span><br><span class="line">  tmux.x86_64 0:1.8-4.el7                                                                                                                                                                                                              </span><br><span class="line"></span><br><span class="line">Dependency Installed:</span><br><span class="line">  libevent.x86_64 0:2.0.21-4.el7                                                                                                                                                                                                       </span><br><span class="line"></span><br><span class="line">Complete!</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | Installation of Tomcat 9, Java 8, and MySQL 5.7.20</title>
    <url>/2021/01/05/Linux-Installation-of-Tomcat-9/</url>
    <content><![CDATA[<p>Tomcat 服务器是一个免费的开放源代码的 Web 应用服务器，属于轻量级应用服务器，在中小型系统和并发访问用户不是很多的场合下被普遍使用，是开发和调试 JSP 程序的首选。Tomcat 是一个 JSP/Servlet 容器。其作为 Servlet 容器，有三种工作模式：独立的 Servlet 容器、进程内的 Servlet 容器和进程外的 Servlet 容器。</p>
<p>tomcat 与 nginx、apache的区别是什么？这三者都是 web server，那他们各自有什么特点呢？他们之间的区别是什么呢？Apache Tomcat 是 Apache 基金会下的一个项目，与 Apache HTTP Server 相比，Tomcat 能够动态的生成资源并返回到客户端。Apache HTTP Server 和 Nginx 都能够将某一个文本文件的内容通过 HTTP 协议返回到客户端，但是这个文本文件的内容是固定的——也就是说无论何时、任何人访问它得到的内容都是完全相同的，这样的资源我们称之为静态资源。动态资源则与之相反，在不同的时间、不同的客户端访问得到的内容是不同的，例如：包含显示当前时间的页面显示当前IP地址的页面。（摘抄自：<a href="https://www.zhihu.com/question/32212996/answer/87524617">David</a>）</p>
<h2 id="一-下载安装-java"><a class="markdownIt-Anchor" href="#一-下载安装-java"></a> 一、下载安装 Java</h2>
<p>Tomcat是应用（Java）服务器，它只是一个Servlet(JSP也翻译成Servlet)容器，可以认为是Apache的扩展，但是可以独立于Apache运行。要安装 Tomcat 9，我们将需要 JAVA 8 或更高版本。 所以首先我们需要在我们的系统上安装和设置 JAVA。 您可以使用以下命令安装 JAVA。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># tomcat 9 版本需要java8以上才能支持</span><br><span class="line">cd /tmp &amp;&amp; wget --no-check-certificate --no-cookies --header &quot;Cookie: oraclelicense=accept-securebackup-cookie&quot; http://download.oracle.com/otn-pub/java/jdk/8u131-b11/d54c1d3a095b4ff2b6607d096fa80163/jdk-8u131-linux-x64.rpm </span><br><span class="line">rpm -ivh jdk-8u131-linux-x64.rpm</span><br><span class="line"></span><br><span class="line"># 修改环境变量：</span><br><span class="line">vi + /etc/profile </span><br><span class="line"></span><br><span class="line"># 加入下列信息</span><br><span class="line">JAVA_HOME=/usr/java/jdk1.8.0_131 </span><br><span class="line">CLASSPATH=.:$JAVA_HOME/lib.tools.jar </span><br><span class="line">PATH=$JAVA_HOME/bin:$PATH</span><br><span class="line">export JAVA_HOME CLASSPATH PATH </span><br><span class="line"></span><br><span class="line"># 保存退出之后加载环境变量</span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<p>Optional:</p>
<p>CentOS/RHEL</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo yum install java-1.8.0</span><br></pre></td></tr></table></figure>
<p>Ubuntu/Debian</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ sudo apt-get install openjdk-8*</span><br></pre></td></tr></table></figure>
<h2 id="二-linux-上安装-apache-tomcat"><a class="markdownIt-Anchor" href="#二-linux-上安装-apache-tomcat"></a> 二、Linux 上安装 Apache Tomcat</h2>
<p>对于 Apache Tomcat 安装，我们将使用以下命令从<a href="https://tomcat.apache.org/download-90.cgi">官方网站</a>下载已存档的软件包，</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://apache.website-solution.net/tomcat/tomcat-9/v9.0.41/bin/apache-tomcat-9.0.41.tar.gz</span><br><span class="line"># 一旦文件完成下载，解压缩/opt目录中的包（我们也可以使用一些其他的目录/数据等）。 在终端中运行以下命令来提取文件，</span><br><span class="line">sudo tar -xvzf pache-tomcat-8.5.23.tar.gz -C /opt</span><br><span class="line">sudo mv /opt/apache-tomcat-8.5.23/ /opt/tomcat</span><br><span class="line"># Optional: 更改tomcat目录的权限</span><br><span class="line">sudo chown -hR fenglei /opt/tomcat</span><br><span class="line">cd /opt/tomcat/bin</span><br><span class="line">sh startup.sh</span><br></pre></td></tr></table></figure>
<p>如果上面的 startup 成功运行，会收到以下提示。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Using CATALINA_BASE:   /opt/tomcat</span><br><span class="line">Using CATALINA_HOME:   /opt/tomcat</span><br><span class="line">Using CATALINA_TMPDIR: /opt/tomcat/temp</span><br><span class="line">Using JRE_HOME:        /usr</span><br><span class="line">Using CLASSPATH:       /opt/tomcat/bin/bootstrap.jar:/opt/tomcat/bin/tomcat-juli.jar</span><br><span class="line">Using CATALINA_OPTS:   </span><br><span class="line">Tomcat started.</span><br></pre></td></tr></table></figure>
<p>使用如下命令开放 Linux 的 8080 端口,再访问 <a href="http://192.168.1.100:8080">http://192.168.1.100:8080</a> 即可打开一个 tomcat 网页。192.168.1.100 是 apache tomcat 服务器的 IP 地址，根据实际情况更改该地址。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo iptables -A INPUT -ptcp --dport 8080 -j ACCEPT</span><br></pre></td></tr></table></figure>
<p><img src="https://ask.qcloudimg.com/http-save/yehe-1000017/eeqqalywve.jpeg?imageView2/2/w/1620" alt="tomcat初始化页面示意图" /></p>
<p>此时在这个tomcat初始页面里，点击“Manager App”按钮会显示无法进入，需要设定conf/tomcat-users.xml文件。</p>
<p>Tomcat 的目录结构</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">bin  # 脚本启动目录</span><br><span class="line">conf #配置文件目录</span><br><span class="line">lib  #tomcat运行的依赖包</span><br><span class="line">logs #日志文件目录</span><br><span class="line">temp #临时文件目录</span><br><span class="line">webapps  # 用来存放应用程序</span><br><span class="line">    --docs  # 文档</span><br><span class="line">    --examples # 示例</span><br><span class="line">    --host-manager # 虚拟主机web管理界面</span><br><span class="line">    --manager # 管理界面</span><br><span class="line">    --ROOT # 默认访问的应用程序</span><br><span class="line">work # 部署的Web应用程序的临时工作目录，当我们需要清除缓存的时候可以将该目录删除，然后重启动 tomcat。</span><br></pre></td></tr></table></figure>
<p>这里有个详细的介绍。包括后面怎么连接的网页：<a href="https://www.cnblogs.com/operationhome/p/10021645.html">tomcat 安装以及常用配置</a></p>
<h3 id="tomcat-9-manager-配置"><a class="markdownIt-Anchor" href="#tomcat-9-manager-配置"></a> Tomcat 9 Manager 配置</h3>
<ol>
<li>首先配置两种角色：</li>
</ol>
<p>找到 tomcat 解压目录下的 conf/tomcat-users.xml 文件，用记事本打开，如下图添加角色，自定义处我都填了 “tomcat”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;role rolename=&quot;manager-gui&quot;/&gt; </span><br><span class="line">&lt;role rolename=&quot;admin-gui&quot;/&gt; </span><br><span class="line">&lt;user username=&quot;自定义&quot; password=&quot;自定义&quot; roles=&quot;manager-gui,admin-gui&quot;/&gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190315150949838.png" alt="注意图中蓝色部分不用去掉，否则会出现 401 错误" /></p>
<ol start="2">
<li>更改 tomcat 目录下的 webapps\manager\META-INF/context.xml 文件</li>
</ol>
<p>如下图，对<Valve  /> 和<Manager  />进行注释</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;!--</span><br><span class="line">  &lt;Valve className=&quot;org.apache.catalina.valves.RemoteAddrValve&quot;</span><br><span class="line">     allow=&quot;127\.\d+\.\d+\.\d+|::1|0:0:0:0:0:0:0:1&quot; /&gt;</span><br><span class="line">  &lt;Manager sessionAttributeValueClassNameFilter=&quot;java\.lang\.(?:Boolean|Integer|Long|Number|String)|org\.apache\.catalina\.filters\.CsrfPreventionFilter\$LruCache(?:\$1)?|java\.util\.(?:Linked)?HashMap&quot;/&gt;</span><br><span class="line">--&gt;</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20190315151458443.png" alt="" /></p>
<p>然后重启 tomcat，从网页端点击 “Manager App”，就可以进入 “Tomcat Web 应用程序管理者”。</p>
<p><img src="https://img2020.cnblogs.com/blog/1552500/202010/1552500-20201015101304750-1675230814.png" alt="" /></p>
<h3 id="端口设置与编码配置文件设置"><a class="markdownIt-Anchor" href="#端口设置与编码配置文件设置"></a> 端口设置与编码配置文件设置</h3>
<p><strong>更改端口</strong></p>
<p>编辑配置文件 server.xml，大约在第 69 行，可以将 port=“8080” 更改成我们想绑定的端口。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">       connectionTimeout=&quot;20000&quot;</span><br><span class="line">       redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>
<p><strong>配置编码</strong></p>
<p>为了避免程序上的一些请求和返回的中文乱码问题，我们需要配置。编辑配置文件 server.xml。</p>
<p>大约在69行后,添加 useBodyEncodingForURI=“true” URIEncoding=“UTF-8”</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               useBodyEncodingForURI=&quot;true&quot; URIEncoding=&quot;UTF-8&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>
<h3 id="tomcat-启动与关闭"><a class="markdownIt-Anchor" href="#tomcat-启动与关闭"></a> Tomcat 启动与关闭</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 启动 tomcat</span><br><span class="line">/opt/tomcat/bin/startup.sh </span><br><span class="line">#或者</span><br><span class="line">/opt/tomcat/bin/catalina.sh start</span><br><span class="line"># </span><br><span class="line"># 关闭tomcat</span><br><span class="line">/opt/tomcat/bin/shutdown.sh</span><br><span class="line">#或者</span><br><span class="line">/opt/tomcat/bin/catalina.sh stop</span><br><span class="line">#还可以直接kill 进程号，当我们的tomcat是有用户进行访问的时候，我们杀死不了这个进程，只能通过强制杀死 kill -9</span><br><span class="line"># 查看当前的版本</span><br><span class="line">/opt/tomcat/bin/version.sh</span><br></pre></td></tr></table></figure>
<h3 id="tomcat-部署项目"><a class="markdownIt-Anchor" href="#tomcat-部署项目"></a> Tomcat 部署项目</h3>
<p>方法1：直接将 war 包放在 ./webapps 下，tomcat 会自动将war解压。</p>
<p><img src="https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/tomcat%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/tomcat%20%E9%83%A8%E7%BD%B2%E6%96%B9%E6%B3%95%E4%B8%80.png" alt="" /></p>
<p>方法2：更改配置文件 server.xml(官方不建议使用该方法)</p>
<p>我们可以在 ./conf/ 目录下找到 server.xml 文件，我们需要在里面添加上我们的项目的访问路径和存放路径配置。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;Context  path=&quot;/djx&quot; docBase=&quot;/tmp/djx/&quot; reloadable=&quot;true&quot; /&gt;</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">path 指的是 访问路径  </span><br><span class="line">docBase 指的是项目存放路径</span><br><span class="line">reloadable 设置为true表示Catalina将监视 /WEB-INF/classes/和/WEB-INF/lib的文件，一旦发生更改将自动重新加载Web应用程序。它可以在在开发的时候使用，但需要消耗更多资源，官方文档写到不建议在生产环境上使用，所以它的默认值是false.</span><br><span class="line">8.0版本文档</span><br><span class="line">Set to true if you want Catalina to monitor classes in /WEB-INF/classes/ and /WEB-INF/lib for changes, and automatically reload the web application if a change is detected. This feature is very useful during application development, but it requires significant runtime overhead and is not recommended for use on deployed production applications. That&#x27;s why the default setting for this attribute is false. You can use the Manager web application, however, to trigger reloads of deployed applications on demand.</span><br></pre></td></tr></table></figure>
<p>配置示例：<br />
<img src="https://djxblog.oss-cn-shenzhen.aliyuncs.com/picture/tomcat%E5%AE%89%E8%A3%85%E4%BB%A5%E5%8F%8A%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/tomcat%20%E9%83%A8%E7%BD%B2%E6%96%B9%E6%B3%95%E4%BA%8C.png" alt="" /></p>
<p>方法3：使用xml配置文件(建议方法)</p>
<p>在 ./conf/Catalina/localhost/ 下添加xml配置文件。示例：我要让 /tmp/www/ 里的网站部署在tomcat上 。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim  djx.xml    # 文件的名称也就是我们后面访问时要在ip端口加的后缀</span><br></pre></td></tr></table></figure>
<p>编辑 djx.xml 内容如下，docBase 后面填入项目的路径 /var/www/html/jbrowse/，这是我之前安装JBrowser的路径，路径下有 index.html 文件和一堆其他文件。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;Context  docBase=&quot;/var/www/html/jbrowse/&quot; /&gt;</span><br></pre></td></tr></table></figure>
<p>然后我们重启tomcat，然后在浏览器 192.168.1.198/djx/访问的文件名 即可访问到我们的项目文件了。<br />
（原来JBrowser放在Tomcat上面也是一样的可以用于浏览。）</p>
<p><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201003184221.jpg?w=1024" alt="" /></p>
<h3 id="设置开机启动-tomcat"><a class="markdownIt-Anchor" href="#设置开机启动-tomcat"></a> 设置开机启动 Tomcat</h3>
<p>服务器关机重启的时候，服务不能随计算机的启动而自己启动，那么我们可以将 tomcat 服务设置为开机启动。</p>
<p>打开 Linux 设置开机启动的文件，将下面的配置文件写入此文件的最后，注意，是文件的最后，以后若还要增加其他开机启动，只能加在这前面，总之一句话，要保持下面这句话一直在文件的最后。</p>
<p>打开开机启动文件 <code>/etc/rc.d/rc.local</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vi /etc/rc.d/rc.local</span><br></pre></td></tr></table></figure>
<p>添加如下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># java配置 环境变量。根据自己的实际情况修改路径和软件版本号</span><br><span class="line">export JAVA_HOME=/usr/local/java/jdk1.8.0_161</span><br><span class="line">export CLASSPATH=.:$JAVA_HOME/jre/lib/rt.jar:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar</span><br><span class="line">export PATH=$PATH:$JAVA_HOME/bin</span><br><span class="line"># tomcat 配置环境变量，根据自己的实际情况修改路径</span><br><span class="line">export CATALINA_HOME=/usr/local/tomcat7</span><br><span class="line"># tomcat自启动</span><br><span class="line">/opt/tomcat/bin/startup.sh</span><br></pre></td></tr></table></figure>
<p>Tomcat依赖于Java的jdk，所以jdk也同步导入。完成上面的步骤之后可以将CentOS关机重启检查一下。</p>
<h2 id="三-安装-mysql"><a class="markdownIt-Anchor" href="#三-安装-mysql"></a> 三、安装 MySQL</h2>
<p>Linux 系统（CentOS7）安装 mysql (5.7.25)</p>
<p><strong>卸载centos7自带的 MariaDB</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rpm -qa|grep mariadb  // 查询出来已安装的mariadb</span><br><span class="line"># 删除查询出来的mariadb</span><br><span class="line">rpm -e --nodeps mariadb-5.5.64-1.el7.x86_64</span><br><span class="line">rpm -e --nodeps mariadb-libs-5.5.64-1.el7.x86_64</span><br><span class="line">rpm -e --nodeps mariadb-server-5.5.64-1.el7.x86_64</span><br><span class="line"># 安装依赖</span><br><span class="line">yum -y install numactl.x86_64</span><br></pre></td></tr></table></figure>
<p><strong>MySQL依赖libaio，所以安装libaio</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install libaio</span><br></pre></td></tr></table></figure>
<p><strong>检查MySQL是否安装</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum list installed | grep mysql</span><br></pre></td></tr></table></figure>
<p>如果已安装，先卸载</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum -y remove mysql-libs.x86_64</span><br></pre></td></tr></table></figure>
<p>检查其他方式安装的 mysql</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rpm -qa | grep mysql</span><br></pre></td></tr></table></figure>
<p>有的话，通过 <code>rpm -e</code> 命令，或者 <code>rpm -e --nodeps</code> 命令来卸载掉。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">rpm -e mysql 检查出的名称　　#普通删除模式</span><br><span class="line">rpm -e --nodeps 检查出的名称　　#强力删除模式，如果使用上面命令删除时，提示有依赖的其它文件，则用该命令可以对其进行强力删除</span><br></pre></td></tr></table></figure>
<p>在删除完以后我们可以通过 <code>rpm -qa | grep mysql</code> 命令来查看 mysql 是否已经卸载成功！！</p>
<p><strong>安装 MySQL</strong></p>
<p>进入MySQL下载官网，下载页面：<a href="https://dev.mysql.com/downloads/mysql/">https://dev.mysql.com/downloads/mysql/</a>，选择 MySQL Community Server 下的 Linux generic 版本。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 下载 mysql </span><br><span class="line">wget http://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.20-linux-glibc2.12-x86_64.tar.gz</span><br><span class="line"></span><br><span class="line"># 在/usr/local/中解压压缩包，并改名为mysql</span><br><span class="line">cd /usr/local/</span><br><span class="line">tar -xzvf /data/software/mysql-5.7.13-linux-glibc2.5-x86_64.tar.gz (我的下载目录为 data/software)</span><br><span class="line">mv mysql-5.7.13-linux-glibc2.5-x86_64 mysql</span><br><span class="line"></span><br><span class="line"># 创建数据文件存放目录, 进入mysql目录，新建data目录</span><br><span class="line">cd /usr/local/mysql</span><br><span class="line">mkdir data</span><br><span class="line"></span><br><span class="line"># 创建用户组mysql，创建用户mysql并将其添加到用户组mysql中，并赋予读写权限</span><br><span class="line">groupadd mysql</span><br><span class="line">useradd -r -g mysql mysql</span><br><span class="line">chown -R mysql mysql/</span><br><span class="line">chgrp -R mysql mysql/</span><br><span class="line"></span><br><span class="line"># 修改当前目录权限</span><br><span class="line">chown -R mysql:mysql /usr/local/mysql</span><br></pre></td></tr></table></figure>
<p><strong>初始化数据库</strong></p>
<p>注：可以先按照下文配置 my.cnf，再初始化数据库。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/mysql/bin       //进入bin目录</span><br><span class="line">./mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data</span><br></pre></td></tr></table></figure>
<p>注意屏幕上的输出，包含了密码信息。摘抄如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# ./mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data</span><br><span class="line">2021-01-06T03:34:49.698565Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).</span><br><span class="line">2021-01-06T03:34:51.569548Z 0 [Warning] InnoDB: New log files created, LSN=45790</span><br><span class="line">2021-01-06T03:34:52.006540Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.</span><br><span class="line">2021-01-06T03:34:52.194069Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: 22e1b266-4fd0-11eb-81c9-989096c937ac.</span><br><span class="line">2021-01-06T03:34:52.218950Z 0 [Warning] Gtid table is not ready to be used. Table &#x27;mysql.gtid_executed&#x27; cannot be opened.</span><br><span class="line">2021-01-06T03:34:52.219393Z 1 [Note] A temporary password is generated for root@localhost: /-hyrfM3Huy&lt;</span><br></pre></td></tr></table></figure>
<p><strong>配置my.cnf</strong><br />
find / -name my.cnf 找到后复制到 /etc/my.cnf，或者直接新建 /etc/my.cnf，写入以下内容。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[mysqld]</span><br><span class="line">character_set_server=utf8</span><br><span class="line">init_connect=&#x27;SET NAMES utf8&#x27;</span><br><span class="line">basedir=/usr/local/mysql</span><br><span class="line">datadir=/usr/local/mysql/data</span><br><span class="line">socket=/tmp/mysql.sock</span><br><span class="line">#不区分大小写 </span><br><span class="line">lower_case_table_names = 1</span><br><span class="line">#不开启sql严格模式</span><br><span class="line">sql_mode = &quot;STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION&quot;</span><br><span class="line">log-error=/var/log/mysqld.log</span><br><span class="line">pid-file=/usr/local/mysql/data/mysqld.pid</span><br></pre></td></tr></table></figure>
<p><strong>添加开机自启</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/mysql/support-files</span><br><span class="line">cp mysql.server /etc/init.d/mysqld</span><br><span class="line">chkconfig --add mysqld</span><br></pre></td></tr></table></figure>
<p>chkconfig是管理系统服务(service)的命令行工具。所谓系统服务(service)，就是随系统启动而启动，随系统关闭而关闭的程序。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chkconfig --add mysqld</span><br><span class="line">chkconfig mysqld on</span><br></pre></td></tr></table></figure>
<p>检查是否添加成功。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# chkconfig --list mysqld</span><br><span class="line"></span><br><span class="line">Note: This output shows SysV services only and does not include native</span><br><span class="line">      systemd services. SysV configuration data might be overridden by native</span><br><span class="line">      systemd configuration.</span><br><span class="line"></span><br><span class="line">      If you want to list systemd services use &#x27;systemctl list-unit-files&#x27;.</span><br><span class="line">      To see services enabled on particular target use</span><br><span class="line">      &#x27;systemctl list-dependencies [target]&#x27;.</span><br><span class="line"></span><br><span class="line">mysqld          0:off   1:off   2:on    3:on    4:on    5:on    6:off</span><br></pre></td></tr></table></figure>
<p><strong>关闭与启动 MySQL</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/usr/local/mysql/support-files/mysql.server stop</span><br><span class="line"># 屏幕显示：Shutting down MySQL.. SUCCESS!</span><br><span class="line"></span><br><span class="line">/usr/local/mysql/support-files/mysql.server start</span><br><span class="line"># 屏幕显示：Starting MySQL. SUCCESS!</span><br><span class="line"></span><br><span class="line"># 查看 MySQL 状态</span><br><span class="line">/usr/local/mysql/support-files/mysql.server status</span><br><span class="line"># 屏幕显示：SUCCESS! MySQL running (15291)</span><br></pre></td></tr></table></figure>
<p>也可以使用 service mysqld 命令启动/停止服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 5.0版本：</span><br><span class="line">service mysqld status</span><br><span class="line">service mysqld start</span><br><span class="line">service mysqld stop</span><br><span class="line">service mysqld restart</span><br></pre></td></tr></table></figure>
<p><strong>修改root本地登录密码</strong></p>
<p>上文配置my.cnf操作是在MySQL初始化之后，所以初始化MySQL的时候密码输出在屏幕上。如果配置my.cnf在MySQL初始化之前，密码会保存至 /var/log/mysqld.log 中。</p>
<p>mysql安装完成之后，在 /var/log/mysqld.log 文件中给root生成了一个默认密码。通过下面的方式找到root默认密码，然后登录mysql进行修改：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">grep &#x27;temporary password&#x27; /var/log/mysqld.log</span><br></pre></td></tr></table></figure>
<p>到这里终于可以登陆进入mysql了，摘抄如下。（备注：一开始没有卸载 Centos 7 自带的 mariadb，运行<code>mysql -uroot -p</code>命令根本不是启动新安装的MySQL，难怪输入密码一直报错。）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost support-files]# /usr/local/mysql/bin/mysql -uroot -p     </span><br><span class="line">Enter password: </span><br><span class="line">Welcome to the MySQL monitor.  Commands end with ; or \g.</span><br><span class="line">Your MySQL connection id is 3</span><br><span class="line">Server version: 5.7.20</span><br><span class="line"></span><br><span class="line">Copyright (c) 2000, 2017, Oracle and/or its affiliates. All rights reserved.</span><br><span class="line"></span><br><span class="line">Oracle is a registered trademark of Oracle Corporation and/or its</span><br><span class="line">affiliates. Other names may be trademarks of their respective</span><br><span class="line">owners.</span><br><span class="line"></span><br><span class="line">Type &#x27;help;&#x27; or &#x27;\h&#x27; for help. Type &#x27;\c&#x27; to clear the current input statement.</span><br><span class="line"></span><br><span class="line">mysql&gt; </span><br></pre></td></tr></table></figure>
<p>登录之后修改密码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/mysql/bin/</span><br><span class="line">./mysql -uroot -p</span><br><span class="line"></span><br><span class="line">按照屏幕提示输入默认密码，即可登录。登录后可用下面的命令修改成新密码，以 MyNewPass4! 为例</span><br><span class="line">alter user &#x27;root&#x27;@&#x27;localhost&#x27; identified by &#x27;新密码&#x27;;</span><br><span class="line"># e.g. ALTER USER &#x27;root&#x27;@&#x27;localhost&#x27; IDENTIFIED BY &#x27;MyNewPass4!&#x27;;</span><br><span class="line">flush privileges; </span><br><span class="line"># 刷新权限，之后退出可用新密码重新登录</span><br></pre></td></tr></table></figure>
<p>也可以用下面这种方法修改密码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">set password for &#x27;root&#x27;@&#x27;localhost&#x27;=password(&#x27;MyNewPass4!&#x27;);</span><br></pre></td></tr></table></figure>
<p><strong>创建用户并授权</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 添加用户允许其在任意地址登录</span><br><span class="line">CREATE USER &#x27;dog&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27;; </span><br><span class="line"></span><br><span class="line">#授予所有库的所有权限 </span><br><span class="line">GRANT ALL PRIVILEGES ON  *.* TO &#x27;dog&#x27;@&#x27;%&#x27; IDENTIFIED BY &#x27;123456&#x27;;</span><br><span class="line"></span><br><span class="line"># 刷新权限</span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
<h2 id="四-发布项目"><a class="markdownIt-Anchor" href="#四-发布项目"></a> 四、发布项目</h2>
<p>将项目文件放到 /usr/local/tomcat7/webapps 文件夹下即可通过 110.120.18.18:8080 访问。</p>
<p>默认端口是8080，可以在 /usr/local/tomcat7/conf/server.xml 中进行修改。</p>
<p>找到如下代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;Connector port=&quot;8080&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>
<p>将8080改为80，即可直接通过 110.120.18.18 访问，代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&lt;Connector port=&quot;80&quot; protocol=&quot;HTTP/1.1&quot;</span><br><span class="line">               connectionTimeout=&quot;20000&quot;</span><br><span class="line">               redirectPort=&quot;8443&quot; /&gt;</span><br></pre></td></tr></table></figure>
<p><strong>参考资料</strong><br />
1 <a href="https://blog.csdn.net/dvdstd/article/details/88575025">Tomcat 9 Manager 配置</a><br />
2 <a href="https://www.cnblogs.com/operationhome/p/10021645.html">tomcat 安装以及常用配置</a><br />
3 <a href="https://cloud.tencent.com/developer/news/97003">Apache Tomcat 安装</a><br />
4 <a href="https://cloud.tencent.com/developer/article/1538210">Linux 安装 JDK+Tomcat+MySQL 及发布项目教程</a><br />
5 <a href="https://blog.csdn.net/lanyang123456/article/details/54695567">系统服务管理工具 chkconfig 使用说明</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | Meet I/O error when using harddisk in Linux</title>
    <url>/2021/10/27/Linux-Meet-I-O-error-when-using-harddisk-in-Linux/</url>
    <content><![CDATA[<p>Linux 系统硬盘似乎出问题，报错信息是 I/O error。网上找资料说可以直接做硬盘修复，记录如下。</p>
<p>切换到 root 账户，执行 badblocks 命令查看出错的扇区数量，-b 指定每次扫描的区块大小，设置为和扇区大小一致，后面的数字 <s>1729898440</s> 为日志提示出错的扇区位置，前面的数字 <s>1729898499</s> 指定扫描扇区的终止位置，扫描后可以看到共有 <s>8</s> 个扇区出错。这里的几个数字要根据实际情况来配置。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost fenglei]# badblocks -b 512 /dev/sdb1 2766144199 2766144103     </span><br><span class="line">[root@localhost fenglei]# badblocks -b 512 /dev/sdb 2766144199 2766144103 </span><br><span class="line">2766144104</span><br><span class="line">2766144105</span><br><span class="line">2766144106</span><br><span class="line">2766144107</span><br><span class="line">2766144108</span><br><span class="line">2766144109</span><br><span class="line">2766144110</span><br><span class="line">2766144111</span><br><span class="line">2766144112</span><br><span class="line">2766144113</span><br><span class="line">2766144114</span><br><span class="line">2766144115</span><br><span class="line">2766144116</span><br><span class="line">2766144117</span><br><span class="line">2766144118</span><br><span class="line">2766144119</span><br><span class="line">2766144128</span><br><span class="line">2766144129</span><br><span class="line">2766144130</span><br><span class="line">2766144131</span><br><span class="line">2766144132</span><br><span class="line">2766144133</span><br><span class="line">2766144134</span><br><span class="line">2766144135</span><br><span class="line">2766144136</span><br><span class="line">2766144137</span><br><span class="line">2766144138</span><br><span class="line">2766144139</span><br><span class="line">2766144140</span><br><span class="line">2766144141</span><br><span class="line">2766144142</span><br><span class="line">2766144143</span><br><span class="line">2766144152</span><br><span class="line">2766144153</span><br><span class="line">2766144154</span><br><span class="line">2766144155</span><br><span class="line">2766144156</span><br><span class="line">2766144157</span><br><span class="line">2766144158</span><br><span class="line">2766144159</span><br></pre></td></tr></table></figure>
<p><strong>1 先备份数据（可选）</strong>：若修复的硬盘或分区的重要数据已备份，此部分可以省略。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dd if=/dev/mapper/VolGroup-lv_home  skip=217874591 of=/tmp/217874591-217874595.dat count=5</span><br></pre></td></tr></table></figure>
<p><strong>2 修复</strong>：硬盘在使用时不能修复，否则可能存在写并发的问题，所以修复前需要 umount 对应分区，例如 <code>umount /mnt/sdb</code>。另外注意若为系统所在分区就没办法在线修复了，因为无法 umount。我在执行 umount 命令室收到提示说无法 umount，发现此时并没有打开窗口读取 /mnt/sdb 目录，查找后台才发现原来 /mnt/sda 目录下正在开展的一个分析项目，代码里面有读取 /mnt/sdb 下面的数据，停止这个进程之后，umount 就可以了。再操作下面的命令的时候就通过了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost fenglei]# badblocks -b 512 -w /dev/sdb 2766144159 2766144104</span><br><span class="line">/dev/sdb is apparently in use by the system; it&#x27;s not safe to run badblocks!</span><br></pre></td></tr></table></figure>
<p>先备份数据（可选），若修复的硬盘或分区的重要数据已备份，此部分可以省略。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dd if=/dev/mapper/VolGroup-lv_home  skip=217874591 of=/tmp/217874591-217874595.dat count=5</span><br></pre></td></tr></table></figure>
<p>在 umount 可能出现&quot;Device busy&quot;错误时，是因为有程序在使用这个分区，需要将这些进程都关闭。那么怎么知道哪些进程占用分区呢？使用 fuser（命令如下），其中 /home 是分区对应的挂载目录。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">fuser -m /home</span><br><span class="line">fuser -m -v -i -k /home</span><br></pre></td></tr></table></figure>
<p>第一条fuser命令列出使用/home的进程ID，第二条列出PID并kill掉进程（带有提示确认），建议先使用第一条命令列出PID，然后针对查看是哪些类型的进程，不要盲目杀死进程。</p>
<p>umount 分区成功后，修复命令如下，其中-s表示给出进度，-w表示写入修复的，后面是结束（END）和开始（START）块号，注意END在前，START在后。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">badblocks -s -w /dev/mapper/VolGroup-lv_home 217874595 217874591</span><br></pre></td></tr></table></figure>
<p>修复后再重新检查下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">badblocks -s -v /dev/mapper/VolGroup-lv_home 217874595 217874591</span><br></pre></td></tr></table></figure>
<p><strong>恢复数据（可选）</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dd if=/tmp/217874591-217874595.dat of=/dev/mapper/VolGroup-lv_home </span><br></pre></td></tr></table></figure>
<p><strong>重新分区检查</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">badblocks -s -v -o /root/bb-home.log /dev/mapper/VolGroup-lv_home</span><br></pre></td></tr></table></figure>
<p>若没有坏道说明修复已完成，若有坏道可以尝试重复以上方法。</p>
<p>完成后重新mount分区</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mount /dev/mapper/VolGroup-lv_home /home</span><br></pre></td></tr></table></figure>
<p><strong>硬盘使用的一些建议</strong></p>
<p>硬RAID还是要有的。硬件RAID服务器自带，性能比软件RAID要高。根据对数据的安全性、硬盘大小，存储性能来评估该选择的RAID类型，常用的RAID类型如下：</p>
<p>RAID0：存储性能（读写效率）最高，连续的数据分散到多个磁盘上存储，提高并发访问。<br />
RAID1：数据安全性高，即同样的数据在另一块盘上备份一份，硬盘的容量也就减少一半。<br />
RAID5：兼具RAID0和RAID1的优点。存储性能大于RAID1，小于RAID0；数据安全性大于RAID0，小于RAID1。</p>
<p>读写频繁的操作不要放在/分区<br />
/ 分区是存放系统程序的，一般也比较小，读写频繁的日志不要放在根分区，这样损坏起码不会影响系统的稳定性。</p>
<p><strong>参考资料</strong><br />
1 <a href="https://www.cnblogs.com/augusite/p/10931175.html">https://www.cnblogs.com/augusite/p/10931175.html</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | 认识 PKG_CONFIG_PATH</title>
    <url>/2021/06/08/Linux-PKG-CONFIG-PATH/</url>
    <content><![CDATA[<p>安装 <a href="https://github.com/agordon/fastx_toolkit/releases/download/0.0.14/fastx_toolkit-0.0.14.tar.bz2">Fastx-Toolkit</a> 的过程中遇问题：No package ‘gtextutils’ found. Consider adjusting the PKG_CONFIG_PATH environment variable if you.</p>
<p>实际上我已经安装 <a href="https://github.com/agordon/libgtextutils/releases/download/0.7/libgtextutils-0.7.tar.gz">libgtextutils</a></p>
<p>解决办法：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo cp /usr/local/lib/pkgconfig/gtextutils.pc /usr/lib64/pkgconfig/</span><br></pre></td></tr></table></figure>
<p><a href="http://www.chenlianfu.com/?p=1490">参考资料</a>：</p>
<p>安装源码包，进行 configure 步骤，提示某依赖的软件包找不到或软件包版本太低；或某一个库文件找不到。而实际上却已经安装好了相应的软件。这两种情况的处理方法分别为：</p>
<ol>
<li>设置环境变量 PKG_CONFIG_PATH</li>
</ol>
<p>.pc 文件是安装软件后生成的一个文件，其中包含该软件的信息；该 .pc 文件一般统一存放于名为 pkgconfig 的目录下。命令 pkg-config 按照系统设置路径（CentOS6 x64_86 系统默认为 /usr/lib64/pkgconfig/）的先后顺序来搜索 .pc 文件，从而或得到软件的版本号、头文件和库文件位置等信息。</p>
<p>因此当把软件包安装到默认位置 /usr/local/ 位置后，则其 .pc 文件会生成到 /usr/local/lib/pkgconfig/ 或 /usr/local/lib64/pkgconfig/ 文件夹下，此时只需要将相应的 .pc 文件复制到 /usr/lib64/pkgconfig/ 中即可。</p>
<p>或者，在安装软件包的时候，使用 “./configure –prefix=/usr/” 将软件直接安装到 /usr/ 目录下。这时有可能会将 .pc 文件生成到 /usr/lib/pkgconfig/ 中，依然导致问题出现，只需将该目录中的 .pc 文件复制到 /usr/lib64/pkgconfig/ 中即可。</p>
<p>或者，设置环境变量PKG_CONFIG_PATH，加入含有相应的.pc文件的路径。注意要使用命令 ‘export’ 。比如:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig/:$PKG_CONFIG_PATH</span><br></pre></td></tr></table></figure>
<p>使用以上3种方法，能解决软件版本不符或系统找不到依赖的软件包的问题。</p>
<ol start="2">
<li>设置环境变量 LD_LIBRARY_PATH</li>
</ol>
<p>Linux 系统默认把 /lib 和 /usr/lib 两个目录作为默认的库搜索路径。而修改库搜索路径有两个方法：</p>
<p>(1) 在 /etc/ld.so.conf 文件中添加库的搜索路径。</p>
<p>(2) 在环境变量 LD_LIBRARY_PATH 中指明库的搜索路径。</p>
<p>将库的路径设置好后，需要使用 /sbin/ldconfig 命令来将这些搜索路径下的共享库文件集中在一起而生成 /etc/ld.so.cache。该 cache 用于快速定位共享库。</p>
<p>特别是新安装了软件后，即使其库文件明明就在库搜索路径下，但是编译的时候依然报错，提示缺少该库。则需要使用 ldconfig 命令来更新缓存。</p>
<p>更详细信息，可参考：<a href="http://www.mike.org.cn/articles/description-configure-pkg-config-pkg_config_path-of-the-relations-between/">简述configure、pkg-config、pkg_config_path三者的关系</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>GCC与R 3.3.3升级与安装 — Linux (RedHat)无root 权限</title>
    <url>/2017/04/17/Linux-R-3-3-3-linux-redhat-without-root/</url>
    <content><![CDATA[<h3 id="非root权限下安装gcc的方法"><a class="markdownIt-Anchor" href="#非root权限下安装gcc的方法"></a> 非root权限下安装gcc的方法</h3>
<p>系统自带的GCC版本太低了（gcc version 4.4.7），不能够编译最新的 R 3.3.3</p>
<p>首先在个人目录下安装了较新版本的GCC（gcc version 6.3.0），无需root权限。</p>
<p>在安装GCC之前，必要条件是先要先依次安装gmp、mpfr和mpc。注意这三个软件configure的时候设定–with-gmp和–with-mpfr等参数。 然后安装GCC的命令是：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./configure --prefix=/home/fenglei/local/ --with-mpc=/home/fenglei/local/ --with-mpfr=/home/fenglei/local/ --with-gmp=/home/fenglei/local/ --with-libelf=/home/fenglei/local/ --disable-multilib </span><br><span class="line">make -j 10 &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<p><em>2017-04-17 备注：</em> Red hat 系统安装 gcc<br />
make的时候报错，经过查询是路径问题。安装完上述三个依赖包后设置环境变量 $LD_LIBRARY_PATH，即在bashrc文件添加如下内容： 因为系统的LD_LIBRARY_PATH中有两个相邻的冒号，编译gcc的导致通不过，所以先把这个变量自己重新定义一下，然后将上面装的三个包添加到该变量中。</p>
<p>bashrc中的内容</p>
<p>找到动态链接库的路径<br />
LD_LIBRARY_PATH=/xxx/xxx:/share/raid12/c-fenglei/local/lib<br />
export LD_LIBRARY_PATH</p>
<p>找到静态库的路径<br />
LIBRARY_PATH=$LD_LIBRARY_PATH<br />
export LIBRARY_PATH</p>
<p>这样更新bashrc之后，顺利make -j 20 &amp;&amp; make install，测试gcc：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) -bash-4.1$ gcc --version</span><br><span class="line">gcc (GCC) 9.1.0</span><br><span class="line">Copyright © 2019 Free Software Foundation, Inc.</span><br><span class="line">本程序是自由软件；请参看源代码的版权声明。本软件没有任何担保；</span><br><span class="line">包括没有适销性和某一专用目的下的适用性担保。</span><br></pre></td></tr></table></figure>
<p><em>2020-12-29 更新</em> CentOS 7 系统安装 gcc</p>
<p>在一台机器上安装新版gcc，遇到问题：libiconv.so.2: cannot open shared object file<br />
下载安装 <a href="https://ftp.gnu.org/pub/gnu/libiconv/libiconv-1.16.tar.gz">libiconv</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./configure --prefix=/usr/local</span><br><span class="line">make -j 20</span><br><span class="line">make install</span><br></pre></td></tr></table></figure>
<p>在/etc/ld.so.conf中加一行/usr/local/lib，執行<code>ldconfig</code>，随后gcc就可以顺利make了。</p>
<p>make的时候加上-j 20参数，大大减少等待的时间。否则安装的时候等挺长时间，差不多两个小时。</p>
<p>make install 完成后，将下面的参数加入环境变量（编辑.bashrc文件）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PATH=/home/user/local/gcc-9.2.0/bin/:$PATH</span><br><span class="line">export LD_LIBRARY_PATH=/home/user/local/gcc-9.2.0/lib/:/home/user/local/gcc-9.2.0/lib64/:$LD_LIBRARY_PATH</span><br></pre></td></tr></table></figure>
<p>测试gcc：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost gnuplot-5.4.1]$ gcc --version</span><br><span class="line">gcc (GCC) 10.2.0</span><br><span class="line">Copyright (C) 2020 Free Software Foundation, Inc.</span><br><span class="line">This is free software; see the source for copying conditions.  There is NO</span><br><span class="line">warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</span><br></pre></td></tr></table></figure>
<h3 id="安装-r"><a class="markdownIt-Anchor" href="#安装-r"></a> 安装 R</h3>
<p>（2020-12-29 备注：其实安装R还有另一个选项，通过conda安装，很方便，<code>conda install R</code> 一句话命令就安装好了。它自动解决依赖的其他程序，甚至都不需要关心gcc版本这些问题。）</p>
<p>下面记录的是手动安装R的过程。(2017-04-17)</p>
<p>随后开始准备安装R 3.3.3，下载了源码并在用户目录下安装，configure的过程遇到了缺失zlib、bzip2、xz、pcre、openssl和curl等问题。需要逐个下载并安装这些包。 在R的configure之前注意设定环境变量。具体如下。或者将其写入~/.bash_profile</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">LD\_LIBRARY\_PATH=/home/fenglei/local/lib:/home/fenglei/local/lib64 export CFLAGS=&quot;-I/home/fenglei/local/include&quot; export LDFLAGS=&quot;-L/home/fenglei/local/lib&quot;</span><br></pre></td></tr></table></figure>
<p>R的安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./configure --prefix=/home/fenglei/local/ --enable-R-shlib make -j 10 &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<p>现在R终于可以启动了，然而在安装devtools等包的时候还是报错！错误信息：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ibssl.so.1.0.0: cannot open shared object file: No such file or directory</span><br></pre></td></tr></table></figure>
<p>我猜想可能是openssl软件版本的问题，于是卸载openssl.1.1.0，安装openssl.1.0.0。然而编译openssl.1.0.0时还是报错：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">POD document had syntax errors</span><br></pre></td></tr></table></figure>
<p>参考网上的文章解决了该问题，网上（<a href="http://www.linuxdiyf.com/linux/20869.html">链接一</a>、<a href="http://blog.csdn.net/zsl10/article/details/52145657">链接二</a>）的建议是删除 pod2man文件。我的解决方法是对pod2man文件进行了重命名：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo mv  /usr/bin/pod2man  /usr/bin/pod2man~</span><br></pre></td></tr></table></figure>
<p>这时候再启动R软件，还是不能安装devtools，想到curl包是依赖openssl的，那么重新安装openssl之后也同样需要重新安装curl。卸载原来的curl，并且重新安装。然后启动R ，终于可以安装git2r和devtools了！ 附安装zlib和bzip2等软件包的流程：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># step1:下载安装zlib </span><br><span class="line">$ wget http://www.zlib.net/zlib-1.2.11.tar.gz </span><br><span class="line">$ tar zlib-1.2.11.tar.gz $ cd zlib-1.2.11.tar.gz </span><br><span class="line">$ ./configure --prefix=/opt/packages </span><br><span class="line">$ make </span><br><span class="line">$ make install </span><br><span class="line"># step2:下载和安装bzip2： </span><br><span class="line"># bzip2不是标准的GNU包，根据下载的安装文件的说明文档，执行以下命令： </span><br><span class="line">$ wget http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gz </span><br><span class="line">$ tar xzvf bzip2-1.0.6.tar.gz $ cd bzip2-1.0.6 </span><br><span class="line">$ make -f Makefile-libbz2\_so </span><br><span class="line">$ make clean </span><br><span class="line">$ make </span><br><span class="line">$ make install PREFIX=/opt/packages </span><br><span class="line"># 注意：这里下载完bzip2后，需要修改Makefile文件，在CFLAGS这个变量后面添加:-fPIC，否则后面安装R的时候会报错。 export CFLAGS=&quot;-fPIC -I/home/fenglei/local/include&quot; export LDFLAGS=&quot;-fPIC -L/home/fenglei/local/lib&quot; </span><br><span class="line"># step3:安装xz包： </span><br><span class="line">$ wget http://tukaani.org/xz/xz-5.2.2.tar.gz </span><br><span class="line">$ tar xzvf xz-5.2.2.tar.gz $ cd xz-5.2.2 </span><br><span class="line">$ ./configure --prefix=/opt/packages </span><br><span class="line">$ make -j3 $ make install # step4:安装pcre包： </span><br><span class="line">$ wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.38.tar.gz </span><br><span class="line">$ tar xzvf pcre-8.38.tar.gz $ cd pcre-8.38 </span><br><span class="line">$ ./configure --enable-utf8 --prefix=/opt/packages </span><br><span class="line">$ make -j3 </span><br><span class="line">$ make install OPENSSL ./config -fPIC --prefix=/home/fenglei/local/ enable-shared ./config -t make make install </span><br><span class="line"># 如何安装OPENSSL  http://www.jianshu.com/p/291294ad0ee7 </span><br><span class="line"># step5:安装curl包： </span><br><span class="line">$ wget --no-check-certificate http://curl.haxx.se/download/curl-7.51.0.tar.gz </span><br><span class="line">$ tar -zxf curl-7.51.0.tar.gz $ cd curl-7.51.0 $ ./configure --prefix=/opt/packages $ make -j3 </span><br><span class="line">$ make install </span><br><span class="line"># step6:设置安装好的包的环境变量，将下面命令写入~/.bash\_profile（这步重要）： </span><br><span class="line"># 前两个是“configure”过程需要用到的，后一个是安装R的“make”过程需要用到的。 </span><br><span class="line">export CFLAGS=&quot;-I/home/fenglei/local/include&quot; </span><br><span class="line">export LDFLAGS=&quot;-L/home/fenglei/local/lib&quot; </span><br><span class="line">LD_LIBRARY_PATH=/home/fenglei/local/lib:/home/fenglei/local/lib64</span><br></pre></td></tr></table></figure>
<p>-END-</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>在Linux平台运行windows程序：mono</title>
    <url>/2020/10/28/Linux-Run-windows-programs-inlinux-mono/</url>
    <content><![CDATA[<p>在Windows系统，最常见的就是Windows Forms程序（以下简称WinForm程序），也就是窗体应用程序，比如MS Office，媒体播放器软件等，WinForm程序比起Web应用程序，明显在实时性，用户亲和度和操作便捷能力方面强很多。在Linux系统下，虽然也有桌面窗体应用程序，但应用很少。能否将WinForm程序移植到Linux系统上面呢？目前，Novell公司的开源项目mono提供了将.NET程序运行在各种非Windows平台的能力，例如控制台程序，WinForm程序和ASP.NET等。(摘抄自：<a href="https://blog.csdn.net/qq%5C_21153619/article/details/81459359">https://blog.csdn.net/qq\_21153619/article/details/81459359</a>)</p>
<p>如何在linux安装mono？我主要目的是在Linux下调用Windows程序做批量文件的处理。因为windows的cmd窗口操作真的不好用，相比之下Linux命令行就好用多了。</p>
<h3 id="1-安装依赖组件"><a class="markdownIt-Anchor" href="#1-安装依赖组件"></a> 1 安装依赖组件</h3>
<p>yum -y install gcc gcc-c++ bison pkgconfig glib2-devel gettext make libpng-devel libjpeg-devel libtiff-devel libexif-devel giflib-devel libX11-devel freetype-devel fontconfig-devel  cairo-devel</p>
<h3 id="2-安装libgdiplus"><a class="markdownIt-Anchor" href="#2-安装libgdiplus"></a> 2 安装libgdiplus</h3>
<ul>
<li><code>wget http://download.mono-project.com/sources/libgdiplus/libgdiplus-4.2.tar.gz</code></li>
<li><code>tar zxf libgdiplus-4.2.tar.gz</code></li>
<li><code>cd libgdiplus-4.2</code></li>
<li><code>./configure --prefix=/home/fenglei/local</code></li>
<li><code>make</code></li>
<li><code>make install</code></li>
</ul>
<h3 id="3-安装mono"><a class="markdownIt-Anchor" href="#3-安装mono"></a> 3 安装mono</h3>
<p>版本选择：<a href="http://download.mono-project.com/sources/mono/">http://download.mono-project.com/sources/mono/</a></p>
<ul>
<li><code>wget http://download.mono-project.com/sources/mono/mono-4.6.0.125.tar.bz2</code></li>
<li><code>tar jxf mono-4.6.0.125.tar.bz2</code></li>
<li><code>cd mono-4.6.0</code></li>
<li><code>./configure --prefix=/home/fenglei/local</code></li>
<li><code>make -j2</code></li>
<li><code>make install</code></li>
</ul>
<p><a href="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028105649.png"><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028105649.png?w=1015" alt="" /></a></p>
<h3 id="4-软件测试我用了informedproteomics和rawtools软件做测试"><a class="markdownIt-Anchor" href="#4-软件测试我用了informedproteomics和rawtools软件做测试"></a> 4 软件测试，我用了InformedProteomics和rawTools软件做测试</h3>
<p>下载rawTools: <a href="https://github.com/kevinkovalchik/RawTools/releases/download/2.0.2/RawTools-2.0.2.zip">https://github.com/kevinkovalchik/RawTools/releases/download/2.0.2/RawTools-2.0.2.zip</a></p>
<p>rawTools其他版本选择：<a href="https://github.com/kevinkovalchik/RawTools/releases/tag/2.0.2">https://github.com/kevinkovalchik/RawTools/releases/tag/2.0.2</a></p>
<p><code>mkdir RawTools</code></p>
<p><code>unzip RawTools-2.0.2.zip -d RawTools</code></p>
<p><code>mono ~/local/app/RawTools/RawTools.exe</code></p>
<p><a href="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028110306.png"><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028110306.png?w=1024" alt="" /></a></p>
<p>下载InformedProteomics：<a href="https://github.com/PNNL-Comp-Mass-Spec/Informed-Proteomics/releases/download/v1.0.7569/InformedProteomics%5C_Program.zip">https://github.com/PNNL-Comp-Mass-Spec/Informed-Proteomics/releases/download/v1.0.7569/InformedProteomics\_Program.zip</a></p>
<p>版本选择：<a href="https://github.com/PNNL-Comp-Mass-Spec/Informed-Proteomics/releases">https://github.com/PNNL-Comp-Mass-Spec/Informed-Proteomics/releases</a></p>
<p><code>mkdir InformedProteomics</code></p>
<p><code>unzip InformedProteomics_Program.zip -d InformedProteomics</code></p>
<p><a href="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028110657.png"><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028110657.png?w=1024" alt="" /></a></p>
<p>mono ~/local/app/InformedProteomics/ProMex.exe</p>
<p><a href="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028110926.png"><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028110926.png?w=1024" alt="" /></a></p>
<p>mono ~/local/app/InformedProteomics/MSPathFinderT.exe</p>
<p><a href="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028110955.png"><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201028110955.png?w=1024" alt="" /></a></p>
<h3 id="报错"><a class="markdownIt-Anchor" href="#报错"></a> 报错</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mono ~/local/app/InformedProteomics/ProMex.exe -i xxx.raw -csv n -maxThreads 6                                                       </span><br><span class="line">************ ProMex version 1.0.7569 (September 21, 2020) ************</span><br><span class="line">InputPath    xxx.raw</span><br><span class="line">OutputPath   </span><br><span class="line">MinMass       2,000 Da</span><br><span class="line">MaxMass      50,000 Da</span><br><span class="line">MinCharge     1</span><br><span class="line">MaxCharge    60</span><br><span class="line">FeatureMap   True</span><br><span class="line">ScoreReport  False</span><br><span class="line">LikelihoodRatioThreshold -10</span><br><span class="line">MaxThreads   4</span><br><span class="line">Exception while processing: The type initializer for &#x27;InformedProteomics.Backend.MassSpecData.MassSpecDataReaderFactory&#x27; threw an exception.</span><br><span class="line">  at InformedProteomics.FeatureFinding.LcMsFeatureFinderLauncher.Run () [0x00011] in &lt;filename unknown&gt;:0 </span><br><span class="line">  at ProMex.Program.Main (System.String[] args) [0x000f1] in &lt;filename unknown&gt;:0 </span><br><span class="line">[MVID] 0604fddcd448487d905c1e71f6809d88 0</span><br><span class="line">[MVID] 072679dfee414eaab286f6a82270167b 1</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux：使用Environment Modules管理环境变量</title>
    <url>/2020/12/29/Linux-Using-Modules-to-manage-env/</url>
    <content><![CDATA[<p>Modules简介：生信分析中需要运用大量分析软件，往往软件有不同版本，如何调用特定版本的软件？比如可以用绝对路径直接调用、设定<code>export PATH</code>、conda（<code>source activate xxx</code>）等方式。在一个博客（<a href="https://bioinformaticsworkbook.org/dataAnalysis/GenomeAssembly/Hybrid/Juicer_Juicebox_3dDNA_pipeline.html#gsc.tab=0">Genome scaffolding</a>）看到通过 <code>module load</code> 命令调用特定版本的软件的做法，学习记录如下。</p>
<p>超级计算机的硬件设施和应用软件，分别是整个超算系统的最底层和最顶层，在它们之间，还存在着我们称之为软件栈（software stack）的系统软件：包括编译器、并行运行环境、作业调度系统、性能分析和调试工具等等。一般较为成熟的超算平台，都必备多种版本、不同种类的编译器、MPI 库，以及数学库等；并在此基础之上，进行各类应用软件的编译与环境配置。于普通使用者而言，因使用需求的变化，其所需的使用场景也不尽相同。若用户自行配置，则可能因为对命令行操作生疏等原因，导致环境变量配置出错，学习成本高，影响使用效率。</p>
<p>Environment module 工具，常用于高性能计算集群（即HPC ：High Perfermance Computing ）的环境配置管理上。它可以将软件编译器，MPI库，数学库、应用软件（计算类软件、分析类软件等）等，以模块的方式，统一到一个框架下，使得用户可以动态切换环境变量，便捷高效。且由于很多资源调度软件，如LSF、PBS、MOAB等，可以通过脚本文件来提交作业。所以，module工具同样可以在shell scripts中使用。</p>
<p>若要充分发挥Environment module 工具的功用，只需要记住两点即可:</p>
<ul>
<li>编写modulefiles，将应用软件所需的环境变量等写入其中，配置成模块。</li>
<li>使用module command(s)，动态调用已经配置好的模块。</li>
</ul>
<h3 id="安装-modules"><a class="markdownIt-Anchor" href="#安装-modules"></a> 安装 modules</h3>
<p>操作系统版本 <code>cat /etc/redhat-release</code>可知 <code>CentOS Linux release 7.7.1908 (Core)</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/cea-hpc/modules.git</span><br><span class="line">cd modules</span><br><span class="line">./configure --prefix=/home/fenglei/local</span><br><span class="line"># ./configure --prefix=/opt/modules/modules421 #指定安装目录为/opt/modules/modules421</span><br><span class="line">make </span><br><span class="line">make install</span><br><span class="line"></span><br><span class="line">NOTICE: Modules installation is complete.</span><br><span class="line">        Please read the &#x27;Configuration&#x27; section in INSTALL guide to learn</span><br><span class="line">        how to adapt your installation and make it fit your needs.</span><br></pre></td></tr></table></figure>
<p>备注：一开始编译失败，升级gcc之后可以编译通过，成功安装Modules。</p>
<p>系统自带的旧版gcc：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/bin/gcc --version</span><br><span class="line">gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-44)</span><br><span class="line">Copyright (C) 2015 Free Software Foundation, Inc.</span><br><span class="line">This is free software; see the source for copying conditions.  There is NO</span><br><span class="line">warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</span><br></pre></td></tr></table></figure>
<p>安装在个人目录下的新版gcc</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">~/local/gcc-10.2.0/bin/gcc --version</span><br><span class="line">gcc (GCC) 10.2.0</span><br><span class="line">Copyright (C) 2020 Free Software Foundation, Inc.</span><br><span class="line">This is free software; see the source for copying conditions.  There is NO</span><br><span class="line">warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.</span><br></pre></td></tr></table></figure>
<p>为了保证用户在登录服务器的时候，能够调用module，你得现将module的初始化脚本（modules.sh和modules.csh，就在上面configure --prefix=xxx命令指定的安装目录位置，不是最初的git clone那个目录）软链接到/etc/profiled.d目录下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 设置软链接，实现登录启动modules工具</span><br><span class="line">sudo ln -s /home/fenglei/local/init/profile.sh /etc/profile.d/modules.sh</span><br><span class="line">sudo ln -s /home/fenglei/local/init/profile.csh /etc/profile.d/modules.csh</span><br><span class="line">#sudo ln -s /home/fenglei/local/app/modules/init/profile.sh /etc/profile.d/modules.sh</span><br><span class="line">#sudo ln -s /home/fenglei/local/app/modules/init/profile.csh /etc/profile.d/modules.csh</span><br><span class="line">source /etc/profile #或重新登录命令行界面之后，则可以使用module 的一系列命令</span><br></pre></td></tr></table></figure>
<p>这样子每个用户在登录服务器的时候，shell会先执行/etc/profile，而/etc/profile的任务之一就是执行/etc/profile.d/下的所有shell脚本，也就将module的运行环境加入了用户登录的shell环境中。</p>
<p>在安装 module的过程中，安装目录下除了 bin、share、lib 文件夹，还会生成 init 和 modulefiles 两个文件夹。</p>
<p>怎么查看默认的 module path（即 modulefiles 所在路径）？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost init]$  echo $MODULEPATH </span><br><span class="line">/home/fenglei/local/modulefiles</span><br><span class="line"># [root@node02 init]#  echo $MODULEPATH   #查看默认的module path</span><br><span class="line"># /home/fenglei/local/modulefiles</span><br><span class="line">(base) [fenglei@localhost init]$ ll /home/fenglei/local/modulefiles</span><br><span class="line">total 24</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  346 Dec 29 11:17 dot</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  558 Dec 29 11:17 module-git</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 2272 Dec 29 11:17 module-info</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  773 Dec 29 11:17 modules</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  340 Dec 29 11:17 null</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 1398 Dec 29 11:17 use.own</span><br></pre></td></tr></table></figure>
<h3 id="配置-modules"><a class="markdownIt-Anchor" href="#配置-modules"></a> 配置 modules</h3>
<p>修改modulerc文件，自定义$MODULEPATH变量</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost local]$ cat ./init/modulerc </span><br><span class="line">#%Module1.0</span><br><span class="line"># This file defines the initial module command configuration, the default</span><br><span class="line"># modulefiles search path and modulefiles you want to load by default for all</span><br><span class="line"># users. It should contains lines of module command like &#x27;module config conf</span><br><span class="line"># val&#x27;, &#x27;module use path&#x27; and &#x27;module load mod&#x27;</span><br><span class="line">module use --append &#123;/home/fenglei/local/modulefiles&#125;</span><br></pre></td></tr></table></figure>
<p>在${MODULEPATH}/…/init文件夹下的modulerc文件，可以自定义多个modulefiles所在的文件夹。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd $MODULEPATH</span><br><span class="line">mkdir  &#123;application,compiler,cuda,mathlib,mpi,python,tool&#125;</span><br><span class="line">更新modulerc文件。</span><br><span class="line">vim $&#123;MODULEPATH&#125;/../init/modulerc</span><br><span class="line"></span><br><span class="line">#%Module1.0</span><br><span class="line"># This file defines  the initial setup for the modulefiles search path</span><br><span class="line"># and modulefiles you  want to load by default for all users. It should</span><br><span class="line"># contains a lines of  module command like &#x27;module use path&#x27; and</span><br><span class="line"># &#x27;module load mod&#x27;</span><br><span class="line"></span><br><span class="line">module use --append  &#123;/home/fenglei/local/modulefiles/application&#125;</span><br><span class="line">module use --append  &#123;/home/fenglei/local/modulefiles/compiler&#125;</span><br><span class="line">module use --append  &#123;/home/fenglei/local/modulefiles/cuda&#125;</span><br><span class="line">module use --append  &#123;/home/fenglei/local/modulefiles/mathlib&#125;</span><br><span class="line">module use --append  &#123;/home/fenglei/local/modulefiles/mpi&#125;</span><br><span class="line">module use --append  &#123;/home/fenglei/local/modulefiles/python&#125;</span><br><span class="line">module use --append  &#123;/home/fenglei/local/modulefiles/tool&#125;</span><br><span class="line"></span><br><span class="line">#重新登陆，查看自定义的MODULEPATH。</span><br><span class="line">source /etc/profile</span><br><span class="line">echo $MODULEPATH</span><br><span class="line">/home/fenglei/local/modulefiles/application:/home/fenglei/local/modulefiles/compiler:/home/fenglei/local/modulefiles/cuda:/home/fenglei/local/modulefiles/mathlib:/home/fenglei/local/modulefiles/mpi:/home/fenglei/local/modulefiles/python:/home/fenglei/local/modulefiles/tool</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>之后是配置用户能够调用的模块。需要进入modules安装目录，我是/PATH/TO/local/app/modules/modulefiles，在这文件里增加不同软件的配置信息，才能用module load进行加载。</p>
<h3 id="通过-modules-调用不同python版本的实例"><a class="markdownIt-Anchor" href="#通过-modules-调用不同python版本的实例"></a> 通过 modules 调用不同python版本的实例</h3>
<p>例如我希望用多个版本的 python，我的 python 的软件分别安装在 /home/fenglei/local/app/anaconda3/envs/python27/bin, /home/fenglei/local/app/anaconda3/envs/python37/bin。</p>
<p>那么，进入modulefiles目录，新建python文件夹，在python目录下分别新建2.7.18和3.7.9这两个目录。在两个版本编号目录下，分别建立“modulefile”文件，里面指定软件安装位置。具体目录结构如下代码块所示。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost local]$ cd modulefiles/</span><br><span class="line">(base) [fenglei@localhost modulefiles]$ pwd</span><br><span class="line">/home/fenglei/local/modulefiles</span><br><span class="line">(base) [fenglei@localhost modulefiles]$ tree python</span><br><span class="line">python</span><br><span class="line">├── 2.7.18</span><br><span class="line">│   └── modulefile</span><br><span class="line">└── 3.7.9</span><br><span class="line">    └── modulefile</span><br><span class="line"></span><br><span class="line">2 directories, 2 files</span><br><span class="line"></span><br><span class="line">(base) [fenglei@localhost modulefiles]$ cat python/2.7.18/modulefile </span><br><span class="line">#%Module1.0#####################################################################</span><br><span class="line">## modules modulefile</span><br><span class="line">module-whatis   &quot;Python 2.7.18&quot;</span><br><span class="line">prepend-path    PATH        /home/fenglei/local/app/anaconda3/envs/python27/bin</span><br><span class="line"></span><br><span class="line">(base) [fenglei@localhost modulefiles]$ cat python/3.7.9/modulefile       </span><br><span class="line">#%Module1.0#####################################################################</span><br><span class="line">## modules modulefile</span><br><span class="line">module-whatis   &quot;Python 3.7.9&quot;</span><br><span class="line">prepend-path    PATH        /home/fenglei/local/app/anaconda3/envs/python37/bin/</span><br></pre></td></tr></table></figure>
<p>按照上面的方法设置不同版本号的modulefile之后呢，下面演示了如何通过module load命令分别调用 python的不同版本。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost ~]$ which python</span><br><span class="line">~/local/app/anaconda3/bin/python</span><br><span class="line">(base) [fenglei@localhost ~]$ module list</span><br><span class="line">No Modulefiles Currently Loaded.</span><br><span class="line">(base) [fenglei@localhost ~]$ module load python/3.7.9</span><br><span class="line">(base) [fenglei@localhost ~]$ which python</span><br><span class="line">~/local/app/anaconda3/envs/python37/bin/python</span><br><span class="line">(base) [fenglei@localhost ~]$ module load python/2.7.18</span><br><span class="line">(base) [fenglei@localhost ~]$ which python             </span><br><span class="line">~/local/app/anaconda3/envs/python27/bin/python</span><br></pre></td></tr></table></figure>
<p>版本切换：如果想要换个环境，就可以用switch进行切换：<code>module switch blast blast/2.7.1</code></p>
<p>如果你不需要BLAST了，那么就用 <code>module unload blast/2.7.1</code> 就能在环境变量中移除。</p>
<p>对于一些依赖工具比较多的生信工具而言，用 conda 安装很方便，那么如何将 module 和 conda 进行整合呢。可以先在 conda 安装，然后在 modules 里面配置。这样可以通过 module load 加载这些程序。</p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<ol>
<li><a href="https://www.jianshu.com/p/c07820dbdfb4">xuzhougeng</a></li>
<li><a href="https://baiyongan.gitee.io/2019/02/23/Engineering-Environment-module/">baiyongan.gitee.io</a></li>
</ol>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>在Linux服务器上使用Nginx部署Hexo站点</title>
    <url>/2021/01/01/Linux-Using-Nginx-to-host-Hexo-blog-in-PC/</url>
    <content><![CDATA[<p>之前，我在内网的 Linux 计算机上通过使用 Nginx（web服务器），然后安装了 JBrowse 基因组浏览器，从而可以使基因组数据以 web 页面形式展示出来。通过内网其他电脑的浏览器访问 Linux 计算机的 IP 地址即可浏览基因组数据。由于没有设置外网IP，外网是不能访问的。</p>
<p>后来，由于尝试个人博客，我在 github 网站上通过 hexo（一种博客框架）搭建了自己的博客。这个博客可以在互联网访问，但是由于托管在 GitHub 仓库，所以有空间限制，不能上传太多大文件到仓库的。</p>
<p>最近买了一个虚拟主机（VPS），其实就是一个具有公网 IP 的 Linux 服务器。理论上，这台虚拟主机也可以用来自建一个 web 服务器，并建立个人博客或网站。下面是实践过程。</p>
<h3 id="一-在虚拟主机上安装-nginx-web服务器"><a class="markdownIt-Anchor" href="#一-在虚拟主机上安装-nginx-web服务器"></a> 一、在虚拟主机上安装 Nginx （web服务器）</h3>
<p>虚拟主机是在 vultr 购买的。基本配置是 CPU: 1 vCore；RAM: 1024 MB； Storage: 25 GB SSD；Bandwidth: 0.26 GB of 1000 GB；OS: CentOS SELinux 8 x64。</p>
<p><strong>Nginx安装</strong></p>
<p>以root用户登陆服务器，新建目录<code>/usr/local/nginx</code>。</p>
<p>Nginx 安装包下载地址：<a href="http://nginx.org/download/">http://nginx.org/download/</a>，我选了 <a href="http://nginx.org/download/nginx-1.19.6.tar.gz">nginx-1.19.6.tar.gz</a>。</p>
<p>安装步骤如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/nginx</span><br><span class="line">wget http://nginx.org/download/nginx-1.19.6.tar.gz</span><br><span class="line">tar -zxvf nginx-1.19.6.tar.gz</span><br><span class="line">cd nginx-1.19.6</span><br><span class="line">./configure --user=fenglei --group=fenglei --prefix=/usr/local/nginx/</span><br><span class="line"># 或者 ./configure --prefix=/usr/local/nginx/</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<p>备注：由于是新购买的主机，很多依赖软件没有安装，上面 <code>configure</code> 和 <code>make</code> 的过程中遇到系统报错信息，安装对应的编译工具就可以了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum -y install gcc</span><br><span class="line">yum -y install gcc-c++</span><br><span class="line">yum -y install openssl openssl-devel</span><br><span class="line">yum -y install pcre-devel</span><br><span class="line">#useradd fenglei</span><br><span class="line">yum -y install automake autoconf libtool make</span><br></pre></td></tr></table></figure>
<p><strong>Nginx启动、关闭、重启</strong></p>
<p>执行下方的 <code>nginx -s reload</code> 命令，即启动 Nginx web 服务器，理论上就可以在任何位置访问到这个 nginx 的初始网页，比如在其他 PC 或手机浏览器输入 <a href="http://123.456.78.89:80">http://123.456.78.89:80</a>，会看到一个如下图所示的静态网页。Nginx 配置文件中默认端口号是 80，如果 80 端口被其他应用占用，就需要更改 nginx 端口号。</p>
<p>更改端口号或者其他相关的配置需要修改 nginx 的配置文件：<code>/usr/local/nginx/conf/nginx.conf</code>，root 权限下 vim 这个配置文件，在 http 内容里面加入下面的文字。端口号可以自己设置，比如 8080、8082 等。location 字样则表示指向主页文件，比如我之前的 JBrowse 浏览器就设定为<code>/var/www/html/jbrowse/index.html</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 停止运行 nginx </span><br><span class="line">/usr/local/nginx/sbin/nginx -s stop  </span><br><span class="line"></span><br><span class="line"># 重启（reload）如果报错，就要先输入下面的命令`</span><br><span class="line">/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf  </span><br><span class="line"></span><br><span class="line"># 重启 nginx</span><br><span class="line">/usr/local/nginx/sbin/nginx -s reload</span><br></pre></td></tr></table></figure>
<p><img src="https://genehub.files.wordpress.com/2020/10/nginx-default-page.jpg?w=834" alt="nginx初始页面示例" /></p>
<h3 id="二-安装-nodejs"><a class="markdownIt-Anchor" href="#二-安装-nodejs"></a> 二、安装 Node.js</h3>
<p>Node.js 是什么？<a href="https://www.zhihu.com/question/33578075/answer/122448279">某网站</a>的解释是：Node.js 是一项服务器技术。我们都知道客户端提出服务请求，而服务器端负责处理请求并提供服务。而对于互联网来说，在Node.js 之前 JavaScript 是一项完全的客户端技术，被用于浏览器中实现各种动画，对 DOM 的操作等等。而后端，即服务端则是由 PHP、Python、Ruby、Java 等等语言来实现。Node.js 的出现，使得前后端使用同一种语言，统一模型的梦想得以实现。</p>
<p>npm 是随同 Node.js 一起安装的包管理工具，能解决 Node.js 代码部署上的很多问题，常见的使用场景有以下几种：允许用户从NPM服务器下载别人编写的第三方包到本地使用；允许用户从NPM服务器下载并安装别人编写的命令行程序到本地使用；允许用户将自己编写的包或命令行程序上传到NPM服务器供别人使用。</p>
<p>Node.js 软件包下载 <a href="https://nodejs.org/dist/v12.18.4/node-v12.18.4-linux-x64.tar.xz">https://nodejs.org/dist/v12.18.4/node-v12.18.4-linux-x64.tar.xz</a></p>
<p>按照下方命令行下载之，直接解压，没有编译步骤。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir /usr/local/app</span><br><span class="line">cd /usr/local/app</span><br><span class="line">https://nodejs.org/dist/v12.18.4/node-v12.18.4-linux-x64.tar.xz</span><br><span class="line">tar -xvJf node-v8.11.1-linux-x64.tar.xz</span><br></pre></td></tr></table></figure>
<p>解压目录里面会包含bin目录（node，npm，npx 三个程序），将 bin 目录路径加入环境变量（.bashrc）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">export PATH=/usr/local/app/node-v12.18.4-linux-x64/bin:$PATH</span><br><span class="line"># source ~/.bashrc 之后即可测试 node -h 与 npm -h，均可以运行。</span><br></pre></td></tr></table></figure>
<p>测试安装是否成功。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">node --version</span><br><span class="line">npm --version</span><br></pre></td></tr></table></figure>
<h3 id="三-安装-hexo-博客框架"><a class="markdownIt-Anchor" href="#三-安装-hexo-博客框架"></a> 三、安装 Hexo （博客框架）</h3>
<p>在虚拟机上直接用 npm 安装 hexo。（什么情况下需要：sudo yum install git-core）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br><span class="line">hexo --version  # 测试是否安装成功</span><br></pre></td></tr></table></figure>
<p>新建hexo项目</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd  /usr/local/app # 设置新建web项目所在路径</span><br><span class="line">hexo init hexo     # 初始化新建一个项目名称，随便起名 hexo init myname 都可以</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>通过 <code>Hexo g</code> 命令生成的静态站点，Hexo 站点目录中将出现一个 public 文件夹。如下方代码块所示。将新生成的静态站点（也就是 public/ 目录），拷贝至 nginx 目录下的 html 文件夹中。然后修改Nginx配置文件 nginx.conf，只修改 root 字段为 public 目录，其他地方都不变（参考下面的代码块所示例），然后重新加载 nginx，执行 <code>nginx -s reload</code>，重新访问 <a href="http://123.456.78.89:8000">http://123.456.78.89:8000</a>，就可以看到 Hexo 静态站点了。这里要注意浏览器缓存的问题，另外应该也可以不用将 public 拷贝到 <code>/usr/local/nginx/html/</code>，直接将 location 定义成绝对路径（/usr/local/app/hexo/public/）可能也能访问。</p>
<p>执行 <code>tree -l 1 /usr/local/app/hexo</code> 可见到其目录下包含的文件列表：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/usr/local/app/hexo/</span><br><span class="line">├── _config.landscape.yml</span><br><span class="line">├── _config.yml</span><br><span class="line">├── db.json</span><br><span class="line">├── node_modules</span><br><span class="line">├── package.json</span><br><span class="line">├── package-lock.json</span><br><span class="line">├── public</span><br><span class="line">├── scaffolds</span><br><span class="line">├── source</span><br><span class="line">└── themes</span><br></pre></td></tr></table></figure>
<p><code>/usr/local/nginx/conf/nginx.conf</code> 配置文件中的部分内容：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">server &#123;</span><br><span class="line">    listen       8000;</span><br><span class="line">    server_name  localhost;</span><br><span class="line"></span><br><span class="line">    #charset koi8-r;</span><br><span class="line"></span><br><span class="line">    #access_log  logs/host.access.log  main;</span><br><span class="line"></span><br><span class="line">    location / &#123;</span><br><span class="line">        root   html/public;</span><br><span class="line">        index  index.html;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>至此就可以看到 Hexo 的静态站点了。就是下图所示的界面。</p>
<p><img src="https://d33wubrfki0l68.cloudfront.net/5997a40576f3beca7bbbd86fe79a795e9d520d8e/87f88/themes/screenshots/landscape.png" alt="Hexo 初始页面示意图" /></p>
<p>Hexo 提供 <code>hexo s</code> 命令来实时查看页面，如果在服务器端启动 <code>hexo s</code>，在浏览器中同样也可以通过服务器 IP 来访问站点，并且能实时显示当前状态。但是，<code>hexo s</code> 效率低，只适合在线调试，不适合作为站点访问。更新的时候，需要使用 <code>hexo g</code> 命令重新生成站点，然后将更新后的 public 目录拷贝到 nginx 目录中 html 文件夹下即可。</p>
<h3 id="四-更改网站主题"><a class="markdownIt-Anchor" href="#四-更改网站主题"></a> 四、更改网站主题</h3>
<p>Hexo 有大量个性化主题，我在 GitHub 博客用的 ，因为简洁轻便，所以在访问博客的时候加载快速，又因为它自动适应不同设备，在电脑、Pad 或手机访问均能良好展示，我非常中意。这次测试 Academia 主题，是一个学术主题，例如展示实验室课题组，或者研究人员个人主页。该主题网址：<a href="https://phosphorw.github.io/">https://phosphorw.github.io/</a></p>
<p>The simplest way to install is to clone the entire repository:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone https://github.com/PhosphorW/hexo-theme-academia.git themes/Academia</span><br></pre></td></tr></table></figure>
<p>Some required renderers:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install hexo-renderer-pug hexo-renderer-stylus</span><br></pre></td></tr></table></figure>
<p>Set theme in hexo work folder’s _config.yml</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">theme: Academia</span><br></pre></td></tr></table></figure>
<p>以上就是安装 Academia 主题的最基本操作，设置 hexo 的 _config.yml 之后，执行 <code>hexo</code> 更新 public 文件夹，再将 public/ 拷贝到 Nginx 安装目录的 html 下面。就可以看到新主题了（类似下图），内容区域还是个空白的，需要参考 Academia 的说明书进行添加页面。</p>
<p><img src="https://raw.githubusercontent.com/PhosphorW/phower-img-folder/master/hexo-theme-academia_mockup.jpg" alt="Academia 示意图" /></p>
<h3 id="五-参考资料"><a class="markdownIt-Anchor" href="#五-参考资料"></a> 五、参考资料</h3>
<ol>
<li><a href="https://bioinfx.github.io/2020/10/03/%E5%9F%BA%E5%9B%A0%E7%BB%84%E6%B5%8F%E8%A7%88%E5%99%A8-jbrowse-%E5%AE%89%E8%A3%85%EF%BC%88%E5%9F%BA%E4%BA%8E-nginx-%E7%9A%84-web-%E6%9C%8D%E5%8A%A1%E5%99%A8%EF%BC%89/">基因组浏览器 JBrowse 安装（基于 Nginx 的 Web 服务器）</a></li>
<li><a href="https://genehub.wordpress.com/2020/12/07/%e4%bd%bf%e7%94%a8-github-hexo-%e5%bb%ba%e7%ab%8b%e4%b8%aa%e4%ba%ba%e5%8d%9a%e5%ae%a2/">使用 GitHub + Hexo 建立个人博客</a></li>
<li><a href="https://www.jianshu.com/p/31eb5c754c01">使用Nginx部署Hexo站点</a></li>
<li><a href="https://segmentfault.com/a/1190000009723457">使用Nginx+Hexo光速搭建博客并实现服务器自动部署</a></li>
<li><a href="https://blog.csdn.net/t8116189520/article/details/81909574">LINUX安装nginx详细步骤</a></li>
</ol>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | 给Linux工作站更换新硬盘</title>
    <url>/2022/05/26/Linux-add-new-harddisk/</url>
    <content><![CDATA[<p>之前已经挂载过硬盘，就是在root界面先<code>fdisk -l</code>查看机箱里有哪些硬盘，比如<code>/dev/sda</code>和<code>/dev/sdb</code>，如果<code>/dev/sdb</code>需要挂载，就用<code>fdisk /dev/sdb</code>命令进行硬盘分区，依次输入<code>n</code>（创建新分区），<code>p</code>（创建主分区）,<code>w</code>（保存新建分区）就可以将一块硬盘作为一个新的分区，比如<code>/dev/sdb1</code>。这样我们就创建完一个分区，如果这块硬盘要创建更多分区，比如<code>/dev/sdb2</code>，可以照上面的步骤继续创建。</p>
<p>现在问题来了，我新买了一块4TB硬盘，按照上面的步骤操作，挂载之后怎么只有2TB呢？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost fenglei]# fdisk -l</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 4000.8 GB, 4000787030016 bytes, 7814037168 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0xabe30878</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sdb1            2048  4294967294  2147482623+  83  Linux</span><br><span class="line">WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.</span><br></pre></td></tr></table></figure>
<p>查看<a href="https://blog.frytea.com/archives/597/">资料</a>才知道：进行分区前需要先明确采用分区表的格式，目前主流的有 MBR 和 GPT ，二者的区别可以自行搜索，总结两点：MBR 兼容性较好，兼容所有 windows，但单盘最大 2TB ；GPT 是一种新格式，最大支持 18EB 的大容量，但并不是所有的 windows 都支持。知道上面两点就够了，这里我使用在 Linux 服务器上，不需要考虑 windows 兼容性，此外是一块 4T 盘，因此采用 GPT 进行分区，下面两种方式请根据自己的需要选择。</p>
<p>看来默认的是 MBR，而不是 GPT。方法也很简单，就是在<code>fdisk /dev/sdb</code>界面先输入<code>d</code>，删除现有分区信息，然后输入<code>g</code>，创建一张新的空 GPT 格式分区表。如下所示，顺利将一整块硬盘的空间新建一个分区。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ fdisk /dev/sdb</span><br><span class="line">Command (m for help): p</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 4000.8 GB, 4000787030016 bytes, 7814037168 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0xabe30878</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line">/dev/sdb1            2048  4294967294  2147482623+  83  Linux</span><br><span class="line"></span><br><span class="line">Command (m for help): d</span><br><span class="line">Selected partition 1</span><br><span class="line">Partition 1 is deleted</span><br><span class="line"></span><br><span class="line">Command (m for help): p               </span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 4000.8 GB, 4000787030016 bytes, 7814037168 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: dos</span><br><span class="line">Disk identifier: 0xabe30878</span><br><span class="line"></span><br><span class="line">   Device Boot      Start         End      Blocks   Id  System</span><br><span class="line"></span><br><span class="line">Command (m for help): g</span><br><span class="line">Building a new GPT disklabel (GUID: A2443A99-8E33-4353-947A-0244414D75A4)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Command (m for help): n</span><br><span class="line">Partition number (1-128, default 1): </span><br><span class="line">First sector (2048-7814037134, default 2048): </span><br><span class="line">Last sector, +sectors or +size&#123;K,M,G,T,P&#125; (2048-7814037134, default 7814037134): </span><br><span class="line">Created partition 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Command (m for help): p</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 4000.8 GB, 4000787030016 bytes, 7814037168 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: gpt</span><br><span class="line">Disk identifier: A2443A99-8E33-4353-947A-0244414D75A4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#         Start          End    Size  Type            Name</span><br><span class="line"> 1         2048   7814037134    3.7T  Linux filesyste </span><br><span class="line"></span><br><span class="line">Command (m for help): w</span><br><span class="line">The partition table has been altered!</span><br><span class="line"></span><br><span class="line">Calling ioctl() to re-read partition table.</span><br><span class="line">Syncing disks.</span><br><span class="line">[root@localhost fenglei]# </span><br></pre></td></tr></table></figure>
<h3 id="硬盘格式化"><a class="markdownIt-Anchor" href="#硬盘格式化"></a> 硬盘格式化</h3>
<p>先看看分区信息</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost fenglei]# fdisk -l</span><br><span class="line">WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.</span><br><span class="line"></span><br><span class="line">Disk /dev/sdb: 4000.8 GB, 4000787030016 bytes, 7814037168 sectors</span><br><span class="line">Units = sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 512 bytes</span><br><span class="line">I/O size (minimum/optimal): 512 bytes / 512 bytes</span><br><span class="line">Disk label type: gpt</span><br><span class="line">Disk identifier: A2443A99-8E33-4353-947A-0244414D75A4</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">#         Start          End    Size  Type            Name</span><br><span class="line"> 1         2048   7814037134    3.7T  Linux filesyste </span><br><span class="line">WARNING: fdisk GPT support is currently new, and therefore in an experimental phase. Use at your own discretion.</span><br></pre></td></tr></table></figure>
<p>没问题后进行格式化，如果没有特殊需求就采用 ext4 ：第四代扩展文件系统（英语：Fourth extended filesystem，缩写为 ext4）是 Linux 系统下的日志文件系统，是 ext3 文件系统的后继版本。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost fenglei]#  mkfs.ext4 /dev/sdb1</span><br><span class="line">mke2fs 1.42.9 (28-Dec-2013)</span><br><span class="line">Filesystem label=</span><br><span class="line">OS type: Linux</span><br><span class="line">Block size=4096 (log=2)</span><br><span class="line">Fragment size=4096 (log=2)</span><br><span class="line">Stride=0 blocks, Stripe width=0 blocks</span><br><span class="line">244195328 inodes, 976754385 blocks</span><br><span class="line">48837719 blocks (5.00%) reserved for the super user</span><br><span class="line">First data block=0</span><br><span class="line">Maximum filesystem blocks=3124756480</span><br><span class="line">29809 block groups</span><br><span class="line">32768 blocks per group, 32768 fragments per group</span><br><span class="line">8192 inodes per group</span><br><span class="line">Superblock backups stored on blocks: </span><br><span class="line">        32768, 98304, 163840, 229376, 294912, 819200, 884736, 1605632, 2654208, </span><br><span class="line">        4096000, 7962624, 11239424, 20480000, 23887872, 71663616, 78675968, </span><br><span class="line">        102400000, 214990848, 512000000, 550731776, 644972544</span><br><span class="line"></span><br><span class="line">Allocating group tables:     0/29809</span><br><span class="line">done                            </span><br><span class="line">Writing inode tables: done                            </span><br><span class="line">Creating journal (32768 blocks): done</span><br><span class="line">Writing superblocks and filesystem accounting information: done </span><br></pre></td></tr></table></figure>
<p>上面的格式化只需要几秒钟！</p>
<p>以前的ext3分区需要几个小时，如下所示，下面这个命令不要再用了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#mkfs -t ext3 -c /dev/sdb1  //如果有多个分区，则分区修改为sdb2这样</span><br><span class="line">（格式化2TB的硬盘，耗时约3小时。20151125 FL备注）</span><br></pre></td></tr></table></figure>
<h3 id="挂载"><a class="markdownIt-Anchor" href="#挂载"></a> 挂载</h3>
<p>下面挂载到 <code>/mnt/sdb</code>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost fenglei]# mount /dev/sdb1 /mnt/sdb</span><br><span class="line">[root@localhost fenglei]# df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">devtmpfs         32G     0   32G   0% /dev</span><br><span class="line">tmpfs            32G     0   32G   0% /dev/shm</span><br><span class="line">tmpfs            32G  9.7M   32G   1% /run</span><br><span class="line">tmpfs            32G     0   32G   0% /sys/fs/cgroup</span><br><span class="line">/dev/sda5       3.2T  3.0T  209G  94% /</span><br><span class="line">/dev/sda3       466G  466G   20K 100% /home</span><br><span class="line">/dev/sda2       197M  186M   11M  95% /boot</span><br><span class="line">tmpfs           6.3G     0  6.3G   0% /run/user/1000</span><br><span class="line">/dev/sdc1       1.8T  707G  1.1T  41% /mnt/sdc</span><br><span class="line">/dev/sdb1       3.6T   89M  3.4T   1% /mnt/sdb</span><br></pre></td></tr></table></figure>
<h3 id="设置开机自动挂载硬盘"><a class="markdownIt-Anchor" href="#设置开机自动挂载硬盘"></a> 设置开机自动挂载硬盘</h3>
<p>直接挂载，重启后配置会丢失，可以修改 /etc/fstab 配置文件配置开机自动挂载，该配置文件的格式如下：<br />
（下面是参考资料直接抄来的）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cat /etc/fstab </span><br><span class="line"># /etc/fstab: static file system information.</span><br><span class="line">#</span><br><span class="line"># Use &#x27;blkid&#x27; to print the universally unique identifier for a</span><br><span class="line"># device; this may be used with UUID= as a more robust way to name devices</span><br><span class="line"># that works even if disks are added and removed. See fstab(5).</span><br><span class="line">#</span><br><span class="line"># &lt;file system&gt; &lt;mount point&gt;   &lt;type&gt;  &lt;options&gt;       &lt;dump&gt;  &lt;pass&gt;</span><br><span class="line"># / was on /dev/sda7 during installation</span><br><span class="line">UUID=4ae9f128-7cee-48fd-998c-4257e394fa4a /               ext4    errors=remount-ro 0       1</span><br><span class="line"># /boot/efi was on /dev/sda1 during installation</span><br><span class="line">UUID=A5EB-573A  /boot/efi       vfat    umask=0077      0       1</span><br><span class="line">/swapfile                                 none            swap    sw              0       0</span><br><span class="line"></span><br><span class="line"># /dev/sda1</span><br><span class="line">/dev/sda1    /    ext4    rw,relatime    0    1</span><br><span class="line">UUID=4ae9f128-7cee-48fd-998c-4257e394fa4a /               ext4    errors=remount-ro 0       1</span><br></pre></td></tr></table></figure>
<p>格式大概是这样的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># &lt;file system&gt; &lt;mount point&gt;   &lt;type&gt;  &lt;options&gt;       &lt;dump&gt;  &lt;pass&gt;</span><br><span class="line"># 要挂载的分区设备号    挂载点    文件系统类型    挂载选项    是否备份    是否检测</span><br></pre></td></tr></table></figure>
<p>如果需要设备号，可以使用 blkid 命令获取：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ blkid</span><br><span class="line">/dev/sda1: UUID=&quot;e943af1e-72cf-4b72-b444-859b9610256f&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;161a8c3f-871d-45f6-a25f-466bf16f6035&quot;</span><br></pre></td></tr></table></figure>
<p>实测下面这两种都是可以挂载的：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">UUID=4ae9f128-7cee-48fd-998c-4257e394fa4a /               ext4    errors=remount-ro     0       1</span><br><span class="line">/dev/sda1       /               ext4            rw,relatime     0       1</span><br></pre></td></tr></table></figure>
<p>我的实际操作如下，在 /etc/fstab  添加如下内容！</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># /dev/sdb1: UUID=&quot;42ece9ae-1c69-4a2d-8862-45c44c44ccac&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;b3035439-0e9e-4512-b56c-d5cfc7754706&quot;</span><br><span class="line">UUID=42ece9ae-1c69-4a2d-8862-45c44c44ccac       /mnt/sdb        ext4    defaults        0       1</span><br></pre></td></tr></table></figure>
<p>写好配置后可以使用该命令生效（挂载 /etc/fstab 中所有档案）：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mount -a</span><br></pre></td></tr></table></figure>
<p>下次重启设备就不需要再手动挂载该磁盘了。</p>
<p>磁盘状态</p>
<p>使用 lsblk 看一下当前硬盘的树形结构：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ lsblk </span><br><span class="line">NAME   MAJ:MIN RM   SIZE RO TYPE MOUNTPOINT</span><br><span class="line">sda      8:0    0 465.8G  0 disk </span><br><span class="line">└─sda1   8:1    0 465.8G  0 part /</span><br><span class="line">sdc      8:32   0   3.7T  0 disk </span><br><span class="line">└─sdc1   8:33   0   3.7T  0 part /home/songtianlun/data</span><br></pre></td></tr></table></figure>
<p>使用 df-h 看看使用率：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ df -h</span><br><span class="line">文件系统        容量  已用  可用 已用% 挂载点</span><br><span class="line">/dev/sda1       459G  8.6G  427G    2% /</span><br><span class="line">...</span><br><span class="line">/dev/sdc1       3.6T   89M  3.4T    1% /home/songtianlun/data</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p><a href="https://blog.frytea.com/archives/597/">https://blog.frytea.com/archives/597/</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | 安装Linux系统之后还想调整home目录的空间怎么操作</title>
    <url>/2022/05/15/Linux-adjust-space-in-home/</url>
    <content><![CDATA[<p>问题：2020 年的时候，服务器系统盘损坏导致系统无法开机，于是新加了一块硬盘作为 Linux 系统盘。系统盘 /dev/sda，拿一个 500 GB 的分区（/dev/sda3）作为系统安装位置，其余 3 TB 左右（/dev/sda5）则准备挂载到系统的某个目录下（比如/mnt/xxx）。但是同学习惯在 home 目录下做项目，于是 500 GB 的空间很快就不够用，同学采取 bind mount 的方法将其余空间也挂载到 home 目录下面。</p>
<p>确定四下无人后, 开始搬家(复制). 使用 cp 命令复制时, 记得带上 -p 参数, 保留文件权限设置. 使用 root 权限, 假设目标分区为 /new_disk :</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cp -p -r /home /home_new/</span><br></pre></td></tr></table></figure>
<p>新家已经建好, 我们先给老家弄个另外的门牌号, 以免把门牌号给新家后, 找不到老家了. 利用 mount –bind 把原 home 目录挂载到一个新目录:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mkdir /home_bkp</span><br><span class="line">mount --bind /home /home_bkp</span><br></pre></td></tr></table></figure>
<p>这时我们就可以在 /home_bkp 这个目录下找到老家的所有文件. 可以把 /home 这个门牌给新家了:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mount --bind /home_new/home /home</span><br></pre></td></tr></table></figure>
<p>至此 home 目录就扩大了。mount bind 是什么原理？有人说“当我们使用 bind 的时候，是将一个目录 A 挂载到另一个目录 B ，目录 B 原有的内容就被屏蔽掉了，目录 B 里面的内容就是目录 A 里面的内容。这和我们挂在其他分区到挂载点目录一样，目录 B 的内容还是存在的，只不过是被屏蔽了，当我们 umount B 后，原内容就会复现。”</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">mount --bind olddir newdir</span><br></pre></td></tr></table></figure>
<p>如果执行了上面这个命令，在 olddir 和 newdir 都可以访问相同的内容，并且如果对其中一个目录内的内容进行了修改，在另一个目录会有相同的显示。</p>
<p>最后，注意一点，如果机器重启，上面的挂载信息会丢失，造成不便，所以可以添加相关挂载信息到 /etc/fstab 文件。这样重启之后也会自动挂载。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/home   /home_bkp   none    bind    0   0</span><br><span class="line">/home_new   /home   none    bind    0   0</span><br></pre></td></tr></table></figure>
<p>备注：这样操作之后，重启还是没有自动挂载！还是需要重新 mount。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[root@localhost fenglei]# mount --bind /home /home_bkp</span><br><span class="line">[root@localhost fenglei]# mount --bind /home_new/home /home</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h3>
<p><a href="http://blog.csdn.net/liuxu0703/article/details/70225591">http://blog.csdn.net/liuxu0703/article/details/70225591</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Awk编程：将数字四舍五入之后输出整数</title>
    <url>/2016/09/11/Linux-awk-how-to-print-int-number/</url>
    <content><![CDATA[<p></p>
<ol>
<li>awk ‘{print int($1+0.5)}’ file</li>
</ol>
<p><em>复制代码</em></p>
<ol>
<li>n====a% more file</li>
<li>40</li>
<li>72</li>
<li>83.25</li>
<li>222.032</li>
<li>249.75</li>
<li>1722.501</li>
<li>n====a% awk ‘{print int($1+0.5)}’ file</li>
<li>40</li>
<li>72</li>
<li>83</li>
<li>222</li>
<li>250</li>
<li>1723</li>
</ol>
<p><strong>+0.5, 然后取整，是很多编程语言常用的计算四舍五入的方法。</strong>   Ref：<a href="http://bbs.linuxtone.org/thread-16472-1-1.html">http://bbs.linuxtone.org/thread-16472-1-1.html</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux更新git</title>
    <url>/2019/07/31/Linux-how-to-upgrade-git/</url>
    <content><![CDATA[<p>系统自带的git无法下载：</p>
<p>error: error:1407742E:SSL routines:SSL23_GET_SERVER_HELLO:tlsv1 alert protocol</p>
<p>查询之后据说是 GitHub 不再支持TLSv1/TLSv1.1了，公告地址：<a href="https://githubengineering.com/crypto-removal-notice/">Weak cryptographic standards removal notice</a> 于是安装新版git（<a href="https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.15.0.tar.gz%EF%BC%89%EF%BC%8Cmake%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E6%8A%A5%E9%94%99%EF%BC%8C%E6%98%BE%E7%A4%BA%E7%B3%BB%E7%BB%9F%E7%9A%84openssl%E6%9C%89%E9%97%AE%E9%A2%98%E3%80%82">https://mirrors.edge.kernel.org/pub/software/scm/git/git-2.15.0.tar.gz），make的过程中报错，显示系统的openssl有问题。</a></p>
<p>error OPENSSL_ALGORITHM_DEFINES no longer supported</p>
<p>重新安装openssl到/usr/local/ 安装openssl到 /usr/local/openssl 目录，安装之后，编译；</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">./config shared zlib  --prefix=/usr/local/openssl &amp;&amp; make &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<p>安装openssl就重新编译git，还报错（实际上上面写成<code>--prefix=/usr/local应该就没问题了</code>）</p>
<p>/usr/local/include/openssl/opensslconf.h  error OPENSSL_ALGORITHM_DEFINES no longer supported</p>
<p>于是进去这个目录，将opensslconf.h做了个软连接到新安装的文件目录/usr/local/openssl/include/openssl/opensslconf.h</p>
<p>ln -s /usr/local/openssl/include/openssl/opensslconf.h /usr/local/include/openssl/opensslconf.h</p>
<p>接下来make的过程还遇到了perl的问题。在将git安装文件里面的Makefile，将里面的/usr/bin/perl修改成自己目录的perl就行了。</p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>Linux安装mysql-5.7.25</title>
    <url>/2019/03/30/Linux-install-mysql-5-7-25/</url>
    <content><![CDATA[<p>下面的操作完全是照搬其他人的经验（<a href="https://segmentfault.com/a/1190000012703513%EF%BC%89%EF%BC%8C%E6%AD%A4%E5%A4%84%E8%AE%B0%E5%BD%95%E5%A4%87%E4%BB%BD%E7%94%A8%E3%80%82%E4%B9%9F%E5%8F%AF%E5%8F%82%E8%80%83%EF%BC%9Ahttps://www.jellythink.com/archives/14">https://segmentfault.com/a/1190000012703513），此处记录备份用。也可参考：https://www.jellythink.com/archives/14</a> ---------------------------------- 由于mysql 5.7.17版本以后 support_files文件夹中无 <strong>my_default.cnf</strong> 文件，所以今天给大家详细描述一下 mysql 5.7.20版本(目前官方最新版)的安装步骤。 第一步：下载mysql最新版</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget http://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.20-linux-glibc2.12-x86_64.tar.gz</span><br></pre></td></tr></table></figure>
<p>第二步：在/usr/local/中解压压缩包，并改名为mysql</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/</span><br><span class="line"></span><br><span class="line">tar -xzvf /data/software/mysql-5.7.13-linux-glibc2.5-x86_64.tar.gz (我的下载目录为 data/software)</span><br><span class="line"></span><br><span class="line">mv mysql-5.7.13-linux-glibc2.5-x86_64 mysql</span><br></pre></td></tr></table></figure>
<p>第三步：创建用户组mysql，创建用户mysql并将其添加到用户组mysql中，并赋予读写权限</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">groupadd mysql</span><br><span class="line"></span><br><span class="line">useradd -r -g mysql mysql</span><br><span class="line"></span><br><span class="line">chown -R mysql mysql/</span><br><span class="line"></span><br><span class="line">chgrp -R mysql mysql/</span><br></pre></td></tr></table></figure>
<p>第四步：创建配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /etc/my.cnf</span><br><span class="line"></span><br><span class="line">#复制以下内容</span><br><span class="line"></span><br><span class="line">[client]</span><br><span class="line">port = 3306</span><br><span class="line">socket = /tmp/mysql.sock</span><br><span class="line"></span><br><span class="line">[mysqld]</span><br><span class="line">character_set_server=utf8</span><br><span class="line">init_connect=&#x27;SET NAMES utf8&#x27;</span><br><span class="line">basedir=/usr/local/mysql</span><br><span class="line">datadir=/usr/local/mysql/data</span><br><span class="line">socket=/tmp/mysql.sock</span><br><span class="line">log-error=/var/log/mysqld.log</span><br><span class="line">pid-file=/var/run/mysqld/mysqld.pid</span><br><span class="line">#不区分大小写</span><br><span class="line">lower_case_table_names = 1</span><br><span class="line"></span><br><span class="line">sql_mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION</span><br><span class="line"></span><br><span class="line">max_connections=5000</span><br><span class="line"></span><br><span class="line">default-time_zone = &#x27;+8:00&#x27;</span><br></pre></td></tr></table></figure>
<p>按ESC保存并关闭，输入如下命令</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">:wq!</span><br></pre></td></tr></table></figure>
<p>第五步：初始化数据库</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#先安装一下这个东东，要不然初始化有可能会报错</span><br><span class="line">yum install libaio</span><br><span class="line">#手动编辑一下日志文件，什么也不用写，直接保存退出</span><br><span class="line">cd /var/log/</span><br><span class="line"></span><br><span class="line">vim mysqld.log</span><br><span class="line">：wq</span><br><span class="line"></span><br><span class="line">chmod 777 mysqld.log</span><br><span class="line">chown mysql:mysql mysqld.log</span><br><span class="line"></span><br><span class="line">/usr/local/mysql/bin/mysqld --initialize --user=mysql --basedir=/usr/local/mysql --datadir=/usr/local/mysql/data --lc_messages_dir=/usr/local/mysql/share --lc_messages=en_US</span><br></pre></td></tr></table></figure>
<p>第六步：查看初始密码</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat /var/log/mysqld.log</span><br></pre></td></tr></table></figure>
<p>执行后关注最后一点：root@localhost: 这里就是初始密码 第七步：启动服务，进入mysql，修改初始密码，运行远程连接（这里执行完后，密码将变成：你设置的新密码）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#如果提示必须要修改密码才可以进行操作的话则执行下面操作</span><br><span class="line">set password=password(&#x27;新密码&#x27;);</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br><span class="line"></span><br><span class="line">UPDATE `mysql`.`user` SET `Host` = &#x27;%&#x27;,  `User` = &#x27;root&#x27;  WHERE (`Host` = &#x27;localhost&#x27;) AND (`User` = &#x27;root&#x27;);</span><br><span class="line"></span><br><span class="line">#然后执行如下操作开启mysql服务，以及设置相关权限</span><br><span class="line">cd /var/run/</span><br><span class="line"></span><br><span class="line">mkdir mysqld</span><br><span class="line"></span><br><span class="line">chmod 777 mysqld</span><br><span class="line"></span><br><span class="line">cd mysqld</span><br><span class="line"></span><br><span class="line">touch mysqld.pid</span><br><span class="line"></span><br><span class="line">chmod 777 mysqld.pid</span><br><span class="line"></span><br><span class="line">chown mysql:mysql mysqld.pid </span><br><span class="line"></span><br><span class="line">/usr/local/mysql/support-files/mysql.server start</span><br><span class="line"></span><br><span class="line">/usr/local/mysql/bin/mysql -uroot -p 你在上面看到的初始密码</span><br><span class="line"></span><br><span class="line"># 以下是进入数据库之后的sql语句</span><br><span class="line"> use mysql;</span><br><span class="line"></span><br><span class="line"> UPDATE `mysql`.`user` SET `Host`=&#x27;%&#x27;, `User`=&#x27;root&#x27;, `Select_priv`=&#x27;Y&#x27;, `Insert_priv`=&#x27;Y&#x27;, `Update_priv`=&#x27;Y&#x27;, `Delete_priv`=&#x27;Y&#x27;, `Create_priv`=&#x27;Y&#x27;, `Drop_priv`=&#x27;Y&#x27;, `Reload_priv`=&#x27;Y&#x27;, `Shutdown_priv`=&#x27;Y&#x27;, `Process_priv`=&#x27;Y&#x27;, `File_priv`=&#x27;Y&#x27;, `Grant_priv`=&#x27;Y&#x27;, `References_priv`=&#x27;Y&#x27;, `Index_priv`=&#x27;Y&#x27;, `Alter_priv`=&#x27;Y&#x27;, `Show_db_priv`=&#x27;Y&#x27;, `Super_priv`=&#x27;Y&#x27;, `Create_tmp_table_priv`=&#x27;Y&#x27;, `Lock_tables_priv`=&#x27;Y&#x27;, `Execute_priv`=&#x27;Y&#x27;, `Repl_slave_priv`=&#x27;Y&#x27;, `Repl_client_priv`=&#x27;Y&#x27;, `Create_view_priv`=&#x27;Y&#x27;, `Show_view_priv`=&#x27;Y&#x27;, `Create_routine_priv`=&#x27;Y&#x27;, `Alter_routine_priv`=&#x27;Y&#x27;, `Create_user_priv`=&#x27;Y&#x27;, `Event_priv`=&#x27;Y&#x27;, `Trigger_priv`=&#x27;Y&#x27;, `Create_tablespace_priv`=&#x27;Y&#x27;, `ssl_type`=&#x27;&#x27;, `ssl_cipher`=&#x27;&#x27;, `x509_issuer`=&#x27;&#x27;, `x509_subject`=&#x27;&#x27;, `max_questions`=&#x27;0&#x27;, `max_updates`=&#x27;0&#x27;, `max_connections`=&#x27;0&#x27;, `max_user_connections`=&#x27;0&#x27;, `plugin`=&#x27;mysql_native_password&#x27;, `authentication_string`=&#x27;*6BB4837EB74329105EE4568DDA7DC67ED2CA2AD9&#x27;, `password_expired`=&#x27;N&#x27;, `password_last_changed`=&#x27;2017-11-20 12:41:07&#x27;, `password_lifetime`=NULL, `account_locked`=&#x27;N&#x27; WHERE  (`User`=&#x27;root&#x27;);</span><br><span class="line"></span><br><span class="line"> flush privileges;</span><br></pre></td></tr></table></figure>
<p>第八步：开机自启</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd /usr/local/mysql/support-files</span><br><span class="line"></span><br><span class="line">cp mysql.server /etc/init.d/mysqld</span><br><span class="line"></span><br><span class="line">chkconfig --add mysqld</span><br></pre></td></tr></table></figure>
<p>第九步：使用service mysqld命令启动/停止服务</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">su - mysql</span><br><span class="line"></span><br><span class="line">service mysqld start/stop/restart</span><br></pre></td></tr></table></figure>
<p>登陆，修改密码 root密码是123456</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 登陆mysql</span><br><span class="line">mysql -uroot -p</span><br><span class="line"></span><br><span class="line"># 修改root用户密码</span><br><span class="line">set password for root@localhost=password(&quot;123456&quot;);</span><br></pre></td></tr></table></figure>
<p>远程用户建立</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">grant all privileges on *.* to &#x27;新用户名&#x27;@&#x27;%&#x27; identified by &#x27;新密码&#x27;;</span><br><span class="line"></span><br><span class="line">flush privileges;</span><br></pre></td></tr></table></figure>
<p><img src="https://genehub.files.wordpress.com/2019/03/e5beaee4bfa1e688aae59bbe_20190330204936.png" alt="微信截图_20190330204936" /> 添加系统路径</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim /etc/profile</span><br><span class="line"></span><br><span class="line">export PATH=/usr/local/mysql/bin:$PATH</span><br><span class="line"></span><br><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure>
<p>以上步骤都执行完毕后，大吉大利，今晚吃鸡！！！！！！ 如果可以使用navicat 使用你刚才设置的用户名和密码访问，那么你的mysql就已经安装成功啦！ ===== 20190814 更新 增加pasa用户，设置只读权限。用于基因预测pasa软件流程。参考 <a href="http://www.chenlianfu.com/?p=1133">http://www.chenlianfu.com/?p=1133</a></p>
<p>$ mysql -uroot -p<br />
Enter password: ******** [# 输入root用户的密码]<br />
Welcome to the MySQL monitor. Commands end with ; or \g.<br />
Your MySQL connection id is 6<br />
Server version: 5.7.25 MySQL Community Server (GPL)</p>
<p>Copyright © 2000, 2019, Oracle and/or its affiliates. All rights reserved.</p>
<p>Oracle is a registered trademark of Oracle Corporation and/or its<br />
affiliates. Other names may be trademarks of their respective<br />
owners.</p>
<p>Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement.</p>
<h2 id="新建pasa用户只设置可读权限"><a class="markdownIt-Anchor" href="#新建pasa用户只设置可读权限"></a> 新建pasa用户，只设置可读权限</h2>
<p>mysql&gt; CREATE USER ‘pasa’@‘localhost’ IDENTIFIED BY ‘123456’;<br />
Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; GRANT SELECT ON *.* TO ‘pasa’@‘%’ IDENTIFIED BY ‘123456’;<br />
Query OK, 0 rows affected, 1 warning (0.00 sec)</p>
<p>mysql&gt; FLUSH PRIVILEGES;<br />
Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt;</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux安装tmux</title>
    <url>/2016/01/27/Linux-install-tmux/</url>
    <content><![CDATA[<p>按照tmux官网（<a href="https://github.com/tmux/tmux%EF%BC%89%E7%9A%84%E6%8C%87%E7%A4%BA%EF%BC%8C%E9%81%87%E5%88%B0%E5%87%A0%E4%B8%AA%E9%97%AE%E9%A2%98%EF%BC%8C%E9%80%90%E4%B8%AA%E8%A7%A3%E5%86%B3%EF%BC%9A">https://github.com/tmux/tmux）的指示，遇到几个问题，逐个解决：</a></p>
<h2 id="问题一-没有root权限tmux进行configure的时候找不到libevent"><a class="markdownIt-Anchor" href="#问题一-没有root权限tmux进行configure的时候找不到libevent"></a> 问题一、没有root权限，tmux进行configure的时候找不到libevent</h2>
<h3 id="why-cant-gcc-find-libevent-when-building-tmux-from-source"><a class="markdownIt-Anchor" href="#why-cant-gcc-find-libevent-when-building-tmux-from-source"></a> <a href="https://unix.stackexchange.com/questions/17907/why-cant-gcc-find-libevent-when-building-tmux-from-source">Why can’t gcc find libevent when building tmux from source?</a></h3>
<p>解决办法：（<a href="https://unix.stackexchange.com/questions/17907/why-cant-gcc-find-libevent-when-building-tmux-from-source/17918#17918?newreg=999d85dd0c684842ac7538811cbe3015%EF%BC%89">https://unix.stackexchange.com/questions/17907/why-cant-gcc-find-libevent-when-building-tmux-from-source/17918#17918?newreg=999d85dd0c684842ac7538811cbe3015）</a> Try:</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">DIR=&quot;$HOME/.bin-libevent&quot;</span><br><span class="line">./configure CFLAGS=&quot;-I$DIR/include&quot; LDFLAGS=&quot;-L$DIR/lib&quot;</span><br></pre></td></tr></table></figure>
</blockquote>
<p>(I’m sure there must be a better way to configure library paths with autoconf. Usually there is a <code>--with-libevent=dir</code> option. But here, it seems there is no such option.) 第二次换了一台机器也遇到了libevent报错，于是先安装libevent到了自己的软件目录（没有root权限）,可在/share/raid12/c-fenglei/local/lib下面看到libevent-2.1.so.6等等文件，可在/share/raid12/c-fenglei/local/include下面看到event.h等文件。 于是接下来在tmux source code文件夹输入：</p>
<p>./configure --prefix=/share/raid12/c-fenglei/local/ CFLAGS=-I/share//raid12/c-fenglei/local/include LDFLAGS=-L/share/raid12/c-fenglei/local/lib</p>
<p>然后就make &amp;&amp; make install，顺利运行tmux。</p>
<h2 id="问题二-启动tmux的时候报错"><a class="markdownIt-Anchor" href="#问题二-启动tmux的时候报错"></a> 问题二、启动tmux的时候报错：</h2>
<h3 id="libevent-20so5-cannot-open-shared-object-file-no-such-file-or-directory"><a class="markdownIt-Anchor" href="#libevent-20so5-cannot-open-shared-object-file-no-such-file-or-directory"></a> libevent-2.0.so.5: cannot open shared object file: No such file or directory</h3>
<p>解决办法： On a 32 bit system:</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ln -s /usr/local/lib/libevent-2.0.so.5 /usr/lib/libevent-2.0.so.5</span><br></pre></td></tr></table></figure>
</blockquote>
<p>On a 64 bit system:</p>
<blockquote>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ln -s /usr/local/lib/libevent-2.0.so.5 /usr/lib64/libevent-2.0.so.5</span><br></pre></td></tr></table></figure></blockquote>
]]></content>
      <categories>
        <category>Linux</category>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>Mac OS X使用chflags命令隐藏文件</title>
    <url>/2017/06/06/Linux-mac-os-x-using-chflags-to-hide-files/</url>
    <content><![CDATA[<p>转载：Mac OS X如何使用chflags快速隐藏文件 Mac OS X 自带的命令行隐藏文件方法，使用chflags即可完成，打开终端程序，输入如下命令：</p>
<blockquote>
<p>chflags hidden 文件绝对路径/ 相对路径</p>
</blockquote>
<p>这样就设置隐藏属性了，进入相应的文件夹之后看不到该文件了。但是此时在Mac的『我的所有文件』下还是能看到被隐藏的文件，这是进入「系统偏好设置」-「Spotlight」-「隐私」- 添加被隐藏的文件夹或文件。 或是输入：chflags hidden []，再将文件直接拖入terminal的“[]”中也可。 重新显示文件使用：</p>
<blockquote>
<p>chflags nohidden /xxx/yyy/file</p>
</blockquote>
<p>再来回顾一下显示/隐藏finder所有隐藏文件的命令： defaults write com.apple.finder AppleShowAllFiles -bool true（false） – killall finder（重启finder） false 表示不显示『隐藏的文件』；true表示显示『隐藏的文件』。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>MYSQL的安装与启动</title>
    <url>/2016/09/06/Linux-mysql-install-start-stop/</url>
    <content><![CDATA[<p>备注：<a href="http://xn--blog-zt9h97fbv9elswnea.shenwei.me">本文转载至blog.shenwei.me</a> 此处仅做备份之用。</p>
<hr />
<p>如何在linux中无root权限安装MySQL。 <strong>约定</strong> 我的MySQL将安装在下面的目录，将设置默认端口号为33060（可任意，必须大于1024，且不能其它软件冲突）。</p>
<p>/db/home/shenwei/local/app/msyql</p>
<p>下文中的配置文件中，最好使用绝对路径，不要使用相对路径，如“~/”。   <strong>安装编译工具</strong> cmake是必须的，其它基本的编译工具，如gcc等就不说了吧，如果configure过程中提醒缺少编译器，请自行google。 请到<a href="http://www.cmake.org/files/%E9%80%89%E6%8B%A9%E6%9C%80%E6%96%B0%E7%89%88%E7%9A%84cmake%E9%93%BE%E6%8E%A5%EF%BC%8C%E7%84%B6%E5%90%8E%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%EF%BC%9A">http://www.cmake.org/files/选择最新版的cmake链接，然后下载安装：</a></p>
<p>wget <a href="http://www.cmake.org/files/v2.8/cmake-2.8.11.1.tar.gz">http://www.cmake.org/files/v2.8/cmake-2.8.11.1.tar.gz</a><br />
cd cmake-2.8.11.1<br />
./configure --prefix=/db/home/shenwei/local/app/cmake<br />
make &amp;&amp; make install</p>
<p>将cmake目录加入环境变量(或者在~/local/bin下面建立链接cmake可执行程序的软链接, ~/local/bin是我自己的bin目录, 已经加入到环境变量$PATH中)：编辑<sub>/.bashrc或者</sub>/.bash_profile，加入以下内容：</p>
<p>export PATH=~/local/app/cmake:$PATH</p>
<p>让其生效</p>
<p>. ~/.bashrc</p>
<p><strong>编译、安装MySQL</strong> 下载前请到<a href="http://dev.mysql.com/downloads/mysql/">http://dev.mysql.com/downloads/mysql/</a>中，选择source code，页面最下端，下载最新版本的源码（mysql-5.6.××.tar.gz）。33060是自定义的端口号。</p>
<p>tar -zxvf mysql-5.6.19.tar.gz<br />
cd mysql-5.6.19<br />
cmake -DCMAKE_INSTALL_PREFIX=/db/home/shenwei/local/app/mysql -DMYSQL_TCP_PORT=33060<br />
make &amp;&amp; make install</p>
<p><strong>配置</strong> **1）**将MySQL的bin目录和scripts目录加入环境变量：编辑<sub>/.bashrc或者</sub>/.bash_profile，加入以下内容：</p>
<p>export PATH=<sub>/local/app/mysql/bin:</sub>/local/app/mysql/scripts:$PATH</p>
<p>让其生效</p>
<p>. ~/.bashrc</p>
<p>**2）**安装数据库。 先再mysql下面创建一个tmp目录。</p>
<p>mkdir ~/local/app/mysql/tmp</p>
<p>用mysql_install_db安装数据库。此处设置的–user是mysqld进程所属用户，最好设置为你的linux用户，才不会出现mysqld对文件操作的权限问题。</p>
<p>mkdir /db/home/shenwei/local/app/mysql/tmp</p>
<p>cd /db/home/shenwei/local/app/mysql/scripts<br />
./mysql_install_db --basedir=/db/home/shenwei/local/app/mysql --datadir=/db/home/shenwei/local/app/mysql/data --tmpdir=/db/home/shenwei/local/app/mysql/tmp --user=shenwei</p>
<p><strong>3）</strong> 配置mysql配置文件 创建etc目录，并将my.cnf移入其中。为何放这儿呢？因为这是mysqladmin命令搜索配置文件的路径之一。</p>
<p>cd /db/home/shenwei/local/app/mysql<br />
mkdir etc<br />
mv my.cnf etc</p>
<p>编辑my.cnf，如下：</p>
<p>[client]<br />
port=33060<br />
socket=/db/home/shenwei/local/app/mysql/my.sock</p>
<p>[mysqld]<br />
port=33060<br />
socket=/db/home/shenwei/local/app/mysql/my.sock<br />
datadir=/db/home/shenwei/local/app/mysql/data</p>
<p>[mysql.server]<br />
user=shenwei<br />
basedir=/db/home/shenwei/local/app/mysql</p>
<p>sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</p>
<p><strong>4)</strong> 创建Mysql启动脚本。 为了方便，在mysql目录scripts下面创建，并增加可执行属性。</p>
<p>cd /db/home/shenwei/local/app/mysql/scripts<br />
touch my_mysql_start<br />
chmod a+x my_mysql_start</p>
<p>my_mysql_start内容为：</p>
<p>#!/bin/sh<br />
/db/home/shenwei/local/app/mysql/bin/mysqld_safe --defaults-file=/db/home/shenwei/local/app/mysql/etc/my.cnf --socket=/db/home/shenwei/local/app/mysql/my.sock --pid-file=/db/home/shenwei/local/app/mysql/my.pid &amp;</p>
<p>**5）**通过mysql_secure_installation进行安全性设置 由于mysql_secure_installation命令无法指定socket文件，无法成功连接mysqld，会出现以下错误，请转到第6）步</p>
<p>ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/tmp/mysql.sock’ (2)</p>
<p>**6）**设置root密码 先通过my_mysql_start脚本启动mysqld，由于它所在目录scripts已经被加入环境变量PATH中，可直接运行。</p>
<p>my_mysql_start</p>
<p>由于目前root密码为空，可直接进去mysql客户端：</p>
<p>cd /db/home/shenwei/local/mysql/bin<br />
./mysql -P 33060 -u root -p</p>
<p>题外话：也可以不必进入你的mysql/bin目录，而直接用系统的mysql客户端mysql，不过一定要指定端口。 输入上述命令，后出现“Enter password:  ”直接回车即可（密码为空）。 进入mysql命令行后，输入以下命令，设置root密码：</p>
<p>mysql&gt; use mysql;<br />
Reading table information for completion of table and column names<br />
You can turn off this feature to get a quicker startup with -A</p>
<p>Database changed<br />
mysql&gt; update user set password=PASSWORD(“mysqlpassword”) where user=“root”;<br />
Query OK, 0 rows affected (0.00 sec)<br />
Rows matched: 4  Changed: 0  Warnings: 0</p>
<p>mysql&gt; flush privileges;<br />
Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; quit<br />
Bye</p>
<p><strong>7）</strong> 创建Mysql关闭脚本。 为了方便，在mysql目录scripts下面创建，并增加可执行属性。</p>
<p>cd /db/home/shenwei/local/app/mysql/scripts<br />
touch my_mysql_stop<br />
chmod a+x my_mysql_stop</p>
<p>my_mysql_stop内容为：</p>
<p>#!/bin/sh<br />
/db/home/shenwei/local/app/mysql/bin/mysqladmin shutdown -P 33060 -u root -p</p>
<p>今后可以直接通过my_mysq_stop关闭mysql。   <strong>经验</strong> 多Google！出错后，自己看提示信息，看帮助信息（command –help）后仍无法解决，用核心的错误信息去Google!   <strong>参考</strong></p>
<ol>
<li><a href="http://notes.oneplus.info/Operation/2012/12/03/install-mysql-php-without-root/">http://notes.oneplus.info/Operation/2012/12/03/install-mysql-php-without-root/</a></li>
<li><a href="http://san-yun.iteye.com/blog/1493931">http://san-yun.iteye.com/blog/1493931</a></li>
<li>其它无数google出来的页面</li>
</ol>
<p>-EOF-</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>Linux系统：Python2.6和Python2.7同时存在</title>
    <url>/2016/02/29/Linux-python2-6-python2-7-in-a-system/</url>
    <content><![CDATA[<p>CENTOS 6.X 系列默认安装的 Python 2.6 ，目前开发中主要是使用 Python 2.7 ，这两个版本之间还是有不少差异的，程序在 Python 2.6 下经常会出问题。 比如： <code>re.sub</code> 函数 ，2.7 支持 <code>flags</code> 参数，而 2.6 却不支持。 所以，打算安装 Python 2.7 来运行 Flask 应用程序，但 2.6 不能删除，因为系统对它有依赖。</p>
<h2 id="1-安装-sqlite-devel"><a class="markdownIt-Anchor" href="#1-安装-sqlite-devel"></a> 1、安装 sqlite-devel</h2>
<p>因为 Flask 应用程序可能使用能 Sqlite 数据库，所以这个得装上（之前因为没装这个，导致 Python 无法导入 sqlite3 库。 当然，也可以从源码编译安装。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">yum install sqlite-devel -y</span><br></pre></td></tr></table></figure>
<h2 id="2-安装-python-27"><a class="markdownIt-Anchor" href="#2-安装-python-27"></a> 2、安装 Python 2.7</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget https://www.python.org/ftp/python/2.7.8/Python-2.7.8.tgz</span><br><span class="line">tar xf Python-2.7.8.tgz</span><br><span class="line">cd Python-2.7.8</span><br><span class="line">./configure --prefix=/usr/local</span><br><span class="line">make &amp;&amp; make install</span><br></pre></td></tr></table></figure>
<p>安装成功之后，你可以在 <code>/usr/local/bin/python2.7</code> 找到 Python 2.7。</p>
<h2 id="3-安装-setuptools-pip"><a class="markdownIt-Anchor" href="#3-安装-setuptools-pip"></a> 3、安装 setuptools + pip</h2>
<p>这里需要注意，一定要使用 python2.7 来执行相关命令。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># First get the setup script for Setuptools:</span><br><span class="line">wget https://bitbucket.org/pypa/setuptools/raw/bootstrap/ez_setup.py</span><br><span class="line"></span><br><span class="line"># Then install it for Python 2.7 :</span><br><span class="line">python2.7 ez_setup.py</span><br><span class="line"></span><br><span class="line"># Now install pip using the newly installed setuptools:</span><br><span class="line">easy_install-2.7 pip</span><br><span class="line"></span><br><span class="line"># With pip installed you can now do things like this:</span><br><span class="line">pip2.7 install [packagename]</span><br><span class="line">pip2.7 install --upgrade [packagename]</span><br><span class="line">pip2.7 uninstall [packagename]</span><br></pre></td></tr></table></figure>
<h2 id="4-使用-virtualenv"><a class="markdownIt-Anchor" href="#4-使用-virtualenv"></a> 4、使用 virtualenv</h2>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Install virtualenv for Python 2.7 and create a sandbox called my27project:</span><br><span class="line">pip2.7 install virtualenv</span><br><span class="line">virtualenv-2.7 my27project</span><br><span class="line"></span><br><span class="line"># Check the system Python interpreter version:</span><br><span class="line">python --version</span><br><span class="line"># This will show Python 2.6.6</span><br><span class="line"></span><br><span class="line"># Activate the my27project sandbox and check the version of the default Python interpreter in it:</span><br><span class="line">source my27project/bin/activate</span><br><span class="line">python --version</span><br><span class="line"># This will show Python 2.7.X</span><br><span class="line">deactivate</span><br></pre></td></tr></table></figure>
<p>基本就是这些了，网上很多教程都说要做软链接，但我感觉那样做或多或少会对系统有一些未知的影响。这个方法能尽量保持系统的完整性，很多自带 Python 程序其实在头部都指定了 <code>#!/usr/bin/python</code> ，所以它们用的其实是 Python 2.6 ，而不是新安装的 Python 2.7 。 原文：<a href="http://digwtx.duapp.com/54.html">http://digwtx.duapp.com/54.html</a> 参考： <a href="http://toomuchdata.com/2014/02/16/how-to-install-python-on-centos/">http://toomuchdata.com/2014/02/16/how-to-install-python-on-centos/</a></p>
<ul>
<li><a href="https://segmentfault.com/a/1190000000654227">2014年08月31日发布</a></li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux shell: 对特定时间的文件执行操作</title>
    <url>/2017/03/31/Linux-shell-find-files-based-on-their-edited-time/</url>
    <content><![CDATA[<p>有时候目录下文件数目比较多，手动逐个操作费时费力，因此可以通过查找文件的生成时间找到这些文件，随后执行删除、转移等操作。 例如需要找到09点92分的文件并转移到tmp文件夹： for filename in `ls`; do if [ `date -r $filename +%H%M` == “0952” ]; then mv $filename ./tmp; fi; done</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>shell脚本和perl脚本的段注释</title>
    <url>/2020/12/05/Linux-shell-perl-mute-multiple-lines/</url>
    <content><![CDATA[<p>shell脚本段注释</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash </span><br><span class="line">echo &quot;Say Something&quot; </span><br><span class="line">&lt;&lt;COMMENT     </span><br><span class="line">  your comment 1     </span><br><span class="line">  comment 2     </span><br><span class="line">  blah </span><br><span class="line">COMMENT </span><br><span class="line">echo &quot;Do something else&quot;</span><br></pre></td></tr></table></figure>
<p>perl脚本段注释。测试了一下，“=”符号和“pod”之间不能加空格，pod不能大写。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">=pod</span><br><span class="line">while(&lt;file&gt;)&#123;</span><br><span class="line">  chomp $_;</span><br><span class="line">  print &quot;$_\n;</span><br><span class="line">&#125;</span><br><span class="line">=cut</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>shellcheck: 自动检测shell脚本的语法</title>
    <url>/2017/08/23/Linux-shellcheck-chech-shell-scripts/</url>
    <content><![CDATA[<p>生物信息分析工作中，可以将数据操作命令写入shell脚本，一方面方便自动化运行，另一方面是将操作记录存档，便于日后查阅。 但是shell脚本也会因人为疏忽而存在错误，我想有没有程序可以检测脚本的正确性呢，一查果然有shellcheck之类的程序。shellcheck有在线版：<a href="http://www.shellcheck.net/">http://www.shellcheck.net/</a> shellcheck也有本地版，安装有多种方法，可参考官方网站：<a href="https://github.com/koalaman/shellcheck">https://github.com/koalaman/shellcheck</a> 我直接下载了编译好的程序：<a href="https://storage.googleapis.com/shellcheck/shellcheck-latest.linux.x86%5C_64.tar.xz">https://storage.googleapis.com/shellcheck/shellcheck-latest.linux.x86\_64.tar.xz</a> 解压之后，即可使用。 使用方法：shellcheck <a href="http://myscript.sh">myscript.sh</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>SSH远程登录设置</title>
    <url>/2019/12/13/Linux-ssh-from-remote/</url>
    <content><![CDATA[<p>如图所示，Linux服务器为C，用户客户端电脑为A。如何从A登录到C服务器。之前尝试多次不成功，原来是没有在Linux服务器正确设置参数（即下面步骤二）。   步骤一、在B路由器设定“端口转发”（或端口映射？），比如将端口22转发到服务器C；参考<a href="https://service.tp-link.com.cn/detail%5C_article%5C_69.html">https://service.tp-link.com.cn/detail\_article\_69.html</a> 步骤二、在Linux服务器上设置远程登录，编辑/etc/ssh/sshd_config，打开22端口，再修改一些设置允许用户远程登录。具体参考：<a href="http://jianshu.com/p/df83a3b96f64">jianshu.com/p/df83a3b96f64</a> 步骤三、在用户电脑客户端进行ssh操作即可。比如ssh <a href="mailto:user@101.1.1.2">user@101.1.1.2</a>，即可登录到服务器C。参考：<a href="https://blog.csdn.net/qiushisoftware/article/details/55258624">https://blog.csdn.net/qiushisoftware/article/details/55258624</a>   <img src="https://genehub.files.wordpress.com/2019/12/790056-20151122112639515-536213849.png" alt="790056-20151122112639515-536213849" /></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux无法开机：An error occurred during the file system check.</title>
    <url>/2016/01/25/Linux-unable-to-reboot-an-error-occurred-during-the-file-system-check/</url>
    <content><![CDATA[<blockquote>
<p>由于有一个硬盘检测不到了，所以开机的时候无法通过/etc/fstab里面的硬盘挂载命令。从而出现故障。可先进入root用户，但是此时为只读模式，需要通过下文中的 “mount -n -o remount,rw / ”进入可写模式才能更改系统配置文件。我将无法检测到的硬盘名称从 /etc/fstab 里面删除对应的那一行内容，然后输入“shutdown -h now”关机，再重启，就可以进入系统了。</p>
</blockquote>
<blockquote>
<p>此时的问题就是如何进入出问题的硬盘了。。。</p>
</blockquote>
<p>===================================================</p>
<p><a href="http://blog.yam.com/invite19/article/10622880">Linux fstab 設定錯誤 導致無法開始 出現 /dev/hdxx</a><a href="http://search.yam.com/Search/Web/DefaultKSA.aspx?SearchType=web&amp;l=0&amp;p=0&amp;k=Linux+fstab+%E8%A8%AD%E5%AE%9A%E9%8C%AF%E8%AA%A4+%E5%B0%8E%E8%87%B4%E7%84%A1%E6%B3%95%E9%96%8B%E5%A7%8B+%E5%87%BA%E7%8F%BE+%2Fdev%2Fhdxx"><img src="http://pics.yamedia.tw/images/icon_search.gif" alt="以文找文" /></a></p>
<span id="more"></span>
<p><a href="http://blog.yam.com/user/invite19.html">invite19</a> - <a href="http://blog.yam.com/BlogIndex.php?BLOG_ID=invite19&amp;CATEGORY_ID=1223242">LINUX</a> Jun 25, 2007</p>
<p><img src="http://pics.yamedia.tw/images/goodsite.gif" alt="" /><a href="http://adminblog.yam.com/confirm.php?op=site&amp;blog_id=invite19&amp;refer=http%3A%2F%2Fblog.yam.com%2Finvite19%2Farticle%2F10622880">推薦這個部落格</a>: 99</p>
<p><a href="http://pics4.blog.yam.com/4/attachfile/7/8/2/287019/1/1467f55992fc6f.pdf"><img src="http://pics.blog.yam.com/images/padmin/attachfile.gif" alt="" /></a><a href="http://pics4.blog.yam.com/4/attachfile/7/8/2/287019/1/1467f5558f403c.pdf"><img src="http://pics.blog.yam.com/images/padmin/attachfile.gif" alt="" /></a> 因為不小心設定錯誤 /etc/fstab or hdd 出現問題時大致上會出現以下畫面，該怎麼辦呢？ <img src="http://pics21.blog.yam.com/4/userfile/i/invite19/blog/1467f5089af958.jpg" alt="" /></p>
<p>Give root password for maintenance 輸入root 的密碼</p>
<p><img src="http://pics21.blog.yam.com/4/userfile/i/invite19/blog/1467f512ea1c4a.jpg" alt="" /></p>
<p>提示 (repair filesystem) 1 # 就會進入 lever 1模式 ，進行修復動作… 此模式下，是唯讀模式，不可以修改檔案…</p>
<p><img src="http://pics21.blog.yam.com/4/userfile/i/invite19/blog/1467f51ad1b25c.jpg" alt="" /></p>
<p>所以要輸入 mount -n -o remount,rw / 重新載入 / ，並給於 寫入讀取權限，再將所設定錯誤的檔案修改回來。</p>
<p><img src="http://pics21.blog.yam.com/4/userfile/i/invite19/blog/1467f52c32bd3b.jpg" alt="" /></p>
<p>由於此例子，是winner 將強制將 ext3 使用 xp 開機光碟，轉換成 NTFS 所以所導致 /etc/fstab 讀取錯誤。 所以應該先將 /etc/fstab 中的 hdb1 錯誤partition 給先拿掉，不要讀取它。 vi /etc/fstab 拿掉 hdb1 拿掉… :wq 存檔離開…並重新開機</p>
<p><img src="http://pics21.blog.yam.com/4/userfile/i/invite19/blog/1467f5340d7c09.jpg" alt="" /></p>
<p>參考文獻：<a href="http://linux.vbird.org/linux_basic/0510osloader.php#solution_config">http://linux.vbird.org/linux_basic/0510osloader.php#solution_config</a> 電子檔下載<a href="http://pics4.blog.yam.com/4/attachfile/7/8/2/287019/1/1467f55cd0d6dc.pdf"><img src="http://pics.blog.yam.com/images/padmin/attachfile.gif" alt="" /></a> <strong>因設定錯誤而無法開機：</strong></p>
<p>如果因為設定錯誤導致無法開機時，要怎麼辦啊？這就更簡單了！ 最容易出錯的設定而導致無法順利開機的步驟，通常就是 /etc/fstab 這個檔案了， 尤其是使用者在 <a href="http://linux.vbird.org/linux_basic/0420quota.php">實作 Quota</a> 時，最容易寫錯參數， 又沒有經過 mount -a 來測試掛載，就立刻直接重新開機，真要命，無法開機成功怎麼辦？ 不要緊啦！利用上個小節提到的以 run level 1 的方法進入 Linux 系統，然後：</p>
<ul>
<li>利用『 mount -n -o remount,rw / 』重新掛載根目錄， 之後將剛剛設定錯誤的地方修改一下，就可以重新開機啦！</li>
</ul>
<p>但萬一是因為不正常關機，導致開機時進行 fsck 無法成功，而出現類似這樣的幾行字：</p>
<p>/home contains a file system with errors,check blocks.<br />
/home:Group 81’s inode table at 2654219 conflicts with some other fs blocks.<br />
/home: UNEXPECTED INCONSISTENCY ; RUN fsck MANUSLLY<br />
(i.e. , without –a or –p options)<br />
*** An error occurred during the file system check.<br />
*** Dropping you to a shrll ; the system will reboot<br />
*** when you to leave shell…<br />
Give root password for maintenance(or type Control-D for normal startup):</p>
<p>這表示你的 filesystem 可能有磁區錯亂的情況，一般來說，這樣的磁區錯亂應該不是實體硬碟錯誤， 比較可能是由於不正成關機造成 filesystem 的不一致 (Inconsistent) 所造成的。 造成這個問題之後，我們必須要輸入 root 的密碼，進入 run level 1 ， 然後以 fsck /dev/hd[a-d][1-16] 來修復磁碟。例如，假設上面的案例中， /home 掛載在 /dev/hda6 上面，那我就『 fsck /dev/hda6 』，不要加上任何參數。 等到系統發現錯誤，並且出現『clear [Y/N]』時，輸入『 y 』吧！ 這個過程可能會很長，而且如果你的 partition 上面的 filesystem 有過多的資料損毀時， 即使 fsck 完成後，可能因為傷到系統槽，導致某些關鍵系統檔案資料的損毀，那麼依舊是無法進入 Linux 的。此時，就好就是將系統當中的重要資料複製出來，然後重新安裝，並且檢驗一下， 是否實體硬碟有損傷的現象才好！不過一般來說，不太可能會這樣啦～ 通常都是 fsck 處理完畢後，就能夠順利再次進入 Linux 了。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux：vim设置</title>
    <url>/2020/12/25/Linux-vim-setting/</url>
    <content><![CDATA[<p>以前是用spf13-vim方案的，运行一个安装命令就可以使用了。最喜欢的功能是自动缩进，还有代码块高亮显示（比如while循环下面的每行子命令左侧都会有一个高亮的方块）。</p>
<p>今天不知道为什么在tmux下面用vim出现问题，很多字段有莫名其妙的红色背景，而且鼠标左键选中字符的时候无法选中，反而是将光标移过去了。</p>
<p>于是换了一个vim设置，如下的代码（<a href="https://blog.csdn.net/geng823/article/details/41804399">代码来源</a>），新建<code>~/.vimrc</code>文件，将下面的代码写入这个文件，保存退出即可，代码中有几行是作者email等信息可以改掉。测试了一下，下方的代码可以用，至少有了我需要自动缩进功能，且不会有上述问题，另外还有新建.sh代码的时候，会自动生成一个包含作者信息和新建文件时间的几行注释信息，很实用的小功能。记录在此。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot; An example for a vimrc file.</span><br><span class="line">&quot;</span><br><span class="line">&quot; Maintainer:	Bram Moolenaar &lt;Bram@vim.org&gt;</span><br><span class="line">&quot; Last change:	2001 Jul 18</span><br><span class="line">&quot;</span><br><span class="line">&quot; To use it, copy it to</span><br><span class="line">&quot;     for Unix and OS/2:  ~/.vimrc</span><br><span class="line">&quot;	      for Amiga:  s:.vimrc</span><br><span class="line">&quot;  for MS-DOS and Win32:  $VIM\_vimrc</span><br><span class="line">&quot;	    for OpenVMS:  sys$login:.vimrc</span><br><span class="line"></span><br><span class="line">set encoding=utf-8</span><br><span class="line">set fileencodings=utf-8,gbk,gb2312,gb18030,ucs-bom,latin1</span><br><span class="line"></span><br><span class="line">set tags=tags;</span><br><span class="line">set shiftwidth=4 </span><br><span class="line">set ts=4</span><br><span class="line">&quot;set nu</span><br><span class="line">set vb t_vb=</span><br><span class="line">&quot; When started as &quot;evim&quot;, evim.vim will already have done these settings.</span><br><span class="line">if v:progname =~? &quot;evim&quot;</span><br><span class="line">  finish</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">&quot; Use Vim settings, rather then Vi settings (much better!).</span><br><span class="line">&quot; This must be first, because it changes other options as a side effect.</span><br><span class="line">set nocompatible</span><br><span class="line"></span><br><span class="line">&quot; allow backspacing over everything in insert mode</span><br><span class="line">set backspace=indent,eol,start</span><br><span class="line"></span><br><span class="line">set autoindent		&quot; always set autoindenting on</span><br><span class="line">set nobackup		&quot; do not keep a backup file, use versions instead</span><br><span class="line">&quot;if has(&quot;vms&quot;)</span><br><span class="line">&quot;  set nobackup		&quot; do not keep a backup file, use versions instead</span><br><span class="line">&quot;else</span><br><span class="line">&quot;  set backup		&quot; keep a backup file</span><br><span class="line">&quot;endif</span><br><span class="line">set history=50		&quot; keep 50 lines of command line history</span><br><span class="line">set ruler		&quot; show the cursor position all the time</span><br><span class="line">set showcmd		&quot; display incomplete commands</span><br><span class="line">set incsearch		&quot; do incremental searching</span><br><span class="line"></span><br><span class="line">set nobackup		&quot; do not keep a backup file, use versions instead</span><br><span class="line"></span><br><span class="line">&quot; For Win32 GUI: remove &#x27;t&#x27; flag from &#x27;guioptions&#x27;: no tearoff menu entries</span><br><span class="line">&quot; let &amp;guioptions = substitute(&amp;guioptions, &quot;t&quot;, &quot;&quot;, &quot;g&quot;)</span><br><span class="line"></span><br><span class="line">&quot; Don&#x27;t use Ex mode, use Q for formatting</span><br><span class="line">map Q gq</span><br><span class="line"></span><br><span class="line">&quot; Make p in Visual mode replace the selected text with the &quot;&quot; register.</span><br><span class="line">vnoremap p &lt;Esc&gt;:let current_reg = @&quot;&lt;CR&gt;gvs&lt;C-R&gt;=current_reg&lt;CR&gt;&lt;Esc&gt;</span><br><span class="line"></span><br><span class="line">&quot; This is an alternative that also works in block mode, but the deleted</span><br><span class="line">&quot; text is lost and it only works for putting the current register.</span><br><span class="line">&quot;vnoremap p &quot;_dp</span><br><span class="line"></span><br><span class="line">&quot; Switch syntax highlighting on, when the terminal has colors</span><br><span class="line">&quot; Also switch on highlighting the last used search pattern.</span><br><span class="line">if &amp;t_Co &gt; 2 || has(&quot;gui_running&quot;)</span><br><span class="line">  syntax on</span><br><span class="line">  set hlsearch</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line">&quot; Only do this part when compiled with support for autocommands.</span><br><span class="line">if has(&quot;autocmd&quot;)</span><br><span class="line"></span><br><span class="line">  &quot; Enable file type detection.</span><br><span class="line">  &quot; Use the default filetype settings, so that mail gets &#x27;tw&#x27; set to 72,</span><br><span class="line">  &quot; &#x27;cindent&#x27; is on in C files, etc.</span><br><span class="line">  &quot; Also load indent files, to automatically do language-dependent indenting.</span><br><span class="line">  filetype plugin indent on</span><br><span class="line"></span><br><span class="line">  &quot; For all text files set &#x27;textwidth&#x27; to 78 characters.</span><br><span class="line">  autocmd FileType text setlocal textwidth=78</span><br><span class="line"></span><br><span class="line">  &quot; When editing a file, always jump to the last known cursor position.</span><br><span class="line">  &quot; Don&#x27;t do it when the position is invalid or when inside an event handler</span><br><span class="line">  &quot; (happens when dropping a file on gvim).</span><br><span class="line">  autocmd BufReadPost *</span><br><span class="line">    \ if line(&quot;&#x27;\&quot;&quot;) &gt; 0 &amp;&amp; line(&quot;&#x27;\&quot;&quot;) &lt;= line(&quot;$&quot;) |</span><br><span class="line">    \   exe &quot;normal g`\&quot;&quot; |</span><br><span class="line">    \ endif</span><br><span class="line"></span><br><span class="line">endif &quot; has(&quot;autocmd&quot;)</span><br><span class="line"></span><br><span class="line">if has(&quot;cscope&quot;)</span><br><span class="line">	let current = &quot;.&quot;</span><br><span class="line">	let num = 1</span><br><span class="line">	while num &lt; 20 </span><br><span class="line">		if filereadable(current . &quot;/cscope.out&quot;)</span><br><span class="line">			let $CSCOPE_DB = current . &quot;/cscope.out&quot;</span><br><span class="line">			cs add $CSCOPE_DB</span><br><span class="line">			break</span><br><span class="line">		else</span><br><span class="line">			let current = current . &quot;/..&quot;</span><br><span class="line">			let num = num + 1</span><br><span class="line">		endif</span><br><span class="line">	endwhile</span><br><span class="line">endif</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">syntax enable</span><br><span class="line">syntax on</span><br><span class="line">colorscheme desert</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">filetype plugin indent on</span><br><span class="line">set completeopt=longest,menu</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">set cst</span><br><span class="line">set csto=1</span><br><span class="line">set cscopequickfix=s-,c-,d-,i-,t-,e-,f-</span><br><span class="line">&quot; cs add /home/yangxl/readcode/cscope-kernel/cscope.out</span><br><span class="line">&quot; cs add /home/yangxl/readcode/cscope-app/cscope.out</span><br><span class="line">let Tlist_Enable_Fold_Column = 0</span><br><span class="line">let Tlist_WinWidth = 30</span><br><span class="line">let Tlist_Show_One_File = 1</span><br><span class="line">let g:miniBufExplMapCTabSwitchBufs = 1</span><br><span class="line">let g:miniBufExplMapWindowNavVim = 1</span><br><span class="line">let g:miniBufExplMapWindowNavArrows = 1</span><br><span class="line">let g:winManagerWindowLayout=&#x27;FileExplorer|TagList&#x27;</span><br><span class="line">let g:SuperTabRetainCompletionType=2</span><br><span class="line">nmap wm :WMToggle&lt;cr&gt;</span><br><span class="line">set tabstop=4</span><br><span class="line">&quot;nmap &lt;F2&gt; :cs find d &lt;C-R&gt;&lt;C-W&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;F3&gt; :cs find c &lt;C-R&gt;&lt;C-W&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;F4&gt; :cs find t &lt;C-R&gt;&lt;C-W&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;F5&gt; :cs find e &lt;C-R&gt;&lt;C-W&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;F6&gt; :cs find f &lt;C-R&gt;&lt;C-W&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;F7&gt; :cs find i &lt;C-R&gt;&lt;C-W&gt;&lt;CR&gt;</span><br><span class="line">nmap &lt;F5&gt; :TlistToggle &lt;CR&gt;</span><br><span class="line"></span><br><span class="line">nmap &lt;F2&gt; :cs find c &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">nmap &lt;F3&gt; :cs find s &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">nmap &lt;F4&gt; :cs find g &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">nmap &lt;F6&gt; :cs find f </span><br><span class="line">nmap &lt;C-n&gt; :cn&lt;CR&gt;</span><br><span class="line">nmap &lt;C-p&gt; :cp&lt;CR&gt;</span><br><span class="line">&quot;nmap  :cs find t &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap  :cs find e &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap  :cs find f &lt;C-R&gt;=expand(&quot;&lt;cfile&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap  :cs find i ^&lt;C-R&gt;=expand(&quot;&lt;cfile&gt;&quot;)&lt;CR&gt;$&lt;CR&gt;</span><br><span class="line">&quot;nmap  :cs find d &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot; Using &#x27;CTRL-spacebar&#x27; then a search type makes the vim window</span><br><span class="line">&quot; split horizontally, with search result displayed in</span><br><span class="line">&quot; the new window.</span><br><span class="line"></span><br><span class="line">&quot;nmap &lt;C-Space&gt;s :scs find s &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;g :scs find g &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;c :scs find c &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;t :scs find t &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;e :scs find e &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;f :scs find f &lt;C-R&gt;=expand(&quot;&lt;cfile&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;i :scs find i ^&lt;C-R&gt;=expand(&quot;&lt;cfile&gt;&quot;)&lt;CR&gt;$&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;F2&gt; :scs find d &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot; Hitting CTRL-space *twice* before the search type does a vertical</span><br><span class="line">&quot; split instead of a horizontal one</span><br><span class="line"></span><br><span class="line">&quot;nmap &lt;C-Space&gt;&lt;C-Space&gt;s</span><br><span class="line">        \:vert scs find s &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;&lt;C-Space&gt;g</span><br><span class="line">        \:vert scs find g &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;&lt;C-Space&gt;c</span><br><span class="line">        \:vert scs find c &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;&lt;C-Space&gt;t</span><br><span class="line">        \:vert scs find t &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;&lt;C-Space&gt;e</span><br><span class="line">        \:vert scs find e &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;C-Space&gt;&lt;C-Space&gt;i</span><br><span class="line">        \:vert scs find i ^&lt;C-R&gt;=expand(&quot;&lt;cfile&gt;&quot;)&lt;CR&gt;$&lt;CR&gt;</span><br><span class="line">&quot;nmap &lt;F2&gt; </span><br><span class="line">        \:vert scs find d &lt;C-R&gt;=expand(&quot;&lt;cword&gt;&quot;)&lt;CR&gt;&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">set nu</span><br><span class="line">set mouse=a</span><br><span class="line">set autoindent</span><br><span class="line">set cindent</span><br><span class="line"></span><br><span class="line">filetype plugin indent on </span><br><span class="line">&quot;打开文件类型检测, 加了这句才可以用智能补全</span><br><span class="line">set completeopt=longest,menu</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</span><br><span class="line">&quot;&quot;&quot;&quot;&quot;新文件标题</span><br><span class="line">&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</span><br><span class="line">&quot;新建.c,.h,.sh,.java文件，自动插入文件头 </span><br><span class="line">autocmd BufNewFile *.cpp,*.[ch],*.sh,*.java exec &quot;:call SetTitle()&quot; </span><br><span class="line">&quot;&quot;定义函数SetTitle，自动插入文件头 </span><br><span class="line">func SetTitle() </span><br><span class="line">	&quot;如果文件类型为.sh文件 </span><br><span class="line">	if &amp;filetype == &#x27;sh&#x27; </span><br><span class="line">		call setline(1,&quot;\#########################################################################&quot;) </span><br><span class="line">		call append(line(&quot;.&quot;), &quot;\# File Name: &quot;.expand(&quot;%&quot;)) </span><br><span class="line">		call append(line(&quot;.&quot;)+1, &quot;\# Author: xx&quot;) </span><br><span class="line">		call append(line(&quot;.&quot;)+2, &quot;\# Mail: xx@163.com&quot;) </span><br><span class="line">		call append(line(&quot;.&quot;)+3, &quot;\# Created Time: &quot;.strftime(&quot;%c&quot;)) </span><br><span class="line">		call append(line(&quot;.&quot;)+4, &quot;\#########################################################################&quot;) </span><br><span class="line">		call append(line(&quot;.&quot;)+5, &quot;\#!/bin/bash&quot;) </span><br><span class="line">		call append(line(&quot;.&quot;)+6, &quot;&quot;) </span><br><span class="line">	else </span><br><span class="line">		call setline(1, &quot;/*************************************************************************&quot;) </span><br><span class="line">		call append(line(&quot;.&quot;), &quot;	&gt; File Name: &quot;.expand(&quot;%&quot;)) </span><br><span class="line">		call append(line(&quot;.&quot;)+1, &quot;	&gt; Author: xx&quot;) </span><br><span class="line">		call append(line(&quot;.&quot;)+2, &quot;	&gt; Mail: xx@163.com&quot;) </span><br><span class="line">		call append(line(&quot;.&quot;)+3, &quot;	&gt; Created Time: &quot;.strftime(&quot;%c&quot;)) </span><br><span class="line">		call append(line(&quot;.&quot;)+4, &quot; ************************************************************************/&quot;) </span><br><span class="line">		call append(line(&quot;.&quot;)+5, &quot;&quot;)</span><br><span class="line">	endif</span><br><span class="line">	if &amp;filetype == &#x27;cpp&#x27;</span><br><span class="line">		call append(line(&quot;.&quot;)+6, &quot;#include&lt;iostream&gt;&quot;)</span><br><span class="line">		call append(line(&quot;.&quot;)+7, &quot;using namespace std;&quot;)</span><br><span class="line">		call append(line(&quot;.&quot;)+8, &quot;&quot;)</span><br><span class="line">	endif</span><br><span class="line">	if &amp;filetype == &#x27;c&#x27;</span><br><span class="line">		call append(line(&quot;.&quot;)+6, &quot;#include&lt;stdio.h&gt;&quot;)</span><br><span class="line">		call append(line(&quot;.&quot;)+7, &quot;&quot;)</span><br><span class="line">	endif</span><br><span class="line">	&quot;	if &amp;filetype == &#x27;java&#x27;</span><br><span class="line">	&quot;		call append(line(&quot;.&quot;)+6,&quot;public class &quot;.expand(&quot;%&quot;))</span><br><span class="line">	&quot;		call append(line(&quot;.&quot;)+7,&quot;&quot;)</span><br><span class="line">	&quot;	endif</span><br><span class="line">	&quot;新建文件后，自动定位到文件末尾</span><br><span class="line">	autocmd BufNewFile * normal G</span><br><span class="line">endfunc </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</span><br><span class="line">&quot; 显示相关  </span><br><span class="line">&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</span><br><span class="line">&quot;set shortmess=atI   &quot; 启动的时候不显示那个援助乌干达儿童的提示  </span><br><span class="line">&quot;winpos 5 5          &quot; 设定窗口位置  </span><br><span class="line">&quot;set lines=40 columns=155    &quot; 设定窗口大小  </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&quot;</span><br><span class="line">set go=             &quot; 不要图形按钮  </span><br><span class="line">&quot;color asmanian2     &quot; 设置背景主题  </span><br><span class="line">&quot;set guifont=Courier_New:h10:cANSI   &quot; 设置字体  </span><br><span class="line">&quot;syntax on           &quot; 语法高亮  </span><br><span class="line">&quot;</span><br><span class="line">&quot;autocmd InsertLeave * se nocul  &quot; 用浅色高亮当前行  </span><br><span class="line">&quot;autocmd InsertEnter * se cul    &quot; 用浅色高亮当前行 </span><br><span class="line">set ruler           &quot; 显示标尺  </span><br><span class="line">set showcmd         &quot; 输入的命令显示出来，看的清楚些  </span><br><span class="line">&quot;set cmdheight=1     &quot; 命令行（在状态行下）的高度，设置为1  </span><br><span class="line">&quot;set whichwrap+=&lt;,&gt;,h,l   &quot; 允许backspace和光标键跨越行边界(不建议)  </span><br><span class="line">&quot;set scrolloff=3     &quot; 光标移动到buffer的顶部和底部时保持3行距离  </span><br><span class="line">&quot;</span><br><span class="line">set novisualbell    &quot; 不要闪烁(不明白)  </span><br><span class="line">set statusline=%F%m%r%h%w\ [FORMAT=%&#123;&amp;ff&#125;]\ [TYPE=%Y]\ [POS=%l,%v][%p%%]\ %&#123;strftime(\&quot;%d/%m/%y\ -\ %H:%M\&quot;)&#125;   &quot;状态行显示的内容  </span><br><span class="line">set laststatus=1    &quot; 启动显示状态行(1),总是显示状态行(2)  </span><br><span class="line">set foldenable      &quot; 允许折叠  </span><br><span class="line">set foldmethod=manual   &quot; 手动折叠  </span><br><span class="line">&quot;set background=dark &quot;背景使用黑色 </span><br><span class="line">&quot;</span><br><span class="line">set nocompatible  &quot;去掉讨厌的有关vi一致性模式，避免以前版本的一些bug和局限  </span><br><span class="line">&quot; 显示中文帮助</span><br><span class="line">if version &gt;= 603</span><br><span class="line">	set helplang=cn</span><br><span class="line">	set encoding=utf-8</span><br><span class="line">endif</span><br><span class="line">&quot; 设置配色方案</span><br><span class="line">&quot;colorscheme murphy</span><br><span class="line">&quot;字体 </span><br><span class="line">&quot;if (has(&quot;gui_running&quot;)) </span><br><span class="line">&quot;   set guifont=Bitstream\ Vera\ Sans\ Mono\ 10 </span><br><span class="line">&quot;endif </span><br><span class="line"></span><br><span class="line">&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</span><br><span class="line">&quot;键盘命令</span><br><span class="line">&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;</span><br><span class="line"></span><br><span class="line">nmap &lt;leader&gt;w :w!&lt;cr&gt;</span><br><span class="line">nmap &lt;leader&gt;f :find&lt;cr&gt;</span><br><span class="line"></span><br><span class="line">&quot; 映射全选+复制 ctrl+a</span><br><span class="line">map &lt;C-A&gt; ggVGY</span><br><span class="line">map! &lt;C-A&gt; &lt;Esc&gt;ggVGY</span><br><span class="line">map &lt;F12&gt; gg=G</span><br><span class="line">&quot; 选中状态下 Ctrl+c 复制</span><br><span class="line">vmap &lt;C-c&gt; &quot;+y</span><br><span class="line">&quot;去空行  </span><br><span class="line">nnoremap &lt;F2&gt; :g/^\s*$/d&lt;CR&gt; </span><br><span class="line">&quot;比较文件  </span><br><span class="line">nnoremap &lt;C-F2&gt; :vert diffsplit </span><br><span class="line">&quot;新建标签  </span><br><span class="line">map &lt;M-F2&gt; :tabnew&lt;CR&gt;  </span><br><span class="line">&quot;列出当前目录文件  </span><br><span class="line">map &lt;F3&gt; :tabnew .&lt;CR&gt;  </span><br><span class="line">&quot;打开树状文件目录  </span><br><span class="line">map &lt;C-F3&gt; \be  </span><br><span class="line">&quot;C，C++ 按F5编译运行</span><br><span class="line">map &lt;F5&gt; :call CompileRunGcc()&lt;CR&gt;</span><br><span class="line">func! CompileRunGcc()</span><br><span class="line">	exec &quot;w&quot;</span><br><span class="line">	if &amp;filetype == &#x27;c&#x27;</span><br><span class="line">		exec &quot;!g++ % -o %&lt;&quot;</span><br><span class="line">		exec &quot;! ./%&lt;&quot;</span><br><span class="line">	elseif &amp;filetype == &#x27;cpp&#x27;</span><br><span class="line">		exec &quot;!g++ % -o %&lt;&quot;</span><br><span class="line">		exec &quot;! ./%&lt;&quot;</span><br><span class="line">	elseif &amp;filetype == &#x27;java&#x27; </span><br><span class="line">		exec &quot;!javac %&quot; </span><br><span class="line">		exec &quot;!java %&lt;&quot;</span><br><span class="line">	elseif &amp;filetype == &#x27;sh&#x27;</span><br><span class="line">		:!./%</span><br><span class="line">	elseif &amp;filetype == &#x27;py&#x27;</span><br><span class="line">		exec &quot;!python %&quot;</span><br><span class="line">		exec &quot;!python %&lt;&quot;</span><br><span class="line">	endif</span><br><span class="line">endfunc</span><br><span class="line">&quot;C,C++的调试</span><br><span class="line">map &lt;F8&gt; :call Rungdb()&lt;CR&gt;</span><br><span class="line">func! Rungdb()</span><br><span class="line">	exec &quot;w&quot;</span><br><span class="line">	exec &quot;!g++ % -g -o %&lt;&quot;</span><br><span class="line">	exec &quot;!gdb ./%&lt;&quot;</span><br><span class="line">endfunc</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux：zsh的安装与使用（oh-my-zsh）</title>
    <url>/2020/03/05/Linux-zsh-installation-and-oh-my-zsh/</url>
    <content><![CDATA[<p>Mac OS更新系统之后，进入iTerm2收到提示说可以使用zsh，查资料比较了一下它和bash的区别，然后就安装了。 简要过程：在客户端（Mac OS）安装zsh并启动，通过oh-my-zsh配置zsh；随后在服务器（Linux CentOS 7）安装zsh，从bash切换到zsh，同样通过oh-my-zsh配置zsh，由于<sub>/.bashrc和</sub>/.bash_profile里面保存了环境变量和alias等信息，切换成zsh之后也需要在~/.zshrc文件里面做相应设置；还有服务器的Tmux软件也要做设置。 具体操作都是参考网络资料，下面直接转载一篇比较详细的文章。 ==========</p>
<h3 id="安装zsh"><a class="markdownIt-Anchor" href="#安装zsh"></a> 安装zsh</h3>
<p>然后开始安装配置 ：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install zsh</span><br></pre></td></tr></table></figure>
<p>然后把bash的配置文件(<sub>/.bash_prorile或者</sub>/.profile等) 我的是<sub>/.bashrc拷贝到zsh的配置文件</sub>/.zshrc里，因为zsh兼容bash) 每次进入是都使用命令<code>zsh</code>进入, 而输入<code>exit</code>退出 或者直接设置成默认shell（但是这里我并不需要执行，因为我的默认shell其实想设置成tmux，后文再说，然后使用tmux来调用zsh）命令行输入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#取代bash，设为默认shell</span><br><span class="line">sudo usermod -s /bin/zsh username</span><br><span class="line">#或者</span><br><span class="line">chsh -s /bin/zsh</span><br><span class="line">chsh -s `which zsh`</span><br><span class="line"></span><br><span class="line">#如果要切换回去bash：</span><br><span class="line">chsh -s /bin/bash</span><br></pre></td></tr></table></figure>
<h3 id="安装oh-my-zsh"><a class="markdownIt-Anchor" href="#安装oh-my-zsh"></a> 安装oh-my-zsh</h3>
<p>直接用zsh会很难受，因为zsh功能很强大但是太复杂，所以需要oh-my-zsh来将它简单化</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git clone git://github.com/robbyrussell/oh-my-zsh.git ~/.oh-my-zsh</span><br><span class="line"></span><br><span class="line">备份已有的zshrc, 替换zshrc</span><br><span class="line">cp ~/.zshrc ~/.zshrc.orig</span><br><span class="line">cp ~/.oh-my-zsh/templates/zshrc.zsh-template ~/.zshrc</span><br><span class="line"></span><br><span class="line">直接使用脚本安装</span><br><span class="line">cd .oh-my-zsh/tools</span><br><span class="line">./install.sh</span><br></pre></td></tr></table></figure>
<p>直接最终的~/.zshrc内容备份一哈： <a href="https://github.com/YuYuCong/Ubuntu">https://github.com/YuYuCong/Ubuntu</a></p>
<h3 id="配置主题"><a class="markdownIt-Anchor" href="#配置主题"></a> 配置主题</h3>
<p>oh-my-zsh 集成了大量的主题, 位于<a href="https://github.com/robbyrussell/oh-my-zsh/"><code>oh-my-zsh/theme</code></a> 配置主题, 可以通过修改<code>~/.zshrc</code>中的环境变量<code>ZSH_THEME</code>来完成，我最后挑中了bira</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ZSH_THEME=&quot;bira&quot;</span><br></pre></td></tr></table></figure>
<p>如果觉得主题太多，可以选择使用随机模式, 不过这就比较刺激了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ZSH_THEME=&quot;random&quot; # (...please let it be pie... please be some pie..)</span><br></pre></td></tr></table></figure>
<p><a href="https://github.com/robbyrussell/oh-my-zsh/wiki/themes">主题介绍</a></p>
<h3 id="配置插件"><a class="markdownIt-Anchor" href="#配置插件"></a> 配置插件</h3>
<p>修改<code>~/.zshrc</code>中<code>plugins</code></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">plugins=(git bundler osx rake ruby)</span><br></pre></td></tr></table></figure>
<p>详细的插件信息, 可以参见<a href="https://github.com/robbyrussell/oh-my-zsh/wiki/Plugins">zsh插件Plugins介绍</a></p>
<h3 id="更新oh-my-zsh"><a class="markdownIt-Anchor" href="#更新oh-my-zsh"></a> 更新oh-my-zsh</h3>
<p>默认情况下, 您将被提示检查每几周的升级. 如果你想我ZSH自动升级本身没有提示你, 修改~/.zshrc</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">disable_update_prompt = true1</span><br></pre></td></tr></table></figure>
<p>禁用自动升级, 修改~/.zshrc</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">disable_auto_update = true1</span><br></pre></td></tr></table></figure>
<p>当然你也可以选择手动更新 如果你想在任何时间点升级（也许有人刚刚发布了一个新的插件，你不想等待一个星期？)你只需要运行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">upgrade_oh_my_zsh1</span><br></pre></td></tr></table></figure>
<h3 id="卸载oh-my-zsh"><a class="markdownIt-Anchor" href="#卸载oh-my-zsh"></a> 卸载oh-my-zsh</h3>
<p>如果你想卸载<code>oh-my-zsh</code>, 只需要执行<code>uninstall_oh_my_zsh zsh</code>， 从命令行运行. 这将删除本身和恢复你以前的bash或者zsh配置.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">uninstall_oh_my_zsh zsh1</span><br></pre></td></tr></table></figure>
<h3 id="配置tmux默认调用oh-my-zsh"><a class="markdownIt-Anchor" href="#配置tmux默认调用oh-my-zsh"></a> 配置tmux默认调用oh-my-zsh</h3>
<p>但是感觉装完之后，有一种很不实用的感觉，就只是主题比较多？我想tmux的分屏和zsh的漂亮界面融合起来。 1.在 <strong>~/.tmux.conf</strong>文件中加了 “set -g default-shell /bin/zsh” 设置tmux的默认shell为zsh。 2.然后重新刷新tmux的配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tmux source-file ~/.tmux.conf</span><br></pre></td></tr></table></figure>
<h3 id="终端默认启动tmux"><a class="markdownIt-Anchor" href="#终端默认启动tmux"></a> 终端默认启动tmux</h3>
<p>到目前为止，我都是启动命令行之后会直接bash，需要输入tmux，才能开启tmux，然而我已经想直接抛弃bash了，所以默认启动tmux吧。 看看我现在都有些什么shell:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat /etc/shells</span><br></pre></td></tr></table></figure>
<p>结果 /bin/sh /bin/dash /bin/bash /bin/rbash /usr/bin/tmux /bin/zsh /usr/bin/zsh 然后:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">chsh -s /usr/bin/tmux</span><br></pre></td></tr></table></figure>
<p>重启电脑生效。 结束。</p>
<hr />
<h2 id="tmux"><a class="markdownIt-Anchor" href="#tmux"></a> tmux</h2>
<h3 id="安装配置"><a class="markdownIt-Anchor" href="#安装配置"></a> 安装配置</h3>
<p>因为很久之前就安装了tmux，当时没有写笔记，今天趁机会备注一下我的博文<a href="http://blog.csdn.net/williamyuyuyu/article/details/79283374">http://blog.csdn.net/williamyuyuyu/article/details/79283374</a> 主要是tmux的配置文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">vim ~/.tmux.conf</span><br></pre></td></tr></table></figure>
<p>记得配置完了之后刷新tmux的配置文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tmux source-file ~/.tmux.conf</span><br></pre></td></tr></table></figure>
<p>我借用了别人的配置,当然也备份到github了:<a href="https://github.com/YuYuCong/Ubuntu">https://github.com/YuYuCong/Ubuntu</a></p>
<h3 id="脚本"><a class="markdownIt-Anchor" href="#脚本"></a> 脚本</h3>
<p>tmux里面的脚本： 写一个脚本在<sub>/.tmux/dev，脚本名字就叫dev，放在</sub>/.tmux/目录下</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd ~</span><br><span class="line">mkdir .tmux</span><br><span class="line">cd .tmux</span><br><span class="line">vim dev</span><br></pre></td></tr></table></figure>
<p>写入</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">selectp -t 0 #选择第一个标签</span><br><span class="line">splitw -h -p 50 #分割成两半</span><br><span class="line"></span><br><span class="line">selectp -t 1 # 选择第二个标签</span><br><span class="line">splitw -v -p 50 &#x27;typora&#x27; #分割成两半</span><br><span class="line">selectp -t 0 # 返回第一个标签</span><br></pre></td></tr></table></figure>
<p>然后tmux的配置文件里面补上 <code>bind b source-file ~/.tmux/dev</code> 使用前缀+b按键调用此脚本。</p>
<h5 id="q1但是有个问题我的脚本为啥一直不运行脚本没配好啊"><a class="markdownIt-Anchor" href="#q1但是有个问题我的脚本为啥一直不运行脚本没配好啊"></a> 【Q1】但是有个问题：：：我的脚本为啥一直不运行！！！，脚本没配好啊。</h5>
<p>—————————————第二天————————————-</p>
<h3 id="继续tmux脚本"><a class="markdownIt-Anchor" href="#继续tmux脚本"></a> 继续tmux脚本</h3>
<h5 id="a1于是今天早上起床没洗漱继续研究发现重启一遍之后脚本配置都可以用了"><a class="markdownIt-Anchor" href="#a1于是今天早上起床没洗漱继续研究发现重启一遍之后脚本配置都可以用了"></a> 【A1】于是今天早上起床没洗漱继续研究，发现重启一遍之后脚本配置都可以用了。</h5>
<p>但是又有了新问题：注意一点，因为第三个标签调用的是typora，不是终端程序，运行typora之后，第三个标签会进入一种神奇的状态，不能输入任何命令，当你关闭typora时，它又会立即关闭。 突发奇想在Ctrl+Alt+F1之后的无窗口界面试了试Ctrl+b b的方式，发现typora完全无法运行，只打开了两个标签。——这就是之前所述的X服务未打开的缘故。</p>
<h5 id="q2所以我打算试试向建立3个标签并向终端输入命令开启typora的方式"><a class="markdownIt-Anchor" href="#q2所以我打算试试向建立3个标签并向终端输入命令开启typora的方式"></a> 【Q2】所以，我打算试试向建立3个标签并向终端输入命令开启typora的方式。</h5>
<h5 id="a2解决了"><a class="markdownIt-Anchor" href="#a2解决了"></a> 【A2】解决了！</h5>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">selectp -t 0 # 选择第一个标签</span><br><span class="line">splitw -h -p 50 # 竖着分割成两半</span><br><span class="line">selectp -t 1 # 选择第二个标签</span><br><span class="line">splitw -v -p 20 #水平分割成两个,新分割出来的占20%</span><br><span class="line">selectp -t 2 # 选择第三个标签</span><br><span class="line">send-keys -t 2 &#x27;typora ./daily_record/2018.md&#x27; #向标签2输入typora</span><br><span class="line">#send-keys -t 2 &#x27;typora ./daily_record/2018.md&#x27; C-m #向标签2输入命令，并回车确定  </span><br><span class="line">#selectp -t 0 # 返回第一个标签</span><br></pre></td></tr></table></figure>
<p>然后会自动分割成3个标签，并且向第三个标签输入typora，并且指向我的记录文档，刚好如果我想记录，直接Enter，如果不想开typora，那就重新输入命令即可。嘻嘻 &gt;_&lt; 当然注意，启动typora后的那个标签会进入运行状态，除非typora已经关闭，才能再输入命令。 ###　[注意]tmux比较权威的说明书： 《tmux: Productive Mouse-Free Development》<a href="https://www.kancloud.cn/kancloud/tmux/62464">https://www.kancloud.cn/kancloud/tmux/62464</a>， CSDN上很多博客都是在灌水，关乎脚本的只字不提，只说了快捷键部分。但是感觉脚本脚本脚本真的真的真的才是tmux最重要的是部分哇！ 当然这个脚本中所述的方法是用bashl下运行tmux脚本，所以每一条命令前面都有一句tmux，既然我已经设置了tmux为默认shell，已经是tmux环境了，所以我的脚本是不用每一句命令之前加tmux的。以上已经完成了一个快捷键调用我要的脚本 的配置。 【Q3】然后我又想，终端输入命令调用脚本的方式，正如前几行那个<a href="https://www.kancloud.cn/kancloud/tmux/62464">文档</a>说讲的方式，输入一个可执行脚本的名字develop，然后执行脚本，运行这个开发环境出来，平时不需要的时候就不调用，而不是tmux快捷按键的方式调用脚本。尤其 ，在我使用ros的时候，那么多的窗口，需要一个集成的界面出来！这个问题待续。</p>
<h2 id="总结一哈"><a class="markdownIt-Anchor" href="#总结一哈"></a> 总结一哈</h2>
<p>用了tmux的分割标签，快捷键，脚本运行； 配置文件在 .tmux.conf 其中一个插件 ~/.tmux/dev； 用了zsh的主题； 配置文件在~/.zshrc</p>
<h2 id="references"><a class="markdownIt-Anchor" href="#references"></a> References</h2>
<ul>
<li><a href="http://williamyu.top/blog/2018/02/13/shell/">http://williamyu.top/blog/2018/02/13/shell/</a></li>
<li><a href="https://segmentfault.com/a/1190000013857738">https://segmentfault.com/a/1190000013857738</a></li>
<li>《tmux: Productive Mouse-Free Development》<a href="https://www.kancloud.cn/kancloud/tmux/62464">https://www.kancloud.cn/kancloud/tmux/62464</a></li>
<li><a href="http://blog.csdn.net/gatieme/article/details/52741221">http://blog.csdn.net/gatieme/article/details/52741221</a></li>
</ul>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>NAS 安装与使用</title>
    <url>/2020/10/15/Others-NAS-set-up/</url>
    <content><![CDATA[<p>我主要用NAS做数据存储和备份，一些生物实验的原始数据比较大。<br />
<strong>一 组装</strong><br />
NAS型号：群晖 DS918+，有四个硬盘卡槽，底部还有一个内存卡插槽。买了两块IronWolf的NAS专用硬盘，各8 TB，一起16 TB。网络上有大量教程参考，组装完毕就是下图。</p>
<p><a href="https://genehub.files.wordpress.com/2020/10/81yfruavezl._ac_sl1500_.jpg"><img src="https://genehub.files.wordpress.com/2020/10/81yfruavezl._ac_sl1500_.jpg?w=1024" alt="" /></a></p>
<p><a href="https://genehub.files.wordpress.com/2020/10/synology-ds918-installing-hard-drive.jpg"><img src="https://genehub.files.wordpress.com/2020/10/synology-ds918-installing-hard-drive.jpg?w=800" alt="" /></a></p>
<p><strong>二 系统安装与配置</strong></p>
<p>在官网下载相应的系统安装文件 <a href="https://www.synology.com/zh-tw/support/download/DS918+#firmware">https://www.synology.com/zh-tw/support/download/DS918+#firmware</a> 。安裝 DSM （DiskStation Manager）。</p>
<p>[安装过程：<a href="https://ningselect.com/11397/40/%5C">https://ningselect.com/11397/40/\</a>]</p>
<p><strong>三 使用</strong></p>
<p>1 在任意位置使用web登入NAS服务器</p>
<p>2 在内网web浏览器输入IP即可登录使用</p>
<p>3 FTP连接。在FTP客户端（FileZilla）输入 sftp://admin@192.168.x.y 即可，后面不用加端口号。</p>
<p>4 将NAS挂载到本地网络的一个个人电脑下。这样相当于将NAS作为个人电脑的硬盘使用。先在NAS管理界面设置NFS，参考：<a href="https://www.synology.com/zh-cn/knowledgebase/DSM/tutorial/File%5C_Sharing/How%5C_to%5C_access%5C_files%5C_on%5C_Synology%5C_NAS%5C_within%5C_the%5C_local%5C_network%5C_NFS%E3%80%82%E7%84%B6%E5%90%8E%E5%9C%A8%E4%B8%AA%E4%BA%BA%E7%94%B5%E8%84%91%EF%BC%88%E6%88%91%E7%94%A8%E7%9A%84windows">https://www.synology.com/zh-cn/knowledgebase/DSM/tutorial/File\_Sharing/How\_to\_access\_files\_on\_Synology\_NAS\_within\_the\_local\_network\_NFS。然后在个人电脑（我用的windows</a> 10）设置，将群晖NAS映射为网络驱动器。在“我的电脑”右键，选择“映射网络驱动器”，驱动器选“Y”（随便选都可，一般考虑Z-&gt;A的顺序），文件夹地址输入“\\192.168.x.x\share_name”（192.168.x.x是NAS的IP地址，视具体情况而定；share_name就是NAS里面盘阵的名称，视具体情况而定），点击“完成”并输入账户名和密码。依次映射了两个硬盘，我得到了下面的界面，可见“网络位置”下方出现了相应的磁盘，这样就像使用本机硬盘一样的，很方便。</p>
<p>参考 <a href="https://jingyan.baidu.com/article/e75057f22d7901ebc81a8966.html">https://jingyan.baidu.com/article/e75057f22d7901ebc81a8966.html</a></p>
<p><a href="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201015112922.png"><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201015112922.png?w=702" alt="" /></a></p>
<p><strong>四 空间清理</strong></p>
<p>收到系统提醒说存储空间将满，删除了一部分文件，并清空回收站，但是空间还是没有释放。查询资料之后发现是 Synology Drive 这个应用的缘故，它会将已删除的文件保留备份，所以占用大量空间，将其卸载可以释放哪些空间。</p>
<p><a href="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201026162623.png"><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201026162623.png?w=831" alt="" /></a></p>
<p>Use a terminal (eg. Putty, SecureCRT) to connect Synology through SSH.<br />
ie: 192.168.x.x port 22<br />
Login ID: admin; Password: admin password.<br />
Switch to ROOT by “sudo -i”, type a new password for root user. Then detect space usage by “du -h -d 1”</p>
<p><a href="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201026160121.png"><img src="https://genehub.files.wordpress.com/2020/10/e5beaee4bfa1e688aae59bbe_20201026160121.png?w=1024" alt="" /></a></p>
<p>进入 Synology Drive Sever，选择“版本资源管理器”，勾选“显示已删除文件”，可见到那些被删除的文件实际上还保存在硬盘里，所以占用大量空间。</p>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
  </entry>
  <entry>
    <title>Peoteomics | Using MaxQuant to analyze LC-MS/MS data</title>
    <url>/2022/03/09/Peoteomics-Using-MaxQuant-to-analyze-LC-MS-MS-data/</url>
    <content><![CDATA[<h3 id="一-蛋白质谱的背景知识"><a class="markdownIt-Anchor" href="#一-蛋白质谱的背景知识"></a> 一、蛋白质谱的背景知识</h3>
<p>LC-MS/MS</p>
<p>Liquid Chromatography-Mass Spectrometry（LC-MS/MS ，液相色谱-质谱串联）可用于残留化合物检测、有机小分子检测、鉴定和定量污染物以及在医药和食品领域添加剂检测和生物小分子等检测。。</p>
<p>LC-MS/MS一般包含五个步骤：</p>
<p>样本制备；<br />
样本分离：使用液相色谱方法分离；<br />
质谱上机：离子化、LUMOS原理、采集模式（DDA、DIA、SRM/PRM）；<br />
质谱鉴定：谱图格式（Raw、MzXML、MGF）、搜库、打分算法、FDR质控、蛋白推断；<br />
生信分析：谱图校验和下游数据统计分析。</p>
<p><img src="https://zouhua.top/images/Omics_Proteomics_01/LCMSMS_concept.jpg" alt="" /></p>
<p><em>液相色谱（HPLC）分离肽段的原理是什么？</em> 色谱法的分离原理是：溶于流动相(mobile phase)中的各组分经过固定相时，由于与固定相(station phase)发生作用(吸附、分配、排阻、亲和)的大小、强弱不同，在固定相中滞留时间不同，从而先后从固定相中流出。又称为色层法、层析法。（<a href="https://www.sohu.com/a/471080306_121044873">参考资料</a>）</p>
<p><em>为什么质谱上机之前必须去盐？</em> 上机前的最后一步就是要保证多肽经过脱盐纯化，脱盐不充分不仅会影响目的肽段的鉴定，而且容易损坏仪器。此时可使用反相（RP）树脂来去除盐和缓冲液，其中C18基质是用于捕获疏水肽的理想基质。多肽在高水相流动相中与反相柱结合，同时盐和缓冲液被洗去，然后用高有机相流动相洗脱多肽。Pierce™ C18系列不仅提供了适合大体积样本的离心柱（column），还提供了适合小体积样本的吸头（tip）。（<a href="http://www.ebiotrade.com/newsf/2019-7/201972164022321.htm">参考资料</a>）</p>
<p><em>离子化（Ionization）是什么？</em> 只有分子转化为气相离子后，质谱仪才能测量其质量。为了达到这一目的，质谱仪使分子带上电荷，然后将带电离子流转化为数据系统能够识别的成比例电流。数据系统将这一电流转化为数字信息，得到质谱图。（<a href="https://www.waters.com/waters/zh_CN/What-is-MS-and-How-does-it-Work%3F/nav.htm?locale=zh_CN&amp;cid=10073253">参考资料</a>）离子源的性能决定了离子化效率，很大程度上决定了质谱仪的灵敏度。常见的离子化方式有两种：一种是样品在离子源中以气体的形式被离子化，另一种为从固体表面或溶液中溅射出带电离子。在很多情况下进样和离子化同时进行。比如，电子轰击电离(EI)是指气化后的样品分子进入离子化室后，受到由钨或铼灯丝发射并加速的电子流的轰击产生正离子。离子化室压力保持在10-4～10-6mmHg。轰击电子的能量大于样品分子的电离能，使样品分子电离或碎裂。电子轰击质谱能提供有机化合物最丰富的结构信息，有较好的重现性，其裂解规律的研究也最为完善，已经建立了数万种有机化合物的标准谱图库可供检索。其缺点在于不适用于难挥发和热稳定性差的样品。还有其他离子化方法，这里未摘录。（<a href="https://shiyanjia.com/knowledge/articleinfo-1611.html">参考资料</a>）</p>
<h3 id="一-使用-maxquant-软件对-label-free-lc-msms-数据进行定量分析"><a class="markdownIt-Anchor" href="#一-使用-maxquant-软件对-label-free-lc-msms-数据进行定量分析"></a> 一、使用 MaxQuant 软件对 label free LC-MS/MS 数据进行定量分析</h3>
<p>质谱数据下机之后，需要用软件来进行搜库（根据物种的蛋白质数据库来进行序列比对检索），有多种软件可以选择，以 Orbitrap 下机数据为例，可以用 ProteinDiscover 软件里面调用相应的搜索引擎进行分析，这里不做阐述。下面主要介绍 MaxQuant，一方面是免费，另一方面操作界面人性化，上手快。</p>
<p>2016年，德国马普所的 Cox 和蛋白质组学领域巨擘 Matthias Mann 合作开发了 MaxQuant 软件，并发表在 nbt 上，protocol 也相应发表在 nature protocols。不足五年，引用已高达上万次，其中不乏CNS级别文章。毫不夸张地说，MaxQuant 是业界良心。（摘自：<a href="https://www.cnblogs.com/jessepeng/p/13580371.html%EF%BC%89">https://www.cnblogs.com/jessepeng/p/13580371.html）</a></p>
<p>主要特点：</p>
<p>支持多种质谱仪厂商产生原始数据，如 raw/wiff；<br />
免费不开源，基于 Andromeda 搜索引擎；；<br />
支持标记定量和非标定量，如 labelfree（优势）/ICAT/SILAC/TMT/iTRAQ 等；<br />
蛋白鉴定数多，定量准确性高（主要是因为非线性质量校正和 Match Between Runs）；<br />
有较完整的结果查看和分析界面；<br />
主要部署在 Windows 系统（Linux 需要 mono，MacOS 需借助 Parallels 或 Bootcamp）；<br />
有配套的结果后处理软件 Perseus。</p>
<p><em>下载安装</em></p>
<p>官网：<a href="https://www.maxquant.org/%EF%BC%8C%E6%8C%89%E7%85%A7%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A3%E8%BF%9B%E8%A1%8C%E5%AE%89%E8%A3%85%E3%80%82MQ%E7%9A%84%E4%B8%8B%E8%BD%BD%E9%9C%80%E8%A6%81%E7%94%A8%E9%82%AE%E7%AE%B1%E6%B3%A8%E5%86%8C%EF%BC%8C%E5%B9%B6%E5%A1%AB%E5%86%99%E6%B3%A8%E5%86%8C%E7%A0%81%E3%80%82%E4%BE%9D%E8%B5%96.NET">https://www.maxquant.org/，按照官方文档进行安装。MQ的下载需要用邮箱注册，并填写注册码。依赖.NET</a> Framework（基于.net框架编写，有些没安装的电脑需要安装） 和 MSFileReader（识别质谱raw文件）。解压后无需安装，点击文件目录下的 MaxQuant.exe 即可使用。</p>
<p><em>配置与运行</em></p>
<p>MaxQuant使用很简单，参数界面设置也不像PD那么凌乱。我的系统是win 11 中文版，软件的菜单有一部分成了中文。</p>
<p><img src="https://i.imgur.com/Xaw0jTc.jpeg" alt="" /></p>
<p>6 大参数配置模块，我这里只选一些重要的参数，大部分默认就好：</p>
<ol>
<li>Raw files：导入原始数据和设计实验，包括组分和样本，Group（指不同的实验，如label/SILAC同时进行即为2个Group0和Group1，一般跑一个就好）；</li>
<li>Group-specific parameters：Group参数的设置，一般只是Group0；（忘了在哪里看到这么一句话：“Type” will usually be “Standard” (obviously), and the “Multiplicity” will be 1 for label-free quantification, 2 if you have light and heavy labels, and 3 if you have light, medium, and heavy.）</li>
<li>Global parameters：全局参数配置；</li>
<li>Performance：显示正在运行的具体步骤和动态；</li>
<li>Viewer：数据可视化模块， 能在labelfree定量中呈现三维图形。我认为没啥用，无需设置，拖慢速度；</li>
<li>Andromeda configuration：用于配置修饰、酶，以及数据库ID规则设置等，一般无额外需求，无需设置。</li>
</ol>
<p>所以，实际需要配置的就是前面三项，以 Labelfree 定量为例，写下 Group-specific parameters 和 Global parameters 中一些重要的参数：</p>
<p><img src="https://i.imgur.com/V0CLPDb.jpeg" alt="" /></p>
<p>备注：我在实际操作中遇到的一个问题，在“组特定参数配置”菜单里，Label-free quantification 里面的 LFQ 选上的话，点击开始分析的时候会报错“LFQ requires at least two experiments”。</p>
<p><img src="https://i.imgur.com/aSnmScM.jpeg" alt="" /></p>
<p>后来我发现，在“全局参数”菜单下面，也有一个 Label-free quantification 栏目。这里也有 LFQ 字样，不过我并没有测试。这里的 iBAQ 我是选择了的，跑完数据能够得到 iBAQ 值。</p>
<p><img src="https://i.imgur.com/RpMgWls.jpeg" alt="" /></p>
<p>一篇文献中提到的使用 maxquant 进行蛋白组数据分析：</p>
<p><img src="https://i.imgur.com/dekTX7j.png" alt="" /></p>
<p>搜库完成之后，在raw文件路径下，会生成一个combined目录，里面就有结果文件：proteinGroups.txt，可以用excel打开这个文件，并另存为xlsx格式，这个文件里面就有各个蛋白的iBAQ值。</p>
<p>在一个实践项目中，同一批数据分别用 PD 和 maxquant 跑，出来的结果大体一致，但是想让 maxquant 显示更多结果，如何调整参数？如下图，我将 FDR 从 0.01 调整到 0.05，另外 min pipetides 从1调整到0，这样出来的结果要从一千多个蛋白变成两千多个蛋白。</p>
<p><img src="https://i.imgur.com/RfL4mwM.jpeg" alt="" /></p>
<p><img src="https://i.imgur.com/FYZpr0W.jpeg" alt="" /></p>
<p>combined文件夹包含了搜库结果，如果是DIA建库，导入的即是这个文件夹。里面包含了txt文件夹，即鉴定和定量的全部结果。</p>
<p>mqpar.xml是所有参数配置文件，若二次搜库，可直接导入MaxQuant中，无需重复设置。所以，一般建议保留下来，这样也可对结果的设置进行追溯。</p>
<h3 id="二-蛋白质组定量结果之组间差异分析"><a class="markdownIt-Anchor" href="#二-蛋白质组定量结果之组间差异分析"></a> 二、蛋白质组定量结果之组间差异分析</h3>
<p>查资料看到的，可以用 Perseus 进行后处理。Perseus也是上面两位大佬开发的软件，发在nature methods上。一开始是专门针对MQ数据处理的。后来对所有矩阵类型的表达数据，甚至是多组学数据都适合。</p>
<p>实际操作中，我要对两组蛋白组学样品进行差异分析，两组各有4个生物学重复。</p>
<p>在知乎看到一篇文章总结了三个工具：limma，DEP 和 DEqMS。（参考：<a href="https://zhuanlan.zhihu.com/p/448479536%EF%BC%89">https://zhuanlan.zhihu.com/p/448479536）</a></p>
<p>其中 DEP 可以直接以 maxquant 的结果文件（ProteinGroups.txt）作为输入，而且分析之后的结果有命令可以直接画图，真是值得试试。</p>
<p>同时，我看到另一篇文章（<a href="https://www.bioinfo-scrounger.com/archives/541/%EF%BC%89%E4%B8%AD%EF%BC%8C%E4%BD%9C%E8%80%85%E8%AE%A4%E4%B8%BA">https://www.bioinfo-scrounger.com/archives/541/）中，作者认为</a> limma 使用结果也不错的。</p>
<p>良心作者，甚至还提供一个label-free MS的数据矩阵文件：<a href="http://www.bioinfo-scrounger.com/data/labelfree.csv">http://www.bioinfo-scrounger.com/data/labelfree.csv</a></p>
<p>下面摘抄该作者使用 limma 对两组蛋白质谱数据进行差异分析：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 如果就测试数据两组比较而言，limma需要先做log2转化，然后设定分组矩阵，最后用线性模型拟合再用Empirical Bayes test求出检验的P值</span><br><span class="line"></span><br><span class="line">library(limma)</span><br><span class="line"></span><br><span class="line">df1 &lt;- log2(df + 1)</span><br><span class="line">group_list &lt;- factor(c(rep(&quot;A&quot;,3), rep(&quot;B&quot;,3)))</span><br><span class="line">design &lt;- model.matrix(~group_list)</span><br><span class="line">colnames(design) &lt;- levels(group_list)</span><br><span class="line">rownames(design) &lt;- colnames(df1)</span><br><span class="line"></span><br><span class="line">fit &lt;- lmFit(df1, design)</span><br><span class="line">fit &lt;- eBayes(fit, trend=TRUE)</span><br><span class="line">result_limma &lt;- topTable(fit, coef=2,n=Inf)</span><br><span class="line">&gt;sum(result_limma$P.Value &lt; 0.05 &amp; abs(result_limma$logFC) &gt; 1)</span><br><span class="line">[1] 952</span><br><span class="line"># Limma的差异蛋白数目就相比以上就略多了，满足阈值的有952个</span><br></pre></td></tr></table></figure>
<p>下面是我的测试过程，并且用自己的蛋白组数据做了组间差异分析。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">### 蛋白质组学差异分析的博文：《浅谈蛋白组的差异蛋白分析》https://www.bioinfo-scrounger.com/archives/541/</span><br><span class="line">###  这篇文章也差不多：《蛋白质组差异分析的三个R包》 https://zhuanlan.zhihu.com/p/448479536</span><br><span class="line"></span><br><span class="line">##############################################################</span><br><span class="line"></span><br><span class="line">#测试数据下载：labelfree.csv (http://www.bioinfo-scrounger.com/data/labelfree.csv)</span><br><span class="line"></span><br><span class="line">#首先做一步过滤处理，以50%原则过滤掉缺失值较多的Protein，这步主要针对后续T检验和limma的预处理，而MSstats则有其默认的预处理方式</span><br><span class="line"></span><br><span class="line">library(ggplot2)</span><br><span class="line">library(dplyr)</span><br><span class="line"></span><br><span class="line">#data &lt;- read.table(file = &quot;labelfree.csv&quot;, sep = &quot;,&quot;, header = T, row.names = 1)</span><br><span class="line">data &lt;- read.table(file = &quot;labelfree-edited.txt&quot;, sep = &quot;\t&quot;, header = T, row.names = 1)</span><br><span class="line">rm &lt;- apply(data, 1, function(x)&#123;  # 这个函数的功能是去掉：超过50%的样品的表达值为0的样品</span><br><span class="line">  sum(x == 0) &gt; 3</span><br><span class="line">&#125;)</span><br><span class="line">df &lt;- data[!rm,]</span><br><span class="line">#&gt;nrow(df)</span><br><span class="line">#[1] 5325</span><br><span class="line"></span><br><span class="line">##################################################################</span><br><span class="line"></span><br><span class="line">#接着则是做log转化，这步有没有必要呢？Label-free技术是用峰谱积分计算丰度的，其丰度的数量级在10的7次到10的11次不等，从下面每个样本的均值和标准差可看出，丰度值数据分布非常离散</span><br><span class="line"></span><br><span class="line">Mean &lt;- apply(df, 2, mean)</span><br><span class="line">SD &lt;- apply(df, 2, sd)</span><br><span class="line">#&gt; Mean</span><br><span class="line">#A1         A2         A3         B1         B2         B3 </span><br><span class="line">#2366243926 2351546722 2165457844 2175212680 2708233812 2290120209</span><br><span class="line">#&gt; SD</span><br><span class="line">#A1          A2          A3          B1          B2          B3 </span><br><span class="line">#13098498790 14392930144 14179115278 11151997873 12092333164 10344859562</span><br><span class="line">#那么做log转化有什么用呢，一般作用为消除异方差；减少自变量数量级不一致的情况；使非线性变量关系转化为线性关系；最主要的还是为了使数据的呈现方式接近我们所希望的假设，从而更好的进行统计推断（以上来自知乎）</span><br><span class="line"></span><br><span class="line">#下面左边是原始数据AB两组的散点图，右边是做了对数转化后的</span><br><span class="line"></span><br><span class="line">#---------------</span><br><span class="line">#   T检验</span><br><span class="line">#---------------</span><br><span class="line">#在做Two-Sample T检验前，需要样本总体符合正态分布，并且方差齐性，以测试数据为例（未做对数转化），先做个F检验</span><br><span class="line"></span><br><span class="line">fvalue &lt;- apply(df, 1, function(x)&#123;</span><br><span class="line">  a &lt;- factor(c(rep(&quot;A&quot;,3), rep(&quot;B&quot;,3)))</span><br><span class="line">  var.test(x~a)</span><br><span class="line">&#125;)</span><br><span class="line">sum(unlist(lapply(fvalue, function(x)&#123;</span><br><span class="line">  x$p.value &gt; 0.05</span><br><span class="line">&#125;)))</span><br><span class="line">#[1] 4605</span><br><span class="line">#可看出5325个蛋白有4605个是方差齐性的</span><br><span class="line"></span><br><span class="line">#接下来用t.test函数做成组T检验，双尾（默认），方差不齐性的用var.equal = FALSE</span><br><span class="line"></span><br><span class="line">pvalue &lt;- apply(df, 1, function(x)&#123;</span><br><span class="line">  a &lt;- factor(c(rep(&quot;A&quot;,3), rep(&quot;B&quot;,3)))</span><br><span class="line">  fvalue &lt;- var.test(x~a)</span><br><span class="line">  if (fvalue$p.value &gt; 0.05)&#123;</span><br><span class="line">    t.test(x~a, var.equal = T)</span><br><span class="line">  &#125;else&#123;</span><br><span class="line">    t.test(x~a, var.equal = F)</span><br><span class="line">  &#125;</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">result_ttest &lt;- data.frame(ID=row.names(df), </span><br><span class="line">                           Pvalue = as.numeric(unlist(lapply(pvalue, function(x) x$p.value))),</span><br><span class="line">                           log2FC = log2(as.numeric(unlist(lapply(pvalue, function(x) x$estimate[1]/x$estimate[2]))))</span><br><span class="line">)</span><br><span class="line">sum(result_ttest$Pvalue &lt; 0.05 &amp; abs(result_ttest$log2FC) &gt; 1)</span><br><span class="line">#[1] 704</span><br><span class="line">#可看出差异蛋白数目为704个；如果是预处理时做了对数转化的话，代码同上（其中有略微区别，logFC是作相减，而不是上面代码的相除），结果符合相同的阈值的差异蛋白有694个</span><br><span class="line"></span><br><span class="line">#---------------</span><br><span class="line">     Limma</span><br><span class="line">#---------------</span><br><span class="line">#Limma就比较熟悉了，如果就测试数据两组比较而言，limma需要先做log2转化，然后设定分组矩阵，最后用线性模型拟合再用Empirical Bayes test求出检验的P值</span><br><span class="line">library(limma)</span><br><span class="line">df1 &lt;- log2(df + 1)</span><br><span class="line">group_list &lt;- factor(c(rep(&quot;A&quot;,3), rep(&quot;B&quot;,3)))</span><br><span class="line">design &lt;- model.matrix(~group_list)     ### 这是什么函数？？？</span><br><span class="line">colnames(design) &lt;- levels(group_list)</span><br><span class="line">rownames(design) &lt;- colnames(df1)</span><br><span class="line">fit &lt;- lmFit(df1, design)</span><br><span class="line">fit &lt;- eBayes(fit, trend=TRUE)</span><br><span class="line">result_limma &lt;- topTable(fit, coef=2,n=Inf)</span><br><span class="line">sum(result_limma$P.Value &lt; 0.05 &amp; abs(result_limma$logFC) &gt; 1)</span><br><span class="line">#[1] 952</span><br><span class="line">#Limma的差异蛋白数目就相比以上就略多了，满足阈值的有952个</span><br><span class="line">write.table(result_limma, file = &quot;limma_output.xls&quot;, sep = &quot;\t&quot;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">################################################################################</span><br><span class="line">############</span><br><span class="line">############   下面用自己的数据调用limma做差异分析</span><br><span class="line">############</span><br><span class="line">################################################################################</span><br><span class="line"></span><br><span class="line"># 用Perl写脚本，将不同样品的ProteinGroups.txt文件一起合并成一个表达谱矩阵。第一列为基因名，其余各列为表达值。类似于RNA Seq的表达矩阵。</span><br><span class="line"></span><br><span class="line">#首先做一步过滤处理，以50%原则（可以自己调整）过滤掉缺失值较多的Protein，这步主要针对后续T检验和limma的预处理，而MSstats则有其默认的预处理方式</span><br><span class="line"></span><br><span class="line">library(ggplot2)</span><br><span class="line">library(dplyr)</span><br><span class="line"></span><br><span class="line">#data &lt;- read.table(file = &quot;labelfree.csv&quot;, sep = &quot;,&quot;, header = T, row.names = 1)</span><br><span class="line">data &lt;- read.table(file = &quot;merged_iBAQ_table_v3_input_for_R.txt&quot;, sep = &quot;\t&quot;, header = T, row.names = 1)</span><br><span class="line">rm &lt;- apply(data, 1, function(x)&#123;  # 这个函数的功能是去掉：超过50%的样品的表达值为0的样品</span><br><span class="line">  sum(x == 0) &gt; 7</span><br><span class="line">&#125;)</span><br><span class="line">df &lt;- data[!rm,]</span><br><span class="line">#&gt;nrow(df)</span><br><span class="line">#[1] 5325</span><br><span class="line"></span><br><span class="line">library(limma)</span><br><span class="line">df1 &lt;- log2(df + 1)</span><br><span class="line">group_list &lt;- factor(c(rep(&quot;A&quot;,4), rep(&quot;B&quot;,4)))</span><br><span class="line">design &lt;- model.matrix(~group_list)     ### 这是什么函数？？？</span><br><span class="line">colnames(design) &lt;- levels(group_list)</span><br><span class="line">rownames(design) &lt;- colnames(df1)</span><br><span class="line"></span><br><span class="line">fit &lt;- lmFit(df1, design)</span><br><span class="line">fit &lt;- eBayes(fit, trend=TRUE)</span><br><span class="line">result_limma &lt;- topTable(fit, coef=2,n=Inf)</span><br><span class="line">sum(result_limma$P.Value &lt; 0.05 &amp; abs(result_limma$logFC) &gt; 1)</span><br><span class="line">#[1] 952</span><br><span class="line">#Limma的差异蛋白数目就相比以上就略多了，满足阈值的有952个</span><br><span class="line"></span><br><span class="line">write.table(result_limma, file = &quot;limma_output_FREE1.xls&quot;, sep = &quot;\t&quot;)</span><br><span class="line">### 如果下次重新打开R画图，则直接读入文件：</span><br><span class="line">#result_limma &lt;- read.table(&quot;limma_output_FREE1.xls&quot;, sep = &quot;\t&quot;, head=T)</span><br><span class="line"></span><br><span class="line">####</span><br><span class="line"># Volcano Plot</span><br><span class="line">#logFC AveExpr         t      P.Value   adj.P.Val         B</span><br><span class="line">#AT5G09660.4 -24.86099 12.4305 -13.67679 2.515145e-07 0.000174047 -1.497474</span><br><span class="line">#AT5G09660.3 -24.86099 12.4305 -13.67679 2.515145e-07 0.000174047 -1.497474</span><br><span class="line"></span><br><span class="line">#----------------     计算-logFC     ----------------</span><br><span class="line">#prop &lt;- apply(df, 2,function(x,y) (x/y)*100, df$Total)</span><br><span class="line">#x &lt;- apply(result_limma, 2, function(x) -x, result_limma$logFC)</span><br><span class="line">result_limma$x &lt;- -result_limma$logFC</span><br><span class="line">head(result_limma)</span><br><span class="line">#----------------    计算-log10(Pvalue)   -----------</span><br><span class="line">result_limma$y &lt;- -log10(result_limma$P.Value)</span><br><span class="line"></span><br><span class="line">#install.packages(&#x27;ggrepel&#x27;)</span><br><span class="line">library(ggrepel)</span><br><span class="line"></span><br><span class="line">library(ggplot2)</span><br><span class="line"></span><br><span class="line">####  Volcano Plot</span><br><span class="line"></span><br><span class="line">ggplot() +</span><br><span class="line">  #ggplot(data=a, aes(x=normalized_log2Fab, y=log2_mark_1_2_PrSM))</span><br><span class="line">  geom_hline(yintercept = 0, linetype=&quot;dashed&quot;, color = &quot;grey&quot;, size=1.5) +</span><br><span class="line">  geom_hline(yintercept = -log10(0.05), linetype=&quot;dashed&quot;, color = &quot;grey&quot;, size=1.5) +</span><br><span class="line">  geom_vline(xintercept = 0, linetype=&quot;dashed&quot;, color = &quot;grey&quot;, size=1.5) +</span><br><span class="line">  #geom_point(color=&quot;#9167a9&quot;, size=4, alpha=0.7)+</span><br><span class="line">  geom_point(data=filter(result_limma, P.Value&lt;=0.05 &amp; x&gt;0), aes(x=x, y=y), size = 2, color=&quot;red&quot;, alpha=0.2) +</span><br><span class="line">  geom_point(data=filter(result_limma, P.Value&lt;=0.05 &amp; x&lt;0), aes(x=x, y=y), size = 2, color=&quot;green&quot;, alpha=0.2) +</span><br><span class="line">  geom_point(data=filter(result_limma, P.Value&gt;0.05), aes(x=x, y=y), size = 2, color=&quot;darkblue&quot;, alpha=0.2) +</span><br><span class="line">  #scale_size(range = c(0.5, 10))  + </span><br><span class="line">  theme_bw() +</span><br><span class="line">  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) +</span><br><span class="line">  #theme(axis.text.x = element_text(size = 15, color = &quot;black&quot;, face = &quot;bold&quot;, vjust = 0.5, hjust = 0.5, angle = 45)) +</span><br><span class="line">  theme(axis.text.x = element_text(size = 15, color = &quot;black&quot;, face = &quot;bold&quot;)) +</span><br><span class="line">  theme(axis.text.y = element_text(color = &quot;black&quot;, size = 15)) +</span><br><span class="line">  ylab(&quot;-log10(P value)&quot;) +</span><br><span class="line">  xlab(&quot;log10(Fold Change)&quot;) +</span><br><span class="line">  theme(axis.title.y = element_text(size = 18)) +</span><br><span class="line">  theme(axis.title.x = element_text(size = 18))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Proteomics</category>
      </categories>
  </entry>
  <entry>
    <title>2014 年植物科学最新SCI影响因子前50强排行榜</title>
    <url>/2014/08/17/Plant-2014-sci-if-rank/</url>
    <content><![CDATA[<p>2014 Journal Rankings on Plant Science:</p>
<span id="more"></span>
<p>No.</p>
<p>Journal</p>
<p>Impact Factor</p>
<p>5-year IF</p>
<p>1</p>
<p>ANNU REV PLANT BIOL</p>
<p>18.9</p>
<p>32.189</p>
<p>2</p>
<p>TRENDS PLANT SCI</p>
<p>13.479</p>
<p>14.22</p>
<p>3</p>
<p>ANNU REV PHYTOPATHOL</p>
<p>11</p>
<p>13.8</p>
<p>4</p>
<p>PLANT CELL</p>
<p>9.575</p>
<p>10.656</p>
<p>5</p>
<p>CURR OPIN PLANT BIOL</p>
<p>9.385</p>
<p>9.825</p>
<p>6</p>
<p>PLANT PHYSIOL</p>
<p>7.394</p>
<p>7.908</p>
<p>7</p>
<p>PLANT J</p>
<p>6.815</p>
<p>7.535</p>
<p>8</p>
<p>NEW PHYTOL</p>
<p>6.373</p>
<p>7.289</p>
<p>9</p>
<p>J ECOL</p>
<p>5.694</p>
<p>6.477</p>
<p>10</p>
<p>MOL PLANT</p>
<p>6.605</p>
<p>6.348</p>
<p>11</p>
<p>CRIT REV PLANT SCI</p>
<p>5.292</p>
<p>6.255</p>
<p>12</p>
<p>PLANT CELL ENVIRON</p>
<p>5.906</p>
<p>6.242</p>
<p>13</p>
<p>J EXP BOT</p>
<p>5.794</p>
<p>6.019</p>
<p>14</p>
<p>PLANT BIOTECHNOL J</p>
<p>5.677</p>
<p>5.913</p>
<p>15</p>
<p>PLANT CELL PHYSIOL</p>
<p>4.978</p>
<p>4.972</p>
<p>16</p>
<p>MOL PLANT MICROBE IN</p>
<p>4.455</p>
<p>4.871</p>
<p>17</p>
<p>MOL PLANT PATHOL</p>
<p>4.485</p>
<p>4.795</p>
<p>18</p>
<p>BMC PLANT BIOL</p>
<p>3.942</p>
<p>4.758</p>
<p>19</p>
<p>PLANT MOL BIOL</p>
<p>4.072</p>
<p>4.61</p>
<p>20</p>
<p>PERSPECT PLANT ECOL</p>
<p>3.324</p>
<p>4.41</p>
<p>21</p>
<p>ANN BOT-LONDON</p>
<p>3.295</p>
<p>4.001</p>
<p>22</p>
<p>PLANT GENOME-US</p>
<p>3.878</p>
<p>3.922</p>
<p>23</p>
<p>PLANT SCI</p>
<p>4.114</p>
<p>3.785</p>
<p>24</p>
<p>PHYSIOL PLANTARUM</p>
<p>3.262</p>
<p>3.764</p>
<p>25</p>
<p>THEOR APPL GENET</p>
<p>3.507</p>
<p>3.759</p>
<p>26</p>
<p>PLANTA</p>
<p>3.376</p>
<p>3.715</p>
<p>27</p>
<p>PLANT SOIL</p>
<p>3.235</p>
<p>3.713</p>
<p>28</p>
<p>FRONT PLANT SCI</p>
<p>3.637</p>
<p>3.645</p>
<p>29</p>
<p>PHYTOCHEMISTRY</p>
<p>3.35</p>
<p>3.571</p>
<p>30</p>
<p>J VEG SCI</p>
<p>3.372</p>
<p>3.564</p>
<p>31</p>
<p>ENVIRON EXP BOT</p>
<p>3.003</p>
<p>3.529</p>
<p>32</p>
<p>BOT REV</p>
<p>2.208</p>
<p>3.455</p>
<p>33</p>
<p>J NAT PROD</p>
<p>3.947</p>
<p>3.404</p>
<p>34</p>
<p>PHOTOSYNTH RES</p>
<p>3.185</p>
<p>3.365</p>
<p>35</p>
<p>PLANT METHODS</p>
<p>2.586</p>
<p>3.36</p>
<p>36</p>
<p>J ETHNOPHARMACOL</p>
<p>2.939</p>
<p>3.284</p>
<p>37</p>
<p>PHYTOMEDICINE</p>
<p>2.877</p>
<p>3.237</p>
<p>38</p>
<p>J INTEGR PLANT BIOL</p>
<p>3.448</p>
<p>3.112</p>
<p>39</p>
<p>J PLANT PHYSIOL</p>
<p>2.77</p>
<p>3.065</p>
<p>40</p>
<p>PLANT PHYSIOL BIOCH</p>
<p>2.352</p>
<p>3.051</p>
<p>41</p>
<p>PHYTOPATHOLOGY</p>
<p>2.746</p>
<p>3.028</p>
<p>42</p>
<p>FUNCT PLANT BIOL</p>
<p>2.569</p>
<p>3.021</p>
<p>43</p>
<p>PRESLIA</p>
<p>2.778</p>
<p>2.937</p>
<p>44</p>
<p>PROTOPLASMA</p>
<p>3.171</p>
<p>2.931</p>
<p>45</p>
<p>AM J BOT</p>
<p>2.463</p>
<p>2.843</p>
<p>46</p>
<p>PLANT CELL REP</p>
<p>2.936</p>
<p>2.833</p>
<p>47</p>
<p>ADV BOT RES</p>
<p>1.74</p>
<p>2.796</p>
<p>48</p>
<p>PLANT DIS</p>
<p>2.742</p>
<p>2.795</p>
<p>49</p>
<p>PLANT PATHOL</p>
<p>2.969</p>
<p>2.788</p>
<p>50</p>
<p>PLANT FOOD HUM NUTR</p>
<p>2.416</p>
<p>2.774</p>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>Plant | Chromatin immunoprecipitation</title>
    <url>/2021/04/16/Plant-Chromatin-immunoprecipitation/</url>
    <content><![CDATA[<p>##Crosslinking</p>
<ol>
<li>Prepare crosslinking buffer (Extraction buffer 1). For each gram of leaves, 36 ml buffer is needed.</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Reagent  Amount (500 mL)</span><br><span class="line">0.4 M sucrose 68.46 g</span><br><span class="line">10 mM Tris-HCl, pH 8.0 5 mL of 1 M stock</span><br><span class="line">5 mM beta-ME  (Add prior to use) 176 uL of 14.2 M stock</span><br><span class="line">0.1 mM PMSF (Add prior to use) 500 uL of 0.1 M stock</span><br><span class="line">1% Formaldehyde (Add prior to use) 13.5 mL of 37% stock</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>Prepare 2M glycine solution (for stopping the crosslinking reaction). For each gram of leaves, 2.5 ml solution is needed. Store at 4°C.</li>
<li>Collect beaker with appropriate capacity. Make sure the buffer volume will not exceed 60-70% of the beaker capacity (to avoid spillage).</li>
<li>Harvest soybean leaves (C08).</li>
<li>Cut leaves into 0.5-1 cm pieces and submerge them in Milli-Q water in beaker.</li>
<li>Rinse leaves with Milli-Q water twice.</li>
<li>Add 5 mM beta-ME into the cold extraction buffer 1. Pour buffer into the beaker with leaves.</li>
<li>Place the beaker into the transparent “bowl” for vacuum infiltration.</li>
<li>Disconnect centrivap with the cold trap.</li>
<li>Connect the bowl with the cold trap.</li>
<li>Add appropriate volume of formaldehyde solution to the buffer. 1 ml formaldehyde solution in 36 ml extraction buffer 1. working concentration ~ 1% formaldehyde</li>
<li>Stir the mixture with stirrer.</li>
<li>Place a piece of gauze under the bottom of a flask/beaker.</li>
<li>Place the flask/beaker with gauze onto the water surface in the beaker.</li>
<li>Cover the lid of the “bowl”.</li>
<li>Close the valve at the cold trap. (Turn the valve to a position perpendicular to the pipe).</li>
<li>Turn on the vacuum pump. After a while, the lid will be closed tightly and bubbles can be observed in the solution. Vacuum infiltrate for 5 minutes.</li>
<li>Turn off the pump. Open the valve and the lid.</li>
<li>Stir the solution again and make sure all leaves are submerged. Repeat step 16-18.</li>
<li>Add appropriate volume of 2M glycine solution to the buffer. For each gram of leaves, 2.5 ml solution is added.</li>
<li>Vacuum infiltrate for 5 minutes again.</li>
<li>Cover the opening with the gauze already used in vacuum infiltration and filter out all the buffer under running tap water in a sink.</li>
<li>Rinse the cross-linked leaves with Milli-Q water. (Cold Milli-Q water is preferred in some protocols.)</li>
<li>With the aid of a stirrer/rod, transfer cross-linked leaves onto layers of tissue paper.</li>
<li>Remove excess water by gently pressing cross-linked leaves with tissue paper.</li>
<li>Pack leaves with aluminum foil.</li>
<li>Freeze leaves with liquid nitrogen. Store at -80°C.</li>
</ol>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>Plant | Rice: Oryza sativa subsp. japonica and indica</title>
    <url>/2021/10/31/Plant-Rice-Oryza-sativa-subsp-japonica-and-indica/</url>
    <content><![CDATA[<p>本文总结粳稻（japonica）与籼稻（indica）的分类，以及相对应的数据库的事项。</p>
<p>作者：稻我家安全食材<br />
链接：<a href="https://www.zhihu.com/question/28272395/answer/513511209">https://www.zhihu.com/question/28272395/answer/513511209</a><br />
来源：知乎<br />
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>籼稻（Indica rice）：有 20% 左右为直链淀粉。属中黏性。籼稻起源于亚热带，种植于热带和亚热带地区，生长期短，在无霜期长的地方一年可多次成熟。去壳成为籼米后，外观细长、透明度低。有的品种表皮发红，如中国江西出产的红米，煮熟后米饭较干、松。通常用于萝卜糕、米粉、炒饭。</p>
<p>粳稻（Japonica rice）：粳稻的直链淀粉较少，低于15%。种植于温带和寒带地区，生长期长，一般一年只能成熟一次。去壳成为粳米后，外观圆短、透明（部分品种米粒有局部白粉质）。煮食特性介于糯米与籼米之间。用途为一般食用米。籼稻和粳稻是长期适应不同生态条件，尤其是温度条件而形成的两种气候生态型，两者在形态生理特性方面部有明显差异因为籼稻和粳稻产自不同的地方，米粒的形状也不同，口感上更是相差很远。</p>
<p>那么二者的区别又在哪里呢？</p>
<ol>
<li>
<p>首先在品种上籼稻是由野生稻演变来的，而粳稻是由籼稻在人们不断向高纬度、高海拔地区引种的过程中不断演变和人工选育而来的。因此说籼稻是基本型，粳稻是变异型。</p>
</li>
<li>
<p>从形态特征和经济性状上看，一般籼稻的茎杆较粗，分蘖力较强，叶色较淡，谷粒细长，容易落粒，出米率较低。籼米的直链淀粉含量高，煮饭时胀饭性大，黏性小，米饭散落。粳稻一般茎杆较细，传统粳稻品种的分蘖力不如籼稻，叶色较深，谷粒短圆，不容易落粒，出米率较高，碎米少。粳米的直链淀粉含量低，米饭黏性大，胀饭性小。</p>
</li>
<li>
<p>从生理特征和适应性上看，籼稻一般吸肥性强，而耐肥力差，易倒伏，耐寒力较差，温度在12℃以上时才能发芽。粳稻则耐肥力强而吸肥性差，较抗倒伏，耐寒力较强，温度达到10℃即可发芽。在温度适宜的条件下，籼稻叶片的光合速率高于粳稻，繁茂性好，易早生快发。</p>
</li>
<li>
<p>从地区分布上看，籼稻适于在低纬度、低海拔的湿热地区栽培，如我国的南方稻区。粳稻则适于在高纬度、高海拔地区栽培，如我国的东北稻区、华北稻区和西北稻区，也可在云贵高原的高海拔地区和江淮流域双季稻区作中粳和晚粳种植。</p>
</li>
<li>
<p>从稻株外部形态进行区别：籼稻一般株高多在1米以上，茎秆较软，叶片宽，色泽淡绿，剑叶开度小。叶片茸毛多，有短小茸毛散生于颖壳。大多为无芒或短芒，谷粒细长而稍扁平，一般长度为宽度的二倍以上。谷粒易脱落，较耐湿、耐热和耐强光，但不耐寒。粳稻一般株高多为75-95厘米，茎秆较矮，叶子较窄，深绿色，米粒不易脱落，耐寒性强。</p>
</li>
</ol>
<p>因此，籼稻是由野生稻演变成的栽培稻，是基本型。粳稻分布范围广泛，从南方的高寒山区，云贵高原到秦岭，淮河以北的广大的地区均有栽培。粳稻具有耐寒，耐弱光的习性，粒形短圆，米质粘性较强，叶面少毛或无毛，颖毛长密，不易落粒等特性，与野生稻有较大差异。因此，可以说粳稻是人类将籼稻由南向北，由低向高引种后，逐渐适应低温的变异型。</p>
<h3 id="籼稻indica9311的基因组信息"><a class="markdownIt-Anchor" href="#籼稻indica9311的基因组信息"></a> 籼稻（indica，9311）的基因组信息</h3>
<p>数据下载</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget ftp://ftp.genomics.org.cn/pub/ricedb/SynVs9311/9311/Sequence/Chromosome/ChrAll.fasta.gz</span><br><span class="line">wget ftp://ftp.genomics.org.cn/pub/ricedb/rice_update_data/GLEAN_genes/Beijing_indica/GLEAN_genes/9311.glean.gff.cds.gz</span><br><span class="line">wget ftp://ftp.genomics.org.cn/pub/ricedb/rice_update_data/GLEAN_genes/Beijing_indica/GLEAN_genes/9311.glean.gff.gff.gz</span><br><span class="line">hisat2-build -p 8  genome.fa genome</span><br><span class="line">gffread 9311.glean.gff.gff -F -T -o 9311.glean.raw.gtf</span><br><span class="line">perl ~/local/app/NGSQCToolkit/Statistics/N50Stat.pl -i ChrAll.fasta -o ChrAll.fasta.stat</span><br></pre></td></tr></table></figure>
<p>基因命名</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##gff-version 3</span><br><span class="line">##sequence-region Chr01 1 47283185</span><br><span class="line">Chr01   glean   gene    47275570        47278635        .       -       .       ID=BGIOSGA000001;Name=BGIOSGA000001;</span><br><span class="line">Chr01   glean   mRNA    47275570        47278635        0.798504        -       .       ID=BGIOSGA000001-TA;Name=BGIOSGA000001-TA;Parent=BGIOSGA000001;</span><br><span class="line">Chr01   glean   CDS     47278477        47278635        .       -       0       Parent=BGIOSGA000001-TA;</span><br><span class="line">Chr01   glean   CDS     47278262        47278399        .       -       0       Parent=BGIOSGA000001-TA;</span><br><span class="line">Chr01   glean   CDS     47278135        47278186        .       -       0       Parent=BGIOSGA000001-TA;</span><br><span class="line">Chr01   glean   CDS     47277979        47278058        .       -       2       Parent=BGIOSGA000001-TA;</span><br><span class="line">Chr01   glean   CDS     47276528        47276587        .       -       0       Parent=BGIOSGA000001-TA;</span><br><span class="line">Chr01   glean   CDS     47275842        47275922        .       -       0       Parent=BGIOSGA000001-TA;</span><br><span class="line">Chr01   glean   CDS     47275570        47275662        .       -       0       Parent=BGIOSGA000001-TA;</span><br><span class="line">Chr01   glean   gene    47247293        47259724        .       -       .       ID=BGIOSGA000002;Name=BGIOSGA000002;</span><br><span class="line">Chr01   glean   mRNA    47247293        47259724        0.997143        -       .       ID=BGIOSGA000002-TA;Name=BGIOSGA000002-TA;Parent=BGIOSGA000002;</span><br><span class="line">Chr01   glean   CDS     47259551        47259724        .       -       0       Parent=BGIOSGA000002-TA;</span><br><span class="line">Chr01   glean   CDS     47259199        47259261        .       -       0       Parent=BGIOSGA000002-TA;</span><br><span class="line">Chr01   glean   CDS     47258441        47258518        .       -       0       Parent=BGIOSGA000002-TA;</span><br><span class="line">Chr01   glean   CDS     47258327        47258376        .       -       0       Parent=BGIOSGA000002-TA;</span><br><span class="line">Chr01   glean   CDS     47257303        47257405        .       -       1       Parent=BGIOSGA000002-TA;</span><br><span class="line">Chr01   glean   CDS     47256255        47256407        .       -       0       Parent=BGIOSGA000002-TA;</span><br><span class="line">Chr01   glean   CDS     47255968        47256060        .       -       0       Parent=BGIOSGA000002-TA;</span><br></pre></td></tr></table></figure>
<h3 id="粳稻japonica或称日本晴var-nipponbare的基因组信息"><a class="markdownIt-Anchor" href="#粳稻japonica或称日本晴var-nipponbare的基因组信息"></a> 粳稻（japonica，或称“日本晴”，var Nipponbare）的基因组信息</h3>
<p>下载地址 <a href="https://rapdb.dna.affrc.go.jp/download/irgsp1.html">https://rapdb.dna.affrc.go.jp/download/irgsp1.html</a>，从下面下载的文件来看，该数据集的更新日期为2020年12月。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">drwxrwxr-x 2 fenglei fenglei      4096 Mar 10  2021 index</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   2205461 Mar 10  2021 IRGSP-1.0_representative_transcript_exon_2020-12-02.gtf.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   2910542 Mar 10  2021 IRGSP-1.0_representative_annotation_2020-12-02.tsv.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  15479652 Mar 10  2021 IRGSP-1.0_representative_2020-12-02.tar.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   8071768 Mar 10  2021 IRGSP-1.0_protein_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  12921645 Mar 10  2021 IRGSP-1.0_cds_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  21521204 Mar 10  2021 IRGSP-1.0_transcript_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  14082338 Mar 10  2021 IRGSP-1.0_1kb-upstream_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  13852984 Mar 10  2021 IRGSP-1.0_1kb-downstream_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  27531029 Mar 10  2021 IRGSP-1.0_2kb-upstream_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  40892583 Mar 10  2021 IRGSP-1.0_gene_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei     65536 Mar 10  2021 irgsp1_repeat_unit.gff.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  27067699 Mar 10  2021 IRGSP-1.0_2kb-downstream_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  40469323 Mar 10  2021 IRGSP-1.0_3kb-upstream_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei  39804961 Mar 10  2021 IRGSP-1.0_3kb-downstream_2020-12-02.fasta.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei 208876624 Mar 10  2021 kasalath_genome.tar.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei    828064 Mar 10  2021 IRGSP-1.0_predicted_2020-12-02.tar.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei    212118 Mar 10  2021 IRGSP-1.0_predicted_transcript_exon_2020-12-02.gtf.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei     65407 Mar 10  2021 IRGSP-1.0_predicted_annotation_2020-12-02.tsv.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   1624227 Mar 10  2021 IRGSP-1.0_predicted-protein_2020-12-02.fasta</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei     18236 Mar 10  2021 irgsp1_rRNA_tRNA.gff.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei    323084 Mar 10  2021 RAP-MSU_2020-12-02.txt.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei    339560 Mar 10  2021 IRGSP-1.0_transcript-evidence_2012-04-11.txt.gz</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   4589349 Mar 10  2021 IRGSP-1.0_predicted-cds_2020-12-02.fasta</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei    174987 Mar 10  2021 organelle.gff</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei    650061 Mar 10  2021 Mt_Pt_genome.fasta</span><br><span class="line">-rw-rw-r-- 1 fenglei fenglei   8054917 Mar 10  2021 Rice_vegetative_and_reproductive_stage-specific_sRNAs_and_networks.zip</span><br><span class="line">-rwxr-xr-x 1 fenglei fenglei        51 Mar 10  2021 opt.sh</span><br></pre></td></tr></table></figure>
<p>看看他的基因命名</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost O.sativa_japonica_2021]$ less IRGSP-1.0_representative_transcript_exon_2020-12-02.gtf.gz</span><br><span class="line">chr01   irgsp1_rep      transcript      2983    10815   .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    2983    3268    .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    3354    3616    .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    4357    4455    .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    5457    5560    .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    7136    7944    .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    8028    8150    .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    8232    8320    .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    8408    8608    .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    9210    9615    .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    10102   10187   .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    10274   10430   .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      exon    10504   10815   .       +       .       gene_id &quot;Os01g0100100&quot;; transcript_id &quot;Os01t0100100-01&quot;;</span><br><span class="line">chr01   irgsp1_rep      transcript      11218   12435   .       +       .       gene_id &quot;Os01g0100200&quot;; transcript_id &quot;Os01t0100200-01&quot;;</span><br></pre></td></tr></table></figure>
<h3 id="粳稻另一个版本"><a class="markdownIt-Anchor" href="#粳稻另一个版本"></a> 粳稻另一个版本</h3>
<p>下载地址 <a href="http://rice.uga.edu/">http://rice.uga.edu/</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">RGAP 7 Summary</span><br><span class="line">Gene Annotation</span><br><span class="line"></span><br><span class="line">Total loci	55,986</span><br><span class="line">Non-TE Loci	</span><br><span class="line">Number	39,045</span><br><span class="line">Gene models	49,066</span><br><span class="line">Gene size	2,853 bp</span><br><span class="line">Exons/gene	4.9</span><br><span class="line">Introns/gene	3.9</span><br><span class="line">TE Loci	</span><br><span class="line">Number	16,941</span><br><span class="line">Gene models	17,272</span><br><span class="line">Gene size	3,223 bp</span><br><span class="line">Exons/gene	4.2</span><br><span class="line">Introns/gene	3.2</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ le MSU_japonica_all.gff3</span><br><span class="line">##gff-version 3</span><br><span class="line">Chr1    MSU_osa1r7      gene    2903    10817   .       +       .       ID=LOC_Os01g01010;Name=LOC_Os01g01010;Note=TBC%20domain%20containing%20protein%2C%20expressed</span><br><span class="line">Chr1    MSU_osa1r7      mRNA    2903    10817   .       +       .       ID=LOC_Os01g01010.1;Name=LOC_Os01g01010.1;Parent=LOC_Os01g01010</span><br><span class="line">Chr1    MSU_osa1r7      exon    2903    3268    .       +       .       ID=LOC_Os01g01010.1:exon_1;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    3354    3616    .       +       .       ID=LOC_Os01g01010.1:exon_2;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    4357    4455    .       +       .       ID=LOC_Os01g01010.1:exon_3;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    5457    5560    .       +       .       ID=LOC_Os01g01010.1:exon_4;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    7136    7944    .       +       .       ID=LOC_Os01g01010.1:exon_5;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    8028    8150    .       +       .       ID=LOC_Os01g01010.1:exon_6;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    8232    8320    .       +       .       ID=LOC_Os01g01010.1:exon_7;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    8408    8608    .       +       .       ID=LOC_Os01g01010.1:exon_8;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    9210    9617    .       +       .       ID=LOC_Os01g01010.1:exon_9;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    10104   10187   .       +       .       ID=LOC_Os01g01010.1:exon_10;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    10274   10430   .       +       .       ID=LOC_Os01g01010.1:exon_11;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      exon    10504   10817   .       +       .       ID=LOC_Os01g01010.1:exon_12;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      five_prime_UTR  2903    3268    .       +       .       ID=LOC_Os01g01010.1:utr_1;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      five_prime_UTR  3354    3448    .       +       .       ID=LOC_Os01g01010.1:utr_2;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      CDS     3449    3616    .       +       .       ID=LOC_Os01g01010.1:cds_1;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      CDS     4357    4455    .       +       .       ID=LOC_Os01g01010.1:cds_2;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      CDS     5457    5560    .       +       .       ID=LOC_Os01g01010.1:cds_3;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      CDS     7136    7944    .       +       .       ID=LOC_Os01g01010.1:cds_4;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      CDS     8028    8150    .       +       .       ID=LOC_Os01g01010.1:cds_5;Parent=LOC_Os01g01010.1</span><br><span class="line">Chr1    MSU_osa1r7      CDS     8232    8320    .       +       .       ID=LOC_Os01g01010.1:cds_6;Parent=LOC_Os01g01010.1</span><br></pre></td></tr></table></figure>
<p>注意粳稻有两个版本的基因组，使用的染色体编号与基因编号均有不同，曾经因为参考基因组版本问题导致生成的比对 bam 格式文件无法浏览，后续查询才发觉问题。</p>
<h3 id="新的分析项目"><a class="markdownIt-Anchor" href="#新的分析项目"></a> 新的分析项目</h3>
<p>某分析项目的 gff 文件如下所示，这是哪个版本的基因组？</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Chr1    MSU_osa1r7      gene    2903    10817   .       +       .       ID=LOC_Os01g01010;</span><br><span class="line">Chr1    MSU_osa1r7      mRNA    2903    10817   .       +       .       ID=LOC_Os01g01010.1;Parent=LOC_Os01g01010;</span><br><span class="line">Chr1    MSU_osa1r7      exon    2903    3268    .       +       .       ID=LOC_Os01g01010.1:exon_1;Parent=LOC_Os01g01010.1;</span><br><span class="line">Chr1    MSU_osa1r7      exon    3354    3616    .       +       .       ID=LOC_Os01g01010.1:exon_2;Parent=LOC_Os01g01010.1;</span><br><span class="line">Chr1    MSU_osa1r7      exon    4357    4455    .       +       .       ID=LOC_Os01g01010.1:exon_3;Parent=LOC_Os01g01010.1;</span><br><span class="line">Chr1    MSU_osa1r7      exon    5457    5560    .       +       .       ID=LOC_Os01g01010.1:exon_4;Parent=LOC_Os01g01010.1;</span><br><span class="line">Chr1    MSU_osa1r7      exon    7136    7944    .       +       .       ID=LOC_Os01g01010.1:exon_5;Parent=LOC_Os01g01010.1;</span><br><span class="line">Chr1    MSU_osa1r7      exon    8028    8150    .       +       .       ID=LOC_Os01g01010.1:exon_6;Parent=LOC_Os01g01010.1;</span><br><span class="line">Chr1    MSU_osa1r7      exon    8232    8320    .       +       .       ID=LOC_Os01g01010.1:exon_7;Parent=LOC_Os01g01010.1;</span><br></pre></td></tr></table></figure>
<p>经过比对，推测该数据来自：<a href="http://rice.uga.edu/pub/data/Eukaryotic_Projects/o_sativa/annotation_dbs/pseudomolecules/version_7.0/all.dir/">http://rice.uga.edu/pub/data/Eukaryotic_Projects/o_sativa/annotation_dbs/pseudomolecules/version_7.0/all.dir/</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Index of /pub/data/Eukaryotic_Projects/o_sativa/annotation_dbs/pseudomolecules/version_7.0/all.dir</span><br><span class="line">[ICO]	Name	Last modified	Size	Description</span><br><span class="line">[PARENTDIR]	Parent Directory	 	-	 </span><br><span class="line">[TXT]	APK_ftp_file.txt	2011-10-31 10:12	3.9M	 </span><br><span class="line">[TXT]	POG_ftp_file.txt	2011-10-31 10:12	2.3M	 </span><br><span class="line">[   ]	all.GOSlim_assignment	2011-11-21 10:15	12M	 </span><br><span class="line">[   ]	all.cdna	2011-10-31 10:12	114M	 </span><br><span class="line">[   ]	all.cds	2011-10-31 10:12	91M	 </span><br><span class="line">[   ]	all.chrs.con	2011-10-31 10:11	363M	 </span><br><span class="line">[   ]	all.con	2011-10-31 10:12	364M	 </span><br><span class="line">[   ]	all.gff3	2012-02-07 09:41	78M	 </span><br><span class="line">[   ]	all.interpro	2011-10-31 10:12	62M	 </span><br><span class="line">[   ]	all.locus_brief_info..&gt;	2012-02-07 09:38	6.8M	 </span><br><span class="line">[   ]	all.masked.con.gz	2011-11-21 15:13	78M	 </span><br><span class="line">[   ]	all.pep	2011-10-31 10:11	33M	 </span><br><span class="line">[   ]	all.pfam	2011-10-31 10:12	4.9M	 </span><br><span class="line">[   ]	all.seq	2011-10-31 10:12	165M	 </span><br><span class="line">[TXT]	final_rice_v7_expres..&gt;	2011-10-31 10:12	10M	 </span><br><span class="line">[   ]	final_rice_v7_expres..&gt;	2011-10-31 10:12	38M	 </span><br><span class="line">[   ]	rice_osa1r7_rm.gff3.gz	2011-11-21 15:21	7.5M	 </span><br><span class="line">[   ]	rice_r7_all_tiling_p..&gt;	2011-10-31 10:12	412K	 </span><br></pre></td></tr></table></figure>
<p>将该目录下的文件全部下载</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget -r -np -nH -R index.html  http://rice.uga.edu/pub/data/Eukaryotic_Projects/o_sativa/annotation_dbs/pseudomolecules/version_7.0/all.dir/</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>2015年度植物学科杂志的影响因子Top50</title>
    <url>/2016/08/22/Plant-SCI-impact-factors-top50/</url>
    <content><![CDATA[<p></p>
<p>排名</p>
<p>期刊名</p>
<p>IF2015</p>
<p>IF2015-5Y</p>
<p>1</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=1&amp;journal=ANNU+REV+PLANT+BIOL">ANNU REV PLANT BIOL</a></p>
<p>22.131</p>
<p>25.829</p>
<p>2</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=2&amp;journal=TRENDS+PLANT+SCI">TRENDS PLANT SCI</a></p>
<p>10.899</p>
<p>14.191</p>
<p>3</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=3&amp;journal=ANNU+REV+PHYTOPATHOL">ANNU REV PHYTOPATHOL</a></p>
<p>9.308</p>
<p>11.959</p>
<p>4</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=4&amp;journal=PLANT+CELL">PLANT CELL</a></p>
<p>8.538</p>
<p>9.88</p>
<p>5</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=5&amp;journal=NEW+PHYTOL">NEW PHYTOL</a></p>
<p>7.21</p>
<p>7.554</p>
<p>6</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=6&amp;journal=MOL+PLANT">MOL PLANT</a></p>
<p>7.142</p>
<p>6.885</p>
<p>7</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=7&amp;journal=CURR+OPIN+PLANT+BIOL">CURR OPIN PLANT BIOL</a></p>
<p>6.78</p>
<p>7.843</p>
<p>8</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=8&amp;journal=PLANT+PHYSIOL">PLANT PHYSIOL</a></p>
<p>6.28</p>
<p>7.367</p>
<p>9</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=9&amp;journal=J+ECOL">J ECOL</a></p>
<p>6.18</p>
<p>6.409</p>
<p>10</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=10&amp;journal=PLANT+CELL+ENVIRON">PLANT CELL ENVIRON</a></p>
<p>6.169</p>
<p>6.443</p>
<p>11</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=11&amp;journal=PLANT+BIOTECHNOL+J">PLANT BIOTECHNOL J</a></p>
<p>6.09</p>
<p>5.951</p>
<p>12</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=12&amp;journal=J+EXP+BOT">J EXP BOT</a></p>
<p>5.677</p>
<p>6.229</p>
<p>13</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=13&amp;journal=PLANT+J">PLANT J</a></p>
<p>5.468</p>
<p>6.468</p>
<p>14</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=14&amp;journal=CRIT+REV+PLANT+SCI">CRIT REV PLANT SCI</a></p>
<p>4.81</p>
<p>6.028</p>
<p>15</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=15&amp;journal=FRONT+PLANT+SCI">FRONT PLANT SCI</a></p>
<p>4.495</p>
<p>4.461</p>
<p>16</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=16&amp;journal=MOL+PLANT+PATHOL">MOL PLANT PATHOL</a></p>
<p>4.335</p>
<p>4.819</p>
<p>17</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=17&amp;journal=PLANT+CELL+PHYSIOL">PLANT CELL PHYSIOL</a></p>
<p>4.319</p>
<p>4.847</p>
<p>18</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=18&amp;journal=MOL+PLANT+MICROBE+IN">MOL PLANT MICROBE IN</a></p>
<p>4.145</p>
<p>4.328</p>
<p>19</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=19&amp;journal=PHOTOSYNTH+RES">PHOTOSYNTH RES</a></p>
<p>4.122</p>
<p>3.6</p>
<p>20</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=20&amp;journal=ANN+BOT-LONDON">ANN BOT-LONDON</a></p>
<p>3.982</p>
<p>4.088</p>
<p>21</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=21&amp;journal=PLANT+MOL+BIOL">PLANT MOL BIOL</a></p>
<p>3.905</p>
<p>3.874</p>
<p>22</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=22&amp;journal=THEOR+APPL+GENET">THEOR APPL GENET</a></p>
<p>3.9</p>
<p>4.115</p>
<p>23</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=23&amp;journal=ENVIRON+EXP+BOT">ENVIRON EXP BOT</a></p>
<p>3.712</p>
<p>3.707</p>
<p>24</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=24&amp;journal=J+INTEGR+PLANT+BIOL">J INTEGR PLANT BIOL</a></p>
<p>3.67</p>
<p>3.993</p>
<p>25</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=25&amp;journal=J+NAT+PROD">J NAT PROD</a></p>
<p>3.662</p>
<p>3.644</p>
<p>26</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=26&amp;journal=BMC+PLANT+BIOL">BMC PLANT BIOL</a></p>
<p>3.631</p>
<p>4.604</p>
<p>27</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=27&amp;journal=PERSPECT+PLANT+ECOL">PERSPECT PLANT ECOL</a></p>
<p>3.578</p>
<p>4.619</p>
<p>28</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=28&amp;journal=PHYSIOL+PLANTARUM">PHYSIOL PLANTARUM</a></p>
<p>3.52</p>
<p>3.799</p>
<p>29</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=29&amp;journal=PLANT+GENOME-US">PLANT GENOME-US</a></p>
<p>3.509</p>
<p>5</p>
<p>30</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=30&amp;journal=PLANT+METHODS">PLANT METHODS</a></p>
<p>3.449</p>
<p>3.627</p>
<p>31</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=31&amp;journal=PLANT+SCI">PLANT SCI</a></p>
<p>3.362</p>
<p>3.981</p>
<p>32</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=32&amp;journal=PLANTA">PLANTA</a></p>
<p>3.239</p>
<p>3.593</p>
<p>33</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=33&amp;journal=PLANT+DIS">PLANT DIS</a></p>
<p>3.192</p>
<p>3.268</p>
<p>34</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=34&amp;journal=J+VEG+SCI">J VEG SCI</a></p>
<p>3.151</p>
<p>3.31</p>
<p>35</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=35&amp;journal=PLANT+CELL+REP">PLANT CELL REP</a></p>
<p>3.088</p>
<p>3.187</p>
<p>36</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=36&amp;journal=J+ETHNOPHARMACOL">J ETHNOPHARMACOL</a></p>
<p>3.055</p>
<p>3.333</p>
<p>37</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=37&amp;journal=PHYTOPATHOLOGY">PHYTOPATHOLOGY</a></p>
<p>3.011</p>
<p>3.248</p>
<p>38</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=38&amp;journal=J+PLANT+PHYSIOL">J PLANT PHYSIOL</a></p>
<p>2.971</p>
<p>3.241</p>
<p>39</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=39&amp;journal=PLANT+SOIL">PLANT SOIL</a></p>
<p>2.969</p>
<p>3.581</p>
<p>40</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=40&amp;journal=PHYTOMEDICINE">PHYTOMEDICINE</a></p>
<p>2.937</p>
<p>3.343</p>
<p>41</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=41&amp;journal=PLANT+PHYSIOL+BIOCH">PLANT PHYSIOL BIOCH</a></p>
<p>2.928</p>
<p>3.434</p>
<p>42</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=42&amp;journal=TAXON">TAXON</a></p>
<p>2.907</p>
<p>2.926</p>
<p>43</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=43&amp;journal=AM+J+BOT">AM J BOT</a></p>
<p>2.811</p>
<p>2.794</p>
<p>44</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=44&amp;journal=PHYTOCHEMISTRY">PHYTOCHEMISTRY</a></p>
<p>2.779</p>
<p>3.218</p>
<p>45</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=45&amp;journal=PRESLIA">PRESLIA</a></p>
<p>2.711</p>
<p>3.285</p>
<p>46</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=46&amp;journal=PHYTOCHEM+REV">PHYTOCHEM REV</a></p>
<p>2.686</p>
<p>3.883</p>
<p>47</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=47&amp;journal=J+PHYCOL">J PHYCOL</a></p>
<p>2.536</p>
<p>2.747</p>
<p>48</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=48&amp;journal=BOT+J+LINN+SOC">BOT J LINN SOC</a></p>
<p>2.523</p>
<p>2.333</p>
<p>49</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=49&amp;journal=PHYTOCHEM+ANALYSIS">PHYTOCHEM ANALYSIS</a></p>
<p>2.497</p>
<p>2.479</p>
<p>50</p>
<p><a href="http://admin-apps.webofknowledge.com/JCR/JCR?RQ=RECORD&amp;rank=50&amp;journal=FUNCT+PLANT+BIOL">FUNCT PLANT BIOL</a></p>
<p>2.491</p>
<p>3.015</p>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>大豆产业现状</title>
    <url>/2020/12/12/Plant-Soybean-introduction/</url>
    <content><![CDATA[<p>全球大豆年产量 <a href="http://www.mczx.agri.cn/scts/gxyb/201910/t20191008_7206083.htm">3.42 亿吨</a>，主要为表中的6个国家生产。2019年全年，中国大豆播种面积 <a href="http://www.stats.gov.cn/tjsj/zxfb/201912/t20191206_1716156.html">1.40 亿亩</a>（约 2300 万英亩，或 9.33 万平方公里，或 933 万公顷），产量 <a href="http://www.cngrain.com/Publish/1/660407.html">1810 万吨</a>。中国 2019 年进口大豆  <a href="https://www.thepaper.cn/newsDetail_forward_6206738">8851 万吨</a>，从巴西、美国、阿根廷三国进口大豆比例分别为 <a href="http://pdf.dfcfw.com/pdf/H3_AP202004121377900207_1.PDF">65.1%、19.1%、9.9%</a>。也就是说，2019年全年中国自产加进口的大豆总量是 10661 万吨，占世界全年产量的 31.17%。</p>
<p><strong>为什么中国需要这么多大豆？</strong> 大豆主要用途是什么？<a href="http://www.gov.cn/xinwen/2020-06/22/content_5520960.htm">我国是世界最大的大豆消费国，每年大豆消费量1亿吨以上，其中进口大豆消费量9000多万吨。目前，我国大豆消费已形成了食用和压榨两个相对独立的市场。其中，国产大豆主要用于直接食用、加工豆制品和大豆蛋白；进口大豆主要用于满足国内植物油和蛋白粕需求。</a> <a href="https://www.yicai.com/news/100377221.html">国内居民对动物源蛋白需求增加，刺激了我国养殖行业快速增长，而动物饲料中的重要成分就是豆粕。</a><a href="https://www.sohu.com/a/340624292_100032755">全球 1.2 亿吨猪肉产量，欧盟 2000 多万吨，中国是 5400 多万吨，美国不到 1200 万吨，我们占接近50%，欧盟占20%，美国占不到10%。目前我国人均年消费猪肉量为38kg，全年国内猪肉消费量大概在5500万吨</a>。</p>
<p><strong>大豆的单位面积产值并不高</strong> 大豆净利润远低于玉米：2012年，黑龙江省大豆每亩净利润256元，而玉米则为495元，粳稻为695元——<a href="http://ww2.usc.cuhk.edu.hk/PaperCollection/Details.aspx?id=9316">难怪该地越来越多农民不愿意种大豆</a>。</p>
<p><strong>进口大豆价格</strong> “<a href="http://chinawto.mofcom.gov.cn/article/ap/p/201907/20190702882188.shtml">2019年1至6月（截止到6月21日）大豆价格维持在325美元/吨左右，仍在2009年以来的低位徘徊，刚刚超过308美元/吨（约为每千克2.1元人民币）的成本线。</a>” 2019年4月4日，中国发布对美国的关税反制措施，将对原产于美国 106 项商品加征关税，其中大豆、玉米、小麦、牛肉、汽车、飞机和部分化学品等在列。同时，商务部公告称，中国加征关税的商品金额约为 500 亿美元。大豆是中美贸易的重要组成部分，此次公告对进口自美国的大豆加征 25%关税，标志着中美贸易摩擦再次升级。“<a href="http://pg.jrj.com.cn/acc/Res/CN_RES/INDUS/2018/4/10/573a9dd8-293d-4246-a7e8-13c9f1a53b57.pdf">目前美豆到岸完税价约为 3300~3400 元/吨，根据测算，加征 25%关税之后到岸完税价提高至 4100 元/吨左右，进口成本增加 700 多元/吨（上涨幅度 22%左右）。</a>” <a href="http://www.gov.cn/xinwen/2020-06/22/content_5520960.htm">2020年6月16日，9月份船期美湾大豆到我国港口完税成本约为每吨3190元，比1月初每吨下跌170元。国产大豆与进口大豆价格差距进一步拉大，目前国产大豆价格比进口大豆每吨高2000多元。</a></p>
<p><strong>国产大豆价格</strong> <a href="http://www.gov.cn/xinwen/2020-06/22/content_5520960.htm">2020年6月12日，中储粮油脂公司委托中储粮网竞价销售储备轮换国产大豆60486吨，起拍价格为每吨4800元，最低成交价5140元，最高成交价5270元。</a></p>
<p><strong>大豆亩产量</strong> 中国大豆亩产量比美国低。“<a href="https://www.guancha.cn/economy/2019_05_29_503615.shtml?s=zwyxgtjdt">根据我国大豆振兴计划，到2020年，全国大豆平均亩产达到135公斤，到2022年，全国大豆平均亩产达到140公斤，逐步缩小与世界大豆主产国的单产差距。</a>” <a href="https://world.huanqiu.com/article/9CaKrnKbg1t">在整个黑龙江垦区，大豆平均亩产为167.5公斤，距离美国大豆的亩产200公斤差距已经不大。</a>根据媒体报道的大豆总产量计算，中国2019年大豆种植面积 1.4 亿亩，年产量 1810 万吨，平均亩产 129 公斤，按照 5000 元/吨售出价计算，合646元人民币。美国大豆种植面积由3100万公顷增至3566万公顷，年均增长1.8%；产量由9066万吨增至1.24亿吨，年均增长4%。美国2019年大豆种植面积料为 <a href="http://chinawto.mofcom.gov.cn/article/ap/p/201907/20190702882188.shtml">3566万公顷</a>（5.35亿亩），产量 1.24 亿吨，平均亩产 232 公斤。</p>
<p>如果中国想要完全由自己来生产每年所消费的大豆，每年需要另外播种多少亩大豆，占用全国总播种面积多少？每年需要另外播种约四亿亩以上的大豆，占到全国总播种面积的15％～20％。这意味着必须减少如此幅度的谷物或高值新农业产品，实际上根本就不可考虑。这是国内大豆产量没有显著增加而大豆进口快速增长的基本原因。</p>
<p>2019年2月19日，新华社受权发布《中共中央、国务院关于坚持农业农村优先发展做好“三农”工作的若干意见》要求，严守<a href="https://www.yicai.com/news/100121079.html">18亿亩耕地红线</a>，全面落实永久基本农田特殊保护制度，确保永久基本农田保持在15.46亿亩以上。按照18亿亩耕地的红线，这个面积高达120万平方公里。<a href="https://mp.weixin.qq.com/s/wtNo0KQmHdWkv-gzm81dNg">一亩土地是666.67平米，乘以18亿亩，刚好是120万平方公里整数</a>，约等于西藏的面积。</p>
<p>如果按照当前中国大豆亩产量 129 公斤/亩来计算，如果需要满足国内总需求量 10661 万吨的生产，需要耕地面积 8.2 亿亩，合 54.67 万平方公里，比整个黑龙江省的面积（47.7 万平方公里）略大。</p>
<p><strong>中国和美国的大豆有什么不一样？</strong><br />
学者曾比较过中美大豆生产的投入费用。根据其分析，2009年至2012年，中国大豆生产的物质和人工平均费用，分别为166.96、133.18元；美国大豆生产的物质和人工平均费用，分别是236.54、21.26元。美国大豆生产的物质费用比中国高69.58元，人工费用比中国却低111.92元。<a href="https://news.fx168.com/opinion/column/hujiajun/1806/2541828.shtml">两项合计，美国比中国大豆生产成本整体上低了42.34元。</a> 更为关键的是，美国大豆生产不仅投入成本低，亩产量还比中国高。2009年至2012年，中国大豆亩产量平均为142.46公斤，美国大豆亩产量平均则为201.32公斤，较中国高出58.86公斤。一进一出，美国大豆取得了绝对的价格优势。</p>
<p><strong>美国大豆单位面积产量为什么比中国大豆更高？</strong></p>
<p><strong>转基因大豆的原理</strong><br />
1976年，美国孟山都公司（Monsanto Company）推出一款高效除草剂，名为农达草甘膦（Roundup）。草甘膦能够抑制深根杂草生长，大大减少农作物的田间管理强度。对于大规模农场来说，农达是一个巨大福音。但是，具体到大豆农户，则喜忧参半，因为草甘膦在消灭杂草的同时，也会杀死豆苗。为了解决这个难题，孟山都公司又组织科学家，利用前期的转基因研究，1993年培育出了抗农达大豆品种。农户买了他们的大豆种子，即使喷洒草甘膦，也不会影响豆苗生长。</p>
<p>大豆基础研究：</p>
<ol>
<li>增加产量</li>
<li>提高抗虫性</li>
<li>提高含油量</li>
<li>提高植物蛋白含量</li>
</ol>
<table>
<thead>
<tr>
<th>国家</th>
<th>种植面积（英亩）</th>
<th>产量</th>
<th>出口量</th>
<th>进口量</th>
</tr>
</thead>
<tbody>
<tr>
<td>巴西</td>
<td>9509万</td>
<td>1.2500亿吨</td>
<td>7700万吨</td>
<td>-</td>
</tr>
<tr>
<td>美国</td>
<td>8670万</td>
<td>1.2400亿吨</td>
<td>4967万吨</td>
<td>-</td>
</tr>
<tr>
<td>阿根廷</td>
<td>4820万</td>
<td>5100万吨</td>
<td>820万吨</td>
<td>-</td>
</tr>
<tr>
<td>中国</td>
<td>2187万</td>
<td>1800万吨</td>
<td>-</td>
<td>8859万吨</td>
</tr>
<tr>
<td>印度</td>
<td>2680万</td>
<td>1346万吨</td>
<td>NA</td>
<td>NA</td>
</tr>
<tr>
<td>巴拉圭</td>
<td>940万</td>
<td>1030万吨</td>
<td>630万吨</td>
<td>-</td>
</tr>
<tr>
<td>其他</td>
<td>-</td>
<td>-</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>总计</td>
<td>30641万</td>
<td>3.42亿吨</td>
<td>1.5亿吨</td>
<td>-</td>
</tr>
</tbody>
</table>
<p><img src="http://img.zhitongcaijing.com/images/contentformat/10a8eb25dc1e1cc86384b6337f9cb2f3.jpg" alt="大豆种植面积" /></p>
<p><img src="http://img.zhitongcaijing.com/images/contentformat/42907666545e4dd2a32c1065f9eda879.jpg" alt="大豆产量" /></p>
<p><img src="http://www.dwjmsw.com/Uploads/Article/image/20191118/20191118100510_56129.jpg" alt="中国大豆产量、进口量、消费量" /></p>
<p><img src="http://img.zhitongcaijing.com/images/contentformat/0905bdc7968f303cb5c4ca1f54d74f4a.jpg" alt="中国进口大豆来源" /></p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<ol>
<li><a href="https://www.zhitongcaijing.com/content/detail/162164.html">西部证券研究报告：大豆之争，渔翁得利 2018-11-07</a></li>
<li><a href="http://pdf.dfcfw.com/pdf/H3_AP202004121377900207_1.PDF">全球大豆价格还能一路上涨吗？2020-04-11</a></li>
<li><a href="http://chinawto.mofcom.gov.cn/article/ap/p/201907/20190702882188.shtml">农民日报：美国大豆产业的发展现状如何？2019-07-16</a></li>
<li><a href="http://www.xzfutures.com/files/document/20170510/6363000333771339151814280.pdf">兴证期货：大豆气象周报 2017-05-10</a></li>
<li><a href="">《开放时代》2014年第1期：大豆生产和进口的经济逻辑 2014-01-01</a></li>
<li><a href="https://www.guancha.cn/economy/2019_05_29_503615.shtml?s=zwyxgtjdt">国产大豆振兴 2020年大豆种植面积将达到1.4亿亩 </a></li>
<li><a href="https://www.qianzhan.com/analyst/detail/220/191120-8ccd4a58.html">前瞻经济学人：2019年全球大豆行业市场发展现状分析 全球大豆产量稳步增长 2019-11-21</a></li>
<li><a href="http://finance.ifeng.com/topic/money/ddzz/index.shtml">凤凰网财经专题：大豆战争 2012年</a></li>
<li><a href="http://www.cciee.org.cn/archiver/cciee/UpFile/Files/qqh/20191009140421154928.pdf">《全球化》2019年第5期：中国大豆产业发展：主要问题、原因以及对策建议</a></li>
<li><a href="http://jjckb.xinhuanet.com/2010-05/07/content_220528.htm">新华网：中洋大豆之争 实乃产业链的抗衡 2010-05-07</a></li>
<li><a href="http://www.cqvip.com/qk/91584x/201009/33584422.html">《求是》2010年 第9期 | 万宝瑞: 振兴我国大豆产业的根本途径</a></li>
<li><a href="https://www.yicai.com/news/345460.html">第一财经：我国大豆产业急需发展专业合作社 2010-05-05</a></li>
<li><a href="https://news.fx168.com/opinion/column/hujiajun/1806/2541828.shtml">财经报社：美国大豆是如何“征服”世界的？ 2018-06-09</a></li>
</ol>
<h3 id="附注"><a class="markdownIt-Anchor" href="#附注"></a> 附注</h3>
<p><strong>草甘膦的作用机理</strong></p>
<p>草甘膦是由著名的美国公司孟山都（Monsanto）研制成功的灭生性茎叶处理除草剂，具有高效 、广谱 、低毒（草甘膦的急性经口毒性比食盐都低，但后来有报道草甘膦具有肾毒性，我还没有认真查找相关的学术报道，先不做评论。）、低残留 、易于被微生物分解 ,不破坏土壤环境 ,对大多数植物具有灭生性等优点。后来又得益于抗草甘膦转基因作物的发展和推广，这种除草剂一直稳坐世界第一大农药的宝座。    草甘膦作为一种非选择性除草剂，它的作用机理是竞争性地抑制莽草酸途径中 5 - 烯醇丙酮莽草酸 - 3 - 磷酸合成酶 ( EPSPS)的活性 。该合成酶是真菌 、细菌 、藻类和高等植物体内芳香族氨基酸 (包括色氨酸 、酪氨酸 、苯丙氨酸 )生物合成过程中一个关键性的酶。具体的生理生化过程见下图。用草甘膦处理植物以后，植物体内含有这类氨基酸的蛋白质合成就会受阻，进而影响一系列代谢过程，导致植物死亡。草甘膦使用时一般将其制成异丙胺盐或钠盐。草甘膦除草性能优异，极易通过叶面少量通过根吸收，并运送到植物生长点。<br />
<img src="https://pic2.zhimg.com/80/fccf586c8c431cd3b71435d878b4851c_720w.jpg?source=1940ef5c" alt="" /></p>
<p><strong>转基因大豆抵御草甘膦的机理</strong></p>
<p>目前研究者主要从三个方面入手来改善作物的抗草甘膦特性：1. 通过使草甘膦抑制的酶过量表达，进而让植物吸收草甘膦之后能够进行正常代谢。但是目前用这个方法得到的抗草甘膦作物暴露在草甘膦之下时仍表现出生长抑制，未达到能够商业化的水平。2. 引入酶系统，在草甘膦进入植物体后迅速将其降解。目前这一策略也没有在生产上大量应用。3. 而应用于生产实践的上的主要方法是对草甘膦作用的酶进行修饰，降低它对草甘膦的敏感性。这里插一句背景知识，生物体内的酶大部分都是由氨基酸按照一定顺序排列组成的大分子物质，具有一定的空间结构，能够由特定酶催化，和特定酶反应的分子需要和这种酶的结构位点相结合才能发挥作用。改变了草甘膦作用的酶的结构，就可以降低甚至消除草甘膦对这种酶的作用效力。目前研究者们从大肠杆菌( <em>Escherichia coli</em>)、沙门氏杆菌( <em>Salmonella typhimurium</em>)和农杆菌( <em>Agrobacterium tumefaciens</em>) 等微生物中分离出了抗草甘膦的突变基因，而应用于生产的是从农杆菌菌株( <em>A. tumefaciens</em> sp. CP4) 上分离出的CP4基因。在大豆上导入了这种抗草甘膦基因，在大豆植株中表达出的CP4-EPSP合成酶对草甘膦的敏感性比较低，使得转基因植物体内的莽草酸途径可以正常进行。这样以来大豆就表现出了对草甘膦的抗性。</p>
<p><strong>转基因植物抗虫的机理</strong><br />
以转基因Bt抗虫作物为例, Bt蛋白为什么能够杀死昆虫？Bt进入昆虫的消化道, 昆虫的消化道是碱性环境, Bt蛋白和昆虫消化道上的受体结合, 引起肠穿孔, 从而导致害虫生长缓慢, 直至死亡。人的消化道结构和昆虫不一样, 而且人的肠道环境是酸性的, Bt蛋白进入胃中后很快在胃液中被消化降解为氨基酸, 对人体消化道没有任何作用。也就是说, Bt基因的杀虫功能具有很强的选择性, 只在鳞翅目昆虫的碱性消化道中发挥作用, 对人和哺乳动物都不会产生影响(Sheltonet al., 2002)。抗除草剂性状由于其巨大的经济效益和环境效益, 成为作物的第一大改良性状。2011年抗除草剂大豆、玉米、油菜、棉花、甜菜以及苜蓿种植面积达9 390万公顷, 占全球转基因作物种植总面积的59%。其中使用最为广泛的抗除草剂基因是从根瘤农杆菌中分离的编码455个氨基酸的抗草甘膦基因CP4-EP- SPS。安全性评价表明, CP4-EPSPS蛋白在哺乳动物消化系统中极易分解, 小鼠经口食入高达572 mg·kg–1(高于转基因大豆、玉米等植物中的1 300倍)的CP4-EPSPS蛋白, 亦无不良影响, 其在胃中的半衰期小于15秒, 在肠系统中小于10分钟。以上结果结合种子成分分析及动物营养研究表明, 转基因抗草甘膦大豆对人和动物是安全的(Harrison et al., 1998)。</p>
]]></content>
  </entry>
  <entry>
    <title>转：国家重点保护野生植物名录介绍</title>
    <url>/2017/03/01/Plant-endangered-plants-in-China/</url>
    <content><![CDATA[<p>国家重点保护野生植物名录介绍   国家重点保护野生植物是指受国家法律重点保护的野生植物。1984年7月24日国务院环境保护委员会公布《中国珍稀濒危保护植物名录》，目的是对我国的珍稀濒危植物予以正式确认，进行重点保护。该名录共列出濒危、渐危、稀有植物354种，并分别规定了每种植物的保护级别。其中一级保护的8种，二级保护的143种，三级保护的203种。虽然该目录第一次对我国的珍稀濒危植物进行了确认和保护，但是并没有相应的法律来规范和保护。 直到1996年9月30日，我国第一部专门保护野生植物的行政法规——《中华人民共和国野生植物保护条例》由国务院正式发布，并于1997年1月1日起实施。才真正意义上有了保护野生植物的法律规范。在该条例中野生植物种类按其濒危稀有程度和其价值，仅分为国家一级和二级保护植物。 国家一级和二级保护植物由《国家重点保护野生植物名录》确定，是《中华人民共和国野生植物保护条例》的具体保护和管理对象。1999年8月4日，《国家重点保护野生植物名录（第一批）》由国务院正式批准公布，这是我国野生植物保护管理工作的一个里程碑，标志着此项工作纳入法制化轨道，意义重大。 该名录是由我国野生植物行政主管部门国家林业总局和农业部共同组织制定的，共列植物419种和13类（指种以上分类等级），其中一级保护的67种和4类，二级保护的352种和9类，受国家重点保护的野生植物一共约有1900种。 由于国家林业总局、农业部对《国家重点保护野生植物名录》所列物种的分管意见尚需协商，因此将分批上报、公布。现经国务院批准公布的只是分管意见一致的《国家重点保护野生植物名录（第一批）》，共列植物246种和8类。2001年8月4日，农业部、国家林业局发布第53号令，将念珠藻科的发菜保护级别由二级调整为一级。其余物种多属经济价值较高、资源破坏严重的种类（如人参、杜仲、甘草、肉苁蓉、五味子、牡丹组、黄连属、兰科等），待两部门协商分管意见后，将作为《国家重点保护野生植物名录（第二批）》再上报国务院批准公布。为了加强生物多样性保护，2011年国家林业总局“林办发[2011]1号”文件再次提出要推动《国家重点保护野生植物名录（第二批）》的调整和颁布。该名录有望近期得到国务院的批准公布。 《国家重点保护野生植物名录（第一批）》和《国家重点保护野生植物名录（第二批）》所批准或建议的物种可在中国科学院植物研究所建立的“中国植物主题数据库”国家重点保护野生植物名录（第一批和第二批）子数据库中查询：<a href="http://www.plant.csdb.cn/protectlist">http://www.plant.csdb.cn/protectlist</a> 此外许多地方政府为了保护地方特有的野生植物，也制定了地方性野生动植物保护法规，公布了地方性的“重点保护野生植物名录”或“重点保护野生动植物名录”。如浙江省人民政府制定的《浙江省野生植物保护办法》，北京市人民政府批准的《北京市重点保护野生植物名录》等。 （植物分类学研究组 杜诚）</p>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>Proteomics | Common reagents and their functions in LC-MS/MS proteomics</title>
    <url>/2021/03/03/Proteomics-Common-reagents-and-their-functions-in-LC-MS-MS-proteomics/</url>
    <content><![CDATA[<p>蛋白质组学实验 LC-MS/MS “液相色谱法-质谱联用”中，常见的试剂的功能是什么？</p>
<h3 id="acetone-丙酮"><a class="markdownIt-Anchor" href="#acetone-丙酮"></a> Acetone 丙酮</h3>
<p>使用场景：提取组蛋白的过程中，当用 TCA 三氯乙酸沉淀组蛋白之后，加入预冷的丙酮清洗组蛋白沉淀。</p>
<p>丙酮是最简单的酮，化学式 CH<sub>3</sub>COCH<sub>3</sub>。由于甲醇、乙醇、丙酮等有机溶剂加入水中使容积介电常数降低，增加了相反电荷的吸引力，另一方面因为这些有机溶剂是强亲水试剂，争夺蛋白质分子表面的水化水，破坏蛋白质胶体分子表面的水化层而使分子聚集沉淀。当蛋白沉淀后，立即分离蛋白和丙酮并复溶蛋白完成提取。丙酮在提取蛋白质中的主要作用是通过有机溶剂破坏蛋白质的水化层，降低介电常数 增强带电蛋白质分子的相互作用，促进蛋白颗粒的聚集沉淀。<br />
丙酮要求低温操作且尽量缩短时间，避免蛋白变性。丙酮容易挥发。在提取大分子蛋白质时，TCA使蛋白沉淀之后，使用丙酮尽量将TCA抽提干净，</p>
<h3 id="acetonitrile-乙腈"><a class="markdownIt-Anchor" href="#acetonitrile-乙腈"></a> Acetonitrile 乙腈</h3>
<p>使用场景一：HPLC 实验中，ACN 可以与水分别作为流动相 B 与 A，用来洗脱不同种类的蛋白分子。<br />
使用场景二：SDS-PAGE 胶，切下目的条带之后，加入ACN，无色透明的胶块会迅速失水，皱缩成白色不透明状。</p>
<p>乙腈（英语：Acetonitrile，又称氰基甲烷），化学式 CH<sub>3</sub>CN，英文缩写：ACN 或 AeCN。乙腈是无色的液体，是最简单的有机腈，并广泛用作极性非质子溶剂。对于 HPLC 级溶剂（我们在 HPLC 分析中应始终使用 HPLC 级溶液），<u>乙腈的吸光度在这两种溶剂中最低</u>，非常适合低紫外光分析。作为比较，甲醇在 205–210 nm 左右有较高的紫外光吸收值，在非常低的紫外光范围内略有限制。注意乙腈可以燃烧，并且有毒性。</p>
<h3 id="ammonium-acetate"><a class="markdownIt-Anchor" href="#ammonium-acetate"></a> Ammonium acetate</h3>
<p>乙酸铵是一个有机盐，分子式为CH<sub>3</sub>COONH<sub>4</sub>。</p>
<h3 id="ammonium-sulfate"><a class="markdownIt-Anchor" href="#ammonium-sulfate"></a> Ammonium sulfate</h3>
<p>使用场景：在配制考马斯亮蓝染色液的时候，需要准备2% (wt/vol) phosphoric acid and 20% (wt/vol) ammonium sulfate 溶液。</p>
<p>硫酸铵，简称硫铵，又称硫酸铔，化学式为(NH<sub>4</sub>)<sub>2</sub>SO<sub>4</sub>，无色斜方晶体，易溶于水，水溶液为酸性。</p>
<h3 id="ammonium-hydrogen-carbonate-abc"><a class="markdownIt-Anchor" href="#ammonium-hydrogen-carbonate-abc"></a> Ammonium hydrogen carbonate （ABC）</h3>
<p>使用场景： In-gel digestion 的 buffer，即 100 mM ABC</p>
<p>碳酸氢铵 (Ammonium bicarbonate), 碳酸氢铵是氨的碳酸盐，分子式为NH<sub>4</sub>HCO<sub>3</sub>。用 Trypsin 酶解蛋白质时，碳酸氢氨的浓度应该是多少？酶解时碳酸氢氨的浓度一般在 10 ～ 50 mM 之间。碳酸氢氨的作用主要是提供一个碱性的水解环境，因为 Typsin 的活力在 pH8 ～ 9 之间最高。最常用的碳酸氢氨浓度有 20 mM ， 40 mM 。盐浓度过大时，后续的冻干过程中会有较多的盐析出；盐浓度过小时，则不能有效的提供碱性 pH 的水解环境（尤其是在样品的 pH 值低，而且体积大时）。</p>
<h3 id="ammonium-persulfate"><a class="markdownIt-Anchor" href="#ammonium-persulfate"></a> Ammonium persulfate</h3>
<p>过硫酸铵（APS）是一种白色晶体，分子式为(NH<sub>4</sub>)<sub>2</sub>S<sub>2</sub>O<sub>8</sub>，具有强氧化性和腐蚀性，易溶于水。其干品具有良好的稳定性，保存在防潮箱中。聚丙烯酰胺（PAGE）是由丙烯酰胺聚合形成的高分子，这个聚合反应是自由基聚合，需要有引发剂产生自由基将反应引发过硫酸铵就是引发剂，而 TEMED 可以催化过硫酸铵产生自由基，从而加速丙烯酰胺凝胶的聚合。过硫酸铵配制成 10%溶液后，应当-20℃保存。同时应尽量减少室温存放时间，以防失效。保存不能超过两周。最好现配现用。</p>
<h3 id="tca-三氯乙酸"><a class="markdownIt-Anchor" href="#tca-三氯乙酸"></a> TCA 三氯乙酸</h3>
<p>使用场景：用硫酸溶液破裂细胞核，释放组蛋白之后，加入 TCA 使组蛋白沉淀，为什么用 TCA 呢？</p>
<p>TCA 化学式 CCl<sub>3</sub>COOH，其作用主要是在酸性条件下可与蛋白质形成不溶性盐。同时作为蛋白质变性剂使蛋白质构象发生改变，暴露出较多的疏水性基团，使之聚集沉淀。但是 TCA 可能渗入蛋白质分子内部而使之较难被完全除去，在电泳前样品加热处理时可能使蛋白质结构发生酸水解而形成碎片，所以在提取大分子蛋白质时要使用丙酮（Acetone）尽量将 TCA 抽提干净。</p>
<h3 id="acetic-acid-乙酸"><a class="markdownIt-Anchor" href="#acetic-acid-乙酸"></a> Acetic acid 乙酸</h3>
<p>使用场景：SDS-PAGE胶脱色液，即考马斯亮蓝染色脱色液，配方为：40%乙醇，10%乙酸，50%蒸馏水。也可以使用其它适当的脱色液。</p>
<p>乙酸也叫做醋酸，化学式 CH<sub>3</sub>COOH，甲醇是为了更容易洗脱考马斯亮蓝，加得越多洗脱越容易，结合在蛋白上的染料也容易洗下来。冰乙酸是固定蛋白的，防止蛋白扩散。两者作用完全不同。</p>
<h3 id="tfa-trifluoroacetic-acid-三氟乙酸"><a class="markdownIt-Anchor" href="#tfa-trifluoroacetic-acid-三氟乙酸"></a> TFA (trifluoroacetic acid ) 三氟乙酸</h3>
<p>使用场景：组蛋白的 HPLC 纯化过程中，流动相 A 和 B 里面都会添加 0.1% TFA。</p>
<p>三氟乙酸化学式 CF<sub>3</sub>COOH，在反相色谱分离多肽和蛋白质的实验中，使用三氟乙酸 (TFA) 作为离子对试剂是常见的手段。流动相中的三氟乙酸通过与疏水键合相和残留的极性表面以多种模式相互作用，来改善峰形、克服峰展宽和拖尾问题。三氟乙酸与多肽上的正电荷及极性基团相结合以减少极性保留，并把多肽带回到疏水的反相表面。以同样的方式，三氟乙酸屏蔽了固定相上残留的极性表面。三氟乙酸的行为可以理解为它滞留在反相固定相的表面，同时与多肽及柱床作用。三氟乙酸优于其他离子修饰剂的原因是它容易挥发，可以方便地从制备样品中除去。另一方面，三氟乙酸的紫外最大吸收峰低于 200 nm，对多肽在低波长处的检测干扰很小。改变三氟乙酸的浓度，可以细微地调整多肽在反相色谱上的选择性。这一影响对于优化分离条件、增大复杂色谱分析（如多肽的指纹图谱）的信息量是非常有益的。三氟乙酸添加在流动相中的浓度一般为 0.1%，在这个浓度下，大部分的反相色谱柱都可以产生良好的峰形，当三氟乙酸浓度大大低于这个水平时，峰的展宽和拖尾就变得十分明显。</p>
<h3 id="fa-formic-acid-甲酸"><a class="markdownIt-Anchor" href="#fa-formic-acid-甲酸"></a> FA (Formic acid) 甲酸</h3>
<p>使用场景：经过酶解和纯化的短肽，溶解于 0.1% FA 然后在 Orbitrap 质谱仪进行 LC-MS/MS 分析。</p>
<p>甲酸又称作蚁酸，化学式为HCOOH。在反相色谱分离多肽和蛋白质的实验中，使用三氟乙酸(TFA) 作为离子对试剂是常见的手段，流动相中的三氟乙酸通过与疏水键合相和残留的极性表面以多种模式相互作用，来改善峰形、克服峰展宽和拖尾问题。同时反相色谱与电喷雾质谱联用已成为多肽和蛋白质的分子量测定和结构分析的重要工具，但是含有三氟乙酸的流动相对质谱离子的产生具有抑制作用，一定程度上降低了液质联用技术的灵敏性和分析可靠性。目前常用的方法是降低流动相中 TFA 浓度， 达到降低这种抑制作用，但是也会造成色谱分析质量的降低；而如果用甲酸代替 TFA, 会造成色谱分离柱效降低，达不到理想的分离效果。本文采用双三元液相色谱系统 (DGLC)，充分利用双泵的优势，将两个泵分别作为流动相的输液泵和柱后溶液的传输泵，实现与质谱的全自动连接。采用 TFA-Fix 技术或者抑制器技术降低流动相中 TFA 对 MS 的离子产生的抑制作用，尤其是柱后抑制器技术大大提高了多肽样品在质谱上的灵敏度。</p>
]]></content>
      <categories>
        <category>Proteomics</category>
      </categories>
  </entry>
  <entry>
    <title>Proteomics | 蛋白质硫巯基化修饰</title>
    <url>/2021/03/04/Proteomics-Protein-Persulfidation/</url>
    <content><![CDATA[<p>随着对硫化氢（hydrogen sulfide，H<sub>2</sub>S）生理效应的研究，蛋白质硫巯基化（S-sulfhydration，Protein Persulfidation）修饰已进入人们的视野。已知依赖于 H<sub>2</sub>S 的蛋白质硫巯基化是继磷酸化（phosphorylation）、泛素化（ubiquitylation）、乙酰化（acetylation）和 S-亚硝基化（S-nitrosylation）等之后的一种新的蛋白质翻译后修饰方式。对动物的研究表明，蛋白质硫巯基化修饰通过影响蛋白质活性和功能，从而在细胞内信号通路中发挥重要的调控作用。最近的研究结果提示，硫巯基化修饰还参与调节植物新陈代谢和形态建成。硫巯基化修饰也可能参与植物细胞信号转导。</p>
<p>硫化氢（hydrogen sulfide, H<sub>2</sub>S）是一种无色、具有臭鸡蛋气味的气体。在人们的传统观念中，硫化氢一直被认为是一种有毒有害的气体。然而随着科技发展，关于生物体内产生硫化氢的现象被陆续报道，这暗示着硫化氢在某些生理代谢过程中可能发挥着重要作用。硫化氢可自由通过生物膜，以信号分子的角色参与信号传递。最近的发现表明，H<sub>2</sub>S 具有促使蛋白质 Cys 残基的硫醇基团（R-SH）转变为过硫化基团（R-SSH）的能力，这种翻译后修饰作用被称为 蛋白质过硫化/硫巯基化修饰（persulfidation）。蛋白质过硫化修饰是一种基于氧化还原状态的修饰，然而在高等植物中这一翻译后修饰的机制仍然知之甚少。</p>
<p>当植物受到干旱、高低温、高盐、重金属等非生物胁迫刺激时，体内的硫化氢含量会显著提高，暗示硫化氢参与植物非生物胁迫响应过程。研究表明，在这一过程中硫化氢与多种信号分子，如活性氧（ROS）、一氧化氮（NO）、脱落酸（ABA）、乙烯等信号交叉对话，共同调节植物对胁迫的耐受性。</p>
<p>脱落酸（ABA）作为一种重要的植物激素，在种子的成熟和休眠，气孔关闭和植物生长中起关键作用。同时，ABA也是增强植物对非生物胁迫如干旱，盐碱和寒冷的适应性的核心调节因子，而这些非生物胁迫是导致全球农作物减产的主要原因，因此研究植物体内ABA信号转导途径具有重要的实践意义。ABA促进气孔关闭并抑制气孔开放，从而在植物缺水时保留水分。SnRK2.6蛋白在植物气孔的保卫细胞中表达，是ABA信号通路中调节植物气孔开合的关键调节因子。硫化氢（H2S）是一种水溶性的气体信号分子，在调节植物对环境胁迫和生长的适应性方面发挥重要功能。Cys残基的翻译后修饰（Cys-SH基团转换为Cys-SSH基团）引起的过硫基团的形成直接受硫化氢调节，被称为S-硫巯基化修饰作用。研究首先在SnRK2.6中发现了两个S-硫巯基化修饰位点，并且发现这两个Cys残基暴露在SnRK2.6表面并且与激酶的催化环和关键的磷酸化位点相邻。研究表明当这两个Cys残基被S-硫巯基化修饰后，促进了SnRK2.6的活性及其与ABA信号下游的转录因子的相互作用。当将SnRK2.6中的Cys131，Cys137或两者均被丝氨酸部分或者全部取代时：SnRK2.6C131S和SnRK2.6C137S或SnRK2.6C131SC137S突变基因转入到ost1-3突变体中，这些点突变的基因无法恢复ost1-3突变体表型，显示出对ABA和H2S诱导的气孔关闭和Ca2+流入的敏感性降低，并增加了水分流失和抗旱性下降。此外，该研究还表明ABA诱导保卫细胞中的DES1酶催化产生硫化氢，随后硫化氢又通过SnRK2.6的过硫化反应过来正调控ABA信号传导，并影响钙离子流，最终调控气孔运动。因此该研究提出了一种新的调控ABA信号通路的机制，其中硫化氢通过S-硫巯基化SnRK2.6在保卫细胞中正调控ABA信号传导。</p>
<p><img src="https://news.nwafu.edu.cn/images/content/2020-02/20200219193146422506.png" alt="" /></p>
<p>参考资料</p>
<ol>
<li><a href="https://www.sohu.com/a/426629232_732029">2020 南农综述：气体信号分子——硫化氢在植物适应非生物胁迫中的生理功能及作用机制 </a></li>
<li><a href="https://news.nwafu.edu.cn/xnxw/95411.htm">2020 西农文章：硫化氢介导的S-硫巯基化修饰促进气孔闭合关键调控蛋白SnRK2.6/OST1的活性从而参与调控脱落酸信号诱导植物气孔闭合的分子机制</a></li>
<li><a href="http://cjbmb.bjmu.edu.cn/CN/abstract/abstract24425.shtml">2018 生物化学与分子生物学报：《硫巯基化：一种新的蛋白质翻译后修饰》</a></li>
</ol>
]]></content>
      <categories>
        <category>Proteomics</category>
      </categories>
  </entry>
  <entry>
    <title>Proteomics | 组蛋白五羟色胺化修饰 H3Q5ser 及其生物学功能</title>
    <url>/2021/03/05/Proteomics-Serotonylation-A-novel-histone-H3-marker/</url>
    <content><![CDATA[<p>五羟色胺是人体重要的一种神经递质与激素，在中枢神经系统中控制着认知、学习、感情、情绪等脑神经活动；在外周神经系统中，五羟色胺控制着生殖、代谢、血管收缩、骨骼发育等生理功能。因此，五羟色胺系统一直是药物研究与开发的热点，作用于该系统的药物广泛用于抗精神分裂症、偏头痛、抗呕吐及肥胖症等疾病。</p>
<p><img src="https://cdn.shopify.com/s/files/1/0511/1981/6889/articles/a58d3fb0a0a9ce4fa1c5d180b499130c_1440x.png" alt="" /></p>
<p>五羟色胺，又称血清素 (serotonin)，是一类神经递质，对情绪等神经生物学事件有重要的调控作用。五羟色胺广泛存在于哺乳动物组织中，除中枢神经组织外，其主要外周产生部位是胃肠道，约 90% 合成和分布于肠嗜铬细胞。Ian Maze 课题组曾于 2019 年在 Nature 杂志发表论文，首次报道了 H3Q5ser 修饰的存在，以及“H3K4me3Q5ser”修饰组合对基因表达和神经发育的影响（Nature，2019，567：535–539）。该工作把五羟色胺这一内源生物活性小分子与表观遗传修饰调控联系了起来，启示了营养代谢除为细胞活动提供物质、能量和信号之外的“信息”功能。由于 H3Q5 紧邻 H3K4 位点，因此 H3Q5ser 修饰很可能对 H3K4me3 修饰的催化和识别产生影响。</p>
<p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41392-019-0048-7/MediaObjects/41392_2019_48_Fig1_HTML.png" alt="Regulation model of serotonin. a Serotonin, a neurotransmitter, functions through the serotonergic signaling pathway. b MLL and SET1 mediate H3K4me3 methylation and regulate gene expression. c The H3K4me3Q5ser double modification enhances the interaction of histone with certain H3K4me3 ‘reader’ proteins, such as TFIID, and then reinforces permissive patterns of gene expression" /></p>
<p>2021年2月2日，清华大学医学院李海涛课题组携手普林斯顿大学 Tom Muir 课题组和西奈山医学院 Ian Maze 课题组于《美国科学院院刊》（PNAS）在线发表题为“Histone H3Q5 serotonylation stabilizes H3K4 methylation and potentiates its readout”（组蛋白 H3Q5 五羟色胺化修饰稳定 H3K4 甲基化修饰并强化其识别）的研究论文，报道了组蛋白 H3Q5 五羟色胺化修饰（H3Q5ser）对于转录起始标志 H3K4 三甲基化（H3K4me3）修饰的影响。该研究发现 H3Q5Ser 不影响邻近 H3K4me3 的酶促产生，可促进 H3K4me3 下游阅读器的识别，但抑制了 H3K4me3 的酶促消除，从而稳定 H3K4me3 修饰并强化其基因活化功能。</p>
<p><img src="http://www.med.tsinghua.edu.cn/__local/F/EE/A8/7E72FE89E5984EFB6A2E622C1AE_39F33F28_37F347.png" alt="组蛋白H3Q5ser稳定H3K4me3修饰并强化其功能" /></p>
<p>该研究探究 H3Q5ser 修饰与 H3K4me3 修饰的交叉会话（crosstalk）机制。首先，研究人员利用表面等离子体共振成像（SPRi）技术，对目前已知的代表性 H3K4me3 阅读器（如BPTF，CHD1，DIDO1，ING2，KDM5A，KDM4A，MLL5，PHF13，PHF2，RAG2，SET3，SGF29，SPIN1，TAF3，和ZCWPW1)，进行了基于蛋白质芯片阵列的互作表征。研究发现，组蛋白 H3Q5ser 修饰并不会打破这些下游效应因子对于 H3K4me3 修饰的识别。其中，对于 TAF3 的 PHD 结构域来说，无论 K4 的甲基化状态如何（K4me0，K4me1，K4me2，K4me3），H3Q5ser 修饰都可以增强结合强度，甚至达到 9 倍。如果将五羟色胺化修饰替换五羟色胺的类似物（如 H3Q5（tryptamine），H3Q5（5-methoxytryptamine），H3Q5（7-azatryptamine），H3Q5（6-hydroxytryptamine），则会不同程度地削弱与 TAF3 的结合。这表明组蛋白同 TAF3 结合强度的增强是五羟色胺修饰依赖的。</p>
<p>对于 H3K4me3 修饰因子 MLL1 甲基转移酶复合物来讲，H3Q5ser 修饰不会对其活性产生明显影响。更进一步的酶反应动力学分析发现，H3Q5ser 修饰对于 MLL1 催化 H3K4me0 到 H3K4me1 没有影响，对于催化 H3K4me1 到 H3K4me2 有轻微的抑制作用。因此，总体来讲H3Q5ser修饰对于MLL1复合物的酶活没有产生明显的影响。</p>
<p>有趣的是，对于 H3K4me3 的酶促消除而言，由于存在空间位阻效应，H3Q5ser 修饰可以完全打破 H3K4 去甲基化酶 KDM5 和 LSD1 的活性。在多肽和重构染色质水平的实验都表明 H3Q5ser 修饰可以使 LSD1 及 KDM5 无法催化 H3K4me3 的去甲基化反应。进一步的重构染色质水平的酶活实验表明 H3Q5ser 修饰影响了 KDM5 催化结构域的活性而非 PHD 结构域的结合能力。值得一提的是，KDM5 家族成员通过负调控增强子与启动子区 H3K4me3 水平，发挥着转录抑制分子功能，在肿瘤转录异质性调控、肿瘤免疫逃逸、肠道微生物组稳态调节、神经系统发育等过程中发挥着重要作用。本研究所揭示的 H3Q5ser 修饰对 KDM5 的拮抗作用对于进一步理解 KDM5 去甲基化酶的生理功能与调控提供了新视角。</p>
<p>组蛋白修饰交叉会话是一类重要的表观调控机制，在表观景观建立和基因开关切换等细胞进程中扮演着重要角色，彰显了表观调控的层次性和精密性。李海涛课题组与 Josefowicz 课题组合作，曾在去年报道组蛋白 H3.3S31ph 修饰同 H3.3K36me3 之间的交叉会话（Nature, 2020, 583：852-857），揭示 H3.3S31ph 通过强化 H3.3K36me3 的转录延伸功能，实现刺激诱导型基因的快速转录延伸。在本工作中，研究人员揭示了H3Q5ser对转录起始标志性修饰H3K4me3的调制作用，即在H3Q5ser存在情况下，H3K4me3无法被“擦除器”（eraser）有效去除，而H3K4me3“阅读器”（reader）如 TAF3 却可以被更有效的招募，提示 H3Q5ser 可以通过强化 H3K4me3 的功能，实现 H3K4me3 靶基因的转录起始活化。</p>
<p><font color=blue>越来越多的研究表明，类似 H3K4me3 和 H3K36me3 等甲基化修饰单独不足以代表基因的激活表达，通过产生 H3Q5ser 和 H3.3S31ph 等邻近修饰而拮抗负调控因子的沉默作用，对于完全释放 H3K4me3 和 H3K36me3 修饰的转录激活功能发挥着重要正向调控作用。</font></p>
<p>参考资料</p>
<ol>
<li><a href="https://biokplus.com/blogs/news/serotonin-the-happy-hormone-produced-in-our-gut">Serotonin: The Happy Hormone Produced In Our Gut</a></li>
<li><a href="https://www.nature.com/articles/s41586-019-1024-7">2019 Nature: Histone serotonylation is a permissive modification that enhances TFIID binding to H3K4me3</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/59800502">2019 知乎专栏：Nature重磅+点评丨你的情绪信号或可印记到组蛋白上——首次报道组蛋白五羟色胺化修饰及其生物学功能</a></li>
<li><a href="http://www.med.tsinghua.edu.cn/info/1028/2827.htm">2021 清华大学：李海涛团队揭示五羟色胺活化基因表达的组蛋白修饰会话机制</a></li>
<li><a href="https://www.thepaper.cn/newsDetail_forward_11197874">2021 澎湃新闻：李海涛团队揭示五羟色胺活化基因表达的组蛋白修饰会话机制</a></li>
</ol>
]]></content>
      <categories>
        <category>Proteomics</category>
      </categories>
  </entry>
  <entry>
    <title>Proteomics | Top-down proteomics analysis of histones</title>
    <url>/2021/09/20/Proteomics-Top-down-proteomics-analysis-of-histones/</url>
    <content><![CDATA[<h3 id="1-workflow"><a class="markdownIt-Anchor" href="#1-workflow"></a> 1 workflow</h3>
<ol>
<li>crude histone isolation from cells or tissues;</li>
<li>offline HPLC to separete core histones  (H2, H3.1, H3.2, H4)</li>
<li>LC-MS (raw data)</li>
<li>MS data analysis</li>
</ol>
<p>Note: 图见 RGC proposal。</p>
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S1046202319301732-gr1.jpg" alt="图例" /></p>
<h3 id="2-offline-hplc"><a class="markdownIt-Anchor" href="#2-offline-hplc"></a> 2 Offline HPLC</h3>
<p>Note：图见 RGC proposal</p>
<p><img src="https://www.researchgate.net/profile/Yifan-Liu-41/publication/235775342/figure/fig2/AS:931921148276736@1599198724085/HPLC-and-SDS-PAGE-separation-of-core-histones_W640.jpg" alt="图例" /></p>
<h3 id="3-ms1-chromatograph"><a class="markdownIt-Anchor" href="#3-ms1-chromatograph"></a> 3 MS1 chromatograph</h3>
<p>首先要安装 Thermo Fisher 的 Xcalibur 软件。安装方法，<a href="https://thermo.flexnetoperations.com/control/thmo/login">https://thermo.flexnetoperations.com/control/thmo/login</a> ，使用教育邮箱注册，xx@link.cuhk.edu.hk，注册并登入，即可看到一系列软件的列表，我们选择 Xcalibur <a href="https://thermo.flexnetoperations.com/control/thmo/product?child_plneID=820487&amp;ver=CURRENT">https://thermo.flexnetoperations.com/control/thmo/product?child_plneID=820487&amp;ver=CURRENT</a>，可执行文件 exe 格式，将文件下载到windows电脑，再安装，安装的软件里面就包含了 freestype。</p>
<p>将 raw data 导入 freestyle 软件，即可浏览 MS1 的图。如何导出高清图片？</p>
<p><img src="" alt="图例" /></p>
<h3 id="raw-data-to-pbf-和-ms2ft-格式文件"><a class="markdownIt-Anchor" href="#raw-data-to-pbf-和-ms2ft-格式文件"></a> raw data to pbf 和 ms2ft 格式文件。</h3>
<p>使用 ProMex 软件，可以将 raw 格式的质谱文件转换成 pbf 和 ms2ft 格式文件。</p>
<p>已经有公开的文献报道 top down proteomics 数据的分析方法 <a href="https://www.nature.com/articles/nmeth.4388">NATURE METHODS: Informed-Proteomics: open-source software package for top-down proteomics</a>，可以去 <a href="https://github.com/PNNL-Comp-Mass-Spec/Informed-Proteomics">github</a> 下载 Informed Proteomics，软件处于持续更新中，本笔记撰写的 2021 年仍有更新。</p>
<p>这些格式有什么不同呢？</p>
<p>raw:<br />
pbf: Creates a .pbf file This file contains spectra information and full chromatograms for MS1 and MSn data, allowing fast access to extracted ion chromatograms during the search.<br />
ms2ft:</p>
<p>“插播一句，这些格式转换的软件是 windows 平台的，如果要再 linux 下面跨平台运行，则需要用到 mono 软件，具体可以参考 <a href="https://www.cnblogs.com/jessepeng/p/12452276.html">https://www.cnblogs.com/jessepeng/p/12452276.html</a>。mono 的安装并不容易，可能有些普通用户会碰到问题，主要是依赖libgdiplus库，只要这个解决了，源码安装三部曲就行了，这里不加以赘述。”</p>
<p>转换代码如下（参考：<a href="https://github.com/PNNL-Comp-Mass-Spec/Informed-Proteomics">https://github.com/PNNL-Comp-Mass-Spec/Informed-Proteomics</a>）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">PbfGen.exe -s MyDataset.raw</span><br><span class="line">ProMex.exe -i MyDataset.pbf -minCharge 2 -maxCharge 60 -minMass 3000 -maxMass 50000 -score n -csv n -maxThreads 0</span><br></pre></td></tr></table></figure>
<h3 id="sequence-alignment-and-idntification-of-ptms"><a class="markdownIt-Anchor" href="#sequence-alignment-and-idntification-of-ptms"></a> sequence alignment and idntification of PTMs</h3>
<p>得到pbf 和 ms2ft 文件之后，就可以检索蛋白序列和可能的修饰情况。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">MSPathFinderT.exe -s MyDataset.pbf -feature MyDataset.ms1ft -d C:\FASTA\ProteinList.fasta -o C:\WorkDir -t 10 -f 10 -m 1 -tda 1 -minLength 21 -maxLength 300 -minCharge 2 -maxCharge 30 -minFragCharge 1 -maxFragCharge 15 -minMass 3000 -maxMass 50000 -mod MSPathFinder_Mods.txt</span><br></pre></td></tr></table></figure>
<p>上面的 <code>Mods.txt</code> 文件即是可能的修饰情况，以大豆组蛋白为例，文件内容如下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># This file is used to specify modifications for MSPathFinder</span><br><span class="line"></span><br><span class="line"># Max Number of Modifications per peptide</span><br><span class="line">NumMods=9</span><br><span class="line"></span><br><span class="line"># Static mods</span><br><span class="line"># None</span><br><span class="line"></span><br><span class="line"># Dynamic mods</span><br><span class="line"># Functional group, Amino acid, opt?, Position, Modification type</span><br><span class="line">O1,MC,opt,any,Oxidation</span><br><span class="line">HO3P,ST,opt,any,Phospho</span><br><span class="line">C2H2O1,K,opt,any,Acetyl</span><br><span class="line">CH2,KR,opt,any,Methyl</span><br><span class="line">C2H4,KR,opt,any,Dimethyl</span><br><span class="line">C3H6,K,opt,any,Trimethyl</span><br><span class="line">C2H2O,*,opt,Prot-N-term,Acetyl     # Acetylation Protein N-term (C2H2O can be replaced with &quot;H(2) C(2) O&quot;)  </span><br></pre></td></tr></table></figure>
<p>运行结果，将得到一个 tsv （表格）文本文件，列出了可能的蛋白序列以及修饰情况，另有一个图片文件 <code>xxx.ms1ft.png</code>，意思？。</p>
<h3 id="图片"><a class="markdownIt-Anchor" href="#图片"></a> 图片</h3>
<p>上面的分析中，mods 文件中设定了一条蛋白序列上修饰的数目为 9 个，怎么确定这个数字是合理的？我设定为 10 个，跑了一天也没有结果，所以少于这10 会比较合适。另外需要画一个统计图，即从1到9个修饰的密度图，如果类似正态分布，就可以说明我们的设定是合理的。</p>
<p><img src="https://www.researchgate.net/publication/329379093/figure/fig4/AS:699921351049216@1543885662248/Degree-distribution-All-the-networks-show-a-Poisson-distribution-as-corresponds-to_W640.jpg" alt="图例" /></p>
<h3 id="图片-2"><a class="markdownIt-Anchor" href="#图片-2"></a> 图片</h3>
<p>各个位点的修饰情况统计。</p>
<p>（D:\博后课题文件\PHD5 project\200831 top-down proteomics in soybean\R代码-冯磊\ptm_freq_diagram\version 2 custom color）</p>
<p><img src="https://ars.els-cdn.com/content/image/1-s2.0-S1046202319301732-gr5.jpg" alt="图例" /></p>
<h3 id="interplay-score"><a class="markdownIt-Anchor" href="#interplay-score"></a> Interplay Score</h3>
<p>何谓 interplay score：<a href="https://www.sciencedirect.com/science/article/pii/S1046202319301732">https://www.sciencedirect.com/science/article/pii/S1046202319301732</a><br />
何为 co-existence？<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5240223/bin/nihms840427f5.jpg">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5240223/bin/nihms840427f5.jpg</a></p>
<p>两个修饰是否存在coexisence？</p>
<p><img src="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5240223/bin/nihms840427f5.jpg" alt="图例" /></p>
<h3 id="样品之间的比较定量的问题"><a class="markdownIt-Anchor" href="#样品之间的比较定量的问题"></a> 样品之间的比较，定量的问题？</h3>
]]></content>
      <categories>
        <category>Proteomics</category>
      </categories>
  </entry>
  <entry>
    <title>Proteomics | 质谱分析中DDA与DIA有什么不同？</title>
    <url>/2021/03/04/Proteomics-What-the-differences-between-DDA-and-DIA-in-mass-spectrometer/</url>
    <content><![CDATA[<p>液相色谱与串联质谱（LC-MS/MS）相结合的技术成为蛋白质组研究的主要研究手段。在自下而上的蛋白质组学中，蛋白质通过蛋白水解酶消化成肽段，这些肽段通过高效液相分离后经电喷雾电离源（ESI）加上电荷，发射到质谱仪中进行一级质谱（MS）和二级质谱（MS/MS）的分析。一级质谱由肽段离子的质荷比和信号强度组成，二级质谱由肽段碎裂后的碎片离子质荷比和信号强度组成。</p>
<p>DDA 为数据依赖性采集方式，选择一级质谱中特定数量的肽段分子（如信号强度最强的前 10 个离子）进行高能碰撞碎裂，产生的碎片离子送入二级质谱检测。</p>
<p>DIA 为数据非依赖性采集方式，随着时间连续设置一定范围的质荷比窗口，对将通过窗口的全部肽段离子进行碎裂并用二级质谱检测碎片离子的信号。相比之下，DIA 模式不涉及到对肽段离子的限制性筛选，<u>定量准确性和重复性都要优于 DDA 模式</u>。但 DIA 模式产生的碎片离子谱图过于复杂，丢失了肽段及碎片离子的对应关系，对其结果的解析较为困难。目前的方法是通过建立样本的参考库（如同一样本的 DDA 数据），对 DIA 的混合数据进行去卷积分析来鉴定和定量肽段。</p>
<p>DDA 模式对肽段离子的选择具有限制性和随机性，存在较多的数据信息缺失，而 DIA 模式的目标则是获得完整的数据，实现蛋白质的深度覆盖和精准定量。此外在复杂样品中，二级信号的定量比一级信号更为灵敏（例如一级质谱信号可能存在相似质荷比离子的干扰）。DDA模 式为一级质谱信号定量，而 DIA 模式为二级质谱信号定量，因此 DIA 模式的定量准确性和重现性都更好。</p>
<p>DDA 模式下肽段分子和其二级碎片离子有着对应关系，通过对已知数据库的搜索匹配，即可得到样本中的肽段及相关蛋白质信息。而 DIA 模式下肽段离子与其碎片离子之间的直接关系丢失（DIA 光谱中的碎片离子可能是由多个肽段离子），复杂的谱图仍然给后续的数据分析和统计学检验带来很多挑战。对此目前已有多个团队开发出 DIA 分析的软件，例如 OpenSWATH 和 Skyline，这些软件通过建立样本的参考库，对色谱峰进行抽提并分析。此外也有研发团队提出不需要参考库的数据分析方法 DIA-Umpire，通过对肽段离子和碎片离子的匹配合成产生虚拟谱图进而搜库分析。因此，DIA 技术非常适合一次性获取数百上千种蛋白质更为全面信息（高覆盖率，高准确度，高重复性）的研究。</p>
<p><img src="https://pic1.zhimg.com/80/v2-42e5990e613ffb77de82db5ad6aca80c_720w.jpg" alt="DIA与DDA对比" /></p>
<p><img src="http://wayen.ezweb1-3.35.com/htdocs/d/2/wayen/resource/rich/99c6d7e97d73a0c753a8e5ed2f3c4756.png" alt="DIA技术原理图（来源：LCGC North America.Volume 35, Issue 10, pg 756–759）" /></p>
<p><img src="https://f1000researchdata.s3.amazonaws.com/manuscripts/7580/6631ee4c-6910-44ec-a8cc-c8bdb77fc401_figure1.gif" alt="" /></p>
<p>参考资料</p>
<ol>
<li><a href="https://cloud.tencent.com/developer/news/131977">2018 一篇SCI来看蛋白DIA技术如何完胜DDA</a> （这里面有个DIA与DDA对比的图，也可帮助理解，但是因网站设置导致图片链接过不来。）</li>
<li><a href="http://html.rhhz.net/SWJSTB/html/2017-9-73.htm">2017 《生物技术通报》基于质谱的定量蛋白质组学技术发展现状</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/47994226">2018 知乎专栏：学会DIA技术</a></li>
<li><a href="http://www.wayenbiotech.com/danbaizhizuxue-316395-151150-item-683817.html">简介：DIA蛋白质组学技术</a></li>
<li><a href="https://chemistry.fudan.edu.cn/a9/84/c21871a240004/page.htm">2020 复旦化学系：基于深度学习的DIA蛋白质组分析新方法</a></li>
</ol>
]]></content>
      <categories>
        <category>Proteomics</category>
      </categories>
  </entry>
  <entry>
    <title>Python：通过Anaconda管理python2和python3</title>
    <url>/2020/04/21/Python-Anaconda-python2-python3/</url>
    <content><![CDATA[<h3 id="一-安装anaconda3"><a class="markdownIt-Anchor" href="#一-安装anaconda3"></a> 一、安装anaconda3</h3>
<p>anaconda3 的下载页面：<a href="https://www.anaconda.com/distribution/#download-section">https://www.anaconda.com/distribution/#download-section</a> 我在 Linux 系统里下载的版本：<a href="https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86%5C_64.sh">https://repo.anaconda.com/archive/Anaconda3-2020.02-Linux-x86\_64.sh</a> 用sh命令安装即可，安装路径可以自定义，比如<code>/home/username/xxx/yyy</code> 此时输入 <code>conda</code> 命令没有反应。 安装完毕之后，将 bin 目录加入到 <code>.bashrc</code>，并执行 <code>source ~/.bashrc</code>，马上看到命令行前面出现<code>(base)</code>的字符，说明现在已经在 conda 的环境中了。这时候输入<code>conda list</code> 命令就有反应了。</p>
<h3 id="二-通过conda安装python3和python2"><a class="markdownIt-Anchor" href="#二-通过conda安装python3和python2"></a> 二、通过conda安装python3和python2</h3>
<p>查看当前使用的Python：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) fenglei@localhost:~/local/app/anaconda3/bin$ conda info --envs</span><br><span class="line">\# conda environments:</span><br><span class="line">\#</span><br><span class="line">base \* /home/fenglei/local/app/anaconda3</span><br></pre></td></tr></table></figure>
<p>创建新的Python版本环境：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ conda create --name python37 python=3.7</span><br><span class="line">$ conda create --name python27 python=2.7</span><br><span class="line">\#</span><br><span class="line">$ conda info --envs</span><br><span class="line">\# conda environments:</span><br><span class="line">\#</span><br><span class="line">base \* /home/fenglei/local/app/anaconda3</span><br><span class="line">python27 /home/fenglei/local/app/anaconda3/envs/python27</span><br><span class="line">python37 /home/fenglei/local/app/anaconda3/envs/python37</span><br></pre></td></tr></table></figure>
<p>其中 * 号表示当前使用的 Python 环境。</p>
<p><strong>切换 Python 环境</strong>，用 <code>source activate</code> 命令</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">(base) fenglei@localhost:~/local/app/anaconda3$ python -V</span><br><span class="line">Python 3.7.6</span><br><span class="line">(base) fenglei@localhost:~/local/app/anaconda3$ source active python27</span><br><span class="line">-bash: active: No such file or directory</span><br><span class="line">(base) fenglei@localhost:~/local/app/anaconda3$ source activate python27</span><br><span class="line">(python27) fenglei@localhost:~/local/app/anaconda3$ python -V</span><br><span class="line">Python 2.7.17 :: Anaconda, Inc.</span><br><span class="line">(python27) fenglei@localhost:~/local/app/anaconda3$ conda info --envs</span><br><span class="line">\# conda environments:</span><br><span class="line">\#</span><br><span class="line">base                     /home/fenglei/local/app/anaconda3</span><br><span class="line">python27              *  /home/fenglei/local/app/anaconda3/envs/python27</span><br><span class="line">python37                 /home/fenglei/local/app/anaconda3/envs/python37</span><br></pre></td></tr></table></figure>
<p>注意上面的“*”位置相应变动了，另一个是命令行前面的(base)变成了(python27)。 如果不想使用当前版本，而想恢复到默认版面，那么</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash"><span class="built_in">source</span> deactivate</span></span><br></pre></td></tr></table></figure>
<p><strong>删除 Python 环境</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda remove --name python26 --all</span></span><br></pre></td></tr></table></figure>
<p><strong>管理包</strong><br />
查看当前已经安装的包</p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda list</span></span><br><span class="line">\# packages in environment at /apps/anaconda2/envs/python35:</span><br><span class="line">\#</span><br><span class="line">ca-certificates           2017.08.26           h1d4fec5_0</span><br><span class="line">certifi                   2017.7.27.1      py35h19f42a1_0</span><br><span class="line">libedit                   3.1                  heed3624_0</span><br><span class="line">libffi                    3.2.1                h4deb6c0_3</span><br><span class="line">libgcc-ng                 7.2.0                h7cc24e2_2</span><br><span class="line">libstdcxx-ng              7.2.0                h7a57d05_2</span><br><span class="line">ncurses                   6.0                  h06874d7_1</span><br><span class="line">openssl                   1.0.2l               h077ae2c_5</span><br><span class="line">pip                       9.0.1            py35haa8ec2a_3</span><br><span class="line">python                    3.5.4               he2c66cf_20</span><br><span class="line">readline                  7.0                  hac23ff0_3</span><br><span class="line">setuptools                36.5.0           py35ha8c1747_0</span><br><span class="line">sqlite                    3.20.1               h6d8b0f3_1</span><br><span class="line">tk                        8.6.7                h5979e9b_1</span><br><span class="line">wheel                     0.29.0           py35h601ca99_1</span><br><span class="line">xz                        5.2.3                h2bcbf08_1</span><br><span class="line">zlib                      1.2.11               hfbfcf68_1</span><br></pre></td></tr></table></figure>
<p><strong>安装包</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">conda install -n python35 psutil</span><br></pre></td></tr></table></figure>
<p><strong>删除包</strong></p>
<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta prompt_">$ </span><span class="language-bash">conda uninstall -n python35 psutil</span></span><br></pre></td></tr></table></figure>
<p>下面是一些conda的常见命令： 对conda的基本掌握：<br />
1：基本操作：<br />
升级全部库：  conda upgrade --all<br />
升级一个包  conda update packagename<br />
安装包：conda install packagename<br />
也可以安装多个包：   conda installl numpy pandas scipy<br />
安装固定版本的包：conda install numpy =1.10<br />
移除一个包：conda remove packagename <br />
查看所有包：conda list</p>
<p>2：管理python环境：<br />
创建虚拟环境：conda create -n env_name<br />
list of packagenaem eg:  conda create -n env_name pandas <br />
指定python版本：conda create -n env_name python2 = 2.7 pandas <br />
激活环境： activate env_name （前面加source才可以吧）<br />
退出环境 :  deactivate  env_name<br />
删除虚拟环境：conda env remove -n env_name<br />
显示所有虚拟环境：conda env list  <br />
conda 创建的虚拟环境是在anaconda安装目录下的evens下，所以使用pycharm，只要在特定项目配置运行环境就可以了</p>
<h3 id="利用conda安装生物信息软件"><a class="markdownIt-Anchor" href="#利用conda安装生物信息软件"></a> 利用conda安装生物信息软件</h3>
<p>安装命令:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install gatk</span><br></pre></td></tr></table></figure>
<p>搜索需要的安装包: 提供一个网址,用于事先查找想安装的软件存不存在 <a href="https://links.jianshu.com/go?to=https%3A%2F%2Fbioconda.github.io%2Frecipes">conda available packages</a> 当然, 也可以用这个命令进行搜索</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda search gatk</span><br></pre></td></tr></table></figure>
<p>安装完成后，可以用“which 软件名”来查看该软件安装的位置：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">which</span> gatk</span><br></pre></td></tr></table></figure>
<p>如需要安装特定的版本:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install 软件名=版本号</span><br><span class="line">conda install gatk=3.7</span><br></pre></td></tr></table></figure>
<p>这时conda会先卸载已安装版本，然后重新安装指定版本。 查看已安装软件:</p>
<figure class="highlight cpp"><table><tr><td class="code"><pre><span class="line">conda list</span><br></pre></td></tr></table></figure>
<p>更新指定软件:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda update gatk</span><br></pre></td></tr></table></figure>
<p>卸载指定软件:</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">conda <span class="keyword">remove</span> gatk</span><br></pre></td></tr></table></figure>
<p>退出conda环境 退出也很简单，之前我们是<code>. ./activate 或者 (. ~/miniconda3/bin/activate)</code>现在退出只要:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">. ./deactivate</span><br></pre></td></tr></table></figure>
<p>就退出当前的环境了</p>
<p>也可以用bioconda：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda install -c bioconda bowtie2</span><br><span class="line">conda install -c bioconda hisat2</span><br><span class="line">conda install -c bioconda samtools</span><br></pre></td></tr></table></figure>
<p><strong>创建软件的软链接</strong></p>
<p>跟着命令一路敲到这里的小旁友们估计发现了，现在退出conda环境之后之前安装的软件全都GG了，敲命令没法执行了！ 怎么办呢！其实只要把安装好的软件软连接到一个处在环境变量里的位置就可以使用了。三步走：</p>
<ul>
<li>第一步，创建一个文件夹 我一般的习惯是在<code>/home</code>目录下创建一个<code>.soft</code>文件夹</li>
<li>第二步，将这个文件夹添加到环境变量中</li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;~/.soft:<span class="variable">$PATH</span>&quot;</span></span><br></pre></td></tr></table></figure>
<ul>
<li>第三步，软链接</li>
</ul>
<figure class="highlight ruby"><table><tr><td class="code"><pre><span class="line">ln -s ~<span class="regexp">/miniconda3/bin</span><span class="regexp">/gatk ~/</span>.soft</span><br></pre></td></tr></table></figure>
<p>这样就可以运行啦~如果还是不行建议试试初始化一下bashrc：<code>. ./bashrc</code></p>
<p><strong>创建conda环境</strong></p>
<p>之前创建的时候显示的是（base）这是conda的基本环境，有些软件依赖的是python2的版本，当你还是使用你的base的时候你的base里的python会被自动降级，有可能会引发别的软件的报错，所以，可以给一些特别的软件一些特别的关照，比如创建一个单独的环境。 在conda环境下，输入<code>conda env list</code>（或者输入<code>conda info --envs</code>也是一样滴）查看当前存在的环境：</p>
<p><img src="//upload-images.jianshu.io/upload_images/7979561-eeb52438a3dd89dc.png?imageMogr2/auto-orient/stripimageView2/2/w/570/format/webp" alt="" /></p>
<p>目前的环境</p>
<p>目前只有一个base</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n python2 python=2</span><br><span class="line">\<span class="comment">#-n: 设置新的环境的名字</span></span><br><span class="line">\<span class="comment">#python=2 指定新环境的python的版本</span></span><br></pre></td></tr></table></figure>
<p>conda会创建一个新的python2的环境，并且会很温馨的提示你只要输入conda activate python2就可以启动这个环境了</p>
<p><img src="//upload-images.jianshu.io/upload_images/7979561-5d90c4988132d600.png?imageMogr2/auto-orient/stripimageView2/2/w/543/format/webp" alt="" /></p>
<p>新的环境</p>
<p><strong>退出环境</strong></p>
<p>如上面的截图提到的，只要</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda deactivate</span><br></pre></td></tr></table></figure>
<p><code>2019-6-28 update: 如何删除和重命名一个已存在的环境</code></p>
<p><strong>删除环境</strong></p>
<p>删除也很容易的</p>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">conda <span class="keyword">remove</span> -n myenv --all</span><br></pre></td></tr></table></figure>
<p>就可以退出当前环境。 掌握了创建和删除我们就可以实现重命名的操作了</p>
<p><strong>重命名环境</strong></p>
<p>实际上conda并没有提供这样的功能，但是可以曲线救国，原理是先克隆一个原来的环境，命名成想要的名字，再把原来的环境删掉即可 参考自：<a href="https://www.jianshu.com/p/7265011ba3f2">conda 创建/删除/重命名 环境</a> 接下来演示把一个原来叫做py2的环境重新命名成python2：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">conda create -n python2 --<span class="built_in">clone</span> py2</span><br><span class="line">conda remove -n py2 --all</span><br></pre></td></tr></table></figure>
<p><strong>骚操作：allias简化启动</strong></p>
<p><img src="//upload-images.jianshu.io/upload_images/7979561-e5ec5df4252fcdd0.png?imageMogr2/auto-orient/stripimageView2/2/w/941/format/webp" alt="" /></p>
<p>image.png</p>
<p>linux提供了一个给大家偷懒的命令叫alias，只要在你的<code>.bashrc</code>里设置一下就好了，我添加了一条叫做<code>condaup</code>的命令，这样就可以免去每次敲<code>. ~/miniconda/bin/dactivate</code>的麻烦，一步搞定~技术宅改变世界！</p>
<p><img src="//upload-images.jianshu.io/upload_images/7979561-744e8c59cdf14b19.png?imageMogr2/auto-orient/stripimageView2/2/w/435/format/webp" alt="" /></p>
<p>image.png</p>
<p>参考资料： 链接：<a href="https://www.jianshu.com/p/edaa744ea47d">https://www.jianshu.com/p/edaa744ea47d</a> 链接：<a href="https://blog.csdn.net/qq%5C_18668137/java/article/details/80807829">https://blog.csdn.net/qq\_18668137/java/article/details/80807829</a></p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Python：Python 模块的多种安装方法</title>
    <url>/2016/02/29/Python-How-to-install-packages/</url>
    <content><![CDATA[<p><strong>Python模块安装方法</strong><br />
<strong>一、方法1： 单文件模块</strong><br />
直接把文件拷贝到 <code>$python\_dir/Lib</code></p>
<p><strong>二、方法2： 多文件模块，<a href="http://xn--setup-3o1j.py">带setup.py</a></strong><br />
下载模块包，进行解压，进入模块文件夹，执行： <code>python setup.py install</code></p>
<p><strong>三、 方法3：easy_install 方式</strong><br />
先下载ez_setup.py,运行<code>python ez\_setup</code> 进行easy_install工具的安装，之后就可以使用<code>easy\_install</code>进行安装package了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt;  easy\_install  packageName </span><br><span class="line"># 安装  easy\_install -m packageName </span><br><span class="line"># 卸载  easy\_install  package.egg #安装</span><br></pre></td></tr></table></figure>
<p><strong>四、方法4：pip 方式</strong><br />
先进行pip工具的安裝：easy_install pip（pip 可以通过easy_install 安裝，而且也会装到 Scripts 文件夹下。）</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; 安裝：pip install PackageName </span><br><span class="line">更新：pip install -U PackageName </span><br><span class="line">移除：pip uninstall PackageName </span><br><span class="line">搜索：pip search PackageName </span><br><span class="line">帮助：pip help</span><br></pre></td></tr></table></figure>
<hr />
<p>注：虽然Python的模块可以拷贝安装，但是一般情况下推荐制作一个安装包，即写一个setup.py文件来安装。<br />
setup.py文件的使用如下:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">python setup.py build     </span><br><span class="line">#编译 % python setup.py install    </span><br><span class="line">#安装 % python setup.py sdist     </span><br><span class="line">#制作分发包 % python setup.py bdist\_wininst    </span><br><span class="line">#制作windows下的分发包 % python setup.py bdist\_rpm</span><br></pre></td></tr></table></figure>
<p>setup.py文件的编写 setup.py中主要执行一个 setup函数，该函数中大部分是描述性东西，最主要的是packages参数，列出所有的package，可以用自带的find_packages来动态获取package。<br />
所以setup.py文件的编写实际是很简单的。 简单的例子: setup.py文件：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">from setuptools import setup, find\_packages setup(       name = &quot; mytest &quot; ,       version = &quot; 0.10 &quot; ,       description = &quot; My test module &quot; ,       author = &quot; Robin Hood &quot; ,       url = &quot; http://www.csdn.net &quot; ,       license = &quot; LGPL &quot; ,       packages = find\_packages(),       scripts = \[ &quot; scripts/test.py &quot; \],       ) mytest.py import sys def get():     return sys.path scripts/test.py import os print os.environ.keys() </span><br></pre></td></tr></table></figure>
<p>setup中的scripts表示将该文件放到 Python的Scripts目录下，可以直接用。OK，简单的安装成功，可以运行所列举的命令生成安装包，或者安装该python包。本机测试成功(win32-python25)！</p>
<p><strong>附注：setuptools工具安装方法</strong></p>
<h3 id="方法一-使用ez_setuppy安装setuptools"><a class="markdownIt-Anchor" href="#方法一-使用ez_setuppy安装setuptools"></a> （方法一）. 使用ez_setup.py安装<strong>setuptools</strong></h3>
<p>进入<a href="https://pypi.python.org/pypi/setuptools%E4%B8%8B%E8%BD%BDez%5C_setup.py">https://pypi.python.org/pypi/setuptools下载ez\_setup.py</a> 这是 setuptools 自豪的一种安装方式，只需要一个大约 8K 作为的脚本ez_setup.py，就能自动为用户安装包括 setuptools 自身在内的许多 Python 包。 使用这种方式，用户只需要下载 ez_setup。py 并运行，就可以自动下载和安装适合用户当前 Python 版本的适当的 setuptools egg 文件(当然，用户需要 Python 2.3.5 以上的版本，64 位操作系统的用户则需要 Python 2.4 以上的版本)。此外，这段脚本还会将可执行的 easy_install 脚本安装到用户所有的操作系统 Python 可执行脚本正常应该安装的位置(例如，Windows 用户会安装到 Python 安装目录下的 Scripts 目录中)。关于这种安装方法的更详细说明和注意事项，请参考其官方说明（见扩展阅读）。简单的安装命令如下： 　　wget -q ez_setup。py下载地址（见扩展阅读） 安装完后，最好确保</p>
<h3 id="方法二-使用完整的安装包安装setuptools"><a class="markdownIt-Anchor" href="#方法二-使用完整的安装包安装setuptools"></a> （方法二）. 使用完整的安装包安装<strong>setuptools</strong></h3>
<p>当然，用户也可以直接使用 setuptools发布版本来安装。<br />
对于使用 Windows 的用户，这也是挺方便的方法，许多 Linux 发行版的官方包管理仓库都包含 setuptools 的某个版本。<br />
例如，如果你跟我一样使用 Ubuntu ，那安装 setuptools 只是简单的进行如下操作： # apt-get install python-setuptools</p>
<p>安装 easy_install package-name，比如 easy_install pylab</p>
<p>模块卸载 easy_install -m package-name， 比如easy_install -m pylab</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">easy\_install -m 包名，可以卸载软件包，但是卸载后还要手动删除遗留文件。</span><br></pre></td></tr></table></figure>
<p>setuptools它可以自动的安装模块，只需要你提供给它一个模块名字就可以，并且自动帮你解决模块的依赖问题。一般情况下用setuptools给安装的模块会自动放到一个后缀是.egg的目录里。<br />
在Windows里，easy_install这个命令在python安装目录下的scripts里面，所以需要把scripts加到环境变量的PATH里，这样用起来就更方便，linux下不需要注意这个问题。</p>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Python 发行版：Anaconda</title>
    <url>/2016/03/06/Python-intro-anaconda/</url>
    <content><![CDATA[<p>转自：<a href="http://liam0205.me/2015/11/21/Python-distribution-Anaconda/">http://liam0205.me/2015/11/21/Python-distribution-Anaconda/</a></p>
<h1 id="python-发行版anaconda"><a class="markdownIt-Anchor" href="#python-发行版anaconda"></a> Python 发行版：Anaconda</h1>
<p>发表于 2015 年 11 月 21 日 分类于 <a href="http://liam0205.me/categories/IT/">IT</a>     本文共被围观 205 次     <a href="http://liam0205.me/2015/11/21/Python-distribution-Anaconda/#comments">1条评论</a></p>
<p>Python 是一款优秀的编程语言，其语法优雅简单，但更重要的是各类第三方 Python 库丰富。甚至可以说，学 Python 主要不是学它的语法，而是学习各类第三方 Python 库的用法。安装第三方 Python 库也很简单：Python 拥有 pip 这个包管理器（Package Manager），执行 <code>pip install &lt;package_name&gt;</code> 即可安装所需。 然而，在实际使用中，可能经常会遇到以下一些情况，导致我们无法轻易用 pip 安装第三方库：</p>
<ul>
<li>系统 Python 安装在系统目录，需要 Root 权限才可写入，因此执行 <code>pip</code> 需要使用 <code>sudo</code> 命令。若当前用户不在 sudoer 组内，则无法使用 pip 安装第三方库。</li>
<li>系统 Python 安装在系统目录，需要 Root 权限才可写入。若当前用户不在 sudoer 组内，且未安装 pip，则用户无法安装 pip，继而无法用 pip 安装第三方库。</li>
<li>系统 Python 安装在用户 Home 目录，但因系统没有 <code>libffi</code>/<code>zlib</code>/<code>openssl</code> 或编译安装 Python 时没有正确配置好这些库的依赖，则也无法安装 Python 的 Setuptools 和 pip。</li>
</ul>
<p>总而言之，pip 虽然方便，但是因为系统权限、依赖库等问题，有时难以使用。问系统管理员要权限，当然是一个解决方案，但是每次安装新的 Python 库都要麻烦别人，未免麻烦。 最近，我就遇到了这样的问题。 使用的账号没有在 sudoer 组内，因而不能用 <code>sudo</code> 命令获得临时的 root 权限。于是，我只能尝试自行编译安装，但又被各种第三方依赖库搞得焦头烂额。一番搜索之后，在网络上也并没有找到合适的解决方法，只好在<a href="http://unix.stackexchange.com/questions/239691/how-to-install-python-on-centos-without-root-privileges">Unix.sx 上提问</a>。 其中，<a href="http://unix.stackexchange.com/users/47709/back2basics">Back2Basics</a> 提出，可以尝试 Anaconda 这个 Python 发行版。该发行版内置了许多常用的 Python 第三方库，安装之后直接就可使用。此外，Anaconda 还安装了 Setuptools 和 pip 两个 Python 包管理器。最关键的是，Anaconda 不需要自己编译，可以直接安装在用户目录。此外 Anaconda 支持 Windows/Linux/Mac OS X 全平台，更是让人心头爱得不行。 具体：</p>
<ul>
<li>默认安装的第三方库列表：<a href="http://docs.continuum.io/anaconda/pkg-docs">http://docs.continuum.io/anaconda/pkg-docs</a></li>
<li>下载地址：<a href="https://www.continuum.io/downloads">https://www.continuum.io/downloads</a>
<ul>
<li>Windows: 64 位 - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.0-Windows-x86_64.exe">Python 2.7</a> - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda3-2.4.0-Windows-x86_64.exe">Python 3.5</a> 32 位 - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.0-Windows-x86.exe">Python 2.7</a> - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda3-2.4.0-Windows-x86.exe">Python 3.5</a></li>
<li>OS X: 10.7 以上 - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.0-MacOSX-x86_64.pkg">Python 2.7</a> - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda3-2.4.0-MacOSX-x86_64.pkg">Python 3.5</a> 10.5 以上 - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.0-MacOSX-x86_64.sh">Python 2.7</a> - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda3-2.4.0-MacOSX-x86_64.sh">Python 3.5</a></li>
<li>Linux: 64 位 - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.0-Linux-x86_64.sh">Python 2.7</a> - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda3-2.4.0-Linux-x86_64.sh">Python 3.5</a> 32 位 - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda2-2.4.0-Linux-x86.sh">Python 2.7</a> - <a href="https://3230d63b5fc54e62148e-c95ac804525aac4b6dba79b00b39d1d3.ssl.cf1.rackcdn.com/Anaconda3-2.4.0-Linux-x86.sh">Python 3.5</a></li>
</ul>
</li>
</ul>
<p>Anaconda 的安装过程十分简单，这里就不赘述了。<code>: )</code></p>
<p>======</p>
<p>使用过程中遇到的问题：启动故障。</p>
<blockquote>
<p>[fenglei@localhost bin]$ python3<br />
Failed to import the site module<br />
Traceback (most recent call last):<br />
File “/usr/local/lib/python2.7/site-packages/site.py”, line 75, in <module><br />
__boot()<br />
File “/usr/local/lib/python2.7/site-packages/site.py”, line 27, in __boot<br />
import imp # Avoid import loop in Python &gt;= 3.3<br />
File “/home/fenglei/local/app/anaconda3/lib/python3.6/imp.py”, line 27, in <module><br />
import tokenize<br />
File “/home/fenglei/local/app/anaconda3/lib/python3.6/tokenize.py”, line 33, in <module><br />
import re<br />
File “/home/fenglei/local/app/anaconda3/lib/python3.6/re.py”, line 142, in <module><br />
class RegexFlag(enum.IntFlag):<br />
AttributeError: module ‘enum’ has no attribute ‘IntFlag’</p>
</blockquote>
<p>解决办法：</p>
<p>在home目录下，vi .bashrc，注释掉里面的PYTHONPATH，退出之后打开新窗口，就可以运行python3和conda了。</p>
<hr />
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>python套件 pbh5tools: PacBio rawdata 格式轉換</title>
    <url>/2016/02/25/Python-pbh5tools-pacbio-rawdata-convert/</url>
    <content><![CDATA[<p>2016-09-06更新：pbh5tools是PacBio公司早期推出的数据分析工具，其后已经被SMRTanalysis工具所替换。SMRTanalysis的安装与使用都更简单，Linux安装之后可以直接在网页里面进行数据分析操作。 ====================================== 转载自：<a href="http://jeffreyy.pixnet.net/">http://jeffreyy.pixnet.net/</a> PacBio 是第三代定序技術 (Third generation sequencing)的技術公司，目前的最新機型為RSII，最長長度可到30kb。 出來的rawdata其檔案格式為hdf5，其中有兩種，一個是bas.h5和bax.h5，其PacBio的文件有寫到以下: “Due to the increased throughput and read lengths achieved by the PacBio® RS II upgrade, this information is now contained in one bas.h5 file and three bax.h5 files.” <a href="http://files.pacb.com/software/instrument/2.0.0/bas.h5%20Reference%20Guide.pdf">http://files.pacb.com/software/instrument/2.0.0/bas.h5 Reference Guide.pdf</a> hdf5 格式並無法直接觀看，如果要看序列，必須要經過格式轉換，PacBio有出一個軟體為pbh5tools來進行hdf5的格式轉換。   pbh5tools是以python寫的套件，所以安裝前需要安裝其他python套件，在安裝python套件用pip比較好，pip會兼顧各個依存的套件版本，少用easy-install。 <a href="http://blog.longwin.com.tw/2014/08/python-setup-pip-package-2014/">安裝 PIP 來管理 Python Packages</a> 除了python套件外，其他的套件還有python-devel 和 hdf5與其相關套件。   其安裝其他requirement套件指令為:</p>
<blockquote>
<p><code>sudo yum install python-pip python-devel.x86_64 hdf5-devel.x86_64 hdf5.x86_64 hdf5-mpich-devel.x86_64 hdf5-mpich.x86_64 hdf5-openmpi.x86_64 hdf5-openmpi-devel.x86_64</code> # 上述yum指令，对于没有root权限的Linux用户，该如何解决？？？（FL 2016-02-06备注） <code>sudo pip install --upgrade pip sudo pip install --upgrade nose sudo pip install --upgrade Cython sudo pip install --upgrade numpy sudo pip install --upgrade six sudo pip install --upgrade setuptools sudo pip install --upgrade pkgconfig sudo pip install --upgrade pysam sudo pip install --upgrade h5py sudo pip install --upgrade pbcore</code></p>
</blockquote>
<p>其中，pbcore需要python 2.7，故如果系統為python 2.6又無法利用yum升級上去，就必須手動安裝python 2.7，並注意需雙版本依存。 參考資料: <a href="http://ruiaylin.github.io/2014/12/12/python%20update/">http://ruiaylin.github.io/2014/12/12/python update/</a> <a href="https://github.com/h2oai/h2o-2/wiki/Installing-python-2.7-on-centos-6.3.-Follow-this-sequence-exactly-for-centos-machine-only">https://github.com/h2oai/h2o-2/wiki/Installing-python-2.7-on-centos-6.3.-Follow-this-sequence-exactly-for-centos-machine-only</a> <a href="http://toomuchdata.com/2014/02/16/how-to-install-python-on-centos/">How to install Python 2.7 and Python 3.3 on CentOS 6</a> <a href="http://tecadmin.net/install-python-2-7-on-centos-rhel/">How to Install Python 2.7.10 on CentOS/RHEL 7/6 and Fedora</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Python：python3与python2共存</title>
    <url>/2018/11/27/Python-python3-python2-in-a-system/</url>
    <content><![CDATA[<p><strong>20201208更新：本文已过期。</strong></p>
<p>Linux系统自带了Python2.6，自己又安装了Python2.7和Anaconda3（Python3.6） 今天运行python3.6报错：</p>
<p>[fenglei@localhost lib64]$ /home/fenglei/local/app/anaconda3/bin/python3<br />
Failed to import the site module<br />
Traceback (most recent call last):<br />
File “/usr/local/lib/python2.7/site-packages/site.py”, line 75, in <module><br />
__boot()<br />
File “/usr/local/lib/python2.7/site-packages/site.py”, line 27, in __boot<br />
import imp # Avoid import loop in Python &gt;= 3.3<br />
File “/home/fenglei/local/app/anaconda3/lib/python3.6/imp.py”, line 27, in <module><br />
import tokenize<br />
File “/home/fenglei/local/app/anaconda3/lib/python3.6/tokenize.py”, line 33, in <module><br />
import re<br />
File “/home/fenglei/local/app/anaconda3/lib/python3.6/re.py”, line 142, in <module><br />
class RegexFlag(enum.IntFlag):<br />
AttributeError: module ‘enum’ has no attribute ‘IntFlag’</p>
<p>通过vim进入~/.bashrc文件进行编辑：</p>
<p>export PYTHONPATH=/home/fenglei/local/app/anaconda3/lib/python3.6/site-packages</p>
<p>即可运行 python3.6了。 如果需要运行python2.7，则做下修改：</p>
<p>export PYTHONPATH=/usr/local/lib/python2.7/site-packages</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>R：经验分布函数</title>
    <url>/2020/11/16/R-Empirical-cumulative-distribution/</url>
    <content><![CDATA[<p>经验分布函数（Empirical cumulative distribution (ECDF)），是统计学中一个与样本<strong>经验</strong>测度有关的<strong>分布函数</strong>。 该累积<strong>分布函数</strong>是在所有n个数据点上都跳跃 1/n的阶跃<strong>函数</strong>。 对被测变量的某个值而言，该值的<strong>分布函数</strong>值表示所有观测样本中小于或等于该值的样本所占的比例。</p>
<p>在一个网站看到大量ggplot的画图案例，值得收藏：<a href="https://www.datanovia.com/en/blog/ggplot-examples-best-reference/">https://www.datanovia.com/en/blog/ggplot-examples-best-reference/</a></p>
<p>以 R 内置数据集 iris 为例。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ggplot(iris, aes(Sepal.Length)) +</span><br><span class="line">stat_ecdf(aes(color = Species), size=3) +</span><br><span class="line">scale_color_viridis_d() </span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/e5beaee4bfa1e688aae59bbe_20201116093707.png"><img src="https://genehub.files.wordpress.com/2020/11/e5beaee4bfa1e688aae59bbe_20201116093707.png?w=708" alt="" /></a></p>
<p>便于理解，用了一个简化的数据集画图。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">k=read.table(&quot;test.txt&quot;, head=T)</span><br><span class="line">ggplot(k, aes(Sepal.Length)) +</span><br><span class="line">   stat_ecdf(aes(color = Species), size=3) +</span><br><span class="line">   scale_color_viridis_d()    </span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/e5beaee4bfa1e688aae59bbe_20201116094244.png"><img src="https://genehub.files.wordpress.com/2020/11/e5beaee4bfa1e688aae59bbe_20201116094244.png?w=697" alt="" /></a></p>
<p>计算公式</p>
<p><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/68f10704c974630c3b15d009b884366d2bcbf685" alt="" /></p>
<p>可以理解为将数据按照从小到大排序，然后分布统计不同大小的数字出现的比例，（其实就是histgram？），那么横坐标就是数据从小到大的范围，纵坐标就是0~100%。图形相当于把histgram的柱形顶端和左侧画出来了。</p>
<p>附数据集test.txt：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Sepal.Length    Species</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 10    setosa</span><br><span class="line"> 1    versicolor</span><br><span class="line"> 2    versicolor</span><br><span class="line"> 3    versicolor</span><br><span class="line"> 4    versicolor</span><br><span class="line"> 5    versicolor</span><br><span class="line"> 6    versicolor</span><br><span class="line"> 7    versicolor</span><br><span class="line"> 8    versicolor</span><br><span class="line"> 9    versicolor</span><br><span class="line"> 10    versicolor</span><br><span class="line"> 11    versicolor</span><br><span class="line"> 12    versicolor</span><br><span class="line"> 13    versicolor</span><br><span class="line"> 14    versicolor</span><br><span class="line"> 15    versicolor</span><br><span class="line"> 16    versicolor</span><br><span class="line"> 17    versicolor</span><br><span class="line"> 18    versicolor</span><br><span class="line"> 19    versicolor</span><br><span class="line"> 20    versicolor</span><br><span class="line"> 1    virginica</span><br><span class="line"> 1    virginica</span><br><span class="line"> 2    virginica</span><br><span class="line"> 2    virginica</span><br><span class="line"> 3    virginica</span><br><span class="line"> 2    virginica</span><br><span class="line"> 4    virginica</span><br><span class="line"> 5    virginica</span><br><span class="line"> 4    virginica</span><br><span class="line"> 3    virginica</span><br><span class="line"> 2    virginica</span><br><span class="line"> 4    virginica</span><br><span class="line"> 5    virginica</span><br><span class="line"> 7    virginica</span><br><span class="line"> 6    virginica</span><br><span class="line"> 8    virginica</span><br><span class="line"> 6    virginica</span><br><span class="line"> 15    virginica</span><br><span class="line"> 16    virginica</span><br><span class="line"> 19    virginica</span><br><span class="line"> 13    kaka</span><br><span class="line"> 14    kaka</span><br><span class="line"> 16    kaka</span><br><span class="line"> 15    kaka</span><br><span class="line"> 15    kaka</span><br><span class="line"> 17    kaka</span><br><span class="line"> 18    kaka</span><br><span class="line"> 19    kaka</span><br><span class="line"> 20    kaka</span><br><span class="line"> 13    kaka</span><br><span class="line"> 15    kaka</span><br><span class="line"> 12    kaka</span><br><span class="line"> 16    kaka</span><br><span class="line"> 18    kaka</span><br><span class="line"> 15    kaka</span><br><span class="line"> 13    kaka</span><br><span class="line"> 15    kaka</span><br><span class="line"> 2    kaka</span><br><span class="line"> 4    kaka</span><br><span class="line"> 5    kaka</span><br><span class="line"> 1    kaka</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>R：超几何分布与基因功能富集分析</title>
    <url>/2018/02/08/R-Gene-Ontology-hypergeometric/</url>
    <content><![CDATA[<p>GO功能显著性富集分析给出与基因组背景相比，在差异表达基因中显著富集的GO功能条目，从而给出差异表达基因与哪些生物学功能显著相关。该分析首先把所有差异表达基因向Gene Ontology数据库（<a href="http://www.geneontology.org/">http://www.geneontology.org/</a>）的各个term映射，计算每个term的基因数目，然后应用超几何检验，找出与整个基因组背景相比，在差异表达基因中显著富集的GO条目，其计算公式为 <img src="https://genehub.files.wordpress.com/2018/02/hypergeometric.jpg" alt="hypergeometric" /> 其中，N为所有基因中具有GO注释的基因数目；n为N中差异表达基因的数目；M为所有基因中注释为某特定GO term的基因数目；m为注释为某特定GO term的差异表达基因数目。计算得到的p-value通过Bonferroni校正之后，以corrected p-value≤0.05为阈值，满足此条件的GO term定义为在差异表达基因中显著富集的GO term。通过GO功能显著性富集分析能确定差异表达基因行使的主要生物学功能。 例如，如下的结果： <img src="https://genehub.files.wordpress.com/2018/02/qqe688aae59bbe20180208115638.jpg" alt="QQ截图20180208115638" /> P值计算方法为（在R语言程序中调用phyper命令）：</p>
<p>phyper(66-1, 2775, 20269-2775, 249, lower.tail=F)<br />
[1] 5.546399e-08</p>
<p>Q值计算方法： Q值则需要考虑到全部差异表达基因的P值。引用他人的解释：设总共有m个候选基因，每个基因对应的p值从小到大排列分别是p(1),p(2),…,p(m),则若想控制fdr不能超过q，则只需找到最大的正整数 i，使得 p(i)&lt;= (i*q)/m.然后，挑选对应p(1),p(2),…,p(i)的基因做为差异表达基因，这样就能从统计学上保证fdr不超过q。 例如</p>
<p>&gt; p&lt;-c(0.0003,0.0001,0.02)</p>
<blockquote>
<p>p.adjust(p,method=“fdr”,length(p))<br />
[1] 0.00045 0.00030 0.02000</p>
</blockquote>
<p>注： 一、什么是超几何分布 超几何分布的公式为：</p>
<p>p(x) = choose(m, x) choose(n, k-x) / choose(m+n, k)<br />
for x = 0, …, k.<br />
其中, m 是桶里面白球的个数, n 是黑球的个数, k 是从桶中随机取出的球数, x 是取出球<br />
中白球的个数.</p>
<p>Fisher‘s Exact Test就是依据超几何概率分布得到的。 二、计算公式 公式：计算P值的代码也可以自己写：C(k,M)*C(n-k,N-M)/C(n,N) R语言的代码：</p>
<p>dhyper(x, m, n, k, log = FALSE)<br />
计算某一个点的p值<br />
phyper(q, m, n, k, lower.tail = TRUE, log.p = FALSE)<br />
计算一个分布的p值，默认下计算P(X&lt;=x)<br />
qhyper(p, m, n, k, lower.tail = TRUE, log.p = FALSE)<br />
计算某一个p值对应的分位数<br />
rhyper(nn, m, n, k)<br />
按超几何分布给出nn的可能的模拟结果值</p>
<p>三、运用案例 （见前文） 四、编程 参考： <a href="http://www.chenlianfu.com/?p=1122">http://www.chenlianfu.com/?p=1122</a> <a href="http://www.biotrainee.com/thread-749-1-1.html">http://www.biotrainee.com/thread-749-1-1.html</a> <a href="http://fhqdddddd.blog.163.com/blog/static/1869915420169212398814">http://fhqdddddd.blog.163.com/blog/static/1869915420169212398814</a> <a href="http://blog.sina.com.cn/s/blog%5C_73e6125c01012412.html">http://blog.sina.com.cn/s/blog\_73e6125c01012412.html</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>R：删除包含缺失值NA的行</title>
    <url>/2020/11/14/R-How-to-remove-rows-with-NA-values/</url>
    <content><![CDATA[<p><strong>R数据框，如何删除包含NA的行？</strong></p>
<p>在进行统计建模时，通常需要用到的因变量和自变量都不包含缺失值。tidyr 包的 drop_na() 函数可以对数据框 指定一到多个变量，删去指定的变量有缺失值的行。不指定变量时有任何变量缺失的行都会被删去。</p>
<p>例如，将 NHANES 中所有存在缺失值的行删去后数出保留的行数，原来有 10000 行：</p>
<p>NHANES <strong>%&gt;%</strong> <strong>drop_na</strong>() <strong>%&gt;% nrow</strong>()</p>
<p>## [1] 0 可见所有行都有缺失值。</p>
<p>下面仅剔除 AlcoholDay 缺失的观测并计数：</p>
<p>NHANES <strong>%&gt;% drop_na</strong>(AlcoholDay) <strong>%&gt;% nrow</strong>()</p>
<p>## [1] 4914</p>
<p>基本 stats 包的 complete.cases 函数返回是否无缺失值的逻辑向量，na.omit 函数则返回无缺失值的观测的子集。</p>
<p><strong>如何删除全部为NA的行？只要有非缺省值，可保留对应行。</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> testmatrix &lt;- matrix(nrow=6, ncol=4)</span><br><span class="line">testmatrix</span><br><span class="line">[,1] [,2] [,3] [,4]</span><br><span class="line">[1,] NA NA NA NA</span><br><span class="line">[2,] NA NA NA NA</span><br><span class="line">[3,] NA NA NA NA</span><br><span class="line">[4,] NA NA NA NA</span><br><span class="line">[5,] NA NA NA NA</span><br><span class="line">[6,] NA NA NA NA</span><br><span class="line">testmatrix[2:5,2:3] &lt;- seq(2)</span><br><span class="line">testmatrix</span><br><span class="line">[,1] [,2] [,3] [,4]</span><br><span class="line">[1,] NA NA NA NA</span><br><span class="line">[2,] NA 1 1 NA</span><br><span class="line">[3,] NA 2 2 NA</span><br><span class="line">[4,] NA 1 1 NA</span><br><span class="line">[5,] NA 2 2 NA</span><br><span class="line">[6,] NA NA NA NA</span><br><span class="line">tm1&lt;-testmatrix[,-which(apply(testmatrix,2,function(x)all(is.na(x))))]</span><br><span class="line">tm1</span><br><span class="line">[,1] [,2]</span><br><span class="line">[1,] NA NA</span><br><span class="line">[2,] 1 1</span><br><span class="line">[3,] 2 2</span><br><span class="line">[4,] 1 1</span><br><span class="line">[5,] 2 2</span><br><span class="line">[6,] NA NA</span><br><span class="line">tm2&lt;-tm1[-which(apply(testmatrix,1,function(x)all(is.na(x)))),]</span><br><span class="line">tm2</span><br><span class="line">[,1] [,2]</span><br><span class="line">[1,] 1 1</span><br><span class="line">[2,] 2 2</span><br><span class="line">[3,] 1 1</span><br><span class="line">[4,] 2 2</span><br><span class="line">testmatrix[-which(apply(testmatrix,1,function(x)all(is.na(x)))), -which(apply(testmatrix,2,function(x)all(is.na(x))))]</span><br><span class="line">[,1] [,2]</span><br><span class="line">[1,] 1 1</span><br><span class="line">[2,] 2 2</span><br><span class="line">[3,] 1 1</span><br><span class="line">[4,] 2 2 </span><br></pre></td></tr></table></figure>
<p>Ref: <a href="http://azaleasays.com/2008/02/06/r-remove-row-column-all-na-value/">http://azaleasays.com/2008/02/06/r-remove-row-column-all-na-value/</a></p>
]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title>R | Using ggrepel to repel overlapping text labels in ggplot2</title>
    <url>/2021/03/03/R-Using-ggrepel-to-repel-overlapping-text-labels-in-ggplot2/</url>
    <content><![CDATA[<p>在使用ggplot画图的过程中，如果加上文字标签，比较常见的现象是文字标签之间会出现重叠，影响展示效果。如下图所示。</p>
<p><img src="https://miro.medium.com/max/875/1*CRx8s9NXxVLQG5xXP1Z_gQ.png" alt="" /></p>
<p>通过ggrepel则可以对文字标签进行优化。<br />
如下方案例中使用的 geom_text_repel 和 geom_text_repel 两个函数。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">library(ggplot2)</span><br><span class="line">#使用数据集mtcars演示</span><br><span class="line">ggplot(mtcars)+ geom_point(aes(wt, mpg), color=&quot;red&quot;)+ </span><br><span class="line">  geom_text(aes(wt, mpg, label=rownames(mtcars)))+ </span><br><span class="line">  theme_classic(base_size = 16)</span><br><span class="line"></span><br><span class="line">install.packages(&#x27;ggrepel&#x27;)</span><br><span class="line">library(ggrepel)</span><br><span class="line"></span><br><span class="line">ggplot(mtcars)+ geom_point(aes(wt, mpg), color=&quot;red&quot;)+ </span><br><span class="line">  geom_text_repel(aes(wt, mpg, label=rownames(mtcars)))+</span><br><span class="line">  theme_classic(base_size = 16)</span><br><span class="line">head(mtcars)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">ggplot(mtcars)+ geom_point(aes(wt, mpg), color=&quot;grey&quot;, size=5)+</span><br><span class="line">geom_label_repel(aes(wt, mpg, fill=factor(cyl), </span><br><span class="line">   label=rownames(mtcars)), fontface=&quot;bold&quot;, color=&quot;white&quot;, </span><br><span class="line">   box.padding=unit(0.35, &quot;lines&quot;), point.padding=unit(0.5, &quot;lines&quot;), </span><br><span class="line">   segment.colour = &quot;grey50&quot;)+ theme_classic(base_size = 16)</span><br></pre></td></tr></table></figure>
<p><img src="https://exts.ggplot2.tidyverse.org/ggrepel_files/figure-html/unnamed-chunk-1-1.png" alt="" /></p>
<p><img src="https://exts.ggplot2.tidyverse.org/ggrepel_files/figure-html/unnamed-chunk-1-2.png" alt="" /></p>
<p>资料来源：</p>
<ol>
<li><a href="https://www.jianshu.com/p/84e7e0e029cd">https://www.jianshu.com/p/84e7e0e029cd</a></li>
<li><a href="https://exts.ggplot2.tidyverse.org/ggrepel.html">https://exts.ggplot2.tidyverse.org/ggrepel.html</a></li>
<li><a href="https://blog.exploratory.io/ggrepel-when-things-get-too-crowded-ffefd845665f">https://blog.exploratory.io/ggrepel-when-things-get-too-crowded-ffefd845665f</a></li>
</ol>
]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title>R：条形图(bar plot)上的误差线(Error Bar):SD, SE or CI?</title>
    <url>/2016/03/03/R-bar-plot%E4%B8%8A-error-barsd-se-or-ci/</url>
    <content><![CDATA[<p>转载自：<a href="http://yufree.cn/blogcn/2013/08/18/error-bar.html">http://yufree.cn/blogcn/2013/08/18/error-bar.html</a></p>
<p>经常会遇到有人问条形图上误差线画什么的问题，有人说标准差（sd），有人说标准误（se），有的直接说置信区间（CI），其实这倒也不是什么大问题，你按什么画就在文章中注明就是了。后来看到JCB上有一篇科普<a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2064100/">文章</a>，分析的比较到位，就把里面的干货跳出来翻译一下并对其中的难点进行解读，既是总结也是提高，懒得看过程可直接看文末的规则。</p>
<ul>
<li>概念问题</li>
<li><img src="https://genehub.files.wordpress.com/2016/03/qqe688aae59c9620160303165551.jpg" alt="QQ截圖20160303165551" /></li>
</ul>
<p>误差线</p>
<p>种类</p>
<p>描述</p>
<p>公式</p>
<p>范围</p>
<p>描述性</p>
<p>极值间距离</p>
<p>xmax−xminxmax−xmin</p>
<p>标准差</p>
<p>描述性</p>
<p>数据点与均值的平均差异</p>
<p>SD=∑(x−x¯)2n−1−−−−−−−√SD=∑(x−x¯)2n−1</p>
<p>标准误</p>
<p>推断性</p>
<p>重复多次均值的变化</p>
<p>SE=SDn√SE=SDn</p>
<p>置信区间(95%)</p>
<p>推断性</p>
<p>一个有95%信心出现均值的范围</p>
<p>x¯±tn−1×SEx¯±tn−1×SE</p>
<ul>
<li>标准差</li>
</ul>
<p>标准差是描述性统计里用来表示数据本身均值范围的，两倍标准差范围以外就可能是异常值了，标准差的使用不牵扯均值对比推测，仅仅是描述性的。样本标准差会随着样本数增加接近总体标准差，可用来作为总体标准差的估计，不随样本数变化而变化。</p>
<blockquote>
<p><strong>既然随着样本数增加样本标准差与总体标准差是一致的，怎么又说不随样本数变化？</strong></p>
</blockquote>
<blockquote>
<p>你可以这样理解，总体方差是客观存在的，我们用样本去对总体方差进行估计，具体的算法就是上面那个公式，可用点估计方法自行推导，得到的就是一个接近总体方差的数，这个数当然不会随样本数发生变化了。至于说公式，要记住伴随样本数增大，分子也在增大，所以整体上这个数是不会随样本数发生变化，毕竟只是一个估值无偏性的问题。</p>
</blockquote>
<ul>
<li>标准误</li>
</ul>
<p>置信区间是针对均值自身而言的，是对均值真实值出现范围的估计，在这一范围内每个点都可能是真值，在置信区间的计算中也会用到标准误。因为涉及均值出现范围，一般就会涉及均值比较与估计的问题，谁比谁大或小，是否显著，这属于推断性统计。置信区间与样本是相关的，越大越不准，越小表示准确度高（样本数自然要大一些）。在使用这类误差线时要考虑自己是否有此意图。</p>
<blockquote>
<p><strong>95%置信区间中样本平均值的地位</strong></p>
</blockquote>
<blockquote>
<p>这个95%的置信度可以用仿真实验来掩饰，谢益辉写的R扩展包animation中conf.int()可以很清楚的演示这一过程：不断从总体中取样并计算95%置信区间，重复n次，最后统计区间包含总体均值的概率你会发现有95%的区间包含的真值。区间包含真值的概率是95%，而不是真值在这个区间里变动，计算出的置信区间可能不包含真值，毕竟置信度为95%。样本的均值是没有固定位置的会跟着取样走，但总体均值不会乱跑，因为不知道，所以用含有置信度的区间估计会更可靠一些。</p>
</blockquote>
<blockquote>
<p><strong>标准误与置信区间的区别</strong></p>
</blockquote>
<blockquote>
<p>看公式就知道了，标准误跟着样本数走，样本数越大，标准误越小，很多文章会使用MSE，这代表了均值的标准误。应该说重复越多，这个数就越压缩均值出现的范围，一般而言都是样本数为3，不是因为多了不行，而是说3个样本可以说明问题，有条件当然样本多了好了，结果会更准。置信区间还涉及一个t值的问题，在样本数较少例如3的时候，t值比较大，约为4，样本数多于10，一般就是2左右了。置信区间在一定程度上对样本数不如标准误敏感，给出MSE与样本数是可以推测置信区间的，样本数为3就是4倍MSE，为10就是3倍MSE。</p>
</blockquote>
<blockquote>
<p><strong>如何利用置信区间来判断显著性</strong></p>
</blockquote>
<blockquote>
<p>置信区间是统计估计问题，显著性是统计推断问题，这是首先需要分清楚的，然后看下面这个来自原文的图就很清楚了。通过间距判断就可以，这里需要纠正的问题就是一定要间距完全分开才有显著性差异，根据情况来。</p>
</blockquote>
<blockquote>
<p><img src="http://yufree.github.io/blogcn/figure/cisig.jpg" alt="alt text" /></p>
</blockquote>
<blockquote>
<p><img src="http://yufree.github.io/blogcn/figure/cisig2.jpg" alt="alt text" /></p>
</blockquote>
<ul>
<li>样本数</li>
</ul>
<p>使用样本数要注意你是一个样本重复测定n次，还是n个样本测定1次。前者表示同一样本，n实际为1，后者表示独立样本，样本数为n。如果你展示的是一组代表性独立数据，那就不用给出重复测定误差线，这对总体推断没多大意义。</p>
<blockquote>
<p><strong>实验设计中的可重复性究竟指的是什么？</strong></p>
</blockquote>
<blockquote>
<p>一个实验设计三个平行，重复了4次，那么n应该是多少？n为4，因为这4次测定是与你要检验的假说有关的，那三个平行取均值就可以了，作为对数据真实性的保证。保证数据可用与重复性是两个概念，这一点是经常被混淆的。有人做实验重复了10次发现其中有1次结果是可用的就用这组数据去写文章，里面实际只有平行，没有重复。实际的科研是要考虑这10次结果的，当然前提是每次实验所有操作都是一致的，只用一组数据去写文章是碰运气，可以说完全没有重复性，这里每一次重复代表获得一次独立样本。当然这也分情况，根据你的题目自行考虑。</p>
</blockquote>
<blockquote>
<p><strong>如何表示重复测量数据？</strong></p>
</blockquote>
<blockquote>
<p>做分析的会比较关注，组内重复测量数据对于组间比较是没有意义的。例如在暴露实验中，同一时间点的数据带有误差线的暴露组与对照组是可比的，但是不同时间点的数据置信区间就没什么意义了，或者你可以用配对t检验差值的方法来考虑同一组内不同时间点测定区别是否显著。一般遇到这个问题都是考虑影响因素的时候，最好每个因素单一考虑，当然你也可以设计正交实验。重复性与独立性是相对的，根据你的实验设计来决定。</p>
</blockquote>
<ul>
<li>规则
<ol>
<li>使用误差线要注明种类</li>
<li>要注明样本数n</li>
<li>误差线与显著性只用在独立重复实验上，代表性的实验结果不应该包含误差线与P值，因为这相当于n=1</li>
<li>推断性实验的误差线最好使用标准误或置信区间，对于n为3的实验，可直接列出3次的结果，不标注误差线</li>
<li>95%置信区间表示有95%信心里面有总体的均值，n为3时，标准误的4倍为这个区间</li>
<li>n为3，两倍标准误不重复覆盖，P &lt; 0.05, 刚好覆盖，P接近0.05；n大于10，间距1倍标准误，P接近0.05，两倍就是0.01</li>
<li>置信范围表示误差线时，n为3，重叠一臂，P为0.05；重叠半臂，P为0.01</li>
<li>同一组内的重复实验，标准误与置信区间不能用来表示组内差异</li>
</ol>
</li>
</ul>
<p>原文：Cumming G, Fidler F, Vaux DL.Error bars in experimental biology.J Cell Biol. 2007 Apr 9;177(1):7-11.</p>
<p><a href="http://yufree.github.com/blogcn">yufree</a> / 2013-08-18 Published under <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/">(CC) BY-NC-SA</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>R：corrplot 相关系数矩阵</title>
    <url>/2020/11/16/R-corrplot-coefficient-correlation-/</url>
    <content><![CDATA[<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">install.packages(&quot;corrplot&quot;)</span><br><span class="line">library(&quot;corrplot&quot;)</span><br><span class="line">M = cor(mtcars)</span><br><span class="line">#corrplot(M, order = &quot;hclust&quot;, addrect = 2)</span><br><span class="line">#head(mtcars)</span><br><span class="line">#</span><br><span class="line">#corrplot(M, order = &quot;hclust&quot;, addrect = 2)</span><br><span class="line"># 只需要下半部分三角形</span><br><span class="line">corrplot(M, order = &quot;hclust&quot;, addrect = 2, type=&quot;lower&quot;)</span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/e5beaee4bfa1e688aae59bbe_20201116095756.png"><img src="https://genehub.files.wordpress.com/2020/11/e5beaee4bfa1e688aae59bbe_20201116095756.png?w=894" alt="" /></a></p>
<p>参考资料：</p>
<p>[1] corrplot函数参数调整 <a href="https://zhuanlan.zhihu.com/p/28076189">https://zhuanlan.zhihu.com/p/28076189</a></p>
<p>[2] 图形元素设定 <a href="https://www.cnblogs.com/Mao1518202/p/11270767.html">https://www.cnblogs.com/Mao1518202/p/11270767.html</a></p>
<p>搜资料的时候看到与上述图形类似的点阵图（dot plot），还可以结合聚类分析，顺便记录一下。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># install.packages(&#x27;tidyverse&#x27;)</span><br><span class="line">library(&#x27;tidyverse&#x27;)</span><br><span class="line"># -- Attaching packages ----------------------------------------------------# -------------------------------------------------------- tidyverse 1.3.0</span><br><span class="line"># √ tibble  3.0.4     √ stringr 1.4.0</span><br><span class="line"># √ readr   1.4.0     √ forcats 0.5.0</span><br><span class="line"># √ purrr   0.3.4     </span><br><span class="line"># -- Conflicts -------------------------------------------------------------#-------------------------------------------------- tidyverse_conflicts() --</span><br><span class="line"># x dplyr::filter() masks stats::filter()</span><br><span class="line"># x dplyr::lag()    masks stats::lag()</span><br><span class="line"></span><br><span class="line"># install.packages(&#x27;ggdendro&#x27;)</span><br><span class="line">library(ggdendro)</span><br><span class="line"></span><br><span class="line">library(cowplot)</span><br><span class="line"></span><br><span class="line"># BiocManager::install(&#x27;ggtree&#x27;)</span><br><span class="line">library(ggtree)</span><br><span class="line"></span><br><span class="line">library(patchwork) </span><br><span class="line"></span><br><span class="line">gene_cluster &lt;- read_tsv(&#x27;https://github.com/davemcg/davemcg.github.io/raw/master/content/post/scRNA_dotplot_data.tsv.gz&#x27;)</span><br><span class="line"></span><br><span class="line">gene_cluster %&gt;% sample_n(5)</span><br><span class="line"></span><br><span class="line">markers &lt;- gene_cluster$Gene %&gt;% unique()</span><br></pre></td></tr></table></figure>
<p>#    gene_cluster %&gt;% sample_n(5)</p>
<h1 id="gene_cluster-6列-888行-的矩阵下面显示前5行"><a class="markdownIt-Anchor" href="#gene_cluster-6列-888行-的矩阵下面显示前5行"></a> gene_cluster 6列 888行 的矩阵，下面显示前5行</h1>
<p>A tibble: 5 x 6<br />
Gene    cluster cell_ct cell_exp_ct   count Group</p>
<p>1 CELA1   c16        1278          87 0.0826  Neuron<br />
2 NDUFA1  c13        1725           5 0.00290 Neuron<br />
3 IGFBP7  c13        1725        1013 1.54    Neuron<br />
4 IGFBP7  c09        2124          29 0.0154  Astrocyte<br />
5 SLC10A7 c13        1725          59 0.0413  Neuron</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">   gene_cluster %&gt;% filter(Gene %in% markers) %&gt;% </span><br><span class="line">      mutate(% Expressing = (cell_exp_ct/cell_ct) * 100) %&gt;% </span><br><span class="line">   ggplot(aes(x=cluster, y = Gene, color = count, size = % Expressing)) + </span><br><span class="line">   geom_point()     </span><br><span class="line"># mutate函数来自dplyr，功能是Create, modify, and delete columns</span><br><span class="line"># mutate函数计算一个比例数值，作为矩阵第七列，名称为“% Expression”。</span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/01.png"><img src="https://genehub.files.wordpress.com/2020/11/01.png?w=1024" alt="" /></a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 用dplyr包的filter功能，筛选条件：矩阵中“count”列中大于0，“% expression”列中大于1%。</span><br><span class="line">gene_cluster %&gt;% filter(Gene %in% markers) %&gt;%    </span><br><span class="line">mutate(`% Expressing` = (cell_exp_ct/cell_ct) * 100) %&gt;%    </span><br><span class="line">filter(count &gt; 0, `% Expressing` &gt; 1) %&gt;%    </span><br><span class="line">ggplot(aes(x=cluster, y = Gene, color = count, size = `% Expressing`)) +    geom_point() </span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/02.png"><img src="https://genehub.files.wordpress.com/2020/11/02.png?w=1024" alt="" /></a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 图形调整与美化。使用“theme(axis.line  = element_blank())”取消显示xy坐标轴。“theme(axis.ticks = element_blank()) ”去掉坐标轴的刻度值。</span><br><span class="line"># cowplot包是ggplot2的简单附加组件。它旨在为ggplot2提供一个出版物就绪的主题，一个需要最小量的轴标签尺寸，情节背景等。它的主要目的是方便制作符合要求的图片。除了提供修改的绘图主题外，此包还提供了对ggplot2绘图的自定义注释的功能。</span><br><span class="line"></span><br><span class="line">gene_cluster %&gt;% filter(Gene %in% markers) %&gt;%    </span><br><span class="line">mutate(`% Expressing` = (cell_exp_ct/cell_ct) * 100) %&gt;%    </span><br><span class="line">filter(count &gt; 0, `% Expressing` &gt; 1) %&gt;%    </span><br><span class="line">ggplot(aes(x=cluster, y = Gene, color = count, size = `% Expressing`)) +    geom_point() +    </span><br><span class="line">scale_color_viridis_c(name = &#x27;log2 (count + 1)&#x27;) +    cowplot::theme_cowplot() +    </span><br><span class="line">theme(axis.line  = element_blank()) +   </span><br><span class="line">theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +   ylab(&#x27;&#x27;) +   </span><br><span class="line">theme(axis.ticks = element_blank()) </span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/03.png"><img src="https://genehub.files.wordpress.com/2020/11/03.png?w=1024" alt="" /></a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">gene_cluster %&gt;% </span><br><span class="line">filter(Gene %in% markers) %&gt;%    </span><br><span class="line">mutate(`% Expressing` = (cell_exp_ct/cell_ct) * 100) %&gt;%    </span><br><span class="line">filter(count &gt; 0, `% Expressing` &gt; 1) %&gt;%    </span><br><span class="line">ggplot(aes(x=cluster, y = Gene, color = count, size = `% Expressing`)) +    geom_point() +    </span><br><span class="line">cowplot::theme_cowplot() +    </span><br><span class="line">theme(axis.line  = element_blank()) +   </span><br><span class="line">theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +   ylab(&#x27;&#x27;) +   </span><br><span class="line">theme(axis.ticks = element_blank()) +   </span><br><span class="line">scale_color_gradientn(colours = viridis::viridis(20), limits = c(0,4), oob = scales::squish, name = &#x27;log2 (count + 1)&#x27;)</span><br></pre></td></tr></table></figure>
<p>前面的图中，对所有圆点颜色进行观察，可见整体偏向深蓝，只有一个位于坐标c15 * KCNQ1 的圆点是黄色，其count数值4.94，比其他坐标的数值大了不少。通常绘制热图的时候也会因为这种值（甚至更大的极值，因为大部分基因的表达值FPKM通常小于100，但是少数基因的表达值会接近10000）导致画面颜色不够均匀。 参考原文的做法，调用 <code>scale_color_gradientn</code> 将 <code>c(0,4)</code> 数字范围的圆点进行着色，对于大于4的极值， 调用scales函数的squish功能将其“压碎”成为4（即“squished” down） <code>oob = scales::squish</code></p>
<p><a href="https://genehub.files.wordpress.com/2020/11/05.png"><img src="https://genehub.files.wordpress.com/2020/11/05.png?w=1024" alt="" /></a></p>
<p><a href="https://genehub.files.wordpress.com/2020/11/04.png"><img src="https://genehub.files.wordpress.com/2020/11/04.png?w=1024" alt="" /></a></p>
<p>进一步的，可以将基因进行聚类，并调用ggtree进行树形图绘制。先对原始数据进行整理，提取三列：Gene、cluster、count。调用pivot_wider功能，将其转换为行为gene，列为cluster的矩阵。（tidyr包的 <code>pivot_wider</code> 函数可以将长表变成宽表。 这适用于将多个变量保存到了一列的情况。—— 摘抄自<a href="https://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/%5C_Rbook/summary-manip.html%EF%BC%89">https://www.math.pku.edu.cn/teachers/lidf/docs/Rbook/html/\_Rbook/summary-manip.html）</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># make data square to calculate euclidean distance </span><br><span class="line">mat &lt;- gene_cluster %&gt;%    </span><br><span class="line">filter(Gene %in% markers) %&gt;%    </span><br><span class="line">select(-cell_ct, -cell_exp_ct, -Group) %&gt;%  # drop unused columns to faciliate widening   </span><br><span class="line">pivot_wider(names_from = cluster, values_from = count) %&gt;%    </span><br><span class="line">data.frame() # make df as tibbles -&gt; matrix annoying </span><br><span class="line"></span><br><span class="line">row.names(mat) &lt;- mat$Gene  # put gene in `row` </span><br><span class="line"></span><br><span class="line">mat &lt;- mat[,-1] #drop gene column as now in rows </span><br><span class="line"></span><br><span class="line">clust &lt;- hclust(dist(mat %&gt;% as.matrix())) # hclust with distance matrix</span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/06.png"><img src="https://genehub.files.wordpress.com/2020/11/06.png?w=1024" alt="" /></a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ddgram &lt;- as.dendrogram(clust) # create dendrogram </span><br><span class="line">ggtree_plot &lt;- ggtree::ggtree(ddgram) </span><br><span class="line">ggtree_plot</span><br><span class="line">ggtree::ggtree(ddgram, size=1) + geom_tiplab() </span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/07-1.png"><img src="https://genehub.files.wordpress.com/2020/11/07-1.png?w=1024" alt="" /></a></p>
<p>（右侧的名称有问题）</p>
<p>将树形图和点状图拼接组合。下面的操作只是将两幅图拼起来，基因名并没有对应关系。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dotplot &lt;- gene_cluster %&gt;% filter(Gene %in% markers) %&gt;% </span><br><span class="line">   mutate(% Expressing = (cell_exp_ct/cell_ct) * 100) %&gt;% </span><br><span class="line">   filter(count &gt; 0, % Expressing &gt; 1) %&gt;% </span><br><span class="line">   ggplot(aes(x=cluster, y = Gene, color = count, size = % Expressing)) + </span><br><span class="line">   geom_point() + </span><br><span class="line">   cowplot::theme_cowplot() + </span><br><span class="line">   theme(axis.line  = element_blank()) +</span><br><span class="line">   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +</span><br><span class="line">   ylab(&#x27;&#x27;) +</span><br><span class="line">   theme(axis.ticks = element_blank()) +</span><br><span class="line">   scale_color_gradientn(colours = viridis::viridis(20), limits = c(0,4), oob = scales::squish, name = &#x27;log2 (count + 1)&#x27;)   </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">   plot_grid(ggtree_plot, dotplot, nrow = 1, rel_widths = c(0.5,2), align = &#x27;h&#x27;) </span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/08.png"><img src="https://genehub.files.wordpress.com/2020/11/08.png?w=1024" alt="" /></a></p>
<p>使用</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dotplot &lt;- gene_cluster %&gt;% filter(Gene %in% markers) %&gt;% </span><br><span class="line">mutate(% Expressing = (cell_exp_ct/cell_ct) * 100,</span><br><span class="line">   Gene = factor(Gene, levels = clust$labels[clust$order])) %&gt;% </span><br><span class="line">   #filter(count &gt; 0, % Expressing &gt; 1) %&gt;% </span><br><span class="line">   ggplot(aes(x=cluster, y = Gene, color = count, size = % Expressing)) + </span><br><span class="line">   geom_point() + </span><br><span class="line">   cowplot::theme_cowplot() + </span><br><span class="line">   theme(axis.line  = element_blank()) +</span><br><span class="line">   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +</span><br><span class="line">   ylab(&#x27;&#x27;) +</span><br><span class="line">   theme(axis.ticks = element_blank()) +</span><br><span class="line">   scale_color_gradientn(colours = viridis::viridis(20), limits = c(0,4), oob = scales::squish, name = &#x27;log2 (count + 1)&#x27;)   </span><br><span class="line">   plot_grid(ggtree_plot, NULL, dotplot, nrow = 1, rel_widths = c(0.5,-0.05, 2), align = &#x27;h&#x27;) </span><br></pre></td></tr></table></figure>
<p><a href="https://genehub.files.wordpress.com/2020/11/10.png"><img src="https://genehub.files.wordpress.com/2020/11/10.png?w=1024" alt="" /></a></p>
<p>代码摘抄自：<a href="https://davemcg.github.io/post/lets-plot-scrna-dotplots/">https://davemcg.github.io/post/lets-plot-scrna-dotplots/</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>R | 如何用 RStudio 绘制适合投稿的柱状图（柱状图 + 散点 + 显著性标记）</title>
    <url>/2022/11/09/R-draw-high-quality-figure-in-RStudio/</url>
    <content><![CDATA[<p>以内置的 iris 数据集为例。Iris 鸢尾花数据集是一个经典数据集，在统计学习和机器学习领域都经常被用作示例。数据集内包含 3 类共 150 条记录，每类各 50 个数据，每条记录都有 4 项特征：花萼长度、花萼宽度、花瓣长度、花瓣宽度，可以通过这4个特征预测鸢尾花卉属于（iris-setosa, iris-versicolour, iris-virginica）中的哪一品种。在博文 <a href="https://www.jianshu.com/p/52b86c774b0b">https://www.jianshu.com/p/52b86c774b0b</a> 有对 Iris 数据集进行统计分析以及机器学习的总结。</p>
<span id="more"></span>
<h3 id="柱状图-散点"><a class="markdownIt-Anchor" href="#柱状图-散点"></a> 柱状图 + 散点</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&gt; iris</span><br><span class="line">    Sepal.Length Sepal.Width Petal.Length Petal.Width    Species</span><br><span class="line">1            5.1         3.5          1.4         0.2     setosa</span><br><span class="line">2            4.9         3.0          1.4         0.2     setosa</span><br><span class="line">3            4.7         3.2          1.3         0.2     setosa</span><br><span class="line">4            4.6         3.1          1.5         0.2     setosa</span><br><span class="line">5            5.0         3.6          1.4         0.2     setosa</span><br><span class="line">6            5.4         3.9          1.7         0.4     setosa</span><br><span class="line">7            4.6         3.4          1.4         0.3     setosa</span><br><span class="line">8            5.0         3.4          1.5         0.2     setosa</span><br><span class="line">9            4.4         2.9          1.4         0.2     setosa</span><br><span class="line">51           7.0         3.2          4.7         1.4 versicolor</span><br><span class="line">52           6.4         3.2          4.5         1.5 versicolor</span><br><span class="line">53           6.9         3.1          4.9         1.5 versicolor</span><br><span class="line">54           5.5         2.3          4.0         1.3 versicolor</span><br><span class="line">55           6.5         2.8          4.6         1.5 versicolor</span><br><span class="line">56           5.7         2.8          4.5         1.3 versicolor</span><br><span class="line">57           6.3         3.3          4.7         1.6 versicolor</span><br><span class="line">58           4.9         2.4          3.3         1.0 versicolor</span><br><span class="line">59           6.6         2.9          4.6         1.3 versicolor</span><br><span class="line">100          5.7         2.8          4.1         1.3 versicolor</span><br><span class="line">101          6.3         3.3          6.0         2.5  virginica</span><br><span class="line">102          5.8         2.7          5.1         1.9  virginica</span><br><span class="line">103          7.1         3.0          5.9         2.1  virginica</span><br><span class="line">104          6.3         2.9          5.6         1.8  virginica</span><br><span class="line">105          6.5         3.0          5.8         2.2  virginica</span><br><span class="line">106          7.6         3.0          6.6         2.1  virginica</span><br><span class="line">107          4.9         2.5          4.5         1.7  virginica</span><br></pre></td></tr></table></figure>
<p>柱状图是生物学文献中最常见的一类图形，下面基于 Iris 数据做一个柱状图（展示 MEAN、SE 等信息）。首先想到了 dplyr 函数来进行统计。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 对三个植物品种的花萼 (Sepal)进行平均值和标准差统计</span><br><span class="line">iris %&gt;%</span><br><span class="line">  group_by(Species) %&gt;%</span><br><span class="line">  summarise(</span><br><span class="line">    mean.Sepal.Length = mean(Sepal.Length),</span><br><span class="line">    sd.Sepal.Length = sd(Sepal.Length)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"># A tibble: 3 × 3</span><br><span class="line">#Species    mean.Sepal.Length sd.Sepal.Length</span><br><span class="line">#&lt;fct&gt;                  &lt;dbl&gt;           &lt;dbl&gt;</span><br><span class="line">#1 setosa                  5.01           0.352</span><br><span class="line">#2 versicolor              5.94           0.516</span><br><span class="line">#3 virginica               6.59           0.636</span><br><span class="line"></span><br><span class="line"># 如果要对所有数值型变量计算某些统计量， 可以用summarize_if(is.numeric, list(变量后缀=~统计函数名&lt;, ...&gt;))</span><br><span class="line">a &lt;- iris %&gt;%</span><br><span class="line">  group_by(Species) %&gt;%</span><br><span class="line">  summarise_if(</span><br><span class="line">    is.numeric,</span><br><span class="line">    list(avg = ~mean(.), std = ~sd(.))</span><br><span class="line">  )</span><br><span class="line"># A tibble: 3 × 9</span><br><span class="line">#Species    Sepal.Length_avg Sepal.Width_avg Petal.Length_avg Petal.Width_avg Sepal.Length_std Sepal.Width_std Petal.Length_std</span><br><span class="line">#&lt;fct&gt;                 &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;           &lt;dbl&gt;            &lt;dbl&gt;</span><br><span class="line">#1 setosa                 5.01            3.43             1.46           0.246            0.352           0.379            0.174</span><br><span class="line">#2 versicolor             5.94            2.77             4.26           1.33             0.516           0.314            0.470</span><br><span class="line">#3 virginica              6.59            2.97             5.55           2.03             0.636           0.322            0.552</span><br><span class="line"># … with 1 more variable: Petal.Width_std &lt;dbl&gt;</span><br></pre></td></tr></table></figure>
<p>下面将三个不同植物品种各自花萼平均值来做柱状图。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ggplot() +</span><br><span class="line">  geom_col(data=a, aes(x=Species, y=Sepal.Length_avg)) +</span><br><span class="line">  geom_errorbar(data=a, aes(x=Species, ymin=Sepal.Length_avg-Sepal.Length_std, ymax=Sepal.Length_avg+Sepal.Length_std))</span><br></pre></td></tr></table></figure>
<p>下面是生成的图，可看到灰色网格背景，以及柱子的宽度都不够美观。</p>
<p><img src="https://i.imgur.com/4pwGYUW.jpeg" alt="" /></p>
<p>下面通过 theme_bw() 函数去掉灰色背景；再通过 theme() 函数去掉网格背景，设置坐标轴字体大小；通过 ylab 和 xlab 函数设置坐标轴标签文字；通过 xlim 和 ylim 设置坐标轴展示区间；通过scale_fill_manual 函数来控制柱状图颜色；通过guides 函数控制是否显示 legend。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">pdf(&quot;Sepal_length_barplot.pdf&quot;, width = 2, height = 2)</span><br><span class="line">ggplot() +</span><br><span class="line">  geom_col(data=a, aes(x=Species, y=Sepal.Length_avg, fill=Species), width=.5) +</span><br><span class="line">  geom_errorbar(data=a, aes(x=Species, ymin=Sepal.Length_avg-Sepal.Length_std, ymax=Sepal.Length_avg+Sepal.Length_std), width=.3) +</span><br><span class="line">  geom_jitter(data=iris, size=.3, alpha=.5, color=&quot;darkgrey&quot;, aes(x=Species, y=Sepal.Length), width=.3) +</span><br><span class="line">  scale_fill_manual(values=c(&#x27;#90c9e7&#x27;, &#x27;#219ebc&#x27;, &#x27;#136783&#x27;)) +</span><br><span class="line">  theme_bw() +</span><br><span class="line">  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) +</span><br><span class="line">  theme(axis.text.x = element_text(size = 6, color = &quot;black&quot;)) +</span><br><span class="line">  #theme(axis.text.x = element_text(size = 6, color = &quot;black&quot;, hjust = 0.1, vjust = 0.4, angle = 70)) +</span><br><span class="line">  theme(axis.text.y = element_text(size = 6, color = &quot;black&quot;)) +</span><br><span class="line">  ylab(&quot;Sepal Length&quot;) +</span><br><span class="line">  xlab(&quot;Species&quot;) +</span><br><span class="line">  #xlim(-7, 7) +</span><br><span class="line">  ylim(0, 9) +</span><br><span class="line">  theme(axis.title.x = element_text(size = 8)) +</span><br><span class="line">  theme(axis.title.y = element_text(size = 8)) +</span><br><span class="line">  guides(fill = FALSE)</span><br><span class="line">dev.off()</span><br></pre></td></tr></table></figure>
<p>用pdf函数将图片存储为PDF格式，打开就是下面的效果。</p>
<p><img src="https://i.imgur.com/Nl6NDlZ.jpeg" alt="" /></p>
<p>小结：为了制作适合投稿的图片，需要选择合适的背景色、图片尺寸、字体大小。</p>
<h3 id="坐标轴排序问题"><a class="markdownIt-Anchor" href="#坐标轴排序问题"></a> 坐标轴排序问题</h3>
<p>注意，X 坐标轴的元素顺序默认是首字母排序，有时候我们想根据实验设计的情况自定义排序，更便于读者理解数据，可以将若干个元素如下设置。应该也有其他方法可以实现。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#df$x &lt;- factor(df$x,levels=c(&quot;B&quot;,&quot;A&quot;,&quot;D&quot;,&quot;C&quot;,&quot;E&quot;)) # 参考 https://cloud.tencent.com/developer/article/1711047</span><br><span class="line">a$Species &lt;- factor(a$Species, level=c(&quot;virginica&quot;, &quot;setosa&quot;, &quot;versicolor&quot;))</span><br></pre></td></tr></table></figure>
<p>自定义 X 轴元素顺序之后，再执行画图代码，就可得到新的图。</p>
<p><img src="https://i.imgur.com/JUJP8CC.jpeg" alt="" /></p>
<h3 id="统计显著性20221109-补充"><a class="markdownIt-Anchor" href="#统计显著性20221109-补充"></a> 统计显著性（20221109 补充）</h3>
<p>一般杂志对投稿的要求，还需要加上统计显著性。可以自己用 R 自带的 <code>t.test</code> 或 <code>anova</code> 等函数手动计算，再去 AI 软件手动添加显著性标记。</p>
<p>我最近看到一篇博客介绍用代码自动添加显著性标记，很有参考性：<a href="https://shixiangwang.github.io/home/cn/post/ggpubr-add-pvalue-and-siglevels/">王诗翔：基于ggpubr包为ggplot添加p值和显著性标记</a></p>
<p>作者介绍基于 ggpubr 包来进行显著性分析，该包可以用于向图中添加 p 值的 R 函数：<code>compare_means()</code> 和 <code>stat_compare_means()</code>。演示数据集是　R　内置的　ToothGrowth　数据集：<code>data(&quot;ToothGrowth&quot;)</code>。</p>
<h4 id="比较均值的方法"><a class="markdownIt-Anchor" href="#比较均值的方法"></a> 比较均值的方法：</h4>
<p><a href="http://www.sthda.com/english/wiki/comparing-means-in-r">http://www.sthda.com/english/wiki/comparing-means-in-r</a> 包含了均值方法比较的详细描述，这里我们汇总常见的均值比较方法：</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>R 函数</th>
<th>描述</th>
</tr>
</thead>
<tbody>
<tr>
<td>T检验</td>
<td>t.test()</td>
<td>比较两组 (参数)</td>
</tr>
<tr>
<td>Wilcoxon 检验</td>
<td>wilcox.test()</td>
<td>比较两组 (非参数)</td>
</tr>
<tr>
<td>ANOVA</td>
<td>aov() or anova()</td>
<td>比较多组 (参数)</td>
</tr>
<tr>
<td>Kruskal-Wallis</td>
<td>kruskal.test()</td>
<td>比较多组 (非参数)</td>
</tr>
</tbody>
</table>
<h4 id="比较两个独立组别"><a class="markdownIt-Anchor" href="#比较两个独立组别"></a> 比较两个独立组别</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 执行检验。默认执行method=&quot;wilcox.test&quot;，你可以指定method = &quot;t.test&quot;进行t检验。</span><br><span class="line">compare_means(len ~ supp, data = ToothGrowth)</span><br><span class="line">#&gt; # A tibble: 1 x 8</span><br><span class="line">#&gt;   .y.   group1 group2      p p.adj p.format p.signif method  </span><br><span class="line">#&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   </span><br><span class="line">#&gt; 1 len   OJ     VC     0.0645 0.064 0.064    ns       Wilcoxon</span><br><span class="line"></span><br><span class="line"># 创建一个带p值的箱线图：</span><br><span class="line">p &lt;- ggboxplot(ToothGrowth, x=&quot;supp&quot;,</span><br><span class="line">               y = &quot;len&quot;, color = &quot;supp&quot;,</span><br><span class="line">               palette = &quot;jco&quot;, add = &quot;jitter&quot;)</span><br><span class="line"># 添加p值</span><br><span class="line">p + stat_compare_means()</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-8-1.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 改变方法</span><br><span class="line">p + stat_compare_means(method = &quot;t.test&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-8-2.png" alt="" /></p>
<h4 id="比较两组配对样本"><a class="markdownIt-Anchor" href="#比较两组配对样本"></a> 比较两组配对样本</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 执行检验：</span><br><span class="line">compare_means(len ~ supp, data = ToothGrowth,</span><br><span class="line">              paired = TRUE)</span><br><span class="line">#&gt; # A tibble: 1 x 8</span><br><span class="line">#&gt;   .y.   group1 group2       p  p.adj p.format p.signif method  </span><br><span class="line">#&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   </span><br><span class="line">#&gt; 1 len   OJ     VC     0.00431 0.0043 0.0043   **       Wilcoxon</span><br><span class="line"></span><br><span class="line">#使用ggpaired()函数可视化：</span><br><span class="line">ggpaired(ToothGrowth, x=&quot;supp&quot;, y=&quot;len&quot;,</span><br><span class="line">         color=&quot;supp&quot;, line.color=&quot;gray&quot;,</span><br><span class="line">         line.size=0.4, palette = &quot;jco&quot;) + </span><br><span class="line">    stat_compare_means(paired = TRUE)</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-12-1.png" alt="" /></p>
<h4 id="多组样本组内两两之间的比较如果分组变量包含超过两个水平配对检验会自动执行"><a class="markdownIt-Anchor" href="#多组样本组内两两之间的比较如果分组变量包含超过两个水平配对检验会自动执行"></a> 多组样本：组内两两之间的比较，如果分组变量包含超过两个水平，配对检验会自动执行</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 执行成对比较</span><br><span class="line">compare_means(len ~ dose, data = ToothGrowth)</span><br><span class="line">#&gt; # A tibble: 3 x 8</span><br><span class="line">#&gt;   .y.   group1 group2            p      p.adj p.format p.signif method  </span><br><span class="line">#&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;         &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   </span><br><span class="line">#&gt; 1 len   0.5    1      0.00000702   0.000014   7.0e-06  ****     Wilcoxon</span><br><span class="line">#&gt; 2 len   0.5    2      0.0000000841 0.00000025 8.4e-08  ****     Wilcoxon</span><br><span class="line">#&gt; 3 len   1      2      0.000177     0.00018    0.00018  ***      Wilcoxon</span><br><span class="line"># 可视化： 指定你想要比较的组别</span><br><span class="line">my_comparisons &lt;- list(c(&quot;0.5&quot;,&quot;1&quot;), c(&quot;1&quot;, &quot;2&quot;),</span><br><span class="line">                       c(&quot;0.5&quot;, &quot;2&quot;))</span><br><span class="line">ggboxplot(ToothGrowth, x=&quot;dose&quot;, y=&quot;len&quot;,</span><br><span class="line">          color=&quot;dose&quot;, palette = &quot;jco&quot;) +</span><br><span class="line">    stat_compare_means(comparisons = my_comparisons) + #添加成对p值</span><br><span class="line">    stat_compare_means(label.y = 50) # 添加全局p值</span><br><span class="line">#&gt; Warning in wilcox.test.default(c(4.2, 11.5, 7.3, 5.8, 6.4, 10, 11.2, 11.2, :</span><br><span class="line">#&gt; cannot compute exact p-value with ties</span><br><span class="line">#&gt; Warning in wilcox.test.default(c(4.2, 11.5, 7.3, 5.8, 6.4, 10, 11.2, 11.2, :</span><br><span class="line">#&gt; cannot compute exact p-value with ties</span><br><span class="line">#&gt; Warning in wilcox.test.default(c(16.5, 16.5, 15.2, 17.3, 22.5, 17.3, 13.6, :</span><br><span class="line">#&gt; cannot compute exact p-value with ties</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-16-1.png" alt="" /></p>
<p>如果你想要指定 P 值标注线精确的 Y 轴位置，使用 <code>label.y</code> 参数，参考该作者原文。</p>
<h4 id="多组样本基于参考组的多重成对比较"><a class="markdownIt-Anchor" href="#多组样本基于参考组的多重成对比较"></a> 多组样本：基于参考组的多重成对比较</h4>
<p>使用场景：比如对某个样品按照处理进行若干个时间的检测，可以用初始时间样品作为其他样品的参考点。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 基于参考组</span><br><span class="line">compare_means(len ~ dose, data = ToothGrowth,</span><br><span class="line">              ref.group = &quot;0.5&quot;, </span><br><span class="line">              method = &quot;t.test&quot;)</span><br><span class="line">#&gt; # A tibble: 2 x 8</span><br><span class="line">#&gt;   .y.   group1 group2        p    p.adj p.format p.signif method</span><br><span class="line">#&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; </span><br><span class="line">#&gt; 1 len   0.5    1      1.27e- 7 1.30e- 7 1.3e-07  ****     T-test</span><br><span class="line">#&gt; 2 len   0.5    2      4.40e-14 8.80e-14 4.4e-14  ****     T-test</span><br><span class="line"># 可视化</span><br><span class="line">ggboxplot(ToothGrowth, x=&quot;dose&quot;, y=&quot;len&quot;,</span><br><span class="line">          color=&quot;dose&quot;, palette = &quot;jco&quot;) + </span><br><span class="line">    stat_compare_means(method=&quot;anova&quot;, label.y=40) + </span><br><span class="line">    stat_compare_means(label=&quot;p.signif&quot;, method=&quot;t.test&quot;,</span><br><span class="line">                       ref.group = &quot;0.5&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-19-1.png" alt="" /></p>
<h4 id="多组样本以所有值为基准base-mean进行多个成对比较"><a class="markdownIt-Anchor" href="#多组样本以所有值为基准base-mean进行多个成对比较"></a> 多组样本：以所有值为基准（base-mean）进行多个成对比较</h4>
<p>如果出现很多组别，两两比较过于复杂，通过将所有数据汇总创建一个虚拟的样本，以它为基准进行比较。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Comparison of each group against base-mean</span><br><span class="line">compare_means(len ~ dose,  data = ToothGrowth, ref.group = &quot;.all.&quot;,</span><br><span class="line">              method = &quot;t.test&quot;)</span><br><span class="line">#&gt; # A tibble: 3 x 8</span><br><span class="line">#&gt;   .y.   group1 group2           p      p.adj p.format p.signif method</span><br><span class="line">#&gt;   &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; </span><br><span class="line">#&gt; 1 len   .all.  0.5    0.000000290 0.00000087 2.9e-07  ****     T-test</span><br><span class="line">#&gt; 2 len   .all.  1      0.512       0.51       0.51     ns       T-test</span><br><span class="line">#&gt; 3 len   .all.  2      0.000000425 0.00000087 4.3e-07  ****     T-test</span><br><span class="line">可视化</span><br><span class="line"></span><br><span class="line">ggboxplot(ToothGrowth, x = &quot;dose&quot;, y = &quot;len&quot;,</span><br><span class="line">          color = &quot;dose&quot;, palette = &quot;jco&quot;)+</span><br><span class="line">  stat_compare_means(method = &quot;anova&quot;, label.y = 40)+      # Add global p-value</span><br><span class="line">  stat_compare_means(label = &quot;p.signif&quot;, method = &quot;t.test&quot;,</span><br><span class="line">                     ref.group = &quot;.all.&quot;)                  # Pairwise comparison against all</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-21-1.png" alt="" /></p>
<p>这个方法有时候会非常有用，比如下面这个例子中，我们可以通过每个样本均值与所有样本的均值进行比较，判断基因水平是过表达还是下调了。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Load myeloma data from GitHub</span><br><span class="line">myeloma &lt;- read.delim(&quot;https://raw.githubusercontent.com/kassambara/data/master/myeloma.txt&quot;)</span><br><span class="line"># 执行检验</span><br><span class="line">compare_means(DEPDC1 ~ molecular_group,  data = myeloma,</span><br><span class="line">              ref.group = &quot;.all.&quot;, method = &quot;t.test&quot;)</span><br><span class="line">#&gt; # A tibble: 7 x 8</span><br><span class="line">#&gt;   .y.    group1 group2                      p     p.adj p.format p.signif method</span><br><span class="line">#&gt;   &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;                   &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt; </span><br><span class="line">#&gt; 1 DEPDC1 .all.  Cyclin D-1       0.288          1.00e+0 0.29     ns       T-test</span><br><span class="line">#&gt; 2 DEPDC1 .all.  Cyclin D-2       0.424          1.00e+0 0.42     ns       T-test</span><br><span class="line">#&gt; 3 DEPDC1 .all.  MMSET            0.578          1.00e+0 0.58     ns       T-test</span><br><span class="line">#&gt; 4 DEPDC1 .all.  MAF              0.254          1.00e+0 0.25     ns       T-test</span><br><span class="line">#&gt; 5 DEPDC1 .all.  Hyperdiploid     0.0000000273   1.90e-7 2.7e-08  ****     T-test</span><br><span class="line">#&gt; 6 DEPDC1 .all.  Proliferation    0.0000239      1.20e-4 2.4e-05  ****     T-test</span><br><span class="line">#&gt; 7 DEPDC1 .all.  Low bone disease 0.00000526     3.20e-5 5.3e-06  ****     T-test</span><br><span class="line"></span><br><span class="line"># 可视化表达谱</span><br><span class="line">ggboxplot(myeloma, x=&quot;molecular_group&quot;, y=&quot;DEPDC1&quot;,</span><br><span class="line">          color=&quot;molecular_group&quot;, add=&quot;jitter&quot;,</span><br><span class="line">          legend=&quot;none&quot;) + </span><br><span class="line">    rotate_x_text(angle = 45) + </span><br><span class="line">    geom_hline(yintercept = mean(myeloma$DEPDC1),</span><br><span class="line">               linetype=2) + # 添加base mean的水平线</span><br><span class="line">     stat_compare_means(method = &quot;anova&quot;, label.y = 1600)+        # Add global annova p-value</span><br><span class="line">  stat_compare_means(label = &quot;p.signif&quot;, method = &quot;t.test&quot;,</span><br><span class="line">                     ref.group = &quot;.all.&quot;)                      # Pairwise comparison against all</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-23-1.png" alt="" /></p>
<h4 id="多个分组变量根据某个变量分组后两个独立样本的比较"><a class="markdownIt-Anchor" href="#多个分组变量根据某个变量分组后两个独立样本的比较"></a> 多个分组变量：根据某个变量分组后两个独立样本的比较</h4>
<p>对于 ToothGrowth 数据集，有两种变量，supp（包含：OJ 和 VC）和 dose（包含：0.5、1 和 2）。下面的代码相当于依据 dose 分成三个数据子集，对子集内部的 OJ 和 VC 进行显著性比较。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">执行检验：</span><br><span class="line"></span><br><span class="line">compare_means(len ~ supp, data = ToothGrowth,</span><br><span class="line">              group.by = &quot;dose&quot;)</span><br><span class="line">#&gt; # A tibble: 3 x 9</span><br><span class="line">#&gt;    dose .y.   group1 group2       p p.adj p.format p.signif method  </span><br><span class="line">#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   </span><br><span class="line">#&gt; 1   0.5 len   OJ     VC     0.0232  0.046 0.023    *        Wilcoxon</span><br><span class="line">#&gt; 2   1   len   OJ     VC     0.00403 0.012 0.004    **       Wilcoxon</span><br><span class="line">#&gt; 3   2   len   OJ     VC     1       1     1.000    ns       Wilcoxon</span><br><span class="line">因为生成了不同的子图，根据变量分面</span><br><span class="line"></span><br><span class="line"># 根据 &quot;dose&quot; 变量分面绘制箱线图</span><br><span class="line">p &lt;- ggboxplot(ToothGrowth, x = &quot;supp&quot;, y = &quot;len&quot;,</span><br><span class="line">          color = &quot;supp&quot;, palette = &quot;jco&quot;,</span><br><span class="line">          add = &quot;jitter&quot;,</span><br><span class="line">          facet.by = &quot;dose&quot;, short.panel.labs = FALSE)</span><br><span class="line"># Use only p.format as label. Remove method name.</span><br><span class="line">p + stat_compare_means(label = &quot;p.format&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-25-1.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Or use significance symbol as label</span><br><span class="line">p + stat_compare_means(label =  &quot;p.signif&quot;, label.x = 1.5)</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-26-1.png" alt="" /></p>
<p>将这几个图绘制在单个面板内：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">p &lt;- ggboxplot(ToothGrowth, x = &quot;dose&quot;, y = &quot;len&quot;,</span><br><span class="line">          color = &quot;supp&quot;, palette = &quot;jco&quot;,</span><br><span class="line">          add = &quot;jitter&quot;)</span><br><span class="line">p + stat_compare_means(aes(group = supp))</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-27-1.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 仅显示p值</span><br><span class="line">p + stat_compare_means(aes(group = supp), label = &quot;p.format&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-28-1.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 使用显著性标记</span><br><span class="line">p + stat_compare_means(aes(group = supp), label = &quot;p.signif&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-29-1.png" alt="" /></p>
<h4 id="多个分组变量分组后配对样本比较"><a class="markdownIt-Anchor" href="#多个分组变量分组后配对样本比较"></a> 多个分组变量：分组后配对样本比较</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">compare_means(len ~ supp, data = ToothGrowth,</span><br><span class="line">              group.by = &quot;dose&quot;, paired = TRUE)</span><br><span class="line">#&gt; # A tibble: 3 x 9</span><br><span class="line">#&gt;    dose .y.   group1 group2      p p.adj p.format p.signif method  </span><br><span class="line">#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;   </span><br><span class="line">#&gt; 1   0.5 len   OJ     VC     0.0330 0.066 0.033    *        Wilcoxon</span><br><span class="line">#&gt; 2   1   len   OJ     VC     0.0137 0.041 0.014    *        Wilcoxon</span><br><span class="line">#&gt; 3   2   len   OJ     VC     1      1     1.000    ns       Wilcoxon</span><br><span class="line">可视化，按分组变量dose分面创建一个多面板箱线图：</span><br><span class="line"></span><br><span class="line">p &lt;- ggpaired(ToothGrowth, x=&quot;supp&quot;, y=&quot;len&quot;,</span><br><span class="line">               color=&quot;supp&quot;, palette = &quot;jco&quot;,</span><br><span class="line">               line.color = &quot;grey&quot;, line.size =0.4,</span><br><span class="line">               facet.by = &quot;dose&quot;, short.panel.labs = FALSE)</span><br><span class="line"># Use only p.format as label. Remove method name.</span><br><span class="line">p + stat_compare_means(label = &quot;p.format&quot;, paired = TRUE)</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-31-1.png" alt="" /></p>
<h3 id="其他图形"><a class="markdownIt-Anchor" href="#其他图形"></a> 其他图形</h3>
<h4 id="条形图和线图一组变量"><a class="markdownIt-Anchor" href="#条形图和线图一组变量"></a> 条形图和线图（一组变量）</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 条形图加均值标准误</span><br><span class="line">ggbarplot(ToothGrowth, x = &quot;dose&quot;, y = &quot;len&quot;, add = &quot;mean_se&quot;)+</span><br><span class="line">  stat_compare_means() +                                         # Global p-value</span><br><span class="line">  stat_compare_means(ref.group = &quot;0.5&quot;, label = &quot;p.signif&quot;,</span><br><span class="line">                     label.y = c(22, 29))                   # compare to ref.group</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-32-1.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 线图加均值标准误</span><br><span class="line">ggline(ToothGrowth, x = &quot;dose&quot;, y = &quot;len&quot;, add = &quot;mean_se&quot;)+</span><br><span class="line">  stat_compare_means() +                                         # Global p-value</span><br><span class="line">  stat_compare_means(ref.group = &quot;0.5&quot;, label = &quot;p.signif&quot;,</span><br><span class="line">                     label.y = c(22, 29)) </span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-32-2.png" alt="" /></p>
<h4 id="条形图和线图两组变量"><a class="markdownIt-Anchor" href="#条形图和线图两组变量"></a> 条形图和线图（两组变量）</h4>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ggbarplot(ToothGrowth, x = &quot;dose&quot;, y = &quot;len&quot;, add = &quot;mean_se&quot;,</span><br><span class="line">          color = &quot;supp&quot;, palette = &quot;jco&quot;, </span><br><span class="line">          position = position_dodge(0.8))+</span><br><span class="line">  stat_compare_means(aes(group = supp), label = &quot;p.signif&quot;, label.y = 29)</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-33-1.png" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ggline(ToothGrowth, x = &quot;dose&quot;, y = &quot;len&quot;, add = &quot;mean_se&quot;,</span><br><span class="line">          color = &quot;supp&quot;, palette = &quot;jco&quot;)+</span><br><span class="line">  stat_compare_means(aes(group = supp), label = &quot;p.signif&quot;, </span><br><span class="line">                     label.y = c(16, 25, 29))</span><br></pre></td></tr></table></figure>
<p><img src="https://shixiangwang.github.io/home/cn/post/2019-09-23-ggpubr-add-p-values-and-significance-levels_files/figure-html/unnamed-chunk-33-2.png" alt="" /></p>
]]></content>
      <categories>
        <category>R</category>
      </categories>
  </entry>
  <entry>
    <title>R：绘制中国地图</title>
    <url>/2016/11/21/R-map-of-China/</url>
    <content><![CDATA[<p>转自：<a href="http://cos.name/2009/07/drawing-china-map-using-r/">http://cos.name/2009/07/drawing-china-map-using-r/</a> 鉴于最近有不少人在讨论用R软件绘制地图的问题，我也就跟着凑了凑热闹，对相应的方法学习了一番。下面的这篇文章是一个初步的介绍，还有很多内容仍在学习和探索中，如果大家有什么意见或建议，我将根据自己学习的情况对文章进行进一步的补充。 在R中绘制地图其实是十分方便的，最直接的办法大概就是安装<code>maps</code>和<code>mapdata</code>这两个包，然后输入下面的命令：</p>
<p>library(maps)<br />
library(mapdata)<br />
map(“china”)</p>
<p>其中<code>map()</code>函数还可以加上很多参数，在这里就不一一详述，具体的用法只需问号之。然而仔细看一看这张地图你会发现重庆市和四川省仍然是浑然一体，可见该地图的数据应该是有些年头了。 幸运的是，通过<a href="http://yihui.name/cn/2007/09/china-map-at-province-level/" title="终于搞定了中国分省市地图">谢益辉的这篇博文</a>我们已经可以大体知道该如何操作了，下面就为大家介绍一下具体的步骤。 首先，从<a href="http://cos.name/wp-content/uploads/2009/07/chinaprovinceborderdata_tar_gz.zip">这里</a>下载中国地图的GIS数据，这是一个压缩包，完全解压后包含三个文件（bou2_4p.dbf、bou2_4p.shp和bou2_4p.shx），将这三个文件解压到同一个目录下，并在R中设好相应的工作空间，然后安装<code>maptools</code>包，运行如下程序：</p>
<p>library(maptools);<br />
x=read.shape(‘bou2_4p.shp’);#下文中会继续用到x这个变量，<br />
#如果你用的是其它的名称，<br />
#请在下文的程序中也进行相应的改动。<br />
plot(x);</p>
<p>【修改】新版本的maptools包不再提供read.shape()函数，请用readShapePoly()代替。 这时一张完整的中国地图就已经画好了。但是在实际使用的过程中，我们往往会根据自己的需要对地图中的某些省份着以特定的颜色，这时就可以通过调节<code>plot</code>命令中的<code>fg</code>参数来予以实现。然而为了清楚地说明这部分的内容，我需要插播一段R绘制地图的原理。 ==<mark><mark><mark><mark><mark><mark><mark><mark><mark><mark>传说中的分割线</mark></mark></mark></mark></mark></mark></mark></mark></mark></mark>= 在绘制地图时，每一个省市自治区或者岛屿都是用一个多边形来表示的。之前的GIS数据，其实就是提供了每一个行政区其多边形逐点的坐标，然后R软件通过顺次连接这些坐标，就绘制出了一个多边形区域。在上面的数据中，一共包含了925个多边形的信息，之所以有这么多是因为一些省份有很多小的附属岛屿。在这925个多边形中，每一个都对应一个唯一的ID，编号分别从1到925。 ==<mark><mark><mark><mark><mark><mark><mark><mark><mark><mark>传说中的分割线</mark></mark></mark></mark></mark></mark></mark></mark></mark></mark>= 回到刚才的话题，<code>plot</code>命令中的<code>fg</code>参数在本例中应该是一个长度为925的向量，其第i个分量的取值就代表了地图中第i个多边形的颜色。一个简单的尝试是运行下面这个命令看看效果：</p>
<p>plot(x,fg=gray(924:0/924));</p>
<p>【修改】新版本的<code>maptools</code>包的绘图参数也有所改变，请将<code>fg</code>换成<code>col</code>。 于是自然就产生了一个问题：如何获取某一个特定地区的ID，进而设置我们想要的颜色？事实上，在变量x中，就已经存储了我们想要的信息。在R中输入“<code>x[[2]]</code>”或“<code>x$att.data</code>”，会得到一个925行7列的数据框，这其实是bou2_4p.dbf这个文件中存储的信息，之前的<code>read.shape()</code>函数虽然读取的是bou2_4p.shp文件，但在默认情况下会把dbf文件的信息也放到变量之中。对于这个数据框，其行名就是每一个区域的ID编号，第一列和第二列分别是面积和周长，最后一列是该区域所属的行政区名，其它的列应该也是一些编号性质的变量。于是，通过查找相应的行政区对应的行名，就可以对<code>fg</code>参数进行赋值了。下面是我编的一个函数，用来生成所需的<code>fg</code>向量：</p>
<p>getColor=function(mapdata,provname,provcol,othercol)<br />
{<br />
f=function(x,y) ifelse(x %in% y,which(y==x),0);<br />
colIndex=sapply(mapdata<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>t</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">att.data</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span></span></span></span>NAME,f,provname);<br />
fg=c(othercol,provcol)[colIndex+1];<br />
return(fg);<br />
}</p>
<p>【修改】地图数据的组织形式有所变化，上面函数中的<code>mapdata$att.data$NAME</code>需要替换为<code>mapdata@data$NAME</code>。 其中<code>mapdata</code>是存放地图数据的变量，在上面的例子中就是x，<code>provname</code>是需要改变颜色的地区的名称，<code>provcol</code>是对应于<code>provname</code>的代表颜色的向量（名称和数字均可），<code>othercol</code>是其它地区的颜色。举例如下：</p>
<p>provname=c(“北京市”,“天津市”,“上海市”,“重庆市”);<br />
provcol=c(“red”,“green”,“yellow”,“purple”);<br />
plot(x,fg=getColor(x,provname,provcol,“white”));</p>
<p><img src="http://cos.name/wp-content/uploads/2009/07/map00-e1262748931991.png" alt="map00" title="map00" /> 注意<code>provname</code>一定要写地区的全称，写法可以参照下面这条命令生成的向量：</p>
<p>as.character(na.omit(unique(x<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>t</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">att.data</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span></span></span></span>NAME)));</p>
<p>由此生成的向量有33个元素，少了澳门特别行政区，这是这个数据中的一块瑕疵。在<code>x$att.data</code>的第899行有一个<code>NA</code>，不知道它代表的是否就是澳门。 利用类似的方法就可以根据自己的需要对不同的区域进行着色，下面再举一例。从国家统计局获取2007年我国各地区的人口数据，然后根据人口的多少对各省份进行着色。程序如下：</p>
<p>provname=c(“北京市”,“天津市”,“河北省”,“山西省”,“内蒙古自治区”,<br />
“辽宁省”,“吉林省”,“黑龙江省”,“上海市”,“江苏省”,<br />
“浙江省”,“安徽省”,“福建省”,“江西省”,“山东省”,<br />
“河南省”,“湖北省”,“湖南省”,“广东省”,<br />
“广西壮族自治区”,“海南省”,“重庆市”,“四川省”,“贵州省”,<br />
“云南省”,“西藏自治区”,“陕西省”,“甘肃省”,“青海省”,<br />
“宁夏回族自治区”,“新疆维吾尔自治区”,“台湾省”,<br />
“香港特别行政区”);<br />
pop=c(1633,1115,6943,3393,2405,4298,2730,3824,1858,7625,<br />
5060,6118,3581,4368,9367,9360,5699,6355,9449,<br />
4768,845,2816,8127,3762,4514,284,3748,2617,<br />
552,610,2095,2296,693);<br />
provcol=rgb(red=1-pop/max(pop)/2,green=1-pop/max(pop)/2,blue=0);<br />
plot(x,fg=getColor(x,provname,provcol,“white”),xlab=“”,ylab=“”);</p>
<p><a href="http://cos.name/wp-content/uploads/2009/07/map01.png"><img src="http://cos.name/wp-content/uploads/2009/07/map01-e1262748729327.png" alt="map01" title="map01" /></a> 其中颜色越深的地方代表人口数越多，反之为人口数越少。 此外，在绘制地图的过程中，还有一个比较有用的参数是<code>recs</code>，它是一个由多边形ID组成的向量，表示在地图中只画出这些ID所代表的区域。利用这个参数，就可以画出某一部分的地图，例如下面的例子是我国中部六省的地图：</p>
<p>getID=function(mapdata,provname)<br />
{<br />
index=mapdata<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi><mi>t</mi><mi>t</mi><mi mathvariant="normal">.</mi><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">att.data</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">t</span><span class="mord">.</span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span></span></span></span>NAME %in% provname;<br />
ids=rownames(mapdata$att.data[index,]);<br />
return(as.numeric(ids));<br />
}<br />
midchina=c(“河南省”,“山西省”,“湖北省”,“安徽省”,“湖南省”,“江西省”);<br />
plot(x,recs=getID(x,midchina),fg=“green”,ol=“white”,xlab=“”,<br />
ylab=“”);</p>
<p><img src="http://cos.name/wp-content/uploads/2009/07/map02-e1262748890424.png" alt="map02" title="map02" /> 上面的<code>getID()</code>是我编写的一个功能与<code>getColor()</code>类似的函数，用来返回指定省份的ID。 【修改】新版本的<code>maptools</code>包的绘图函数已经取消了<code>recs</code>这个参数，现在要实现这个功能，可以在颜色上把不需要的省份变成白色，其中填充色用<code>col</code>参数，边界颜色用<code>border</code>参数。例如上面的例子可以用下面的函数来实现：</p>
<p>plot(x, col = getColor(x, midchina, rep(“green”, 6),<br />
“white”), border = “white”, xlab = “”, ylab = “”)</p>
<p>最后要说的是，在画出的图上仍然可以用<code>points()</code>函数和<code>text()</code>函数加上点和文字，而<code>maptools</code>包中还提供了一个<code>pointLabel()</code>函数，用来解决文本标签的重叠问题。这部分内容请参阅博文：<a href="http://yihui.name/cn/2008/10/china-map-and-city-locations-with-r/">用R画中国地图并标注城市位置</a>，以及<a href="http://yihui.name/cn/2008/10/avoid-label-overlap-pointlabel-in-maptools/">避免文本标签重叠：maptools中的pointLabel()</a>。 从以上的内容来看，本文所述的都是一些最基本的绘图方法，还没有对地理信息数据进行更进一步的分析。如果有机会的话，这一主题的下一篇文章将为大家介绍地图数据的组成结构，并说明如何将不同格式的地理数据整合起来，例如如何在上面的地图上绘制出我国的铁路、水系分布等内容。</p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>R: 批量读入文本文件并循环处理，分别输出统计图</title>
    <url>/2020/03/05/R-read-multiple-files-by-loop/</url>
    <content><![CDATA[<p>对于高通量测序数据，通常都是数个或数十个样品，有时候要调用R packages对测序分析结果（例如bed格式文本文件）就行统计绘图，如何批量处理？   一、批量文件读取，逐个统计 demo：</p>
<p>##读取同一目录下的所有文件<br />
path &lt;- “E:/实验数据/UseData/2013”<br />
fileNames &lt;- dir(path)<br />
filePath &lt;- sapply(fileNames, function(x){<br />
paste(path,x,sep=‘/’)})<br />
data &lt;- lapply(filePath, function(x){<br />
read.csv(x, header=T)})<br />
————————————————<br />
版权声明：本文为CSDN博主「HuFeiHu-Blog」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。<br />
原文链接：<a href="https://blog.csdn.net/u011596455/article/details/79601113">https://blog.csdn.net/u011596455/article/details/79601113</a></p>
<p>批量读取bed文件之后调用covplot()函数逐个对数据进行统计，但是先不输出：</p>
<p>path=“/home/xxx/peaks_files” ## 指定输入文件所在路径<br />
fileNames = list.files(path, pattern=“*.bed$”)  ## 读入输入文件目录下后缀为bed的所有文件，到一个文件列表<br />
filePath &lt;- sapply(fileNames, function(x){ paste(path,x,sep=‘/’)}) ## 针对fileNames列表里面的文件名，分别加上路径<br />
data &lt;- lapply(filePath, function(x){ covplot(x, weight=“V4”)}) ### covplot 画图，但是这里不会输出，数据暂时存到列表里面</p>
<h1 id="下面指定一个输出路径"><a class="markdownIt-Anchor" href="#下面指定一个输出路径"></a> 下面指定一个输出路径</h1>
<p>outPath &lt;- “/home/yyy/peaks_genome_distribution” ## 指定输出目录#out_filePath &lt;- sapply(out_fileName, function(x){ paste(outPath ,x,sep=‘/’)}) ##输出路径名<br />
#length(data)</p>
<p>二、循环处理 Demo</p>
<p>outPath &lt;- “E:/实验数据/UseData/2013” ##输出路径<br />
out_fileName &lt;- sapply(names(data),function(x){<br />
paste(x, “.csv”, sep=‘’)}) ##csv格式<br />
out_filePath &lt;- sapply(out_fileName, function(x){<br />
paste(outPath ,x,sep=‘/’)}) ##输出路径名<br />
##输出文件<br />
for(i in 1:length(data)){<br />
write.csv(data[[i]], file=out_filePath[i], row.name=F)<br />
}<br />
————————————————<br />
版权声明：本文为CSDN博主「HuFeiHu-Blog」的原创文章，遵循 CC 4.0 BY-SA 版权协议，转载请附上原文出处链接及本声明。<br />
原文链接：<a href="https://blog.csdn.net/u011596455/article/details/79601113">https://blog.csdn.net/u011596455/article/details/79601113</a></p>
<p>将列表中的统计图逐个输出为pdf格式文件到指定路径，成功在指定目录下得到所有输入文件对应的统计图。</p>
<p>out_fileName &lt;- sapply(names(data),function(x){ paste(x, “.pdf”, sep=‘’)}) ##设定输出pdf后缀的文件名<br />
out_filePath &lt;- sapply(out_fileName, function(x){ paste(outPath ,x,sep=‘/’)}) ##设定输出文件及其完整路径名<br />
for(i in 1:length(data)){ pdf(out_filePath[i]) ; print(data[[i]]); dev.off() } # 依次画图并输出pdf，注意这里的print好重要</p>
<p>参考资料： 【1】<a href="https://anjingwd.github.io/AnJingwd.github.io/2017/09/04/R%E8%AF%AD%E8%A8%80%E4%B9%8B%E6%89%B9%E9%87%8F%E5%AF%BC%E5%85%A5csv%E6%96%87%E4%BB%B6%EF%BC%8C%E5%B9%B6%E4%BB%A5%E6%96%87%E4%BB%B6%E5%90%8D%E4%BD%9C%E4%B8%BA%E5%8F%98%E9%87%8F%E5%90%8D/">R语言之批量导入csv文件，并以文件名作为变量名</a> 【2】<a href="https://blog.csdn.net/u011596455/article/details/79601113">R语言–批量读取和写入目录</a> 【3】<a href="https://blog.csdn.net/m0_37893266/article/details/91169454">R：拆分文件名</a> 【4】<a href="https://life2cloud.com/cn/2018/11/pipelines-styles/">生物信息流程构建的几种方案</a> 【5】<a href="https://blog.csdn.net/yiifaa/article/details/73252980">R：中括号（a[i]）与双中括号（a[[i]]）的区别</a> 【6】<a href="https://zhuanlan.zhihu.com/p/83125846">R批量循环处理同一格式文件-csv,txt,excel</a> 【7】<a href="https://www.jianshu.com/p/e541fa218294">R语言循环多个文件画图生成一个or批量生成多个pdf文件</a> 【8】<a href="https://blog.csdn.net/c1z2w3456789/article/details/79546279">R中的高效批量处理函数（lapply sapply apply tapply mapply）</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>R：如何对坐标轴对应元素的顺序进行调整</title>
    <url>/2020/08/08/R-sorted-values-in-axis/</url>
    <content><![CDATA[<p>R作图中，坐标轴上的元素默认按照数字大小或者 Alphabetical order（字母顺序）排列。如果需要对坐标轴元素顺序进行调整，可以使用 reorder 命令。</p>
<p>例1. 柱状图</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Create data</span><br><span class="line">data &lt;- data.frame(</span><br><span class="line">  name=c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;,&quot;E&quot;) ,  </span><br><span class="line">  value=c(3,12,5,18,45)</span><br><span class="line">  )</span><br><span class="line"></span><br><span class="line"># Barplot</span><br><span class="line">ggplot(data, aes(x=name, y=value)) + </span><br><span class="line">geom_bar(stat = &quot;identity&quot;)</span><br><span class="line"># Barplot</span><br><span class="line">ggplot(data, aes(x=reorder(name, -value), y=value)) + </span><br><span class="line">geom_bar(stat = &quot;identity&quot;)</span><br></pre></td></tr></table></figure>
<p><img src="https://genehub.files.wordpress.com/2020/08/11111.jpeg" alt="" /></p>
<p><img src="https://genehub.files.wordpress.com/2020/08/222222.jpeg" alt="" /></p>
<p>例2. 点状图 + 多个子图</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ggplot(mpg, aes(displ, hwy)) +</span><br><span class="line">  geom_point() +</span><br><span class="line">  facet_wrap(vars(class)</span><br></pre></td></tr></table></figure>
<p><img src="https://genehub.files.wordpress.com/2020/08/test1.jpeg?w=845" alt="" /></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># To change the order in which the panels appear, change the levels</span><br><span class="line"># of the underlying factor.</span><br><span class="line">mpg$class2 &lt;- reorder(mpg$class, mpg$displ)</span><br><span class="line">ggplot(mpg, aes(displ, hwy)) +</span><br><span class="line">  geom_point() +</span><br><span class="line">  facet_wrap(vars(class2))</span><br></pre></td></tr></table></figure>
<p><img src="https://genehub.files.wordpress.com/2020/08/reorder.jpeg?w=845" alt="" /></p>
<p>其他案例：</p>
<p>Reordering groups in a <code>ggplot2</code> chart can be a struggle. This is due to the fact that ggplot2 takes into account the order of the <code>factor</code> levels, not the order you observe in your data frame. You can sort your input data frame with <code>sort()</code> or <code>arrange()</code>, it will never have any impact on your <code>ggplot2</code> output.</p>
<p>This post explains how to reorder the level of your factor through several examples. Examples are based on 2 dummy datasets:</p>
<p># Library<br />
library(ggplot2)<br />
library(dplyr)</p>
<h1 id="dataset-1-one-value-per-group"><a class="markdownIt-Anchor" href="#dataset-1-one-value-per-group"></a> Dataset 1: one value per group</h1>
<p>data &lt;- data.frame(<br />
name=c(“north”,“south”,“south-east”,“north-west”,“south-west”,“north-east”,“west”,“east”),<br />
val=sample(seq(1,10), 8 )<br />
)</p>
<h1 id="dataset-2-several-values-per-group-natively-provided-in-r"><a class="markdownIt-Anchor" href="#dataset-2-several-values-per-group-natively-provided-in-r"></a> Dataset 2: several values per group (natively provided in R)</h1>
<h1 id="mpg"><a class="markdownIt-Anchor" href="#mpg"></a> mpg</h1>
<h1 id="method-1-the-forecats-library"><a class="markdownIt-Anchor" href="#method-1-the-forecats-library"></a> Method 1: the <code>Forecats</code> library</h1>
<hr />
<p>The <a href="https://github.com/tidyverse/forcats">Forecats library</a> is a library from the <a href="https://www.tidyverse.org/">tidyverse</a> especially made to handle factors in R. It provides a suite of useful tools that solve common problems with factors. The <code>fact_reorder()</code> function allows to reorder the factor (<code>data$name</code> for example) following the value of another column (<code>data$val</code> here).</p>
<p># load the library<br />
library(forcats)</p>
<h1 id="reorder-following-the-value-of-another-column"><a class="markdownIt-Anchor" href="#reorder-following-the-value-of-another-column"></a> Reorder following the value of another column:</h1>
<p>data %&gt;%<br />
mutate(name = fct_reorder(name, val)) %&gt;%<br />
ggplot( aes(x=name, y=val)) +<br />
geom_bar(stat=“identity”, fill=“#f68060”, alpha=.6, width=.4) +<br />
coord_flip() +<br />
xlab(“”) +<br />
theme_bw()</p>
<h1 id="reverse-side"><a class="markdownIt-Anchor" href="#reverse-side"></a> Reverse side</h1>
<p>data %&gt;%<br />
mutate(name = fct_reorder(name, desc(val))) %&gt;%<br />
ggplot( aes(x=name, y=val)) +<br />
geom_bar(stat=“identity”, fill=“#f68060”, alpha=.6, width=.4) +<br />
coord_flip() +<br />
xlab(“”) +<br />
theme_bw()</p>
<p><img src="https://www.r-graph-gallery.com/267-reorder-a-variable-in-ggplot2_files/figure-html/unnamed-chunk-2-1.png" alt="" /></p>
<p><img src="https://www.r-graph-gallery.com/267-reorder-a-variable-in-ggplot2_files/figure-html/unnamed-chunk-2-2.png" alt="" /></p>
<p>If you have several values per level of your factor, you can specify which function to apply to determine the order. The default is to use the median, but you can use the number of data points per group to make the classification:</p>
<p># Using median<br />
mpg %&gt;%<br />
mutate(class = fct_reorder(class, hwy, .fun=‘median’)) %&gt;%<br />
ggplot( aes(x=reorder(class, hwy), y=hwy, fill=class)) +<br />
geom_boxplot() +<br />
xlab(“class”) +<br />
theme(legend.position=“none”) +<br />
xlab(“”)</p>
<h1 id="using-number-of-observation-per-group"><a class="markdownIt-Anchor" href="#using-number-of-observation-per-group"></a> Using number of observation per group</h1>
<p>mpg %&gt;%<br />
mutate(class = fct_reorder(class, hwy, .fun=‘length’ )) %&gt;%<br />
ggplot( aes(x=class, y=hwy, fill=class)) +<br />
geom_boxplot() +<br />
xlab(“class”) +<br />
theme(legend.position=“none”) +<br />
xlab(“”) +<br />
xlab(“”)</p>
<p><img src="https://www.r-graph-gallery.com/267-reorder-a-variable-in-ggplot2_files/figure-html/unnamed-chunk-3-1.png" alt="" /></p>
<p><img src="https://www.r-graph-gallery.com/267-reorder-a-variable-in-ggplot2_files/figure-html/unnamed-chunk-3-2.png" alt="" /></p>
<p>The last common operation is to provide a specific order to your levels, you can do so using the <code>fct_relevel()</code> function as follow:</p>
<p># Reorder following a precise order<br />
p &lt;- data %&gt;%<br />
mutate(name = fct_relevel(name,<br />
“north”, “north-east”, “east”,<br />
“south-east”, “south”, “south-west”,<br />
“west”, “north-west”)) %&gt;%<br />
ggplot( aes(x=name, y=val)) +<br />
geom_bar(stat=“identity”) +<br />
xlab(“”)<br />
#p</p>
<p><img src="https://www.r-graph-gallery.com/267-reorder-a-variable-in-ggplot2_files/figure-html/unnamed-chunk-5-1.png" alt="" /></p>
<h1 id="method-2-using-dplyr-only"><a class="markdownIt-Anchor" href="#method-2-using-dplyr-only"></a> Method 2: using <code>dplyr</code> only</h1>
<hr />
<p>The <code>mutate()</code> function of <code>dplyr</code> allows to create a new variable or modify an existing one. It is possible to use it to recreate a factor with a specific order. Here are 2 examples:</p>
<ul>
<li>The first use <code>arrange()</code> to sort your data frame, and reorder the factor following this desired order.</li>
<li>The second specifies a custom order for the factor giving the levels one by one.</li>
</ul>
<p>data %&gt;%<br />
arrange(val) %&gt;%    # First sort by val. This sort the dataframe but NOT the factor levels<br />
mutate(name=factor(name, levels=name)) %&gt;%   # This trick update the factor levels<br />
ggplot( aes(x=name, y=val)) +<br />
geom_segment( aes(xend=name, yend=0)) +<br />
geom_point( size=4, color=“orange”) +<br />
coord_flip() +<br />
theme_bw() +<br />
xlab(“”)</p>
<p>data %&gt;%<br />
arrange(val) %&gt;%<br />
mutate(name = factor(name, levels=c(“north”, “north-east”, “east”, “south-east”, “south”, “south-west”, “west”, “north-west”))) %&gt;%<br />
ggplot( aes(x=name, y=val)) +<br />
geom_segment( aes(xend=name, yend=0)) +<br />
geom_point( size=4, color=“orange”) +<br />
theme_bw() +<br />
xlab(“”)</p>
<p><img src="https://www.r-graph-gallery.com/267-reorder-a-variable-in-ggplot2_files/figure-html/unnamed-chunk-6-1.png" alt="" /></p>
<p><img src="https://www.r-graph-gallery.com/267-reorder-a-variable-in-ggplot2_files/figure-html/unnamed-chunk-6-2.png" alt="" /></p>
<h1 id="method-3-the-reorder-function-of-base-r"><a class="markdownIt-Anchor" href="#method-3-the-reorder-function-of-base-r"></a> Method 3: the <code>reorder()</code> function of base R</h1>
<hr />
<p>In case your an unconditional user of the good old R, here is how to control the order using the <code>reorder()</code> function inside a <code>with()</code> call:</p>
<p># reorder is close to order, but is made to change the order of the factor levels.<br />
mpg$class = with(mpg, reorder(class, hwy, median))</p>
<p>p &lt;- mpg %&gt;%<br />
ggplot( aes(x=class, y=hwy, fill=class)) +<br />
geom_violin() +<br />
xlab(“class”) +<br />
theme(legend.position=“none”) +<br />
xlab(“”)<br />
#p</p>
<p><img src="https://www.r-graph-gallery.com/267-reorder-a-variable-in-ggplot2_files/figure-html/unnamed-chunk-8-1.png" alt="" /></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>R：Using R to draw Heatmap</title>
    <url>/2016/10/11/R-using-r-to-draw-heatmap/</url>
    <content><![CDATA[<h4 id="1-heatmap"><a class="markdownIt-Anchor" href="#1-heatmap"></a> #1 heatmap</h4>
<p><a href="http://blog.qiubio.com:8080/archives/2477">http://blog.qiubio.com:8080/archives/2477</a></p>
<h4 id="2-heatmap2-需要安装gplots包"><a class="markdownIt-Anchor" href="#2-heatmap2-需要安装gplots包"></a> #2 heatmap.2 【需要安装gplots包】</h4>
<p><a href="https://www.r-bloggers.com/r-heatmaps-with-gplots/">https://www.r-bloggers.com/r-heatmaps-with-gplots/</a></p>
<h4 id="3-d3heatmap-可以生成web交互图"><a class="markdownIt-Anchor" href="#3-d3heatmap-可以生成web交互图"></a> #3 d3heatmap 【可以生成Web交互图】</h4>
<p><a href="https://blog.rstudio.org/2015/06/24/d3heatmap/">https://blog.rstudio.org/2015/06/24/d3heatmap/</a></p>
<h4 id="4-pheatmap-全称pretty-heatmap生成的图片比较好看"><a class="markdownIt-Anchor" href="#4-pheatmap-全称pretty-heatmap生成的图片比较好看"></a> #4 pheatmap 【全称pretty heatmap，生成的图片比较好看】</h4>
<p><a href="http://blog.sciencenet.cn/blog-1334016-932200.html">http://blog.sciencenet.cn/blog-1334016-932200.html</a></p>
<h4 id="5-ggplot2"><a class="markdownIt-Anchor" href="#5-ggplot2"></a> #5 ggplot2</h4>
<p><a href="https://learnr.wordpress.com/2010/01/26/ggplot2-quick-heatmap-plotting/">https://learnr.wordpress.com/2010/01/26/ggplot2-quick-heatmap-plotting/</a> <strong>#6 ComplexHeatmap</strong> 可以对热图进行2D的注释，绘制用于注释的框线图、曲线图等。 <a href="http://blog.qiubio.com:8080/archives/4232">http://blog.qiubio.com:8080/archives/4232</a> <strong>#7 heatmap3</strong> 可以对heatmap的每一个单元格做出特殊的标记，并且对行和列加上2D的基本注释图像 <strong>#8 heatPlus</strong> 可以对行和列进行多种不同数据类型的注释，也就是说对行或者列可以绘制2D的基本注释图像，比如说曲线，点图，以及histograms等 <strong>#9 heatmaply</strong> heatmaply是基于plotly的热图包。<a href="https://plot.ly/javascript/">plotly.js</a> 是一个基于javascript的强大的交互绘图包。 <strong>#10 fields</strong>   #11</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>R：火山图 volcano plot</title>
    <url>/2018/04/25/R-volcano-plot-in-R/</url>
    <content><![CDATA[<p>两个实验组之间的若干个基因的差异倍数比较，可以通过 Volcano Plot 图形化展示。 <img src="https://genehub.files.wordpress.com/2018/04/qqe688aae59bbe20180425163433.jpg" alt="QQ截图20180425163433" /> 例如 DEseq2 对转录组测序的样品做差异基因分析之后，会得到一个基因表达差异的表格的。案例使用数据的来源是 GitHub：<a href="https://github.com/hbc/fabio-splicing/blob/master/new-samples/2016-07-29%5C_fabio-newlines/summary/control-vs-e7107-deseq2.csv">https://github.com/hbc/fabio-splicing/blob/master/new-samples/2016-07-29\_fabio-newlines/summary/control-vs-e7107-deseq2.csv</a> 下载上述数据之后，运行下面的命令即可得到文章起始的图。</p>
<p>setwd(“C:\\Users\\FengLei\\Desktop\\scatter-plot”)<br />
library(ggplot2)<br />
library(ggthemes)<br />
library(Cairo)</p>
<p>data=read.csv(“control-vs-e7107-deseq2.csv”, head=T)</p>
<h3 id="火山图"><a class="markdownIt-Anchor" href="#火山图"></a> 火山图</h3>
<p>data<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mi>h</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>h</mi><mi>o</mi><mi>l</mi><mi>d</mi><mo>=</mo><mi>a</mi><mi>s</mi><mi mathvariant="normal">.</mi><mi>f</mi><mi>a</mi><mi>c</mi><mi>t</mi><mi>o</mi><mi>r</mi><mo stretchy="false">(</mo><mi>i</mi><mi>f</mi><mi>e</mi><mi>l</mi><mi>s</mi><mi>e</mi><mo stretchy="false">(</mo><mi>d</mi><mi>a</mi><mi>t</mi><mi>a</mi></mrow><annotation encoding="application/x-tex">threshold = as.factor(ifelse(data</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">e</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord">.</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">a</span><span class="mord mathnormal">c</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mopen">(</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">s</span><span class="mord mathnormal">e</span><span class="mopen">(</span><span class="mord mathnormal">d</span><span class="mord mathnormal">a</span><span class="mord mathnormal">t</span><span class="mord mathnormal">a</span></span></span></span>pvalue =1, ‘Up’, ifelse(data<span class='katex-error' title='ParseError: KaTeX parse error: Expected &#039;EOF&#039;, got &#039;&amp;&#039; at position 15: pvalue &lt; 0.05 &amp;̲ data'>pvalue &lt; 0.05 &amp; data</span>log2FoldChange &lt;= -1, ‘Down’, ‘Not’)))<br />
ggplot(data=data, aes(x=log2FoldChange, y=-log10(pvalue), colour=threshold, fill=threshold)) +<br />
scale_color_manual(values=c(“blue”, “grey”,“red”))+<br />
geom_point(alpha=0.4, size=1.2) +</p>
<h1 id="xlimc-4-4"><a class="markdownIt-Anchor" href="#xlimc-4-4"></a> xlim(c(-4, 4)) +</h1>
<h1 id="ylimc0-75"><a class="markdownIt-Anchor" href="#ylimc0-75"></a> ylim(c(0, 7.5)) +</h1>
<p>theme_bw(base_size = 12, base_family = “Times”) +<br />
geom_vline(xintercept=c(-1,1),lty=4,col=“grey”,lwd=0.6)+<br />
geom_hline(yintercept = -log10(0.05),lty=4,col=“grey”,lwd=0.6)+<br />
theme(legend.position=“right”,<br />
panel.grid=element_blank(),<br />
legend.title = element_blank(),<br />
legend.text= element_text(face=“bold”, color=“black”,family = “Times”, size=8),<br />
plot.title = element_text(hjust = 0.5),<br />
axis.text.x = element_text(face=“bold”, color=“black”, size=12),<br />
axis.text.y = element_text(face=“bold”, color=“black”, size=12),<br />
axis.title.x = element_text(face=“bold”, color=“black”, size=12),<br />
axis.title.y = element_text(face=“bold”,color=“black”, size=12))+<br />
labs(x=“log2 (Fold Change)”,y=“-log10 (P-value)”,title=“Volcano Plot”)</p>
<p>注意 R 语言中 ifelse() 函数的使用方法。其基本语法格式如下： if(con,statement1,statement2) con 是逻辑条件，当逻辑条件的值为 TRUE 时，则输出 statement1 的值，否则输出 statement2 的值。 也就是说 ifelse() 函数只能输出两个类型的值，然而本文使用的转录组案例中，组间基因变化有三种情况，分别为上调、下调与无明显变化，这里可以使用 ifelse() 的嵌套结构来实现三种判断值的输出。</p>
<blockquote>
<p># ifelse() 函数使用例1</p>
<blockquote>
<p>x y # 如果向量 x 中的元素值非0，就输出0，否则输出1<br />
y<br />
[1] 0 1 0 1 0 0 1 1</p>
<h1 id="ifelse-函数使用例2-嵌套结构的应用"><a class="markdownIt-Anchor" href="#ifelse-函数使用例2-嵌套结构的应用"></a> ifelse() 函数使用例2: 嵌套结构的应用</h1>
<p>x y0, 2*x-1, ifelse(x==0,0,3*x-10))</p>
<h1 id="如向量-x-中元素值大于0等于0和小于0分三种情况做转换"><a class="markdownIt-Anchor" href="#如向量-x-中元素值大于0等于0和小于0分三种情况做转换"></a> 如向量 x 中元素值大于0，等于0和小于0，分三种情况做转换</h1>
<p>y<br />
[1] 5 19 0 -13 -40</p>
</blockquote>
</blockquote>
<p>参考资料 [1] ggplot 与火山图：<a href="https://www.tanboyu.com/ggplot2-for-volcano.html">https://www.tanboyu.com/ggplot2-for-volcano.html</a> [2] R 语言 ifelse() 函数使用：<a href="http://www.biye5u.com/article/R/2017/6352.html">http://www.biye5u.com/article/R/2017/6352.html</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Adobe Illustrator (AI) 生物研究的作图笔记</title>
    <url>/2020/09/16/Visualization-Adobe-Illustrator-Learning-Usage/</url>
    <content><![CDATA[<p>Adobe Illustrator 在科研日常修图中应用广泛，而且可以用来绘制细胞、个体、通路等示意图，这里对学习过程中一些元素做个笔记。</p>
<p>关键词：Adobe Illustrator；画图；绘图；AI</p>
<p><strong>1 如何画一个圆圈，且边缘是虚线？</strong></p>
<p>在左侧工具栏选择“椭圆工具”（快捷键：L），在画板上先点击鼠标左键，然后按住shift键不松开，拖动鼠标，在另一个位置点一下鼠标左键，即可得到圆形。单击鼠标左键选中圆圈，上方工具栏有“描边”字样，单击进入菜单，选中“虚线”前面的框框，即可设置虚线，虚线粗细/间隔都可以设置。</p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200916100211.png?w=306" alt="" /></p>
<p><strong>2 如何进行填色或描边？如何结合吸管工具进行颜色设定？</strong></p>
<p>在软件左侧工具栏，“填色”和“描边”两个正方形图标有部分重叠，哪个图标位于上层，就表示将对所选目标的相应部位进行颜色操作，可以用鼠标点击这两个图标进行选择，也可以按键“x”进行快捷切换。以描边为例，我希望圆形边缘颜色与另一个图形A的颜色一致，那么我先点击“描边”，表示将对边缘着色，再点击选中圆形，再点击左侧工具栏中“吸管”工具（快捷键：I），此时按住shift键不松开，将吸管工具在图形A的色彩区域点一下，即可看到圆形边缘颜色与图形A颜色一致。这里关键是shift键，之前一直不知道 T_T</p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200916101800.png?w=406" alt="" /></p>
<p>Adobe 官网也有教程：<a href="https://helpx.adobe.com/cn/illustrator/using/painting-fills-strokes.html">https://helpx.adobe.com/cn/illustrator/using/painting-fills-strokes.html</a></p>
<p><img src="https://i.imgur.com/01EbFL6.jpeg" alt="" /></p>
<p><strong>3 如何设定渐变效果，使一个形状具有立体感？</strong></p>
<p>选中软件左侧工具栏“渐变工具”按钮（快捷键：G），再点击需要设定渐变色的图形，图形上就会出现一个渐变条。软件右侧有一个“渐变”按钮，点击即可对所选图形的渐变颜色/范围/模式进行设定。渐变类型有线性和径向，径向即下图右侧所示，可以做出很好的立体感。颜色设定，可看到渐变条下方有几个可以移动的颜色快，里面可以设定颜色。</p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200916102331.png?w=624" alt="" /></p>
<p><strong>4 如何对一个完整的形状分割成若干部分？如果将重叠的图形进行分割？</strong></p>
<p>如下图所示，A为基本图形元素。B为将椭圆形切成两半，选中图形之后，左键按住软件左侧的“橡皮擦工具图标”，可以跳出“剪刀”图标（快捷键：C），在图形的边缘上选择两个点各自点击，就可以依据两点形成的直线将形状分开。C为长按“橡皮擦工具”图标并选择跳出来的“刻刀”工具，在图形上随便划几下，就可按照划过的痕迹分割，看到C图效果。D是两个形状的重叠，快捷键Ctrl+Shift+F9，出来“路径选择器”，有不同的剪切模式，剪切之后可看到重叠边缘出现交点，右键并选择“取消编组”，就可得到E/F这样的分割效果。</p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200916153510.png?w=1024" alt="" /></p>
<p><strong>5 设置渐变效果的时候如果只有黑白颜色选项怎么办？</strong></p>
<p>在AI中使用渐变填充的时候会发现颜色只有黑白色，这是因为颜色模式选择的是灰度，这就需要更改为RGB模式。打开渐变的属性框，我们在渐变条上双击色标只显示黑白颜色。这是因为颜色模式为灰度，我们鼠标点击右上角的“三横线”按钮。这个时候就会弹出下拉菜单，找到并点击——切换为RGB模式。就可以选择彩色渐变了。</p>
<p><a href="https://genehub.files.wordpress.com/2020/10/e6b890e58f98e58faae69c89e9bb91e799bde889b2.png"><img src="https://genehub.files.wordpress.com/2020/10/e6b890e58f98e58faae69c89e9bb91e799bde889b2.png?w=378" alt="" /></a></p>
<p><strong>6 如何将单个元素旋转复制</strong></p>
<p>应用场景：一个椭圆，旋转复制，成为韦恩图。平时也可以用来将单个花瓣旋转复制成为一朵花，或者单个细胞膜结构重复形成细胞膜。如下图所示，先画一个椭圆，并单击选中，再点击左侧工具栏“旋转”按钮，此时可见椭圆中心出现小圆斑，按住Alt键的同时可以挪动小圆斑，小圆斑表示旋转中心，松开鼠标左键之后，跳出一个旋转对话框，设定旋转角度，比如我希望得到元素的5次重复，设定72度，点击“复制”，然后按Ctrl+D即可逐次复制，得到右边的效果。</p>
<p><img src="https://i.imgur.com/jBv5JEK.jpeg" alt="" /></p>
<p><strong>7 细胞膜的画法</strong></p>
<p>细胞膜，即磷脂双分子层，由磷脂分子紧密排列而成。网上的教程是先画一个磷脂分子：即一个圆圈加两个尾巴，上下对称翻转复制，组合之后成为加入画笔，然后用其他形状，比如直线、曲线、圆形，只要点击画笔中的“磷脂双分子”元素，就可以得到下图下方的细胞膜效果。我希望将圆形的磷脂分子做一个颜色渐变，圆形就有了球形的效果，当把这个立体效果的磷脂分子添加到画笔，遇到了一个软件报错：“所选图稿包含不能在散点画笔中使用的元素”，原来渐变是不能用来作为画笔的设置的，但是文献里面明明可以看到别人画的细胞膜有这个效果。在 <a href="https://www.bilibili.com/video/BV1db41127zL/?spm_id_from=333.788.recommend_more_video.0">B 站</a> 找到了一个解决方案，就是不用将磷脂分子加入画笔，而是直接复制，按住Alt键的同时向右拖动磷脂分子，就得到一个复制品，然后Ctrl+D，就会重复执行上一步的复制操作，多次Ctrl+D，就得到下图所示的立体效果细胞膜。</p>
<p><img src="https://i.imgur.com/lhagU69.jpeg" alt="" /></p>
]]></content>
      <categories>
        <category>Visualization</category>
      </categories>
  </entry>
  <entry>
    <title>Remove Background from Image</title>
    <url>/2021/01/04/Visualization-Remove-Background-from-Image/</url>
    <content><![CDATA[<p>没有扫描仪的情况下，往往会用手机拍摄文档照片，但是其背景通常是不均匀的灰色，不适合打印/复印。如何通过调整使背景变成白色或接近白色？</p>
<p>对于背景均匀的情况，在 PS 中用 ctrl+L 调整色阶或者曲线就可以满足要求。但是受到拍照的时候光线的原因，照片的背景颜色一般会深浅不一，而且手机拍摄的照片往往会有畸变。</p>
<p>下面记录一实用的办法：“高斯模糊”配合“划分”模式做出扫描的效果</p>
<ol>
<li>PS 打开图片文件。由于手机拍摄的照片角度可能不够理想，往往使文档有一定畸变，如果需要调整，选中左侧工具栏“剪裁工具”里面有一个“透视剪裁工具”，鼠标左键依次单击文档的四角，按下回车键，就可以把“透视”一定程度上矫正回来。</li>
<li>crtl+J复制一个图层出来，点击菜单栏：滤镜 -&gt; 模糊 -&gt; 高斯模糊，参数输入100，点击确定。此时视野中的图片变成了模糊的一片。</li>
<li>软件右下角图层设置区域，“不透明度”字样左边有个“正常”字样，将其重设为“划分”。此时视野中的图片背景变成了白色，文字颜色深灰色。</li>
<li>按下Ctrl+Alt+Shift+E，盖印一个图层。把之前的图层合并成另一新图层。再将其复制新图层，右下角图层栏目下“正常”模式更改成“颜色加深”，即可看到文字从深灰色变成黑色。</li>
</ol>
<p>参考资料：B 站有一个视频教学：<a href="https://www.bilibili.com/s/video/BV1i7411Z718">https://www.bilibili.com/s/video/BV1i7411Z718</a></p>
<p><img src="https://199508.com/wp-content/uploads/2016/03/31db1439868311.jpg" alt="复制图层" /><br />
<img src="https://199508.com/wp-content/uploads/2016/03/be261439868309.jpg" alt="高斯模糊" /><br />
<img src="https://199508.com/wp-content/uploads/2016/03/ac5a1439868306.jpg" alt="划分" /><br />
<img src="https://pic2.zhimg.com/80/v2-b7fd16a3ea91d8285cb903aede434689_720w.jpg?source=1940ef5c" alt="效果图（其实可以更好）" /></p>
]]></content>
      <categories>
        <category>Visualization</category>
      </categories>
  </entry>
  <entry>
    <title>解决Can&#39;t locate CPAN.pm in @INC的问题</title>
    <url>/2014/08/30/cant-locate-iozlib-pm/</url>
    <content><![CDATA[<p>Linux <strong>RedHat</strong> 的系统，解决“Can’t locate <a href="http://CPAN.pm">CPAN.pm</a> in @INC”的问题。 参考博文：<a href="http://blog.sina.com.cn/s/blog%5C_645e2f0b01012npz.html">http://blog.sina.com.cn/s/blog\_645e2f0b01012npz.html</a> 实际步骤： $ wget <a href="ftp://ftp.muug.mb.ca/mirror/redhat/redhat/linux/6.2/cpan/i386/perl-CPAN-1.52-6.i386.rpm">ftp://ftp.muug.mb.ca/mirror/redhat/redhat/linux/6.2/cpan/i386/perl-CPAN-1.52-6.i386.rpm</a> $ su root # rpm -ivh perl-CPAN-1.52-6.i386.rpm 至此，CPAN模块就安装好了。 可运行 $ rpm -q perl-CPAN 命令进行检验。</p>
<span id="more"></span>
<p><img src="http://rpm.pbone.net/images/brakreklam.jpg" alt="" /></p>
<p>perl-CPAN rpm build for : <strong>RedHat 6.X</strong>. For other distributions click <a href="http://rpm.pbone.net/index.php3?stat=3&amp;search=perl-CPAN&amp;srodzaj=3">perl-CPAN</a>.</p>
<p>Name : <strong>perl-CPAN</strong></p>
<p>Version : 1.52</p>
<p>Vendor : <a href="http://rpm.pbone.net/index.php3/stat/11/vendor/642/com/Red%20Hat,%20Inc_.html">Red Hat, Inc_</a></p>
<p>Release : 6</p>
<p>Date : 2000-02-18 02:48:25</p>
<p>Group : <a href="http://rpm.pbone.net/index.php3/stat/17/dept/3/idg/CPAN_CPAN">CPAN/CPAN</a></p>
<p>Source RPM : <a href="http://rpm.pbone.net/index.php3/stat/3/srodzaj/2/search/perl-CPAN-1.52-6.src.rpm">perl-CPAN-1.52-6.src.rpm</a></p>
<p>Size : 0.18 MB</p>
<p>Packager : <a href="http://rpm.pbone.net/index.php3/stat/15/pakman/854/com/Red%20Hat,%20Inc_%20%3Chttp://bugzilla_redhat_com/bugzilla%3E.html">Red Hat, Inc_ &lt; http://bugzilla_redhat_com/bugzilla&gt;</a></p>
<p>Summary : CPAN module for perl (CPAN)</p>
<p>Description : CPAN module for Perl</p>
<p>RPM found in directory: /mirror/archive.download.redhat.com/pub/redhat/linux/6.2/cpan/i386</p>
<p><a href="http://rpm.pbone.net/index.php3/stat/4/idpl/2395231/dir/redhat_6.x/com/perl-CPAN-1.52-6.i386.rpm.html#content">Content of RPM</a>  <a href="http://rpm.pbone.net/index.php3/stat/22/idpl/2395231/com/changelog.html">Changelog</a>  <a href="http://rpm.pbone.net/index.php3/stat/4/idpl/2395231/dir/redhat_6.x/com/perl-CPAN-1.52-6.i386.rpm.html#provides">Provides</a> <a href="http://rpm.pbone.net/index.php3/stat/4/idpl/2395231/dir/redhat_6.x/com/perl-CPAN-1.52-6.i386.rpm.html#requires">Requires</a></p>
<p>Download</p>
<p><a href="http://ftp.muug.mb.ca">ftp.muug.mb.ca</a></p>
<p><a href="ftp://ftp.muug.mb.ca/mirror/redhat/redhat/linux/6.2/cpan/i386/perl-CPAN-1.52-6.i386.rpm">perl-CPAN-1.52-6.i386.rpm</a></p>
<p><a href="http://carroll.aset.psu.edu">carroll.aset.psu.edu</a></p>
<p><a href="ftp://carroll.aset.psu.edu/pub/.mirrors/1/rh-mirror.redhat.com/redhat/linux/6.2/cpan/i386/perl-CPAN-1.52-6.i386.rpm">perl-CPAN-1.52-6.i386.rpm</a></p>
<p><a href="http://ftp.pbone.net">ftp.pbone.net</a></p>
<p><a href="ftp://ftp.pbone.net/mirror/archive.download.redhat.com/pub/redhat/linux/6.2/cpan/i386/perl-CPAN-1.52-6.i386.rpm">perl-CPAN-1.52-6.i386.rpm</a></p>
<p><a href="http://ftp.sunet.se">ftp.sunet.se</a></p>
<p><a href="ftp://ftp.sunet.se/pub/Linux/distributions/redhat/redhat-archive/redhat/linux/6.2/cpan/i386/perl-CPAN-1.52-6.i386.rpm">perl-CPAN-1.52-6.i386.rpm</a></p>
<p>Search for other platforms <a href="http://rpm.pbone.net/index.php3/stat/3/srodzaj/2/search/perl-CPAN-1.52-6.sparc.rpm">perl-CPAN-1.52-6.sparc.rpm</a> <a href="http://rpm.pbone.net/index.php3/stat/3/srodzaj/2/search/perl-CPAN-1.52-6.alpha.rpm">perl-CPAN-1.52-6.alpha.rpm</a> <a href="http://rpm.pbone.net/index.php3/stat/3/srodzaj/2/search/perl-CPAN-1.52-6.ppc.rpm">perl-CPAN-1.52-6.ppc.rpm</a> <a href="http://rpm.pbone.net/index.php3/stat/3/srodzaj/2/search/perl-CPAN-1.52-6.ia64.rpm">perl-CPAN-1.52-6.ia64.rpm</a> <a href="http://rpm.pbone.net/index.php3/stat/3/srodzaj/2/search/perl-CPAN-1.52-6.s390.rpm">perl-CPAN-1.52-6.s390.rpm</a></p>
<p><strong>Provides :</strong> perl(Bundle::CPAN) perl(CPAN) perl(CPAN::Author) perl(CPAN::Bundle) perl(CPAN::CacheMgr) perl(CPAN::Complete) perl(CPAN::Config) perl(CPAN::Debug) perl(CPAN::Distribution) perl(CPAN::Eval) perl(CPAN::FTP) perl(CPAN::FTP::netrc) perl(CPAN::FirstTime) perl(CPAN::Index) perl(CPAN::InfoObj) perl(CPAN::Mirrored::By) perl(CPAN::Module) perl(CPAN::Nox) perl(CPAN::Queue) perl(CPAN::Shell) perl(CPAN::Tarzip) perl-CPAN <strong>Requires :</strong></p>
<p><a href="http://rpm.pbone.net/index.php3/stat/3/srodzaj/1/search/perl">/usr/bin/perl</a></p>
<p><a href="http://rpm.pbone.net/index.php3/stat/3/srodzaj/1/search/perl">perl =&gt; 5.00503</a></p>
<p><strong>Content of RPM :</strong> /usr/bin/cpan /usr/lib/perl5/5.00503/Bundle/CPAN.pm /usr/lib/perl5/5.00503/CPAN.pm /usr/lib/perl5/5.00503/CPAN/FirstTime.pm /usr/lib/perl5/5.00503/CPAN/Nox.pm /usr/lib/perl5/man/man3/<a href="http://rpm.pbone.net/index.php3/stat/45/idpl/2395231/numer/3/nazwa/Bundle::CPAN">Bundle::CPAN</a>.3.gz /usr/lib/perl5/man/man3/<a href="http://rpm.pbone.net/index.php3/stat/45/idpl/2395231/numer/3/nazwa/CPAN">CPAN</a>.3.gz /usr/lib/perl5/man/man3/<a href="http://rpm.pbone.net/index.php3/stat/45/idpl/2395231/numer/3/nazwa/CPAN::FirstTime">CPAN::FirstTime</a>.3.gz /usr/lib/perl5/man/man3/<a href="http://rpm.pbone.net/index.php3/stat/45/idpl/2395231/numer/3/nazwa/CPAN::Nox">CPAN::Nox</a>.3.gz</p>
<p>========================================== 解决Can’t locate IO/File.pm in @INC的问题 首先进入下载页：<a href="http://search.cpan.org/~tomhughes/IO-Zlib-1.09/Zlib.pm">http://search.cpan.org/~tomhughes/IO-Zlib-1.09/Zlib.pm</a> 然后复制Zlib.pm的下载链接：<a href="http://search.cpan.org/CPAN/authors/id/T/TO/TOMHUGHES/IO-Zlib-1.09.tar.gz">http://search.cpan.org/CPAN/authors/id/T/TO/TOMHUGHES/IO-Zlib-1.09.tar.gz</a> 并且下载到linux里：$ wget <a href="http://search.cpan.org/CPAN/authors/id/T/TO/TOMHUGHES/IO-Zlib-1.09.tar.gz">http://search.cpan.org/CPAN/authors/id/T/TO/TOMHUGHES/IO-Zlib-1.09.tar.gz</a> 随后开始安装： $ tar zxvf *tzr.gz $ cd IO-Zlib-1.09 $ perl <a href="http://Makefile.PL">Makefile.PL</a> $make $ su root #make install 大功告成！</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>could not find function \&quot;sqliteQuickSQL\&quot;</title>
    <url>/2015/02/05/could-not-find-function-sqlitequicksql/</url>
    <content><![CDATA[<p>问题描述：转录组测序数据分析，使用cummeRbund的过程中报错： &gt; library(cummeRbund) Loading required package: BiocGenerics Loading required package: parallel Attaching package: ‘BiocGenerics’ The following objects are masked from ‘package:parallel’: clusterApply, clusterApplyLB, clusterCall, clusterEvalQ, clusterExport, clusterMap, parApply, parCapply, parLapply, parLapplyLB, parRapply, parSapply, parSapplyLB The following object is masked from ‘package:stats’: xtabs The following objects are masked from ‘package:base’: anyDuplicated, append, as.data.frame, as.vector, cbind, colnames, do.call, duplicated, eval, evalq, Filter, Find, get, intersect, is.unsorted, lapply, Map, mapply, match, mget, order, paste, pmax, pmax.int, pmin, pmin.int, Position, rank, rbind, Reduce, rep.int, rownames, sapply, setdiff, sort, table, tapply, union, unique, unlist Loading required package: RSQLite Loading required package: DBI Loading required package: ggplot2 Loading required package: reshape2 Loading required package: fastcluster Attaching package: ‘fastcluster’ The following object is masked from ‘package:stats’: hclust Loading required package: rtracklayer Loading required package: GenomicRanges Loading required package: IRanges Loading required package: GenomeInfoDb Loading required package: Gviz Loading required package: grid Attaching package: ‘cummeRbund’ The following object is masked from ‘package:GenomicRanges’: promoters The following object is masked from ‘package:IRanges’: promoters &gt; cuff_data &lt;- readCufflinks(‘diff_out_CM_c.vs.m’) Creating database diff_out_CM_c.vs.m/cuffData.db Error in FUN(c(“n-- Creator: MySQL Workbench 5.2.33/ExportSQLite plugin 2009.12.02n-- Author: Loyal Goffn-- Caption: New Modeln-- Project: Name of the projectn-- Changed: 2012-04-30 22:21n-- Created: 2011-05-02 12:52nPRAGMA foreign_keys = OFF”, : could not find function “sqliteQuickSQL” ======================================= 失败的解决方法： &gt; remove.packages(“RSQLite”) &gt;install.packages(“/home/fenglei/Downloads/RSQLite_0.9-0.tar.gz”) &gt; library(RSQLite) Loading required package: DBI &gt; install.packages(“DBI”) 成功解决方法 First, upgrade biocLite: &gt;source(“<a href="http://www.bioconductor.org/biocLite.R">http://www.bioconductor.org/biocLite.R</a>”) &gt;biocLite(“BiocUpgrade”) Then, install “cummeRbund” &gt;biocLite(“cummeRbund”) Last, install or reinstall “RSQLite” &gt;biocLite(“RSQLite”) I hope it works for you.</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>DEseq的sizeFactors什么意思？</title>
    <url>/2015/10/07/deseq%E7%9A%84sizefactors%E4%BB%80%E4%B9%88%E6%84%8F%E6%80%9D%EF%BC%9F/</url>
    <content><![CDATA[<p>？？？？？？？？？？？ &gt;sizeFactors( cds )</p>
<p>UN72_1    UN72_2    UN72_3    ST72_1    ST72_2    ST72_3</p>
<p>0.9805609 1.0420015 0.9164864 1.1083583 0.9599370 1.1462168</p>
<p>Apparently, the way this works (<a href="http://www.biostars.org/p/12273/">http://www.biostars.org/p/12273/</a>) is that you take the genometric mean of each condition for a gene and use this as its reference value. Then you divide the gene expression value for each conditions by its reference value to create a list of values (quotient ie result of the division) for each condition. The size factor is the median value of this list, as there is a list per condition it will generate a size factor value for each condition. The counts are normalised by dividing each column by its size factor, here lets look before and after: &gt; head(counts(cds))</p>
<p>UN72_1 UN72_2 UN72_3 ST72_1 ST72_2 ST72_3</p>
<p>GWD8ZKM01ESPR2          0      0      0      0      0      0</p>
<p>g10671t00001            2      1      1      0      0      0</p>
<p>&gt; head(counts(cds,normalized=TRUE))</p>
<p>UN72_1    UN72_2   UN72_3 ST72_1 ST72_2 ST72_3</p>
<p>GWD8ZKM01ESPR2     0.000000 0.0000000 0.000000      0      0      0</p>
<p>g10671t00001       2.039649 0.9596916 1.091124      0      0      0</p>
<p>g16789t00001       0.000000 0.0000000 0.000000      0      0      0</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Fasta与Fastq文件操作</title>
    <url>/2015/06/23/fasta%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9Cfasta-file-statstics/</url>
    <content><![CDATA[<p><strong>1 fastx_toolkits</strong></p>
<blockquote>
<p>fastx_artifacts_filter fastx_nucleotide_distribution_graph.sh fastx_reverse_complement<br />
fastx_barcode_splitter.pl fastx_nucleotide_distribution_line_graph.sh fastx_trimmer<br />
fastx_clipper fastx_quality_stats fastx_uncollapser<br />
fastx_collapser fastx_renamer</p>
<p>fastqc fastq-dump.2.4.2 fastq-load.2.4.2 fastq_quality_converter fastq_to_fasta<br />
fastq-dump fastq-load fastq_masker fastq_quality_filter<br />
fastq-dump.2 fastq-load.2 fastq_quality_boxplot_graph.sh fastq_quality_trimmer</p>
</blockquote>
<p><strong>2 iTools (BGI_Shenzhen)</strong></p>
<blockquote>
<p><em>$ iTools Fatools</em></p>
<p>FaTools Usage:</p>
<p>stat quick stat fasta’s info<br />
findN quick find fasta’s N region<br />
findSubSeq quick find fasta’s one SubSeq region<br />
extract get fragments from seq based on coordinates<br />
regenerate merge a new Ref Based scaffolds<br />
split split InFa, each Seq one File<br />
filter filter the short &amp; too many ‘N’ Seq<br />
cutF cut fasta to fixed Num of subFile in total<br />
cutS cut fasta to fixed Num of Seq in each subfile<br />
getSP get Seq by specified ID or pattern<br />
getSN get Seq by specified order Num range<br />
reform reform/modify the sequence<br />
sort rank the seq By SeqID or Length<br />
getCdsPep get CDS Seq &amp; Pep Seq based the gffFile<br />
CDS2Pep Translate CDS-Seq to protein-Seq<br />
SamHeader quick give out the Samheader of Fa<br />
BaseModify modify the single base in seq<br />
ChangPosi Change Position back to Scaffolds(regenerate)</p>
</blockquote>
<p><strong>3 常用工具</strong></p>
<blockquote>
<p>3.1 将fasta文件转换成每行固定的碱基数目：<br />
iTools   Fatools  reform   （不要加这一参数：  -oneline ）<br />
fastx_formater</p>
<p>3.2 将fasta的序列名重新命名<br />
seqtk rename<br />
fastx_renamer</p>
<p>3.3 统计fasta的序列长度，N50，N90信息<br />
perl ~/local/app/NGSQCToolkit/Statistics/N50Stat.pl -i genome.fa -o N50.stat.out</p>
<p>3.4 按照坐标从基因组提取某段序列<br />
iTools Fatools extract</p>
<p>3.5 对Fasta序列进行反转<br />
fastx_reverse_complement</p>
<p>3.6 将fasta序列集合里某个长度范围的子序列提取出来<br />
<a href="http://prinseq-lite.pl">prinseq-lite.pl</a> -fastq yourfile.fastq -out_format 4 -out_good seqs_good -min_len 21 -trim_to_len 25</p>
<p>3.7 依据序列ID从fastq提取序列<br />
seqtk subseq 800bp_10M_1.fq FR-oneread.ids.list &gt; FR-oneread.ids.fq</p>
<p>3.8 依据序列ID从fasta文件提取序列<br />
seqtk subseq AM-scaffolds.fasta scafname.list &gt; scaf_selected.fa</p>
<p>3.9 从pair end形式的的两个fastq文件各随机提取序列1000条，二者需要对应。<br />
seqtk sample -s100 800bp_1.fastq.gz 1000 &gt; 800bp_10M_1.fq<br />
seqtk sample -s100 800bp_2.fastq.gz 1000 &gt; 800bp_10M_2.fq</p>
</blockquote>
<p>4 seqtk (Li Heng)</p>
<p>Usage: seqtk <command> <arguments><br />
Version: 1.0-r82-dirty</p>
<p>Command: seq common transformation of FASTA/Q<br />
comp get the nucleotide composition of FASTA/Q<br />
sample subsample sequences<br />
subseq extract subsequences from FASTA/Q<br />
fqchk fastq QC (base/quality summary)<br />
mergepe interleave two PE FASTA/Q files<br />
trimfq trim FASTQ using the Phred algorithm</p>
<p>hety regional heterozygosity<br />
gc identify high- or low-GC regions<br />
mutfa point mutate FASTA at specified positions<br />
mergefa merge two FASTA/Q files<br />
dropse drop unpaired from interleaved PE FASTA/Q<br />
rename rename sequence names<br />
randbase choose a random base from hets<br />
cutN cut sequence at long N<br />
listhet extract the position of each het</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Fastq quality control and filtering</title>
    <url>/2015/08/25/fastq-quality-control-and-filtering/</url>
    <content><![CDATA[<p><strong>数据质量QC：<a href="http://www.bioinformatics.babraham.ac.uk/projects/fastqc/">fastqc</a></strong> fastqc <strong>去除adapter：<a href="http://www.usadellab.org/cms/?page=trimmomatic">Trimmomatic</a></strong> （Trimmomatic: A flexible read trimming tool for Illumina NGS data）</p>
<blockquote>
<p>java -jar trimmomatic-0.30.jar PE -phred33 input_forward.fq.gz input_reverse.fq.gz output_forward_paired.fq.gz output_forward_unpaired.fq.gz output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36</p>
</blockquote>
<p>**去除含N过多的Reads：① ITools ② <a href="http://prinseq.sourceforge.net/manual.html">PRINSEQ</a> ** <em>Filter options</em></p>
<p>-ns_max_p</p>
<p>Filter sequence with more than ns_max_p percentage of Ns</p>
<p>INT [0…100]</p>
<p>-ns_max_n</p>
<p>Filter sequence with more than ns_max_n Ns</p>
<p>INT</p>
<p><strong>去除含低质量碱基过多的Reads：</strong></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Gene Counts Table of RNA seq: The sam/bam file for HTseq should be sorted</title>
    <url>/2015/10/06/gene-counts-table-of-rna-seq-the-sambam-file-for-htseq-should-be-sorted/</url>
    <content><![CDATA[<p>Posted on <a href="https://fengleiblog.wordpress.com/2015/10/06/gene-counts-table-of-rna-seq-the-sambam-file-for-htseq-should-be-sorted/" title="23:44">2015-10-06</a> by <a href="https://fengleiblog.wordpress.com/author/fengleiluck/" title="查看该作者所有主题 FENG Lei">FENG Lei</a> — <a href="https://fengleiblog.wordpress.com/2015/10/06/gene-counts-table-of-rna-seq-the-sambam-file-for-htseq-should-be-sorted/#respond">发表评论</a></p>
<p>下面摘抄自网络。实际使用中，转录组比对使用tophat或者hisat，注意tophat输出的bam文件未经排序，而hisat输出的sam文件已经排序。<strong>HTseq进行reads count时候，要求输入的sam/bam文件是经过排序的。</strong> ————————</p>
<p><strong>A. Counting reads</strong></p>
<p>DEseq uses a table of raw counts as the basis of DE calls. Any transformed counts, such as FPKM counts will not work with this package. The top row of the table can be a descriptor, these can be imported into R to act as column labels. Gene names should be column 1 (remember R counting starts from 1 rather than 0), each column after that should be a raw count for each biological replicate and for each treatment. Note that if technical reps are performed, these should be merged based on the sum of the two runs (they will be normalised by read count latter).</p>
<p>Here I used BWA to align the reads to my reference and generate SAM files that are then processed by <a href="http://www-huber.embl.de/users/anders/HTSeq/doc/overview.html">HTseq</a> count. Note that you have to run this on each sample, so in this current example I will generate 6 sam files, 1 for each treatment and condition. Also, see that I used the<a href="http://www-huber.embl.de/users/anders/HTSeq/doc/count.html">intersection-strict</a> mode for HTseq. &gt;bwa aln sarcop_pep_rnaseqfiltered.fa Sample_ST72-1/ST72-1.subset.fastq &gt; ST72-1.subset.sai</p>
<p>&gt;bwa samse sarcop_pep_rnaseqfiltered.fa ST72-1.subset.sai Sample_ST72-1/ST72-1.subset.fastq &gt; ST72-1.subset.sam</p>
<p>&gt;htseq-count -m intersection-strict –stranded=no ST72-1.subset.sam sarcop_pep_rnaseqfiltered.gtf &gt; ST72-1.subset.counts</p>
<p>In the above ST72-1.subset.counts is a table of counts that can be merged with the other count data before being imported into DEseq as a R data table. Here is a <a href="https://docs.google.com/file/d/0B99ewTsEZTkidElVekliSUxldW8/edit?usp=sharing">python script</a> for merging, see the header of the script for usage, if that helps. For full detailed explanation of HTseq see (<a href="http://www-huber.embl.de/users/anders/HTSeq/doc/install.html#installation-on-linux">http://www-huber.embl.de/users/anders/HTSeq/doc/install.html#installation-on-linux</a>) and this seems to be the default way of doing it (instructions :<a href="http://www-huber.embl.de/users/anders/HTSeq/doc/count.html">http://www-huber.embl.de/users/anders/HTSeq/doc/count.html</a>).</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Hello World</title>
    <url>/2022/07/14/hello-world/</url>
    <content><![CDATA[<p>自 2020 年 12 月 7 日开始使用 Hexo 建立博客，设置主题为 maupassant，博客推送到 github，使用一直很方便。由于 2022 年 5 月份对电脑的硬盘升级，本地的 Hexo 需要重装，一直到 2022 年 7 月 14 日才开始处理，本来以为将原来备份的 Hexo 目录直接拷贝到新的硬盘就可以，哪知道不是这么简单。安装好 node.js 和 git 之后，要重新新建 Hexo，并设置主题。但是原来的 maupassant 主题已经无法使用了，所以新找了 NexT 主题也勉强可以用，只是默认的渲染工具不好用，我更换成了 hexo-renderer-markdown-it-plus。至此，新博客的架构已经搭建好，并且可以在本地用 localhost/4000 成功访问。将旧备份目录下的 markdown 格式的原始博文拷贝到 Hexo/source/_posts 目录下，就能看到。</p>
<span id="more"></span>
<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p>
<p>测试代码折叠语法与单击展开的功能</p>
<details>
<summary>Abstract</summary>
<pre><code>The genus Ammopiptanthus is mainly distributed in the semi-arid regions of northwest China. It only contains two species: A. mongolicus and A. nanus. They exhibit similar morphological characteristics, but little is known about their genetic differences. We performed de novo sequencing and mitochondrial genome assembly and found that both species contain 36 protein-coding genes, 3 rRNA, and 16 tRNA genes. The comparison of A. mongolicus and A. nanus mitogenomes revealed a 6.5-kb region loss in A. nanus mitogenome, which was replaced by a 1.5-kb different sequence element. Other small variations between the two species include 25 SNPs, 4 deletions, and 2 insertions. Meta-analyses indicated that 34% of the A. mongolicus mitogenome was unique to Ammopiptanthus and has no similarity with any other known legume mitogenomes. These unique sequences are mainly distributed in intergenic regions. Gene gain and loss analysis showed that this mitogenome gained two genes, rps7 and sdh4, during evolution, with rps7 transferred from the chloroplast genome. Selective pressure analysis implied that the atp8 gene was under positive selection. Our study established high-quality reference mitogenomes for the genus Ammopiptanthus, revealed novel genetic differences between A. mongolicus and A. nanus, and provided new insights into the evolution of legume plants.</code></pre>
</details>
<h2 id="quick-start"><a class="markdownIt-Anchor" href="#quick-start"></a> Quick Start</h2>
<h3 id="create-a-new-post"><a class="markdownIt-Anchor" href="#create-a-new-post"></a> Create a new post</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p>
<h3 id="run-server"><a class="markdownIt-Anchor" href="#run-server"></a> Run server</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p>
<h3 id="generate-static-files"><a class="markdownIt-Anchor" href="#generate-static-files"></a> Generate static files</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p>
<h3 id="deploy-to-remote-sites"><a class="markdownIt-Anchor" href="#deploy-to-remote-sites"></a> Deploy to remote sites</h3>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
  </entry>
  <entry>
    <title>illumina HiSeq 2500的高通量模式与快速模式</title>
    <url>/2014/08/11/illumina-hiseq-2500/</url>
    <content><![CDATA[<p>快速模式使用2-lane的folw cell，每个lane里面能产出150M reads。（如果PE150测序，产出数据为150M reads/lane * 2 lane * 2*150bp/read = 90G data）</p>
<p>高通量模式使用8-lane的flow cell，每个lane里面能产出约187.5M reads。（如果PE100测序，产出数据为187.5M reads/lane * 8 lane * 2*100bp/read = 300G data）</p>
<p><a href="http://genehub.files.wordpress.com/2014/08/1-pic.jpg"><img src="http://fengleiblog.files.wordpress.com/2014/08/1-pic.jpg?w=300" alt="1.pic" /></a></p>
<span id="more"></span>
<p><a href="http://genehub.files.wordpress.com/2014/08/2-pic.jpg"><img src="http://fengleiblog.files.wordpress.com/2014/08/2-pic.jpg?w=300" alt="2.pic" /></a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>illumina HiSeq与PacBio测序dNTP荧光标记的区别</title>
    <url>/2014/08/12/illumina-pacbio/</url>
    <content><![CDATA[<p>illumina HiSeq（二代测序）测序方法采用边合成边测序的方法。向反应体系中同时添加DNA聚合酶、接头引物和带有<strong>碱基特异荧光标记的4中dNTP</strong>（如同Sanger测序法）。这些dNTP的3’-OH被化学方法所保护，因而每次只能添加一个dNTP。在dNTP被添加到合成链上后，所有未使用的游离dNTP和DNA聚合酶会被洗脱掉。接着，再加入激发荧光所需的缓冲液，用激光激发荧光信号，并有光学设备完成荧光信号的记录，最后利用计算机分析将光学信号转化为测序碱基。这样荧光信号记录完成后，再加入化学试剂淬灭荧光信号并去除dNTP 3’-OH保护基团，以便能进行下一轮的测序反应。Illumina的这种测序技术每次只添加一个dNTP的特点能够很好的地解决同聚物长度的准确测量问题，它的主要测序错误来源是碱基的替换，目前它的测序错误率在1%-1.5%之间，测序周期以人类基因组重测序为例，30x测序深度大约为1周。 <a href="http://genehub.files.wordpress.com/2014/08/qq20140812-1.png"><img src="http://fengleiblog.files.wordpress.com/2014/08/qq20140812-1.png?w=300" alt="QQ20140812-1" /></a></p>
<span id="more"></span>
<p>PacBio SMRT技术其实也应用了边合成边测序的思想，以SMRT芯片为测序载体。基本原理是： DNA聚合酶和模板结合,<strong>4色荧光标记 4 种碱基（荧光基团与dNTP的磷酸基团连接）</strong>,在碱基配对阶段,不同碱基的加入,会发出不同光,根据光的波长与峰值可判断进入的碱基类型。同时这个 DNA 聚合酶是实现超长读长的关键之一,读长主要跟酶的活性保持有关,它主要受激光对其造成的损伤所影响。 <a href="http://genehub.files.wordpress.com/2014/08/qq20140812-2.png"><img src="http://fengleiblog.files.wordpress.com/2014/08/qq20140812-2.png?w=300" alt="QQ20140812-2" /></a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Python报错：ImportError: No module named toolz</title>
    <url>/2014/12/12/importerror-no-module-named-toolz/</url>
    <content><![CDATA[<p>seq_crumbs中的pair_matcher是fastq数据分析中一个小工具，依赖Python和biopython。初次运行报错： [fenglei@localhost new]$ pair_matcher -h Traceback (most recent call last): File “/usr/local/bin/pair_matcher”, line 26, in <module> from crumbs.pairs import match_pairs File “/usr/local/lib/python2.7/site-packages/crumbs/pairs.py”, line 18, in <module> from toolz import first ImportError: No module named toolz</p>
<span id="more"></span>
<p>解决方法：</p>
<p>Use <code>pip</code> to install <code>toolz</code>. First install pip:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install python-pip</span><br></pre></td></tr></table></figure>
<p>After that install <code>toolz</code>:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo pip install toolz</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>给linux工作站添加新硬盘</title>
    <url>/2015/11/25/linux-add-new-harddisks/</url>
    <content><![CDATA[<p>作者：haohaoo 来自：CnLinux.net工作笔记 转载请保留以上信息，谢谢 在服务器上把硬盘接好，启动linux，以root登陆。 比如我新加一块SCSI硬盘，需要将其分成三个区：</p>
<blockquote>
<p>#fdisk /dev/sdb</p>
<p>进入fdisk模式：</p>
<p>Command (m for help):p  //查看新硬盘的分区（FL备注：如果是新硬盘，将显示分区为空。）</p>
<p>Command (m for help):n  //创建新分区（FL备注：输入n命令，将自动出现e和p的选项。）</p>
<p>可以用m命令来看fdisk命令的内部命令；n命令创建一个新分区；d命令删除一个存在的分区；p命令显示分区列表；t命令修改分区的类型ID号；l命令显示分区ID号的列表；a命令指定启动分区；w命令是将对分区表的修改存盘让它发生作用。</p>
<p>Command action</p>
<p>e   extended   //输入e为创建扩展分区</p>
<p>p   primary partition (1-4)   //输入p为创建主分区，这里我们选择p</p>
<p>Partion number(1-4)：1  //第一个扩展分区，按你需求可以最多分4个主分区</p>
<p>First Cylinder(1-1014,default 1):  1  //第一个主分区起始的磁盘块数</p>
<p>Last cylindet or +siza or +sizeM or +sizeK: +1024MB  //可以是以MB为单位的数字或者以磁盘块数，这里我们输入+1024MB表示分区大小为1G。（FL备注：系统默认提示整个硬盘的大小作为一个分区，比如我新增挂载2TB的硬盘，则显示“default 243201”，我直接输入回车就选择这个默认数值即可。）</p>
</blockquote>
<p>这样我们就创建完一个分区，如果要创建更多分区可以照上面的步骤继续创建。 创建完后用w保存分区。</p>
<p>Command (m for help): w</p>
<p>The partition table has been altered!</p>
<p>Calling ioctl() to re-read partition table.</p>
<p>Syncing disks.</p>
<p>这样就分区完，我们还要进行格式化</p>
<p>#mkfs -t ext3 -c /dev/sdb1  //如果有多个分区，则分区修改为sdb2这样<br />
<em>（格式化2TB的硬盘，耗时约3小时。20151125 FL备注）</em></p>
<p>格式化完后我们需要进行挂载分区，</p>
<p>#mkdir /mnt/www //创建/www目录，我们将把新的分区挂到www下</p>
<p>#mount /dev/sdb1 /mnt/www  //将/dev/sdb1挂载到/www</p>
<p># df  //用df命令进行查看</p>
<p>Filesystem           1K-blocks      Used Available Use% Mounted on</p>
<p>/dev/sda2              3771316   1388956   2190788  39% /</p>
<p>/dev/sda1               101089      9463     86407  10% /boot</p>
<p>none                     62988         0     62988   0% /dev/shm</p>
<p>/dev/sdb1               485906      8239    452580   2% /www  //看到了，这就是我们刚</p>
<p>才新挂载的分区</p>
<p>到这里我们工作已接近尾声了，不过我们如果这样就结束的话，我们每次重新启动服务器后都要 进行手工挂载，这样很麻烦，我们需要修改/etc/fstab文件来进行自动挂载。</p>
<p>#vi /etc/fstab</p>
<p>在文件的末尾填加如下内容：</p>
<p>/dev/sdb1               /www                    ext3    defaults        1 2</p>
<p>如有多个分区可修改sdb1和/www，修改完后保存，重起服务器。 到此我们添加新硬盘的工作结束了。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux系统无法挂载格式为ntfs格式的移动硬盘的解决办法</title>
    <url>/2014/08/22/linux-ntfs/</url>
    <content><![CDATA[<p><strong>Linux<strong><strong>系统无法挂载格式为</strong></strong>ntfs****格式的移动硬盘的解决办法</strong> 今天想把网上下载下来的一些软件包用移动硬盘挂载到Red Hat Enterprise Workstation系统计算机器上，可是怎么也挂载不上去，网上查了资料，原来默认 只识别 win 下的 vfat ，不识别 ntfs 格式的。我的移动硬盘就是ntfs格式的。再查了一些资料并结合自己的实际操作，最终解决了不能挂载ntfs移动硬盘的问题。具体步骤如下：</p>
<span id="more"></span>
<p>(1) 下载源码包：<a href="http://tuxera.com/opensource/ntfs-3g%5C_ntfsprogs-2014.2.15.tgz">http://tuxera.com/opensource/ntfs-3g\_ntfsprogs-2014.2.15.tgz</a>  （来源：<a href="http://www.tuxera.com/community/ntfs-3g-download/%EF%BC%89">http://www.tuxera.com/community/ntfs-3g-download/）</a> (2) 安装 :tar -zxf ntfs-3g-2010.10.2.gz; cd tar -zxf ntfs-3g-2010.10.2; ./configure ; make &amp;&amp; make install （ 3 ）新建目录 mkdir /mnt/windows (4) 查看移动硬盘设备名称 [root@localhost local]# fdisk -l Disk /dev/sda: 500.1 GB, 500107862016 bytes 255 heads, 63 sectors/track, 60801cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Device Boot     Start         End     Blocks   Id System /dev/sda1   *           1       13        104391 83 Linux /dev/sda2           14       60801   488279610 8e Linux LVM Disk /dev/sdb: 320.0G, 320072932864 bytes 255 heads, 63 sectors/track, 38913 cylinders Units = cylinders of 16065 * 512 = 8225280 bytes Device Boot     Start         End     Blocks   Id System /dev/sdb1   *           1       389 1 3 312568641   7 HPFS/NTFS 由以上信息可知，移动设备的名称为： sdb1 (4) 安装成功，手动挂载 ntfs 格式硬盘： mount -t ntfs-3g /dev/sdb1 /mnt/windows (5) 开机自动挂载 ntfs 格式硬盘： /dev/sdb1 /mnt/windows ntfs-3g defaults 0 0 (6) 进入磁盘 cd /mnt/windows (7) 复制文件 cp /mnt/windows /*.* /data1/ (8) 卸载磁盘 umount /mnt/windows (9) 拔掉移动硬盘 usb 接口 ============================= 附官网下载页面：</p>
<h1 id="ntfs-3g-ntfsprogs"><a class="markdownIt-Anchor" href="#ntfs-3g-ntfsprogs"></a> NTFS-3G + Ntfsprogs</h1>
<p>NTFS-3G is a stable, full-featured, read-write NTFS driver for Linux, Android, Mac OS X, FreeBSD, NetBSD, OpenSolaris, QNX, Haiku, and other operating systems. It provides safe handling of the Windows XP, Windows Server 2003, Windows 2000, Windows Vista, Windows Server 2008, Windows 7 and Windows 8 NTFS file systems. A <a href="http://www.tuxera.com/products/tuxera-ntfs-embedded/performance/">high-performance</a> alternative, called Tuxera NTFS is available for <a href="http://www.tuxera.com/products/tuxera-ntfs-embedded/">embedded devices</a> and <a href="http://www.tuxera.com/products/tuxera-ntfs-for-mac/">Mac OS X</a>. The release notes and the software changes can be found on the <a href="http://www.tuxera.com/community/release-history/">Release History</a> page. Subscribe <a href="http://lists.sourceforge.net/mailman/listinfo/ntfs-3g-news">here</a>for new release notifications.</p>
<h3 id="download"><a class="markdownIt-Anchor" href="#download"></a> Download</h3>
<p>The latest <strong>stable version</strong> is <a href="http://tuxera.com/opensource/ntfs-3g_ntfsprogs-2014.2.15.tgz">ntfs-3g_ntfsprogs-2014.2.15</a>, released on February 23, 2014. Availability:</p>
<p><a href="http://tuxera.com/opensource/ntfs-3g_ntfsprogs-2014.2.15.tgz">Stable Source Release 2014.2.15</a></p>
<p><a href="http://www.tuxera.com/products/tuxera-ntfs-for-mac/">Tuxera NTFS for Mac</a> (fastest)</p>
<p><a href="http://www.freshports.org/sysutils/fusefs-ntfs">FreeBSD FreshPorts</a></p>
<p><a href="http://macntfs-3g.blogspot.com/">NTFS-3G for Mac OS X</a></p>
<p><a href="http://pkgsrc.se/filesystems/fuse-ntfs-3g">NetBSD Package Collection</a></p>
<p><a href="http://pdb.finkproject.org/pdb/package.php/ntfs-3g">Mac OS X Fink Package</a></p>
<p><a href="http://dev.haiku-os.org/browser/haiku/trunk/src/add-ons/kernel/file_systems/ntfs/">Haiku Source Repository</a></p>
<p><a href="http://trac.macports.org/browser/trunk/dports/fuse/ntfs-3g">Mac OS X MacPorts</a></p>
<p><a href="http://community.qnx.com/sf/wiki/do/viewPage/projects.qnx_community_fuse_project/wiki/HomePage">QNX Portal</a></p>
<h3 id="installation"><a class="markdownIt-Anchor" href="#installation"></a> Installation</h3>
<p>Linux: <a href="http://www.ntfs-3g.com/distributions.html">Most distributions</a> include and use NTFS-3G by default. Please use that one unless it’s an <a href="http://www.tuxera.com/community/release-history/">old version</a>. If you wish to install NTFS-3G from the source code then make sure you have installed the basic development tools (gcc compiler, libc-dev libraries). Then type: <strong>./configure</strong> <strong>make</strong> <strong>make install</strong> # or ‘<strong>sudo make install</strong>’ if you aren’t root Non-Linux: Please see the OS specific installation and source packages above.</p>
<h3 id="usage"><a class="markdownIt-Anchor" href="#usage"></a> Usage</h3>
<p>If there was no error during installation then the NTFS volume can be mounted in read-write mode for everybody as follows. Unmount the volume if it had already been mounted, replace /dev/sda1 and /mnt/windows, if needed. mount -t ntfs-3g /dev/sda1 /mnt/windows Please see the <a href="http://www.tuxera.com/community/ntfs-3g-manual/">NTFS-3G Manual</a> for more options and examples. You can also make NTFS to be mounted during boot by adding the following line to the <strong>end of the /etc/fstab</strong> file: /dev/sda1 /mnt/windows ntfs-3g defaults 0 0</p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>Linux系统从 RedHat 4.4.7-3 升级到 CentOS 7</title>
    <url>/2019/09/04/linux-redhat-4-4-7-3-upgrade-to-centos-7/</url>
    <content><![CDATA[<p>由于Redhat附带的GLIBC 2.12版本过低，导致许多应用（jcvi、interproscan）不能正常使用，遂决定升级到新的系统。 一、下载CentOS的iso文件 进入CentOS网站（<a href="https://www.centos.org/download/%EF%BC%89%EF%BC%8C%E9%80%89%E6%8B%A9DVD">https://www.centos.org/download/），选择DVD</a> ISO按钮，进入下载网站之后点击如下链接即可下载。文件大小约4.3 GB。 <a href="http://mirror.sunnyvision.com/centos/7.6.1810/isos/x86%5C_64/CentOS-7-x86%5C_64-DVD-1810.iso">http://mirror.sunnyvision.com/centos/7.6.1810/isos/x86\_64/CentOS-7-x86\_64-DVD-1810.iso</a> 二、制作光盘启动盘 我的笔记本电脑自带DVD光盘刻录机，需要安装UltraIso软件用于光盘刻录，同时空白DVD光盘空间要大于CentOS的iso文件。也可以用U盘做启动盘，但是我没有合适的U盘，所以这次用了光盘。将光盘放入刻录机中；打开软件UltraISO；在软件上找到iso文件所在的位置，并双击该iso文件；随后选中DVD；再点击“刻录”按钮即可。 <img src="https://genehub.files.wordpress.com/2019/09/iso-burn-_20190904100355.png" alt="ISO burn _20190904100355" /> 三、安装新系统 旧系统在一个1.8 TB的硬盘，已经做了分区，其中50 GB分区是根目录（/），剩下的空间大部分是/home目录。home目录下我已经有多年的数据，这次安装不用动，但是我还是提前备份了。新系统直接安在原有的根目录下。 安装时候参考资料： <a href="https://www.cnblogs.com/set-config/p/9040407.html">https://www.cnblogs.com/set-config/p/9040407.html</a> <a href="https://blog.seisman.info/centos7-setup-1/">https://blog.seisman.info/centos7-setup-1/</a> 1. 往服务器插入光盘，重启系统，开机的时候按F2进入bios，设置光盘优先启动，进入如下界面，光标移动选择第一项Install CentOS 7，进入安装。 <img src="https://genehub.files.wordpress.com/2019/09/1349552-20180515112524220-766717605.png" alt="1349552-20180515112524220-766717605" /> 2. 系统自动提醒进行一些配置 第二个界面是选择安装语言界面，我相信看这个教程的很多童鞋都是新手或者第一次安装Centos的同胞，对于新手而言，最好选择可以看懂的中文语言，往下拉到底就可以看到中文了，选中它。单机Continue/继续 【或者键盘的Tab键选中+回车确定】   <img src="https://genehub.files.wordpress.com/2019/09/1349552-20180515112948570-582636142.png" alt="1349552-20180515112948570-582636142" /> 第三个界面非常关键，这涉及到你系统的基本配置，比如硬盘大小、根分区以及swap分区。 本地化：本地化这一块不需要做过多的配置，按需即可；软件：软件下面的安装源和软件选中，只有特殊需求的童鞋才会用到。这一点从里面的选项描述就可以知道，为了不错误引导新手，这里就不放图了。系统：重点是系统。先说KDUMP，对于新手来说，这个在新手阶段无使用价值，配置启用或者不启用都无关紧要。安装位置，由于安装位置涉及到你自己的磁盘数据以及分区内容，如果原分区包含有数据、有必要先备份数据。 <img src="https://genehub.files.wordpress.com/2019/09/1349552-20180515113632825-1756332663.png" alt="1349552-20180515113632825-1756332663" /> 点击上图的“安装位置”，出现计算机上已有的硬盘，选中系统所在盘，并点击“手动配置分区”。（因为我这块硬盘已经被分区了，旧的home目录数据不用变，所以不必用自动分区。这里忘了拍照。）点击完成按钮之后进入下图界面，左侧显示了“新 CentOS 7 安装”和“Red Hat …”两个栏目，可以看到新的CentOS还没有挂载点，旧的Redhat系统有/home, /boot, / 和 swap 这四个分区。依次点击这四个分区，图中挂载点（P）文字下方的空白栏，就是新的CentOS系统对应的分区，要相应地填入 /home, /boot, / 和 swap；同时注意有个“重新格式化（D）”文字左侧的选择框，/home 不要点这个，其他三个要选重新格式化。设备类型和文件系统我都沿用旧系统的，没做更改，看到资料说新手需记住：除了SWAP分区外，其他分区的文件系统一律选择ext4类型,设备类型默认选LVM。 <img src="https://genehub.files.wordpress.com/2019/09/e9858de7bdaee5898d.jpg" alt="配置前" /> 手动分区之后点击完成就进入了如下界面，可以看到三个挂载区（对应/boot, / 和 swap）将重新格式化，点击“接收更改”。然后新系统将进入自动安装，期间会提醒设置root账户和一个普通用户账户，然后等几分钟就安好了。取出光盘，重启的时候再将bios里面改成原来的硬盘优先启动，就可以进入新系统了。 <img src="https://genehub.files.wordpress.com/2019/09/e9858de7bdaee5908e.jpg" alt="配置后" /> 四、其余配置 对新系统的IP地址等做好设置，即可远程登录了。进入home目录，文件都跟以前的一致，就是所属用户组变成了500（这是啥意思？），我用chown -R username:username ~/ 将文件属性变回了自己的用户名下。   == 20200109 更新== 由于电脑多次经历断电异常关机（没有配置UPS），卡在开机界面无法顺利开机了，进入安全模式下，通过journalctl命令查阅log文件，看到的报错信息如下。</p>
<p>Warning: /<em>dev</em>/<em>mapper</em>/<em>VolGroup</em>-<em>lv_root contains a file system with errors</em>, check forced.</p>
<p>查阅资料之后用fsck命令对磁盘进行修复也没有解决问题，也许是我操作不对，于是按照以上步骤重装系统。重装系统之后除系统分区之外的数据盘都完好，以后还是配置UPS和备份数据盘比较保险。新的系统需要做如下设置。 <strong>1 联网</strong> centos 7 启动之后没有联网，需要在/etc/sysconfig/network-scripts/ifcfg-eth0 (确认ONBOOT=yes)，其中eth0是设备名，不同的设备可能不同。ONBOOT是指明在系统启动时是否激活网卡，只有在激活状态的网卡才能去连接网络，进行网络通讯。 <strong>2 设置静态IP地址</strong> 静态IP地址可以方便用户ssh登录。直接修改网卡配置文件。我有两个网卡，分别设定了不同的IP地址，以下仅以一个网卡举例。</p>
<p>vim /etc/sysconfig/network-scripts/ifcfg-eth0</p>
<p>修改内容：</p>
<p>BOOTPROTO=“static” #dhcp改为static<br />
ONBOOT=“yes” #开机启用本配置<br />
IPADDR=192.168.7.106 #静态IP<br />
GATEWAY=192.168.7.1 #默认网关<br />
NETMASK=255.255.255.0 #子网掩码<br />
DNS1=192.168.7.1 #DNS 配置</p>
<p>输入如下命令重启网卡，激活设置。</p>
<p>service network restart</p>
<p><strong>3 防火墙设置，允许用户远程登录</strong> 确保已经开启静态IP，安装 openssh-server，然后修改ssh配置文件。</p>
<p>yum install -y openssl openssh-server<br />
vim /etc/ssh/sshd_config</p>
<p>修改参数，打开22端口，并允许root登录，RSSAuthentication 和 PubkeyAuthentication 均设置为 yes。 <img src="https://genehub.files.wordpress.com/2019/09/e5beaee4bfa1e688aae59bbe_20200109144722.jpg" alt="微信截图_20200109144722" /> 启动ssh服务</p>
<p>systemctl start sshd.service</p>
<p>重启网络</p>
<p>service network restart</p>
<p>设置开机启动ssh服务，即可从外网远程登录（路由器已经设置端口转发）。</p>
<p>systemctl enable sshd.service</p>
<p><strong>4 DNS设置</strong> 发现没有设置DNS的话，在用git下载的过程中会报错。编辑如下文件并保存退出vim即可生效。</p>
<p>vim /etc/resolv.conf # 加入如下格式的内容，可以写多个DNA服务器</p>
<p>nameserver 8.8.8.8<br />
nameserver 8.8.4.4</p>
<p><strong>5 将用户加入sudo列表</strong> 修改etc/sudoers配置文件，在root ALL=(ALL) ALL下一行，添加新用户，如下所示。文字之间的间隔是tab。sudoers的 权限是只读，编辑内容前修改权限，添加内容完毕将权限改回去。</p>
<p>root   ALL=(ALL)   ALL<br />
username   ALL=(ALL)   ALL</p>
<p><strong>6 安装git</strong> 安装 yum install git 验证 [root@localhost ~]# git --version git version 1.8.3.1 [root@localhost ~]# 配置基本信息 //配置基本信息（输入自己的用户名和密码） [root@localhost ~]# git config --global <a href="http://user.name">user.name</a> “mygitusername” [root@localhost ~]# git config --global user.email <a href="mailto:xxxxx@xx.com">xxxxx@xx.com</a> //查看配置 [root@localhost ~]# git config --list <strong>7 懒人vim配置</strong> 安装spf13，之间安装git里面的教程操作即可：<a href="https://github.com/spf13/spf13-vim">https://github.com/spf13/spf13-vim</a> 舒适的vim配置，在编辑脚本的时候会舒适很多。 <strong>8 CentOS 7 的桌面（optional）</strong> 新装系统是最小化安装，没有桌面系统，可以在服务器上面安装桌面（其实安装了也没什么实际作用，反正可以用ssh登录服务器）。</p>
<p>yum groupinstall “X Window System” 　//注意有引号<br />
yum groupinstall “GNOME Desktop” “Graphical Administration Tools”<br />
startx  # 进入图形桌面界面</p>
<p><strong>9 硬盘挂载</strong> 计算机有多块硬盘的情况下，需要挂载。fdisk -l查看硬盘情况，然后用mount命令挂载到/mnt目录下面。</p>
<p>mount  /dev/sdb1  /mnt/sdb</p>
<p>-END-</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux系统安全策略（IP限定）</title>
    <url>/2015/12/11/linux-safety-by-restricted-ip/</url>
    <content><![CDATA[<h4 id="1-禁止系统响应任何从外部内部来的ping请求"><a class="markdownIt-Anchor" href="#1-禁止系统响应任何从外部内部来的ping请求"></a> 1. 禁止系统响应任何从外部/内部来的ping请求</h4>
<p>攻击者一般首先通过ping命令检测此主机或者IP是否处于活动状态，如果能够ping通 某个主机或者IP，那么攻击者就认为此系统处于活动状态，继而进行攻击或破坏。如果没有人能ping通机器并收到响应，那么就可以大大增强服务器的安全性，linux下可以执行如下设置，禁止ping请求：</p>
<p>[root@localhost ~]#echo “1”&gt; /proc/sys/net/ipv4/icmp_echo_ignore_all</p>
<p>默认情况下“icmp_echo_ignore_all”的值为“0”，表示响应ping操作。 可以加上面的一行命令到/etc/rc.d/rc.local文件中，以使每次系统重启后自动运行。</p>
<span id="more"></span>
<h4 id="2禁止control-alt-delete组合键重启系统"><a class="markdownIt-Anchor" href="#2禁止control-alt-delete组合键重启系统"></a> 2．禁止Control-Alt-Delete组合键重启系统</h4>
<p>在linux的默认设置下，同时按下Control-Alt-Delete键，系统将自动重启，这是很不安全的，因此要禁止Control-Alt-Delete组合键重启系统，只需修改/etc/inittab文件：</p>
<p>[root@localhost ~]#vi /etc/inittab</p>
<p>找到此行：ca::ctrlaltdel:/sbin/shutdown -t3 -r now 在之前加上“#” 然后执行：</p>
<p>[root@localhost ~]#telinit q</p>
<p></p>
<h4 id="3限制shell记录历史命令大小"><a class="markdownIt-Anchor" href="#3限制shell记录历史命令大小"></a> 3．限制Shell记录历史命令大小</h4>
<p>默认情况下，bash shell会在文件<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mi>O</mi><mi>M</mi><mi>E</mi><mi mathvariant="normal">/</mi><mi mathvariant="normal">.</mi><mi>b</mi><mi>a</mi><mi>s</mi><mi>h</mi><mi mathvariant="normal">_</mi><mi>h</mi><mi>i</mi><mi>s</mi><mi>t</mi><mi>o</mi><mi>r</mi><mi>y</mi><mtext>中存放多达</mtext><mn>1000</mn><mtext>条命令记录</mtext><mo stretchy="false">(</mo><mtext>根据系统不同，默认记录条数不同</mtext><mo stretchy="false">)</mo><mtext>。系统中每个用户的主目录下都有一个这样的文件。这么多的历史命令记录，肯定是不安全的，因此必须限制该文件的大小。可以编辑</mtext><mi mathvariant="normal">/</mi><mi>e</mi><mi>t</mi><mi>c</mi><mi mathvariant="normal">/</mi><mi>p</mi><mi>r</mi><mi>o</mi><mi>f</mi><mi>i</mi><mi>l</mi><mi>e</mi><mtext>文件，修改其中的选项如下：</mtext><mi>H</mi><mi>I</mi><mi>S</mi><mi>T</mi><mi>S</mi><mi>I</mi><mi>Z</mi><mi>E</mi><mo>=</mo><mn>30</mn><mtext>表示在文件</mtext></mrow><annotation encoding="application/x-tex">HOME/.bash\_history中存放多达1000条命令记录(根据系统不同，默认记录条数不同)。系统中每个用户的主目录下都有一个这样的文件。 这么多的历史命令记录，肯定是不安全的，因此必须限制该文件的大小。 可以编辑/etc/profile文件，修改其中的选项如下： HISTSIZE=30 表示在文件</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.06em;vertical-align:-0.31em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord">/</span><span class="mord">.</span><span class="mord mathnormal">b</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">h</span><span class="mord" style="margin-right:0.02778em;">_</span><span class="mord mathnormal">h</span><span class="mord mathnormal">i</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord cjk_fallback">中</span><span class="mord cjk_fallback">存</span><span class="mord cjk_fallback">放</span><span class="mord cjk_fallback">多</span><span class="mord cjk_fallback">达</span><span class="mord">1</span><span class="mord">0</span><span class="mord">0</span><span class="mord">0</span><span class="mord cjk_fallback">条</span><span class="mord cjk_fallback">命</span><span class="mord cjk_fallback">令</span><span class="mord cjk_fallback">记</span><span class="mord cjk_fallback">录</span><span class="mopen">(</span><span class="mord cjk_fallback">根</span><span class="mord cjk_fallback">据</span><span class="mord cjk_fallback">系</span><span class="mord cjk_fallback">统</span><span class="mord cjk_fallback">不</span><span class="mord cjk_fallback">同</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">默</span><span class="mord cjk_fallback">认</span><span class="mord cjk_fallback">记</span><span class="mord cjk_fallback">录</span><span class="mord cjk_fallback">条</span><span class="mord cjk_fallback">数</span><span class="mord cjk_fallback">不</span><span class="mord cjk_fallback">同</span><span class="mclose">)</span><span class="mord cjk_fallback">。</span><span class="mord cjk_fallback">系</span><span class="mord cjk_fallback">统</span><span class="mord cjk_fallback">中</span><span class="mord cjk_fallback">每</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">用</span><span class="mord cjk_fallback">户</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">主</span><span class="mord cjk_fallback">目</span><span class="mord cjk_fallback">录</span><span class="mord cjk_fallback">下</span><span class="mord cjk_fallback">都</span><span class="mord cjk_fallback">有</span><span class="mord cjk_fallback">一</span><span class="mord cjk_fallback">个</span><span class="mord cjk_fallback">这</span><span class="mord cjk_fallback">样</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">。</span><span class="mord cjk_fallback">这</span><span class="mord cjk_fallback">么</span><span class="mord cjk_fallback">多</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">历</span><span class="mord cjk_fallback">史</span><span class="mord cjk_fallback">命</span><span class="mord cjk_fallback">令</span><span class="mord cjk_fallback">记</span><span class="mord cjk_fallback">录</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">肯</span><span class="mord cjk_fallback">定</span><span class="mord cjk_fallback">是</span><span class="mord cjk_fallback">不</span><span class="mord cjk_fallback">安</span><span class="mord cjk_fallback">全</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">因</span><span class="mord cjk_fallback">此</span><span class="mord cjk_fallback">必</span><span class="mord cjk_fallback">须</span><span class="mord cjk_fallback">限</span><span class="mord cjk_fallback">制</span><span class="mord cjk_fallback">该</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">大</span><span class="mord cjk_fallback">小</span><span class="mord cjk_fallback">。</span><span class="mord cjk_fallback">可</span><span class="mord cjk_fallback">以</span><span class="mord cjk_fallback">编</span><span class="mord cjk_fallback">辑</span><span class="mord">/</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mord mathnormal">c</span><span class="mord">/</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">e</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span><span class="mord cjk_fallback">，</span><span class="mord cjk_fallback">修</span><span class="mord cjk_fallback">改</span><span class="mord cjk_fallback">其</span><span class="mord cjk_fallback">中</span><span class="mord cjk_fallback">的</span><span class="mord cjk_fallback">选</span><span class="mord cjk_fallback">项</span><span class="mord cjk_fallback">如</span><span class="mord cjk_fallback">下</span><span class="mord cjk_fallback">：</span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.13889em;">T</span><span class="mord mathnormal" style="margin-right:0.05764em;">S</span><span class="mord mathnormal" style="margin-right:0.07847em;">I</span><span class="mord mathnormal" style="margin-right:0.07153em;">Z</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord">3</span><span class="mord">0</span><span class="mord cjk_fallback">表</span><span class="mord cjk_fallback">示</span><span class="mord cjk_fallback">在</span><span class="mord cjk_fallback">文</span><span class="mord cjk_fallback">件</span></span></span></span>HOME/.bash_history中记录最近的30条历史命令。如果将“HISTSIZE”设置为0，则表示不记录历史命令，那么也就不能用键盘的上下键查找历史命令了。</p>
<h4 id="4删除系统默认的不必要用户和组"><a class="markdownIt-Anchor" href="#4删除系统默认的不必要用户和组"></a> 4．删除系统默认的不必要用户和组</h4>
<p>Linux提供了各种系统账户，在系统安装完毕，如果不需要某些用户或者组，就要立即删除它，因为账户越多，系统就越不安全，越容易受到攻击。 删除系统不必要的用户用下面命令 [root@localhost ~]# userdel username 删除系统不必要的组用如下命令： [root@localhost ~]# groupdel  groupname Linux系统中可以删除的默认用户和组有： 删除的用户,如adm,lp,sync,shutdown,halt,news,uucp,operator,games,gopher等。 删除的组,如adm,lp,news,uucp,games,dip,pppusers,popusers,slipusers等。</p>
<h4 id="5-关闭selinux"><a class="markdownIt-Anchor" href="#5-关闭selinux"></a> 5. 关闭selinux</h4>
<p>SELinux是 Security-Enhanced Linux的简称，是一种内核强制访问控制安全系统，目前SELinux已经集成到Linux 2.6内核的主线和大多数Linux发行版上，由于SELinux与现有Linux应用程序和Linux内核模块兼容性还存在一些问题，因此建议初学者先关闭selinux，等到对linux有了深入的认识后，再对selinux深入研究不迟！ 查看linux系统selinux是否启用，可以使用getenforce命令： [root@localhost ~]# getenforce Disabled 关闭selinux，在redhat系列发行版中，可以直接修改如下文件： [root@localhost ~]#vi /etc/sysconfig/selinux # This file controls the state of SELinux on the system. # SELINUX= can take one of these three values: #       enforcing - SELinux security policy is enforced. #       permissive - SELinux prints warnings instead of enforcing. #       disabled - SELinux is fully disabled. SELINUX=enforcing # SELINUXTYPE= type of policy in use. Possible values are: #       targeted - Only targeted network daemons are protected. #       strict - Full SELinux protection. SELINUXTYPE=targeted 将SELINUX=enforcing修改为SELINUX=disabled, 重启系统后将会停止SElinux。</p>
<h4 id="6设定tcp_wrappers防火墙"><a class="markdownIt-Anchor" href="#6设定tcp_wrappers防火墙"></a> 6．设定tcp_wrappers防火墙</h4>
<p>Tcp_Wrappers是一个用来分析TCP/IP封包的软件，类似的IP封包软件还有iptables，linux默认都安装了此软件，作为一个安全的系统，Linux本身有两层安全防火墙，通过IP过滤机制的iptables实现第一层防护，iptables防火墙通过直观地监视系统的运行状况，阻挡网络中的一些恶意攻击，保护整个系统正常运行，免遭攻击和破坏。关于iptables的实现，将在下个章节详细讲述。如果通过了第一层防护，那么下一层防护就是tcp_wrappers了，通过Tcp_Wrappers可以实现对系统中提供的某些服务的开放与关闭、允许和禁止，从而更有效地保证系统安全运行。 Tcp_Wrappers的使用很简单，仅仅两个配置文件：/etc/hosts.allow和/etc/hosts.deny （1） 查看系统是否安装了Tcp_Wrappers [root@localhost ~]#rpm -q tcp_wrappers  或者 [root@localhost ~]#rpm -qa grep tcp tcp_wrappers-7.6-37.2 tcpdump-3.8.2-10.RHEL4 如果有上面的类似输出，表示系统已经安装了tcp_wrappers模块。如果没有显示，可能是没有安装，可以从linux系统安装盘找到对应RPM包进行安装。 （2）tcp_wrappers防火墙的局限性 系统中的某个服务是否可以使用tcp_wrappers防火墙，取决于该服务是否应用了libwrapped库文件，如果应用了就可以使用tcp_wrappers防火墙，系统中默认的一些服务如：sshd、portmap、sendmail、xinetd、vsftpd、tcpd等都可以使用tcp_wrappers防火墙。 (3)  tcp_wrappers设定的规则 tcp_wrappers防火墙的实现是通过/etc/hosts.allow和/etc/hosts.deny两个文件来完成的，首先看一下设定的格式： service:host(s) [:action]  service：代表服务名，例如sshd、vsftpd、sendmail等。  host(s)：主机名或者IP地址，可以有多个，例如192.168.60.0、<a href="http://www.ixdba.net/">www.ixdba.net</a>  action：动作， 符合条件后所采取的动作。 几个关键字：  ALL：所有服务或者所有IP。  ALL EXCEPT：所有的服务或者所有IP除去指定的。 例如：ALL:ALL EXCEPT 192.168.60.132 表示除了192.168.60.132这台机器，任何机器执行所有服务时或被允许或被拒绝。 了解了设定语法后，下面就可以对服务进行访问限定。 例如互联网上一台linux服务器，实现的目标是：仅仅允许222.90.66.4、61.185.224.66以及域名softpark.com通过SSH服务远程登录到系统，设置如下： 首先设定允许登录的计算机，即配置/etc/hosts.allow文件，设置很简单，只要修改/etc/hosts.allow（如果没有此文件，请自行建立）这个文件即可。 只需将下面规则加入/etc/hosts.allow即可。 sshd: 222.90.66.4 61.185.224.66 <a href="http://softpark.com">softpark.com</a> 接着设置不允许登录的机器，也就是配置/etc/hosts.deny文件了。 一般情况下，linux会首先判断/etc/hosts.allow这个文件，如果远程登录的计算机满足文件/etc/hosts.allow设定的话，就不会去使用/etc/hosts.deny文件了，相反，如果不满足hosts.allow文件设定的规则的话，就会去使用hosts.deny文件了，如果满足hosts.deny的规则，此主机就被限制为不可访问linux服务器，如果也不满足hosts.deny的设定，此主机默认是可以访问linux服务器的，因此，当设定好/etc/hosts.allow文件访问规则之后，只需设置/etc/hosts.deny为“所有计算机都不能登录状态”即可。 sshd:ALL 这样，一个简单的tcp_wrappers防火墙就设置完毕了。 本文出自 “<a href="http://ixdba.blog.51cto.com/">技术成就梦想</a>” 博客，请务必保留此出处<a href="http://ixdba.blog.51cto.com/2895551/526443">http://ixdba.blog.51cto.com/2895551/526443</a></p>
<h1 id="linux-hosts的allow和deny"><a class="markdownIt-Anchor" href="#linux-hosts的allow和deny"></a> <strong>linux hosts的allow和deny</strong></h1>
<p>/etc/hosts.allow和/etc/hosts.deny两个文件是控制远程访问设置的，通过他可以允许或者拒绝某个ip或者ip段的客户访问linux的某项服务。 网络防火墙是阻挡非授权主机访问网络的第一道防护，但是它们不应该仅有一道屏障。 Linux使用了两个文件/etc/host.allow和/etc/hosts.deny，根据网络请求的来源限制对服务的访问。 host.allow文件列出了允许连接到一个特定服务的主机，而hosts.deny文件则负责限制访问。 不过，这两个文件只控制对有hosts_access功能的服务（如xinetd所管理的那些服务、sshd和某些配置的sendmail）的访问。 在大多数情况下，明智的做法是先做限制，然后只允许从指定主机访问关键服务。</p>
<blockquote>
<p>我们建议，默认在hosts.deny文件中加上下面这一行配置，拒绝所有的访问： ALL:ALL</p>
</blockquote>
<p>接下来，您可以在hosts.allow文件中逐个开放访问许可。下面的配置允许从网络192.168/16访问SSH，而从任何地方访问sendmail。</p>
<p>sshd: 192.168.0.0/255.255.0.0<br />
sendmail: ALL</p>
<p>两个文件每行配置的格式都是service: host或者service: network。失败的连接企图被记录到syslog中。从没有得到允许访问该服务的主机来的连接会被立即关闭。 大多数Linux发行版本默认都带host.allow和hosts.deny，但是它们通常为空。 修改/etc/hosts.allow文件</p>
<h1 id=""><a class="markdownIt-Anchor" href="#"></a> </h1>
<h1 id="hostsallow-this-file-describes-the-names-of-the-hosts-which-are"><a class="markdownIt-Anchor" href="#hostsallow-this-file-describes-the-names-of-the-hosts-which-are"></a> hosts.allow This file describes the names of the hosts which are</h1>
<h1 id="allowed-to-use-the-local-inet-services-as-decided"><a class="markdownIt-Anchor" href="#allowed-to-use-the-local-inet-services-as-decided"></a> allowed to use the local INET services, as decided</h1>
<h1 id="by-the-usrsbintcpd-server"><a class="markdownIt-Anchor" href="#by-the-usrsbintcpd-server"></a> by the ‘/usr/sbin/tcpd’ server.</h1>
<h1 id="-2"><a class="markdownIt-Anchor" href="#-2"></a> </h1>
<p>sshd:210.13.218.*:allow</p>
<p>sshd:222.77.15.*:allow</p>
<p>以上写法表示允许210和222两个ip段连接sshd服务（这必然需要hosts.deny这个文件配合使用），当然:allow完全可以省略的。 当然如果管理员集中在一个IP那么这样写是比较省事的 all:218.24.129.110 //他表示接受110这个ip的所有请求！ /etc/hosts.deny文件，此文件是拒绝服务列表，文件内容如下：</p>
<h1 id="-3"><a class="markdownIt-Anchor" href="#-3"></a> </h1>
<h1 id="hostsdeny-this-file-describes-the-names-of-the-hosts-which-are"><a class="markdownIt-Anchor" href="#hostsdeny-this-file-describes-the-names-of-the-hosts-which-are"></a> hosts.deny This file describes the names of the hosts which are</h1>
<h1 id="not-allowed-to-use-the-local-inet-services-as-decided"><a class="markdownIt-Anchor" href="#not-allowed-to-use-the-local-inet-services-as-decided"></a> *not* allowed to use the local INET services, as decided</h1>
<h1 id="by-the-usrsbintcpd-server-2"><a class="markdownIt-Anchor" href="#by-the-usrsbintcpd-server-2"></a> by the ‘/usr/sbin/tcpd’ server.</h1>
<h1 id="-4"><a class="markdownIt-Anchor" href="#-4"></a> </h1>
<h1 id="the-portmap-line-is-redundant-but-it-is-left-to-remind-you-that"><a class="markdownIt-Anchor" href="#the-portmap-line-is-redundant-but-it-is-left-to-remind-you-that"></a> The portmap line is redundant, but it is left to remind you that</h1>
<h1 id="the-new-secure-portmap-uses-hostsdeny-and-hostsallow-in-particular"><a class="markdownIt-Anchor" href="#the-new-secure-portmap-uses-hostsdeny-and-hostsallow-in-particular"></a> the new secure portmap uses hosts.deny and hosts.allow. In particular</h1>
<h1 id="you-should-know-that-nfs-uses-portmap"><a class="markdownIt-Anchor" href="#you-should-know-that-nfs-uses-portmap"></a> you should know that NFS uses portmap!</h1>
<p>sshd:all:deny</p>
<p>注意看：sshd:all:deny表示拒绝了所有sshd远程连接。:deny可以省略。 所以：当hosts.allow和 host.deny相冲突时，以hosts.allow设置为准。 注意修改完后： service xinetd restart 才能让刚才的更改生效。 /etc/hosts.allow（允许）和/etc/hosts.deny（禁止）这两个文件是tcpd服务器的配置文件 tcpd服务器可以控制外部IP对本机服务的访问 linux 系统会先检查/etc/hosts.deny规则，再检查/etc/hosts.allow规则，如果有冲突 按/etc/hosts.allow规则处理 比如： 1.禁止所有ip访问linux 的ssh功能 可以在/etc/hosts.deny添加一行 sshd:all:deny 2.禁止某一个ip（192.168.11.112）访问ssh功能 可以在/etc/hosts.deny添加一行sshd:192.168.11.112 3.如果在/etc/hosts.deny和/etc/hosts.allow同时 有sshd:192.168.11.112 规则，则192.168.11.112可以访问主机的ssh服务</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux中对文本的行与列进行转换</title>
    <url>/2017/04/25/linux-transform-row-and-column/</url>
    <content><![CDATA[<p>命令： awk ‘{for(i=0;<ins>i&lt;=NF;)a[i]=a[i]?a[i] FS <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">i:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.65952em;vertical-align:0em;"></span><span class="mord mathnormal">i</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span>i}END{for(i=0;i</ins>&lt;NF;)print a[i]}’  a.txt   Ref: <a href="http://blog.csdn.net/reyleon/article/details/13018119">http://blog.csdn.net/reyleon/article/details/13018119</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux用Parallel命令并行处理命令</title>
    <url>/2016/02/22/linux-using-parallel-for-a-task/</url>
    <content><![CDATA[<p>你是否曾经有过要计算一个非常大的数据(几百GB)的需求？或在里面搜索，或其它操作——一些无法并行的操作。数据专家们，我是在对你们说。你可能有一个4核或更多核的CPU，但我们合适的工具，例如 <strong>grep</strong>, <strong>bzip2</strong>, <strong>wc</strong>, <strong>awk</strong>, <strong>sed</strong>等等，都是单线程的，只能使用一个CPU内核。 借用卡通人物Cartman的话，“如何我能使用这些内核”? 要想让Linux命令使用所有的CPU内核，我们需要用到<a href="https://www.gnu.org/software/parallel/" title="GNU Parallel">GNU Parallel</a>命令，它让我们所有的CPU内核在单机内做神奇的map-reduce操作，当然，这还要借助很少用到的**–pipes** 参数(也叫做**–spreadstdin**)。这样，你的负载就会平均分配到各CPU上，真的。</p>
<h3 id="bzip2"><a class="markdownIt-Anchor" href="#bzip2"></a> BZIP2</h3>
<p>bzip2是比gzip更好的压缩工具，但它很慢！别折腾了，我们有办法解决这问题。 以前的做法：</p>
<p>cat bigfile.bin  bzip2 --best &gt; compressedfile.bz2</p>
<p>现在这样：</p>
<p>cat bigfile.bin  parallel --pipe --recend ‘’ -k bzip2 --best &gt; compressedfile.bz2</p>
<p>尤其是针对bzip2，GNU parallel在多核CPU上是超级的快。你一不留神，它就执行完成了。</p>
<h3 id="grep"><a class="markdownIt-Anchor" href="#grep"></a> GREP</h3>
<p>如果你有一个非常大的文本文件，以前你可能会这样：</p>
<p>grep pattern bigfile.txt</p>
<p>现在你可以这样：</p>
<p>cat bigfile.txt  parallel  --pipe grep ‘pattern’</p>
<p>或者这样：</p>
<p>cat bigfile.txt  parallel --block 10M --pipe grep ‘pattern’</p>
<p>这第二种用法使用了 <strong>–block 10M</strong>参数，这是说每个内核处理1千万行——你可以用这个参数来调整每个CUP内核处理多少行数据。</p>
<h3 id="awk"><a class="markdownIt-Anchor" href="#awk"></a> AWK</h3>
<p>下面是一个用awk命令计算一个非常大的数据文件的例子。 常规用法：</p>
<p>cat rands20M.txt  awk ‘{s+=$1} END {print s}’</p>
<p>现在这样：</p>
<p>cat rands20M.txt  parallel --pipe awk \‘{s+=\$1} END {print s}\’  awk ‘{s+=$1} END {print s}’</p>
<p>这个有点复杂：parallel命令中的**–pipe**参数将cat输出分成多个块分派给awk调用，形成了很多子计算操作。这些子计算经过第二个管道进入了同一个awk命令，从而输出最终结果。第一个awk有三个反斜杠，这是GNU parallel调用awk的需要。</p>
<h3 id="wc"><a class="markdownIt-Anchor" href="#wc"></a> WC</h3>
<p>想要最快的速度计算一个文件的行数吗？ 传统做法：</p>
<p>wc -l bigfile.txt</p>
<p>现在你应该这样：</p>
<p>cat bigfile.txt  parallel  --pipe wc -l  awk ‘{s+=$1} END {print s}’</p>
<p>非常的巧妙，先使用parallel命令‘mapping’出大量的<code>wc -l</code>调用，形成子计算，最后通过管道发送给awk进行汇总。</p>
<h3 id="sed"><a class="markdownIt-Anchor" href="#sed"></a> SED</h3>
<p>想在一个巨大的文件里使用sed命令做大量的替换操作吗？ 常规做法：</p>
<p>sed s<sup>old</sup>new^g bigfile.txt</p>
<p>现在你可以：</p>
<p>cat bigfile.txt  parallel --pipe sed s<sup>old</sup>new^g</p>
<p>…然后你可以使用管道把输出存储到指定的文件里。 转载自：<a href="http://www.vaikan.com/use-multiple-cpu-cores-with-your-linux-commands/">http://www.vaikan.com/use-multiple-cpu-cores-with-your-linux-commands/</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>linux安装mysql</title>
    <url>/2014/09/02/linux%E5%AE%89%E8%A3%85mysql/</url>
    <content><![CDATA[<p><a href="http://xn--shenwei-t52om2jbu2g1b5a.me">本文转自shenwei.me</a></p>
<span id="more"></span>
<p>我的MySQL将安装在下面的目录，将设置默认端口号为33060（可任意，必须大于1024，且不能其它软件冲突）。</p>
<p>1</p>
<p>/db/home/shenwei/local/app/msyql</p>
<p>下文中的配置文件中，最好使用绝对路径，不要使用相对路径，如“~/”。   <strong>安装编译工具</strong> cmake是必须的，其它基本的编译工具，如gcc等就不说了吧，如果configure过程中提醒缺少编译器，请自行google。 请到<a href="http://www.cmake.org/files/%E9%80%89%E6%8B%A9%E6%9C%80%E6%96%B0%E7%89%88%E7%9A%84cmake%E9%93%BE%E6%8E%A5%EF%BC%8C%E7%84%B6%E5%90%8E%E4%B8%8B%E8%BD%BD%E5%AE%89%E8%A3%85%EF%BC%9A">http://www.cmake.org/files/选择最新版的cmake链接，然后下载安装：</a></p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>wget <a href="http://www.cmake.org/files/v2.8/cmake%5C-2.8.11.1.tar.gz">http://www.cmake.org/files/v2.8/cmake\-2.8.11.1.tar.gz</a></p>
<p>cd cmake-2.8.11.1</p>
<p>./configure --prefix=/db/home/shenwei/local/app/cmake</p>
<p>make &amp;&amp; make install</p>
<p>将cmake目录加入环境变量(或者在~/local/bin下面建立链接cmake可执行程序的软链接, ~/local/bin是我自己的bin目录, 已经加入到环境变量$PATH中)：编辑<sub>/.bashrc或者</sub>/.bash_profile，加入以下内容：</p>
<p>1</p>
<p>export PATH=~/local/app/cmake:$PATH</p>
<p>让其生效</p>
<p>1</p>
<p>. ~/.bashrc</p>
<p><strong>编译、安装MySQL</strong> 下载前请到<a href="http://dev.mysql.com/downloads/mysql/">http://dev.mysql.com/downloads/mysql/</a>中，选择source code，页面最下端，下载最新版本的源码（mysql-5.6.××.tar.gz）。33060是自定义的端口号。</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>tar -zxvf mysql-5.6.19.tar.gz</p>
<p>cd mysql-5.6.19</p>
<p>cmake -DCMAKE_INSTALL_PREFIX=/db/home/shenwei/local/app/mysql -DMYSQL_TCP_PORT=33060</p>
<p>make &amp;&amp; make install</p>
<p><strong>配置</strong> **1）**将MySQL的bin目录和scripts目录加入环境变量：编辑<sub>/.bashrc或者</sub>/.bash_profile，加入以下内容：</p>
<p>1</p>
<p>export PATH=<sub>/local/app/mysql/bin:</sub>/local/app/mysql/scripts:$PATH</p>
<p>让其生效</p>
<p>1</p>
<p>. ~/.bashrc</p>
<p>**2）**安装数据库。 先再mysql下面创建一个tmp目录。</p>
<p>1</p>
<p>mkdir ~/local/app/mysql/tmp</p>
<p>用mysql_install_db安装数据库。此处设置的–user是mysqld进程所属用户，最好设置为你的linux用户，才不会出现mysqld对文件操作的权限问题。</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>mkdir /db/home/shenwei/local/app/mysql/tmp</p>
<p>cd /db/home/shenwei/local/app/mysql/scripts</p>
<p>./mysql_install_db --basedir=/db/home/shenwei/local/app/mysql --datadir=/db/home/shenwei/local/app/mysql/data --tmpdir=/db/home/shenwei/local/app/mysql/tmp --user=shenwei</p>
<p><strong>3）</strong> 配置mysql配置文件 创建etc目录，并将my.cnf移入其中。为何放这儿呢？因为这是mysqladmin命令搜索配置文件的路径之一。</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>cd /db/home/shenwei/local/app/mysql</p>
<p>mkdir etc</p>
<p>mv my.cnf etc</p>
<p>编辑my.cnf，如下：</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>[client]</p>
<p>port=33060</p>
<p>socket=/db/home/shenwei/local/app/mysql/my.sock</p>
<p>[mysqld]</p>
<p>port=33060</p>
<p>socket=/db/home/shenwei/local/app/mysql/my.sock</p>
<p>datadir=/db/home/shenwei/local/app/mysql/data</p>
<p>[mysql.server]</p>
<p>user=shenwei</p>
<p>basedir=/db/home/shenwei/local/app/mysql</p>
<p>sql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES</p>
<p><strong>4)</strong> 创建Mysql启动脚本。 为了方便，在mysql目录scripts下面创建，并增加可执行属性。</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>cd /db/home/shenwei/local/app/mysql/scripts</p>
<p>touch my_mysql_start</p>
<p>chmod a+x my_mysql_start</p>
<p>my_mysql_start内容为：</p>
<p>1</p>
<p>2</p>
<p>#!/bin/sh</p>
<p>/db/home/shenwei/local/app/mysql/bin/mysqld_safe --defaults-file=/db/home/shenwei/local/app/mysql/etc/my.cnf --socket=/db/home/shenwei/local/app/mysql/my.sock --pid-file=/db/home/shenwei/local/app/mysql/my.pid &amp;</p>
<p>**5）**通过mysql_secure_installation进行安全性设置 由于mysql_secure_installation命令无法指定socket文件，无法成功连接mysqld，会出现以下错误，请转到第6）步</p>
<p>1</p>
<p>ERROR 2002 (HY000): Can’t connect to local MySQL server through socket ‘/tmp/mysql.sock’ (2)</p>
<p>**6）**设置root密码 先通过my_mysql_start脚本启动mysqld，由于它所在目录scripts已经被加入环境变量PATH中，可直接运行。</p>
<p>1</p>
<p>my_mysql_start</p>
<p>由于目前root密码为空，可直接进去mysql客户端：</p>
<p>1</p>
<p>2</p>
<p>cd /db/home/shenwei/local/mysql/bin</p>
<p>./mysql -P 33060 -u root -p</p>
<p>题外话：也可以不必进入你的mysql/bin目录，而直接用系统的mysql客户端mysql，不过一定要指定端口。 输入上述命令，后出现“Enter password:  ”直接回车即可（密码为空）。 进入mysql命令行后，输入以下命令，设置root密码：</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>mysql&gt; use mysql;</p>
<p>Reading table information for completion of table and column names</p>
<p>You can turn off this feature to get a quicker startup with -A</p>
<p>Database changed</p>
<p>mysql&gt; update user set password=PASSWORD(“mysqlpassword”) where user=“root”;</p>
<p>Query OK, 0 rows affected (0.00 sec)</p>
<p>Rows matched: 4 Changed: 0 Warnings: 0</p>
<p>mysql&gt; flush privileges;</p>
<p>Query OK, 0 rows affected (0.00 sec)</p>
<p>mysql&gt; quit</p>
<p>Bye</p>
<p><strong>7）</strong> 创建Mysql关闭脚本。 为了方便，在mysql目录scripts下面创建，并增加可执行属性。</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>cd /db/home/shenwei/local/app/mysql/scripts</p>
<p>touch my_mysql_stop</p>
<p>chmod a+x my_mysql_stop</p>
<p>my_mysql_stop内容为：</p>
<p>1</p>
<p>2</p>
<p>#!/bin/sh</p>
<p>/db/home/shenwei/local/app/mysql/bin/mysqladmin shutdown -P 33060 -u root -p</p>
<p>今后可以直接通过my_mysq_stop关闭mysql。   <strong>经验</strong> 多Google！出错后，自己看提示信息，看帮助信息（command –help）后仍无法解决，用核心的错误信息去Google!   <strong>参考</strong></p>
<ol>
<li><a href="http://notes.oneplus.info/Operation/2012/12/03/install-mysql-php-without-root/">http://notes.oneplus.info/Operation/2012/12/03/install-mysql-php-without-root/</a></li>
<li><a href="http://san-yun.iteye.com/blog/1493931">http://san-yun.iteye.com/blog/1493931</a></li>
<li>其它无数google出来的页面</li>
</ol>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>linux系统下解压 tgz 文件</title>
    <url>/2014/08/22/linux%E7%B3%BB%E7%BB%9F%E4%B8%8B%E8%A7%A3%E5%8E%8B-tgz-%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<h3 id="解压-tgz-文件"><a class="markdownIt-Anchor" href="#解压-tgz-文件"></a> 解压 tgz 文件</h3>
<span id="more"></span>
<p>.tar 解包：tar xvf FileName.tar 打包：tar cvf FileName.tar DirName （注：tar是打包，不是压缩！） ——————————————— .gz 解压1：gunzip FileName.gz 解压2：gzip -d FileName.gz 压缩：gzip FileName .tar.gz 和 .tgz 解压：tar zxvf FileName.tar.gz 压缩：tar zcvf FileName.tar.gz DirName ——————————————— .bz2 解压1：bzip2 -d FileName.bz2 解压2：bunzip2 FileName.bz2 压缩： bzip2 -z FileName .tar.bz2 解压：tar jxvf FileName.tar.bz2 压缩：tar jcvf FileName.tar.bz2 DirName ——————————————— .bz 解压1：bzip2 -d <a href="http://FileName.bz">FileName.bz</a> 解压2：bunzip2 <a href="http://FileName.bz">FileName.bz</a> 压缩：未知 .tar.bz 解压：tar jxvf <a href="http://FileName.tar.bz">FileName.tar.bz</a> 压缩：未知 ———————————————</p>
<p>.xz</p>
<p>需要安装xz软件，分两步解压：</p>
<p>xz -d isl-0.16.tar.xz</p>
<p>tar -xvf isl-0.16.tar</p>
<p>——————————————— .Z 解压：uncompress FileName.Z 压缩：compress FileName .tar.Z 解压：tar Zxvf FileName.tar.Z 压缩：tar Zcvf FileName.tar.Z DirName ——————————————— .zip 解压：unzip FileName.zip 压缩：zip FileName.zip DirName ——————————————— .rar 解压：rar x FileName.rar 压缩：rar a FileName.rar DirNamerar请到：<a href="http://www.rarsoft.com/download.htm">http://www.rarsoft.com/download.htm</a> 下载！ 解压后请将rar_static拷贝到/usr/bin目录（其他由<span class='katex-error' title='ParseError: KaTeX parse error: Undefined control sequence: \[ at position 20: …环境变量指定的目录也可以）： \̲[̲root@www2 tmp\]…'>PATH环境变量指定的目录也可以）： \[root@www2 tmp\]# cp rar\_static /usr/bin/rar ——————————————— .lha 解压：lha -e FileName.lha 压缩：lha -a FileName.lha FileName lha请到：http://www.infor.kanazawa-it.ac.jp/~ishii/lhaunix/下载！ &gt;解压后请将lha拷贝到/usr/bin目录（其他由</span>PATH环境变量指定的目录也可以）： [root@www2 tmp]# cp lha /usr/bin/ ——————————————— .rpm 解包：rpm2cpio FileName.rpm cpio -div ——————————————— .deb 解包：ar p FileName.deb data.tar.gz tar zxf - ——————————————— .tar .tgz .tar.gz .tar.Z .tar.bz .tar.bz2 .zip .cpio .rpm .deb .slp .arj .rar .ace .lha .lzh .lzx .lzs .arc .sda .sfx .lnx .zoo .cab .kar .cpt .pit .sit .sea 解压：sEx x FileName.* 压缩：sEx a FileName.* FileName sEx只是调用相关程序，本身并无压缩、解压功能，请注意！ sEx请到： <a href="http://sourceforge.net/projects/sex%E4%B8%8B%E8%BD%BD%EF%BC%81">http://sourceforge.net/projects/sex下载！</a> 解压后请将sEx拷贝到/usr/bin目录（其他由$PATH环境变量指定的目录也可以）： [root@www2 tmp]# cp sEx /usr/bin/ gzip 命令 减少文件大小有两个明显的好处，一是可以减少存储空间，二是通过网络传输文件时，可以减少传输的时间。gzip 是在 Linux 系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。 1.以.a为扩展名的文件: #tar xv file.a 2.以.z为扩展名的文件: #uncompress file.Z 3.以.gz为扩展名的文件: #gunzip file.gz 4.以.bz2为扩展名的文件: #bunzip2 file.bz2 5.以.tar.Z为扩展名的文件: #tar xvZf file.tar.Z 或 #compress -dc file.tar.Z tar xvf - 6.以.tar.gz/.tgz为扩展名的文件: #tar xvzf file.tar.gz 或 gzip -dc file.tar.gz tar xvf - 7.以.tar.bz2为扩展名的文件: #tar xvIf file.tar.bz2 或 bzip2 -dc file.tar.bz2 xvf - 8.以.cpio.gz/.cgz为扩展名的文件: #gzip -dc file.cgz cpio -div 9.以.cpio/cpio为扩展名的文件: #cpio -div file.cpio 或cpio -divc file.cpio 10.以.rpm为扩展名的文件安装: #rpm -i file.rpm 11.以.rpm为扩展名的文件解压缩： #rpm2cpio file.rpm cpio -div 12.以.deb为扩展名的文件安装： #dpkg -i file.deb 13.以.deb为扩展名的文件解压缩: #dpkg-deb --fsys-tarfile file.deb tar xvf - ar p file.deb data.tar.gz tar xvzf - 14.以.zip为扩展名的文件: #unzip file.zip 在linux下解压Winzip格式的文件 要是装了jdk的话，可以用jar命令；还可以使用unzip命令。 直接解压.tar.gz文件 xxxx.tar.gz文件使用tar带zxvf参数，可以一次解压开。XXXX为文件名。 例如： <span class='katex-error' title='ParseError: KaTeX parse error: Undefined control sequence: \[ at position 718: … gz格式 gzip gzip\̲[̲选项\]要压缩（或解压缩）的文…'>tar zxvf xxxx.tar.gz 各种压缩文件的解压（安装方法） 文件扩展名 解压（安装方法） .a ar xv file.a .Z uncompress file.Z .gz gunzip file.gz .bz2 bunzip2 file.bz2 .tar.Z tar xvZf file.tar.Z compress -dc file.tar.Z tar xvf - .tar.gz/.tgz tar xvzf file.tar.gz gzip -dc file.tar.gz tar xvf - .tar.bz2 tar xvIf file.tar.bz2 bzip2 -dc file.tar.bz2 xvf - .cpio.gz/.cgz gzip -dc file.cgz cpio -div .cpio/cpio cpio -div file.cpio cpio -divc file.cpio .rpm/install rpm -i file.rpm .rpm/extract rpm2cpio file.rpm cpio -div .deb/install dpkg -i file.deb .deb/exrtact dpkg-deb --fsys-tarfile file.deb tar xvf - ar p file.deb data.tar.gz tar xvzf - .zip unzip file.zip bzip2 -d myfile.tar.bz2 tar xvf tar xvfz myfile.tar.bz2 x 是解压 v 是复杂输出 f 是指定文件 z gz格式 gzip gzip\[选项\]要压缩（或解压缩）的文件名 -c将输出写到标准输出上，并保留原有文件。 -d将压缩文件压缩。 -l对每个压缩文件，显示下列字段：压缩文件的大小，未压缩文件的大小、压缩比、未压缩文件的名字 -r递归式地查找指定目录并压缩或压缩其中的所有文件。 -t测试压缩文件是正完整。 -v对每一个压缩和解压缩的文件，显示其文件名和压缩比。 -num-用指定的数字调整压缩的速度。 举例： 把/usr目录并包括它的子目录在内的全部文件做一备份，备份文件名为usr.tar tar cvf usr.tar /home 把/usr 目录并包括它的子目录在内的全部文件做一备份并进行压缩，备份文件名是usr.tar.gz tar czvf usr.tar.gz /usr 压缩一组文件，文件的后缀为tar.gz #tar cvf back.tar /back/ #gzip -q back.tar or #tar cvfz back.tar.gz /back/ 释放一个后缀为tar.gz的文件。 #tar zxvf back.tar.gz #gzip back.tar.gz #tar xvf back.tar tar的使用方法： 1：压缩一组文件为tar.gz后缀 tar cvf backup.tar /etc 或gzip -q backup.tar.gz 2:释放一个后缀为tar.gz的文件 gunzip backup.tar.gz 或tar xvf backup.tar 3:用一个命令完成压缩 tar cvf -/etc gzip -qc &gt; backup.tar.gz 4:用一个命令完成释放 gunzip -c backup.tar.gz tar xvf - 5:如何解开ta.Z的文件 tar xvfz backup.tar.Z 或uncompress backup.tar.Z tar xvf backup.tar 6:如何解开.tgz文件 gunzip backup.tgz 7:如何压缩和解压缩.bz2的包 bzip2 /etc/smb.conf 这将压缩文件smb.conf成smb.conf.bz2 bunzip2 /etc/smb.conf.bz2 在当前目录下还原smb.conf.bz2为smb.conf ======================= 4 ============================== .tar 解包： tar xvf FileName.tar 打包： tar cvf FileName.tar DirName （注：tar是打包，不是压缩！） --------------------------------------------- .gz 解压1：gunzip FileName.gz 解压2：gzip -d FileName.gz 压缩： gzip FileName .tar.gz 和 .tgz 解压：tar zxvf FileName.tar.gz 压缩：tar zcvf FileName.tar.gz DirName --------------------------------------------- .bz2 解压1：bzip2 -d FileName.bz2 解压2：bunzip2 FileName.bz2 压缩： bzip2 -z FileName .tar.bz2 解压：tar jxvf FileName.tar.bz2 压缩：tar jcvf FileName.tar.bz2 DirName --------------------------------------------- .bz 解压1：bzip2 -d FileName.bz 解压2：bunzip2 FileName.bz 压缩：未知 .tar.bz 解压：tar jxvf FileName.tar.bz 压缩：未知 --------------------------------------------- .Z 解压：uncompress FileName.Z 压缩：compress FileName .tar.Z 解压：tar Zxvf FileName.tar.Z 压缩：tar Zcvf FileName.tar.Z DirName --------------------------------------------- .zip 解压：unzip FileName.zip 压缩：zip FileName.zip DirName --------------------------------------------- .rar 解压：rar a FileName.rar 压缩：rar e FileName.rar rar请到：http://www.rarsoft.com/download.htm 下载！ 解压后请将rar\_static拷贝到/usr/bin目录（其他由</span>PATH环境变量指定的目录也可以）： [root@www2 tmp]# cp rar_static /usr/bin/rar --------------------------------------------- .lha 解压：lha -e FileName.lha 压缩：lha -a FileName.lha FileName lha请到：<a href="http://www.infor.kanazawa-it.ac.jp/~ishii/lhaunix/%E4%B8%8B%E8%BD%BD%EF%BC%81">http://www.infor.kanazawa-it.ac.jp/~ishii/lhaunix/下载！</a> &gt;解压后请将lha拷贝到/usr/bin目录（其他由<span class='katex-error' title='ParseError: KaTeX parse error: Undefined control sequence: \[ at position 20: …环境变量指定的目录也可以）： \̲[̲root@www2 tmp\]…'>PATH环境变量指定的目录也可以）： \[root@www2 tmp\]# cp lha /usr/bin/ --------------------------------------------- .rpm 解包：rpm2cpio FileName.rpm cpio -div --------------------------------------------- .deb 解包：ar p FileName.deb data.tar.gz tar zxf - --------------------------------------------- ★☆★☆★☆★☆★☆★☆★☆★☆★☆★☆★☆★☆ .tar .tgz .tar.gz .tar.Z .tar.bz .tar.bz2 .zip .cpio .rpm .deb .slp .arj .rar .ace .lha .lzh .lzx .lzs .arc .sda .sfx .lnx .zoo .cab .kar .cpt .pit .sit .sea 解压：sEx x FileName.\* 压缩：sEx a FileName.\* FileName sEx只是调用相关程序，本身并无压缩、解压功能，请注意！ sEx请到： http://sourceforge.net/projects/sex下载！ 解压后请将sEx拷贝到/usr/bin目录（其他由</span>PATH环境变量指定的目录也可以）： [root@www2 tmp]# cp sEx /usr/bin/ ★☆★☆★☆★☆★☆★☆★☆★☆★☆★☆★☆★☆ gzip 命令 gzip 是在 Linux 系统中经常使用的一个对文件进行压缩和解压缩的命令，既方便又好用。 语法：gzip [选项] 压缩（解压缩）的文件名 该命令的各选项含义如下： -c 将输出写到标准输出上，并保留原有文件。-d 将压缩文件解压。-l 对每个压缩文件，显示下列字段：     压缩文件的大小；未压缩文件 的大小；压缩比；未压缩文件的名字-r 递归式地查找指定目录并压缩其中的所有文件或者是解压缩。-t 测试，检查压缩文件是否完整。-v 对每一个压缩和解压的文件，显示文件名和压缩比。-num 用指定的数字 num 调整压缩的速度，-1 或 --fast 表示最快压缩方法（低压缩比 ），-9 或–best表示最慢压缩方法（高压缩比）。系统缺省值为 6。 指令实例： gzip *% 把当前目录下的每个文件压缩成 .gz 文件。gzip -dv *% 把当前目录下每个压缩的文件解压，并列出详细的信息。gzip -l *% 详细 显示例1中每个压缩的文件的信息，并不解压。gzip usr.tar% 压缩 tar 备份文件 usr.tar，此时压缩文件的扩展名为.tar.gz。</p>
<p>参考资料：<a href="http://blog.163.com/aragorn%5C_king/blog/static/188005152201162753126735/">http://blog.163.com/aragorn\_king/blog/static/188005152201162753126735/</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>mitogenome (unfinished)</title>
    <url>/2018/03/28/mitogenome-unfinished/</url>
    <content><![CDATA[<p>tRNA tRNA sequences  整理成 fasta 格式 通过 blastn mapping  到 mitogenome，输出 format=6。 编程序转换成 features table 格式的文件。 注意： 1）部分 tRNA 有多个 copies，例如 trnC(gca) 与 trnfM(cat) 各有两个copies； 2）部分 tRNA 具有同样的 anticodon，但是其名称和序列不同，例如 trnI(cat) 和 trnM(cat)； 3）tRNA都没有内含子，所以可以较为简单的转换格式； 4）anticodon 如何自动注释？</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>perl模块的一些操作（安装模块、删除已安装模块）</title>
    <url>/2015/11/16/perl%E6%A8%A1%E5%9D%97%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C%EF%BC%88%E5%AE%89%E8%A3%85%E6%A8%A1%E5%9D%97%E3%80%81%E5%88%A0%E9%99%A4%E5%B7%B2%E5%AE%89%E8%A3%85%E6%A8%A1%E5%9D%97%EF%BC%89/</url>
    <content><![CDATA[<p>关于模块的安装，包含自动/手动，自动使用的是CPAN，系统自动下载、编译、测试、安装，手动需要将安装包下载下来，再执行相关命令。基本原理一样 1、自动安装 在Linux命令行模式下输入“perl -MCPAN -e shell”进入perl界面，然后输入“instal <em>module-name</em>”即可 （在cmd中，cmd&gt;cpan modulename;   cmd&gt;perl -MCPAN -e ‘install module’;） cpan&gt;install modulename; cpan中的相关操作，可通过cpan&gt;h来查看，主要用到以下几个 i          查看模块的相关信息 m          模块的安装信息 reload     重新加载模块 get        获取模块，下载后的位置放在G:\strawberry\cpan\sources\authors\id\…解压对应的位置是.cpan/build install    安装模块 test force    强制进行安装，可能会有问题 notest    不进行test操作，也可能存在问题 2、手动安装，主要分以下几步： tar zxvf CPAN-1.9600.tar.gz cd CPAN-1.9600 perl <a href="http://Makefile.PL">Makefile.PL</a> make Makefile test Makefile make install Makefile ----------------------------------------- <strong>删除已安装的模块</strong>： 使用App::pmunintsall模块来实现:cpan&gt;install App::pmuninstall 安装完成后，退出cpan 执行删除模块操作：cmd&gt;pm-uninstall DBD::Oracle 注：pm-uninstall 是dos下的命令操作，同时-为连字符，之间没有空格 其他可参照：<a href="http://blog.csdn.net/xinke453/article/details/6732300">http://blog.csdn.net/xinke453/article/details/6732300</a> #本文转载 “<a href="http://heshw.blog.51cto.com/">奔跑的羚羊</a>” 博客，出处<a href="http://heshw.blog.51cto.com/5891747/1272581">http://heshw.blog.51cto.com/5891747/1272581</a> #有少许修改。</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>如何将RNA格式的fasta文件转换为DNA格式</title>
    <url>/2014/10/14/rna-fasta-dna/</url>
    <content><![CDATA[<p>从miRBase数据库下载的pre-miRNA序列是RNA格式的，如下所示。 &gt;cel-mir-37 MI0000008 Caenorhabditis elegans miR-37 stem-loop UUCUAGAAACCCUUGGACCAGUGUGGGUGUCCGUUGCGGUGCUACAUUCUCUAAUCUGUA UCACCGGGUGAACACUUGCAGUGGUCCUCGUGGUUUCU 因数据分析的需要将其转换为DNA格式。</p>
<span id="more"></span>
<p>可使用FASTX-toolkit的工具。下载地址是：<a href="http://hannonlab.cshl.edu/fastx%5C_toolkit/index.html">http://hannonlab.cshl.edu/fastx\_toolkit/index.html</a> 分别下载如下两个安装包。 <a href="https://github.com/agordon/libgtextutils">libGTextUtils on Github</a> <a href="https://github.com/agordon/fastx_toolkit">Fastx-Toolkit on Github</a> 下载完毕，先安装libGTextUtils，然后安装Fastx-toolkit。 在安装Fastx-toolkit的过程中，./configure时候遇到报错： checking for GTEXTUTILS… configure: error: Package requirements (gtextutils) were not met: No package ‘gtextutils’ found Consider adjusting the PKG_CONFIG_PATH environment variable if you installed software in a non-standard prefix. Alternatively, you may set the environment variables GTEXTUTILS_CFLAGS and GTEXTUTILS_LIBS to avoid the need to call pkg-config. See the pkg-config man page for more details.   解决方案是：</p>
<p>$ export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH</p>
<p>然后就可以顺利./configure了。随后 make &amp; make install 就搞定这个工具包了。 ======== 参考资料： [1] <a href="http://hannonlab.cshl.edu/fastx%5C_toolkit/index.html">http://hannonlab.cshl.edu/fastx\_toolkit/index.html</a> [2] <a href="http://hannonlab.cshl.edu/fastx%5C_toolkit/pkg%5C_config%5C_email.txt">http://hannonlab.cshl.edu/fastx\_toolkit/pkg\_config\_email.txt</a></p>
<p>-------- Original Message --------<br />
Subject: Re: FASTX-Toolkit installation<br />
Date: Tue, 28 Apr 2009 14:53:21 -0400<br />
From: Assaf Gordon <a href="mailto:gordon@cshl.edu">gordon@cshl.edu</a></p>
<p>… wrote, On 04/28/2009 02:30 PM:</p>
<blockquote>
<p>I’m trying to install the fastx-toolkit on my Mac Leopard workstation.<br />
Ultimately, I’d like to integrate it into my local copy of Galaxy.</p>
<p>However, I ran into a snag trying to compile the latest version.  I was able to configure,<br />
make and install libgtextutils-0.1.  At least there were no errors after I did that.<br />
However, I run into the following when trying to configure fastx-toolkit-0.0.7:</p>
<pre><code>checking for pkg-config... /sw/bin/pkg-config
checking pkg-config is at least version 0.9.0... yes
checking for GTEXTUTILS... configure: error: Package requirements
(gtextutils-0.1) were not met:

No package 'gtextutils-0.1' found

Consider adjusting the PKG\_CONFIG\_PATH environment variable if you
installed software in a non-standard prefix.

Alternatively, you may set the environment variables GTEXTUTILS\_CFLAGS
and GTEXTUTILS\_LIBS to avoid the need to call pkg-config.
See the pkg-config man page for more details.

gen-biocomp-lp:fastx\_toolkit-0.0.7 lparsons$ make
make: \*\*\* No targets specified and no makefile found.  Stop.
</code></pre>
<p>Any suggestions would be appreciated.</p>
</blockquote>
<p>The short answer is that you probably need to set the environment<br />
variable PKG_CONFIG_PATH, like so:<br />
$ export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH</p>
<p>Before running FASTX’s “configure” script.</p>
<p>But there’s also the long answer:</p>
<p>When you run a standard “./configure” script, the default installation<br />
path is “/usr/local”. On some systems (mostly debian/ubuntu), the<br />
default path for most programs is just “/usr” (without “local”).</p>
<p>On the other hand, some system administrators like the separation of<br />
‘standard’ packages into “/usr” and manually built packages into<br />
“/usr/local”.</p>
<p>I’m telling you that because it is likely that “gtextutils” was<br />
installed into “/usr/local”, but you system doesn’t look there at all.</p>
<p>So here’s how to check:<br />
go back to the gtextutil directory.<br />
Assuming you already run “configure” + “make”, run “make install” as a<br />
REGULAR user (not root).<br />
This will surely fail, but you will see the path, where the installation<br />
process tried to put the library files.<br />
Make a note if the path starts with /usr/local or just /usr (or<br />
strangely - something else).</p>
<p>The installation of GTEXTUTILS puts a file (named “gtextutils-0.1.pc”)<br />
somewhere on you disk.<br />
On my computer, it is found on:<br />
/usr/local/lib/pkgconfig/gtextutils-0.1.pc</p>
<p>The program “pkg-config” is a standard program which reads those “.pc”<br />
files and tells the compiler how to use the library (and it is used by<br />
“configure”).</p>
<p>From the command line, run:<br />
$ pkg-config --cflags gtextutils-0.1</p>
<p>If your file was installed into “/usr/local/lib…” but pkg-config shows<br />
the following error:<br />
Package gtextutils-0.1 was not found in the pkg-config search path.<br />
Perhaps you should add the directory containing `gtextutils-0.1.pc’<br />
to the PKG_CONFIG_PATH environment variable<br />
No package ‘gtextutils-0.1’ found</p>
<p>It is like that pkg-config simply doesn’t look in “/usr/local/” for the<br />
needed files.</p>
<p>The solution is set a special environment variable, that will instruct<br />
pkg-config where to look:<br />
$ export PKG_CONFIG_PATH=/usr/local/lib/pkgconfig:$PKG_CONFIG_PATH<br />
$ pkg-config --cflags gtextutils-0.1<br />
-I/usr/local/include/gtextutils-0.1/</p>
<p>Setting “PKG_CONFIG_PATH” to where the “.pc” file is stored will help<br />
the configure process find this library.<br />
After running the “export PKG_CONFIG_PATH” (and assuming the pkg-config<br />
command succeeded), you should be able to run FASTX’s “./configure”<br />
successfully.</p>
<hr />
<p>A different solution is to configure GTEXTUTILS to be installed in<br />
“/usr” to begin with (and then, most of the PATH related problems should<br />
be gone).<br />
To do this, run:<br />
$ ./configure --prefix=/usr<br />
$ make<br />
$ sudo make install</p>
<p>In the GTEXTUTILS directory.</p>
<hr />
<p>I hope these tips were helpful.<br />
If you still encounter problems, please let me know.</p>
<p>-Gordon.</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>DESeq2: RNAseq pipeline – Alignment to DE analysis</title>
    <url>/2016/02/29/rnaseq-pipeline-alignment-to-de-analysis/</url>
    <content><![CDATA[<h1 id="rnaseq-pipeline-alignment-to-de-analysis"><a class="markdownIt-Anchor" href="#rnaseq-pipeline-alignment-to-de-analysis"></a> <a href="https://benchtobioinformatics.wordpress.com/2014/11/10/rnaseq-pipeline-alignment-to-de-analysis-gsea/">RNAseq pipeline – alignment to DE analysis</a></h1>
<p><a href="https://benchtobioinformatics.wordpress.com/2014/11/10/rnaseq-pipeline-alignment-to-de-analysis-gsea/#comments">1 Reply</a></p>
<p>RNA sequencing has quickly surpassed microarrays for differential gene expression analysis in most labs.  I wanted to post a RNAseq pipelines from Raw sequencing reads to differential expression analysis and various other downstream analyses.  There are quite a few pipelines for RNAseq analysis and each has its pro/cons.  One of the most popular pipelines is alignment to the genome with <a href="https://code.google.com/p/rna-star/">STAR aligner</a>, binning of sequencing reads to genes/exons with <a href="http://www-huber.embl.de/users/anders/HTSeq/doc/count.html">HTseq-count</a>, and finally differential analysis with <a href="http://bioconductor.org/packages/release/bioc/html/DESeq.html">DESeq</a>/<a href="http://www.bioconductor.org/packages/release/bioc/html/DESeq2.html">DESeq2</a>.  I linked the online manuals for each tool here but I would highly suggest the initial publications for each as those will include benchmarking compared to other programs and the general theory behind of each algorithm (<a href="http://bioinformatics.oxfordjournals.org/content/early/2012/10/25/bioinformatics.bts635">here</a>, <a href="http://biorxiv.org/content/early/2014/08/19/002824">here</a> and <a href="http://genomebiology.com/2010/11/10/r106">here</a> – the original Deseq paper now has over 1800 citations on google scholar!).  I’d suggest DESeq2. This example assumes that you starting with RNA sequencing reads in fastq format after quality control (FastQC, etc.) and demultiplexing (fastq_multx, etc.).  Those steps will be a future post.  Depending on who is doing your actual sequencing (in-house core, BGI, etc.), they will probably release the fastq reads to you after each of these steps have been done. <strong>1. Alignment to genome with STAR aligner v2.4.0.1.</strong> STAR is wonderfully fast and accurate alignment program written by Alexander Dobin.  Alignment speeds with STAR are advertised at  400 million pairs per hour for 100 bp paired end reads on 12-core server (compared to Tophat at 20 million reads per hour).   In our hands, on 50 bp paired end reads, we are aligning at about 600 million pairs per hour on average with ~75-80% unique alignment rate.   The key with STAR is that it needs A LOT of memory, at least 30 GB.  Our cluster has dedicated job queues to allocate up to 64 GB memory for each STAR alignment job. <strong>1a) Alignment generate genome.</strong> Before alignment can be done, you must prepare the necessary genome index files.  The basic input for genome index files are 1) genome in fasta format and 2) annotation gtf file (needed in later steps).  You can download the genome files for human/mouse/etc from <a href="http://support.illumina.com/sequencing/sequencing_software/igenome.html">igenome</a> from Illumina.  For the new version of STAR, there are pre-made <a href="http://labshare.cshl.edu/shares/gingeraslab/www-data/dobin/STAR/STARgenomes/">index files</a>, depending on which reference you want to build.  They have various builds and model organisms.  We have been using the mouse mm10 reference from UCSC and have been happy with alignment rates.  I downloaded the mouse mm10 reference from igenome and renamed it “mm10_index/” .  You will also have to designate a directory for the genome index files STAR produces (“~/STAR_mm10/” or /path/to/STAR_mm10/”).</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p><code>STAR --runMode genomeGenerate \</code></p>
<p><code>--genomeDir</code> <code>/path/to/STAR_mm10/</code> <code>\</code></p>
<p><code>--genomeFastaFiles ~``/mm10_index/Mus_musculus/UCSC/mm10/Sequence/WholeGenomeFasta/genome``.fa \</code></p>
<p><code>--runThreadN 16</code></p>
<p>After STAR runs, you should have a few files in the /STAR_mm10/ directory:</p>
<ol>
<li>Genome</li>
<li>genomeParameters.txt</li>
<li>chrLength.txt, chrNameLength.txt, chrStart.txt</li>
<li>SA, SAindex</li>
<li>Log.out</li>
</ol>
<p>STAR will use these files for alignment in the next step. <strong>1b) Alignment to genome (or transcriptome).</strong>  The newer version (2.4.0). has the option to align specifically to the transcriptome and not the genome.  This option is for downstream analysis with RSEM ( another future post).  I’ll detail the basic STAR alignment job for now.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p><code>STAR --genomeDir</code> <code>/path/to/STAR_mm10/</code> <code>\</code></p>
<p><code>--readFilesIn read_1.fq read_2.fq \</code></p>
<p><code>--runThreadN 16 \</code></p>
<p><code>--outSAMtype BAM SortedByCoordinate</code></p>
<p>STAR will generate a few files:</p>
<ol>
<li>Log.out</li>
<li>Log.progress.out</li>
<li>Log.final.out – summary mapping statistics – will give you an idea on qc</li>
<li>Aligned.sortedByCoord.out.bam – your reads aligned in standard BAM format sorted by coordinate – similar to samtools sort command</li>
<li>SJ.out.tab – high confidence splice junction in tab-delimited format</li>
</ol>
<p>To generate an alignment file to the transcriptome with STAR v2.4.0:</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p><code>STAR --genomeDir</code> <code>/path/to/STAR_mm10/</code> <code>\</code></p>
<p><code>--readFilesIn read_1.fq read_2.fq \</code></p>
<p><code>--runThreadN 16 \</code></p>
<p><code>--quantMode TranscriptomeSAM</code></p>
<p>I haven’t had a chance to really run through this option yet (more for RSEM instead of DESeq2) but I am excited to try. <strong>Optional) Sorting, munging, etc.</strong>  The new version of STAR allows for generating alignment into a BAM file sorted by genomic coordinate.  Earlier versions didn’t and one would have to run the Aligned.out.sam files through various samtools munging steps to get alignment file into the correct format for downstream read counting.  For this example, it is necessary to have samtools-0.1.19.  First you convert the Aligned.out.sam to bam format with samtools view and pipe the output directly to samtools sort and sorting by genome position.  Finally converting back from bam to sam format.  If you have the python module pysam installed you can use a BAM file in the next steps.</p>
<p>1</p>
<p>2</p>
<p><code>samtools view -uS Aligned.out.sam -b samtools</code> <code>sort</code> <code>-@ 8 -m 800000000 - Aligned.sorted</code></p>
<p><code>samtools view Aligned.sorted.bam &gt; Aligned.sorted.sam</code></p>
<p>**3) raw counts generation using HTSeq-count. ** htseq-count has a few options:</p>
<ul>
<li>-m union: union is one of three options for htseq count for binning of reads to features (genes/exons).  it is the recommended option per <a href="http://www-huber.embl.de/users/anders/HTSeq/doc/count.html">htseq count’s manual</a>.  It is the most stringent option as it will only count a read if it aligns to only 1 gene.</li>
<li>-r pos : meaning that the BAM/SAM file is sorted by genomic coordinate/position</li>
<li>-i gene_name : tells htseq-count to use the gene name in output file</li>
<li>-a 10 : tells htseq-count to skip reads with alignment score less than 10.</li>
<li>–stranded=no : the RNAseq reads are not strand specific</li>
</ul>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p><code>htseq-count -m union \</code></p>
<p><code>-r pos \</code></p>
<p><code>-i gene_name \</code></p>
<p><code>-a 10 \</code></p>
<p><code>--stranded=no \</code></p>
<p><code>Aligned.sortedByCoord.out.bam \</code></p>
<p><code>~``/mm10_index/Mus_musculus/UCSC/mm10/Annotation/Genes/genes``.gtf &gt; output_basename.counts</code></p>
<p>Output of htseq count is a tab-delimited text file containing two columns: 1) gene id 2) number of read counts. Below is just an example of various cadherins with number of reads mapped to each.</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p><code>Cdh1 731</code></p>
<p><code>Cdh10 41</code></p>
<p><code>Cdh11 129</code></p>
<p><code>Cdh12 0</code></p>
<p><code>Cdh13 50538</code></p>
<p><code>Cdh15 0</code></p>
<p><code>Cdh16 0</code></p>
<p><code>Cdh17 648</code></p>
<p><code>Cdh18 0</code></p>
<p><code>Cdh19 0</code></p>
<p><code>Cdh2 570</code></p>
<p><code>Cdh20 0</code></p>
<p><code>Cdh22 0</code></p>
<p><code>Cdh23 11</code></p>
<p><code>Cdh24 3</code></p>
<p><code>Cdh26 140</code></p>
<p><code>Cdh3 3</code></p>
<p><code>Cdh4 0</code></p>
<p><code>Cdh5 237</code></p>
<p><code>Cdh6 496</code></p>
<p><strong>4) differential gene expression analysis using DESeq2.</strong></p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>6</p>
<p>7</p>
<p>8</p>
<p>9</p>
<p>10</p>
<p>11</p>
<p>12</p>
<p>13</p>
<p>14</p>
<p>15</p>
<p>16</p>
<p>17</p>
<p>18</p>
<p>19</p>
<p>20</p>
<p>21</p>
<p>22</p>
<p>23</p>
<p>24</p>
<p>25</p>
<p>26</p>
<p>27</p>
<p>28</p>
<p>29</p>
<p>30</p>
<p>31</p>
<p>32</p>
<p>33</p>
<p>34</p>
<p>35</p>
<p>36</p>
<p>37</p>
<p>38</p>
<p>39</p>
<p>40</p>
<p>41</p>
<p>42</p>
<p>43</p>
<p>44</p>
<p>45</p>
<p>46</p>
<p>47</p>
<p>48</p>
<p>49</p>
<p>50</p>
<p>51</p>
<p>52</p>
<p>53</p>
<p>54</p>
<p>55</p>
<p>56</p>
<p>57</p>
<p>58</p>
<p>59</p>
<p>60</p>
<p>61</p>
<p>62</p>
<p>63</p>
<p>64</p>
<p>65</p>
<p>66</p>
<p>67</p>
<p>68</p>
<p>69</p>
<p>70</p>
<p>71</p>
<p>72</p>
<p>73</p>
<p>74</p>
<p>75</p>
<p>76</p>
<p>77</p>
<p>78</p>
<p>79</p>
<p>80</p>
<p>81</p>
<p>82</p>
<p>83</p>
<p>84</p>
<p>85</p>
<p>86</p>
<p>87</p>
<p>88</p>
<p>89</p>
<p>90</p>
<p>91</p>
<p>92</p>
<p>93</p>
<p>94</p>
<p>95</p>
<p>96</p>
<p>97</p>
<p>98</p>
<p>99</p>
<p>100</p>
<p>101</p>
<p>102</p>
<p>103</p>
<p>104</p>
<p>105</p>
<p>106</p>
<p>107</p>
<p>108</p>
<p>109</p>
<p>110</p>
<p>111</p>
<p>112</p>
<p>113</p>
<p>114</p>
<p>115</p>
<p>116</p>
<p>117</p>
<p>118</p>
<p>119</p>
<p>120</p>
<p>121</p>
<p>122</p>
<p>123</p>
<p>124</p>
<p>125</p>
<p>126</p>
<p>127</p>
<p>128</p>
<p>129</p>
<p>130</p>
<p>131</p>
<p>132</p>
<p>133</p>
<p>134</p>
<p>135</p>
<p>136</p>
<p>137</p>
<p>138</p>
<p>139</p>
<p>140</p>
<p>141</p>
<p>142</p>
<p>143</p>
<p>144</p>
<p>145</p>
<p>146</p>
<p>147</p>
<p>148</p>
<p>149</p>
<p>150</p>
<p>151</p>
<p>152</p>
<p>153</p>
<p>154</p>
<p>155</p>
<p>156</p>
<p>157</p>
<p>158</p>
<p>159</p>
<p>160</p>
<p>161</p>
<p>162</p>
<p>163</p>
<p>164</p>
<p>165</p>
<p>166</p>
<p>167</p>
<p>168</p>
<p>169</p>
<p>170</p>
<p>171</p>
<p>172</p>
<p>173</p>
<p>174</p>
<p>175</p>
<p>176</p>
<p>177</p>
<p>178</p>
<p>179</p>
<p>180</p>
<p>181</p>
<p>182</p>
<p>183</p>
<p>184</p>
<p>185</p>
<p>186</p>
<p>187</p>
<p>188</p>
<p>189</p>
<p>190</p>
<p>191</p>
<p>192</p>
<p>193</p>
<p>194</p>
<p>195</p>
<p>196</p>
<p>197</p>
<p>198</p>
<p>199</p>
<p>200</p>
<p>201</p>
<p>202</p>
<p>203</p>
<p>204</p>
<p>205</p>
<p>206</p>
<p>207</p>
<p>208</p>
<p>209</p>
<p>210</p>
<p>211</p>
<p>212</p>
<p>213</p>
<p>214</p>
<p>215</p>
<p>216</p>
<p>217</p>
<p>218</p>
<p>219</p>
<p>220</p>
<p>221</p>
<p>222</p>
<p>223</p>
<p>224</p>
<p>225</p>
<p>226</p>
<p>227</p>
<p>228</p>
<p>229</p>
<p>230</p>
<p>231</p>
<p>232</p>
<p>233</p>
<p>234</p>
<p>235</p>
<p>236</p>
<p>237</p>
<p>238</p>
<p>239</p>
<p>240</p>
<p>241</p>
<p>242</p>
<p>243</p>
<p>244</p>
<p>245</p>
<p>246</p>
<p>247</p>
<p>248</p>
<p>249</p>
<p>250</p>
<p>251</p>
<p>252</p>
<p>253</p>
<p>254</p>
<p>255</p>
<p>256</p>
<p>257</p>
<p>258</p>
<p>259</p>
<p>260</p>
<p>261</p>
<p>262</p>
<p>263</p>
<p>264</p>
<p>265</p>
<p>266</p>
<p><code>&lt;pre&gt;``####################################################################################</code></p>
<p><code># bioinformatic analysis of RNA-seq data using DESeq2</code></p>
<p><code>#</code></p>
<p><code># combined from DESeq2 manual and vignette</code></p>
<p><code># [http://www.bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.pdf](http://www.bioconductor.org/packages/release/bioc/vignettes/DESeq2/inst/doc/DESeq2.pdf)</code></p>
<p><code># and from Dave Wheeler's blog at Massey University</code></p>
<p><code># [http://dwheelerau.com/2014/02/17/how-to-use-deseq2-to-analyse-rnaseq-data/](http://dwheelerau.com/2014/02/17/how-to-use-deseq2-to-analyse-rnaseq-data/)</code></p>
<p><code>#</code></p>
<p><code># analysis per htseq count -intersections-nonempty</code></p>
<p><code># controlling for batch (different RNAseq prep libraries)</code></p>
<p><code>#</code></p>
<p><code># notes:</code></p>
<p><code>#</code></p>
<p><code>####################################################################################</code></p>
<p><code>library``(``&quot;DESeq2&quot;``)</code></p>
<p><code>setwd``(``&quot;~/path/to/working/directory/&quot;``)</code></p>
<p><code>directory &lt;-</code> <code>&quot;/path/to/counts/directory/&quot;</code></p>
<p><code># can merge individual sample files (i.e. ctrl1.counts, ctrl2.counts, etc.)</code></p>
<p><code>sampleFiles &lt;-</code> <code>grep``(``&quot;counts&quot;``list.files``(directory),value=T)</code></p>
<p><code># view sampleFiles</code></p>
<p><code>sampleFiles</code></p>
<p><code># can designate different batches of samples (i.e. different sequencers,</code></p>
<p><code># PE vs SE, different library preps (eg. BATCH1 vs BATCH2))</code></p>
<p><code>sampleBatch &lt;-</code> <code>c``(``&quot;Batch1&quot;``,``&quot;Batch1&quot;``,``&quot;Batch1&quot;``,``&quot;Batch1&quot;``,``&quot;Batch1&quot;``,``&quot;Batch1&quot;``,</code></p>
<p><code>&quot;Batch2&quot;``,``&quot;Batch2&quot;``,``&quot;Batch2&quot;``,``&quot;Batch2&quot;``)</code></p>
<p><code># set sampleConditions and sampleTable for experimental conditions</code></p>
<p><code>sampleCondition &lt;-</code> <code>c``(``&quot;Control, Experimental&quot;``)</code></p>
<p><code>sampleTable &lt;-</code> <code>data.frame``(sampleName = sampleFiles,</code></p>
<p><code>fileName = sampleFiles,</code></p>
<p><code>condition = sampleCondition,</code></p>
<p><code>Batch = sampleBatch)</code></p>
<p><code># view sampleTable</code></p>
<p><code>sampleTable</code></p>
<p><code>ddsHTseq &lt;-</code> <code>DESeqDataSetFromHTSeqCount``( sampleTable = sampleTable,</code></p>
<p><code>directory = directory,</code></p>
<p><code>design = ~condition)</code></p>
<p><code>## view ddsHTseq - should give summary of class, data, etc.</code></p>
<p><code>ddsHTseq</code></p>
<p><code>colData``(ddsHTseq)$condition &lt;-</code> <code>factor``(``colData``(ddsHTseq)$condition,</code></p>
<p><code>levels =</code> <code>c``(``'Control'``,``'Experimental'``))</code></p>
<p><code># gut of DESeq2 analysis</code></p>
<p><code>dds &lt;-</code> <code>DESeq``(ddsHTseq)</code></p>
<p><code>res &lt;-</code> <code>results``(dds)</code></p>
<p><code># order results by padj value (most significant to least)</code></p>
<p><code>res &lt;- res[``order``(res$padj),]</code></p>
<p><code>head``(res)</code></p>
<p><code># should see DataFrame of baseMean, log2Foldchange, stat, pval, padj</code></p>
<p><code># save data results and normalized reads to csv!</code></p>
<p><code>resdata &lt;-</code> <code>merge``(``as.data.frame``(res),</code> <code>as.data.frame``(``counts``(dds,normalized=T)), by=``'row.names'``,sort=F)</code></p>
<p><code>names``(resdata)[1] &lt;-</code> <code>'gene'</code></p>
<p><code>head``(resdata)</code></p>
<p><code>write.csv``(resdata, file=``&quot;DATE-DESeq2-results-with-normalized.csv&quot;``)</code></p>
<p><code># send normalized counts to tab delimited file for GSEA, etc.</code></p>
<p><code>write.table``(``as.data.frame``(``counts``(dds),normalized=T), file =</code> <code>'DATE_DESeq2_normalized_counts.txt'``, sep =</code> <code>'\t'``)</code></p>
<p><code># produce DataFrame of results of statistical tests</code></p>
<p><code># could way to record experimental design</code></p>
<p><code>mcols``(res, use.names = T)</code></p>
<p><code>write.csv``(``as.data.frame``(``mcols``(res, use.name = T)),file =</code> <code>&quot;DATE-DESeq2-test-conditions.csv&quot;``)</code></p>
<p><code># replacing outlier value with estimated value as predicted by distrubution using</code></p>
<p><code># &quot;trimmed mean&quot; approach. recommended if you have several replicates per treatment</code></p>
<p><code># DESeq2 will automatically do this if you have 7 or more replicates</code></p>
<p><code>ddsClean &lt;-</code> <code>replaceOutliersWithTrimmedMean``(dds)</code></p>
<p><code>ddsClean &lt;-</code> <code>DESeq``(ddsClean)</code></p>
<p><code>tab &lt;-</code> <code>table``(initial =</code> <code>results``(dds)$padj &lt; 0.1,</code></p>
<p><code>cleaned =</code> <code>results``(ddsClean)$padj &lt; 0.1)</code></p>
<p><code>addmargins``(tab)</code></p>
<p><code>write.csv``(``as.data.frame``(tab),file =</code> <code>'DATE-DESeq2-replaceoutliers.csv'``)</code></p>
<p><code>resClean &lt;-</code> <code>results``(ddsClean)</code></p>
<p><code>resClean &lt;- resClean[``order``(resClean$padj),]</code></p>
<p><code>head``(resClean)</code></p>
<p><code>write.csv``(``as.data.frame``(resClean),file =</code> <code>'DATE-DESeq2-replaceoutliers-results.csv'``)</code></p>
<p><code>####################################################################################</code></p>
<p><code># Exploritory data analysis of RNAseq data with DESeq2</code></p>
<p><code>#</code></p>
<p><code># these next R scripts are for a variety of visualization, QC and other plots to</code></p>
<p><code># get a sense of what the RNAseq data looks like based on DESEq2 analysis</code></p>
<p><code>#</code></p>
<p><code># 1) MA plot</code></p>
<p><code># 2) rlog stabilization and variance stabiliazation</code></p>
<p><code># 3) variance stabilization plot</code></p>
<p><code># 4) heatmap of clustering analysis</code></p>
<p><code># 5) PCA plot</code></p>
<p><code>#</code></p>
<p><code>#</code></p>
<p><code>####################################################################################</code></p>
<p><code># MA plot of RNAseq data for entire dataset</code></p>
<p><code># [http://en.wikipedia.org/wiki/MA_plot](http://en.wikipedia.org/wiki/MA_plot)</code></p>
<p><code># genes with padj &lt; 0.1 are colored Red</code></p>
<p><code>plotMA``(dds, ylim=``c``(-8,8),main =</code> <code>&quot;RNAseq experiment&quot;``)</code></p>
<p><code>dev.copy``(png,</code> <code>&quot;DATE-DESeq2_MAplot_initial_analysis.png&quot;``)</code></p>
<p><code>dev.off``()</code></p>
<p><code># transform raw counts into normalized values</code></p>
<p><code># DESeq2 has two options:  1) rlog transformed and 2) variance stabilization</code></p>
<p><code># variance stabilization is very good for heatmaps, etc.</code></p>
<p><code>rld &lt;-</code> <code>rlogTransformation``(dds, blind=T)</code></p>
<p><code>vsd &lt;-</code> <code>varianceStabilizingTransformation``(dds, blind=T)</code></p>
<p><code># save normalized values</code></p>
<p><code>write.table``(``as.data.frame``(``assay``(rld),file=``'DATE-DESeq2-rlog-transformed-counts.txt'``, sep=``'\t'``)</code></p>
<p><code>write.table``(``as.data.frame``(``assay``(vsd),file=``'DATE-DESeq2-vst-transformed-counts.txt'``, sep=``'\t'``)</code></p>
<p><code># plot to show effect of transformation</code></p>
<p><code># axis is square root of variance over the mean for all samples</code></p>
<p><code>par``(mai =</code> <code>ifelse``(1:4 &lt;= 2,</code> <code>par``(``'mai'``),0))</code></p>
<p><code>px &lt;-</code> <code>counts``(dds)[,1] /</code> <code>sizeFactors``(dds)[1]</code></p>
<p><code>ord &lt;-</code> <code>order``(px)</code></p>
<p><code>ord &lt;- ord[px[ord] &lt; 150]</code></p>
<p><code>ord &lt;- ord[``seq``(1,``length``(ord),length=50)]</code></p>
<p><code>last &lt;- ord[``length``(ord)]</code></p>
<p><code>vstcol &lt;-</code> <code>c``(``'blue'``,``'black'``)</code></p>
<p><code>matplot``(px[ord],</code> <code>cbind``(``assay``(vsd)[,1],</code> <code>log2``(px))[ord, ],type=``'l'``, lty = 1, col=vstcol, xlab =</code> <code>'n'``, ylab =</code> <code>'f(n)'``)</code></p>
<p><code>legend``(``'bottomright'``,legend=``c``(``expression``(``'variance stabilizing transformation'``),</code> <code>expression``(log[2](n/s[1]))), fill=vstcol)</code></p>
<p><code>dev.copy``(png,``&quot;DATE-DESeq2_variance_stabilizing.png&quot;``)</code></p>
<p><code>dev.off``()</code></p>
<p><code># clustering analysis</code></p>
<p><code>library``(``&quot;gplots&quot;``)</code></p>
<p><code>distsRL &lt;-</code> <code>dist``(``t``(``assay``(rld)))</code></p>
<p><code>mat &lt;-</code> <code>as.matrix``(distsRL)</code></p>
<p><code>rownames``(mat) &lt;-</code> <code>colnames``(mat) &lt;-</code> <code>with``(``colData``(dds),</code> <code>paste``(condition, type, sep=``&quot; : &quot;``))</code></p>
<p><code># OR</code></p>
<p><code># if you want the conditions used</code></p>
<p><code># rownames(mat) &lt;- colnames(mat) &lt;- with(colData(dds),condition)</code></p>
<p><code>heatmap.2``(mat, trace =</code> <code>&quot;none&quot;``, col =</code> <code>rev``(hmcol), margin =</code> <code>c``(13, 13))</code></p>
<p><code>dev.copy``(png,</code> <code>&quot;DATE-DESeq2-clustering.png&quot;``)</code></p>
<p><code>dev.off``()</code></p>
<p><code># Principal components plot</code></p>
<p><code># will show additional clustering of samples</code></p>
<p><code># showing basic PCA function in R from DESeq2 package</code></p>
<p><code># this lacks sample IDs and only broad sense of sample clustering</code></p>
<p><code># its not nice - but it does the job</code></p>
<p><code>print``(``plotPCA``(rld, intgroup =</code> <code>c``(``&quot;condition&quot;``)))</code></p>
<p><code>dev.copy``(png,</code> <code>&quot;DATE-DESeq2_PCA_initial_analysis.png&quot;``)</code></p>
<p><code>dev.off``()</code></p>
<p><code># or ggplot PCA plot</code></p>
<p><code>library``(``&quot;grDevices&quot;``)</code></p>
<p><code>library``(``'ggplot2'``)</code></p>
<p><code>library``(``&quot;genefilter&quot;``)</code></p>
<p><code>rv &lt;-</code> <code>rowVars``(``assay``(rld))</code></p>
<p><code>select &lt;-</code> <code>order``(rv, decreasing=T)[``seq_len``(``min``(500,``length``(rv)))]</code></p>
<p><code>pc &lt;-</code> <code>prcomp``(``t``(``assay``(vsdMF)[select,]))</code></p>
<p><code># set condition</code></p>
<p><code>condition &lt;-</code> <code>c``(``&quot;condition1&quot;``,</code> <code>'condition2'``)</code></p>
<p><code>scores &lt;-</code> <code>data.frame``(sampleFiles, pca$x, condition)</code></p>
<p><code>(pcaplot &lt;-</code> <code>ggplot``(scores,</code> <code>aes``(x = PC1, y = PC2, col = (``factor``(condition))))</code></p>
<p><code>+</code> <code>geom_point``(size = 5)</code></p>
<p><code>+</code> <code>ggtitle``(``&quot;Principal Components&quot;``)</code></p>
<p><code>+</code> <code>scale_colour_brewer``(name =</code> <code>&quot; &quot;``, palette =</code> <code>&quot;Set1&quot;``)</code></p>
<p><code>+</code> <code>theme``(</code></p>
<p><code>plot.title =</code> <code>element_text``(face =</code> <code>'bold'``),</code></p>
<p><code>legend.position =</code> <code>c``(0,0),</code></p>
<p><code>legend.key =</code> <code>element_rect``(fill =</code> <code>'NA'``),</code></p>
<p><code>legend.text =</code> <code>element_text``(size = 10, face =</code> <code>&quot;bold&quot;``),</code></p>
<p><code>axis.text.y =</code> <code>element_text``(colour =</code> <code>&quot;Black&quot;``),</code></p>
<p><code>axis.text.x =</code> <code>element_text``(colour =</code> <code>&quot;Black&quot;``),</code></p>
<p><code>axis.title.x =</code> <code>element_text``(face =</code> <code>&quot;bold&quot;``),</code></p>
<p><code>axis.title.y =</code> <code>element_text``(face =</code> <code>'bold'``),</code></p>
<p><code>panel.grid.major.x =</code> <code>element_blank``(),</code></p>
<p><code>panel.grid.major.y =</code> <code>element_blank``(),</code></p>
<p><code>panel.grid.minor.x =</code> <code>element_blank``(),</code></p>
<p><code>panel.grid.minor.y =</code> <code>element_blank``(),</code></p>
<p><code>panel.background =</code> <code>element_rect``(color =</code> <code>'black'``,fill =</code> <code>NA``)</code></p>
<p><code>))</code></p>
<p><code>ggsave``(pcaplot,file=``&quot;DATE-PCA_ggplot2.pdf&quot;``)</code></p>
<p><code># scatter plot of rlog transformations between Sample conditions</code></p>
<p><code># nice way to compare control and experimental samples</code></p>
<p><code>head``(``assay``(rld))</code></p>
<p><code>plot``(``log2``(1+``counts``(dds,normalized=T)[,1:2]),col=``'black'``,pch=20,cex=0.3, main=``'Log2 transformed'``)</code></p>
<p><code>plot``(``assay``(rld)[,1:2],col=``'#00000020'``,pch=20,cex=0.3, main =</code> <code>&quot;rlog transformed&quot;``)</code></p>
<p><code>plot``(``assay``(rld)[,3:4],col=``'#00000020'``,pch=20,cex=0.3, main =</code> <code>&quot;rlog transformed&quot;``)</code></p>
<p><code>plot``(``assay``(rld)[,5:6],col=``'#00000020'``,pch=20,cex=0.3, main =</code> <code>&quot;rlog transformed&quot;``)</code></p>
<p><code>plot``(``assay``(rld)[,7:8],col=``'#00000020'``,pch=20,cex=0.3, main =</code> <code>&quot;rlog transformed&quot;``)</code></p>
<p><code>plot``(``assay``(rld)[,9:10],col=``'#00000020'``,pch=20,cex=0.3, main =</code> <code>&quot;rlog transformed&quot;``)</code></p>
<p><code>plot``(``assay``(rld)[,11:12],col=``'#00000020'``,pch=20,cex=0.3, main =</code> <code>&quot;rlog transformed&quot;``)</code></p>
<p><code>plot``(``assay``(rld)[,13:14],col=``'#00000020'``,pch=20,cex=0.3, main =</code> <code>&quot;rlog transformed&quot;``)</code></p>
<p><code>plot``(``assay``(rld)[,15:16],col=``'#00000020'``,pch=20,cex=0.3, main =</code> <code>&quot;rlog transformed&quot;``)</code></p>
<p><code># heatmap of data</code></p>
<p><code>library``(``&quot;RColorBrewer&quot;``)</code></p>
<p><code>library``(``&quot;gplots&quot;``)</code></p>
<p><code># 1000 top expressed genes with heatmap.2</code></p>
<p><code>select &lt;-</code> <code>order``(``rowMeans``(``counts``(dds,normalized=T)),decreasing=T)[1:1000]</code></p>
<p><code>my_palette &lt;-</code> <code>colorRampPalette``(``c``(``&quot;blue&quot;``,``'white'``,``'red'``))(n=1000)</code></p>
<p><code>heatmap.2``(``assay``(vsd)[select,], col=my_palette,</code></p>
<p><code>scale=``&quot;row&quot;``, key=T, keysize=1, symkey=T,</code></p>
<p><code>density.info=``&quot;none&quot;``, trace=``&quot;none&quot;``,</code></p>
<p><code>cexCol=0.6, labRow=F,</code></p>
<p><code>main=``&quot;TITLE&quot;``)</code></p>
<p><code>dev.copy``(png,</code> <code>&quot;DATE-DESeq2-HEATMAP.png&quot;``)</code></p>
<p><code>dev.off``()</code></p>
<p><code># top 2000 genes based on row variance with heatmap3</code></p>
<p><code>library``(heatmap3)</code></p>
<p><code>colsidecolors =</code> <code>c``(``&quot;darkgreen&quot;``,``&quot;darkgreen&quot;``,</code></p>
<p><code>&quot;mediumpurple2&quot;``,``&quot;mediumpurple2&quot;``,</code></p>
<p><code>&quot;mediumpurple2&quot;``,``&quot;mediumpurple2&quot;``,</code></p>
<p><code>&quot;darkgreen&quot;``,``&quot;darkgreen&quot;``,</code></p>
<p><code>&quot;mediumpurple2&quot;``,``&quot;mediumpurple2&quot;``,</code></p>
<p><code>&quot;darkgreen&quot;``,``&quot;darkgreen&quot;``,</code></p>
<p><code>&quot;mediumpurple2&quot;``,``&quot;mediumpurple2&quot;``,</code></p>
<p><code>&quot;mediumpurple2&quot;``,``&quot;mediumpurple2&quot;``)</code></p>
<p><code>rv &lt;-</code> <code>rowVars``(``assay``(vsd))</code></p>
<p><code>select &lt;-</code> <code>order``(rv, decreasing=T)[``seq_len``(``min``(2000,``length``(rv)))]</code></p>
<p><code>my_palette &lt;-</code> <code>colorRampPalette``(``c``(``&quot;blue&quot;``,</code> <code>&quot;white&quot;``,</code> <code>&quot;red&quot;``))(1024)</code></p>
<p><code>heatmap3``(``assay``(vsd)[select,],col=my_palette,</code></p>
<p><code>labRow = F,cexCol = 0.8,margins=``c``(6,6))</code></p>
<p><code>dev.copy``(pdf,</code> <code>&quot;DATE-DESeq2-heatmap3.pdf&quot;``)</code></p>
<p><code>dev.off``()</code></p>
<p><code>sessionInfo``()</code></p>
<p><code>###############################################################</code></p>
<p><code>#</code></p>
<p><code># Optional analyses</code></p>
<p><code>#</code></p>
<p><code>###############################################################</code></p>
<p><code># multifactor designs</code></p>
<p><code># can analysis with more than one factor influencing the counts  (e.g., different library preps, PE vs. SE)</code></p>
<p><code># from manual section 1.5 for more information and rationale</code></p>
<p><code># make copy of DESeq2 results</code></p>
<p><code>ddsMF &lt;- dds</code></p>
<p><code># change design formulate controlling for Batch</code></p>
<p><code>design``(ddsMF) &lt;-</code> <code>formula``(~ Batch + condition)</code></p>
<p><code># rerun DESeq analysis</code></p>
<p><code>ddsMF &lt;-</code> <code>DESeq``(ddsMF)</code></p>
<p><code>resMF &lt;-</code> <code>results``(ddsMF)</code></p>
<p><code># order by padj values</code></p>
<p><code>resMF &lt;- resMF[``order``(resMF$padj),]</code></p>
<p><code>head``(resMF)</code></p>
<p><code># should see DataFrame of baseMean, log2Foldchange, stat, pval, padj</code></p>
<p><code># save data 'resMF' to csv!</code></p>
<p><code>write.csv``(``as.data.frame``(resMF),file=``'DATE-DESeq2_batchcontroll_initial_analysis.csv'``)</code></p>
<p>future post idea: pairing HTSeq-DESeq2 for DE gene expression with DEXSeq for splice variants as this pipeline is agnostic for differential exon usage.  *May miss true DE genes if total exon counts are the same but use different exons in different conditions (per Lior Pachter) Future post idea: comparing STAR-HTSeq-DESeq2 to Bowtie-RSEM for gene expression analysis on the same dataset.</p>
<p>This entry was posted in <a href="https://benchtobioinformatics.wordpress.com/category/bioinformatics/">bioinformatics</a>, <a href="https://benchtobioinformatics.wordpress.com/category/deseq2/">DESeq2</a>, <a href="https://benchtobioinformatics.wordpress.com/category/dexseq/">DEXSeq</a>, <a href="https://benchtobioinformatics.wordpress.com/category/ggplot2/">ggplot2</a>, <a href="https://benchtobioinformatics.wordpress.com/category/htseq-count/">HTSeq-count</a>, <a href="https://benchtobioinformatics.wordpress.com/category/r/">R</a>, <a href="https://benchtobioinformatics.wordpress.com/category/rnaseq/">RNAseq</a>, <a href="https://benchtobioinformatics.wordpress.com/category/star/">STAR</a> on<a href="https://benchtobioinformatics.wordpress.com/2014/11/10/rnaseq-pipeline-alignment-to-de-analysis-gsea/" title="8:33 pm">November 10, 2014</a>.</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Shell编程：获取文件前缀字符串</title>
    <url>/2017/08/23/shell-get-prefix-of-file-name/</url>
    <content><![CDATA[<p>比如处理名为 /xxx/yyy/zzz/abc2017.1.fq.gz 的文件，我们需要获取abc2017这个文件名。</p>
<p>i=/xxx/yyy/zzz/abc2017.1.fq.gz</p>
<p>IN=$i</p>
<h1 id="read1文件绝对路径xxxyyyzzzabc20171fqgz"><a class="markdownIt-Anchor" href="#read1文件绝对路径xxxyyyzzzabc20171fqgz"></a> read1文件绝对路径：/xxx/yyy/zzz/abc2017.1.fq.gz</h1>
<p>path=${IN%/*}</p>
<h1 id="read1文件的绝对路径前缀以作为分隔界限并获取界限之前的字符串xxxyyyzzz"><a class="markdownIt-Anchor" href="#read1文件的绝对路径前缀以作为分隔界限并获取界限之前的字符串xxxyyyzzz"></a> Read1文件的绝对路径前缀，以“/”作为分隔界限并获取界限之前的字符串：/xxx/yyy/zzz</h1>
<p>sample=${path##*/}</p>
<h1 id="read1所在文件夹名称即-zzz"><a class="markdownIt-Anchor" href="#read1所在文件夹名称即-zzz"></a> Read1所在文件夹名称，即 zzz</h1>
<p>prefix=${IN%.1*}</p>
<h1 id="read1与read2两个文件共有的路径前缀即以1作为分隔界限并获取界限之前的字符串-xxxyyyzzzabc2017"><a class="markdownIt-Anchor" href="#read1与read2两个文件共有的路径前缀即以1作为分隔界限并获取界限之前的字符串-xxxyyyzzzabc2017"></a> Read1与Read2两个文件共有的路径前缀，即以“.1”作为分隔界限并获取界限之前的字符串 /xxx/yyy/zzz/abc2017</h1>
<p>sample=${prefix##*/}</p>
<h1 id="sample的名称-abc2017"><a class="markdownIt-Anchor" href="#sample的名称-abc2017"></a> sample的名称 abc2017</h1>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Shell脚本 \&quot;set Illegal option -o pipefail\&quot;</title>
    <url>/2017/08/15/shell-set-illegal-option-o-pipefail/</url>
    <content><![CDATA[<p>在Linux编写Shell 脚本程序的时候，set -o pipefail是很实用的命令。因为Shell脚本中通常有一连串的动作需要执行，一旦某个环节出错，如果设定了pipefail，脚本会立即中断运行；而如果没有设定，脚本将继续执行后续命令，可能造成错误。 然而在Ubuntu中，当使用“set -o pipefail”的时候，一直报错：</p>
<p>set Illegal option -o pipefail</p>
<p>经查，原因是Ubuntu的 shell 默认安装的是 dash，而不是 bash。 运行以下命令查看 sh 的详细信息，确认 shell 对应的程序是哪个： $ls -al /bin/sh dash 比 bash 更轻，更快。但 bash 却更常用。 如果一些命令、脚本等总不能正常执行，有可能是 dash 的原因。 比如编译 Android 源代码的时候，如果使用 dash，则有可能编译出错，或者编译的系统不能启动。 通过以下方式可以使 shell 切换回 bash： $sudo dpkg-reconfigure dash 然后选择 no 或者 否 ，并确认。 这样做将重新配置 dash，并使其不作为默认的 shell 工具。 也可以直接修改 /bin/sh 链接文件，将其指定到 /bin/bash： $sudo ln -fs /bin/bash /bin/sh</p>
<span id="more"></span>
<p>还有一种解决方法是，在脚本文件中直接指定使用的 shell，而不是指定 sh： 例如使用 #!/bin/bash 或者 #!/bin/dash 而不是#!/bin/sh。 但这样将丧失脚本的通用性，使其在不具备所指定脚本的系统下不能被执行。 如果没有root权限，那么在执行shell脚本的时候：“bash <a href="http://xxx.sh">xxx.sh</a>”即可 附专业解释： set -e表示一旦脚本中有命令的返回值为非0，则脚本立即退出，后续命令不再执行; set -o pipefail表示在管道连接的命令序列中，只要有任何一个命令返回非0值，则整个管道返回非0值，即使最后一个命令返回0.</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>基因组组装软件：SOAP denovo与ALLPATHS-LG</title>
    <url>/2014/12/18/soap-denovo/</url>
    <content><![CDATA[<p>2009年12月，华大基因公司李瑞强等人开发的SOAP denovo第一个版本发表在《Genome Research》，题为“De novo assembly of human genomes with massively parallel short read sequencing”，截至2014年12月18日，引用次数达到1090次；（<a href="http://soap.genomics.org.cn/soapdenovo.html">http://soap.genomics.org.cn/soapdenovo.html</a>）SOAP denovo算法利用kmer构建De Brujin Graph。   2010年12月，<a href="http://www.broadinstitute.org/software/allpaths-lg/blog/">ALLPATHS-LG</a>由Broad Institue发布，适合于组装short reads数据，由Computational Research and Development group at the Broad Institute开发，2008年推出ALLPATHS，适用小型基因组，截至目前引用次数分别450；2011年升级版发布，可用于大型基因组，“High-quality draft assemblies of mammalian genomes from massively parallel sequence data”发布在《PNAS》，截至目前引用次数380。ALLPATHS-LG是现在行业内公认进行基因组_De novo_组装效果最好的软件。（<a href="https://www.broadinstitute.org/software/allpaths-lg/blog/">https://www.broadinstitute.org/software/allpaths-lg/blog/</a>）   2011年12月，Steven L. Salzberg开发GAGE对8个组装软件对4个物种分别进行基因组组装，发布在《genome research》，标题“<a href="http://genome.cshlp.org/content/early/2012/01/12/gr.131383.111">GAGE: A critical evaluation of genome assemblies and assembly algorithms</a>.”。评估发现，allpaths-lg综合性能最优，SOAP denovo虽然得到N50最高，但是准确率也很高。主要结论是数据质量非常重要，因此作者使用quake等软件进行数据纠错。Three overarching conclusions are apparent: first, that data quality, rather than the assembler itself, has a dramatic effect on the quality of an assembled genome; second, that the degree of contiguity of an assembly varies enormously among different assemblers and different genomes; and third, that the correctness of an assembly also varies widely and is not well correlated with statistics on contiguity. （<a href="http://gage.cbcb.umd.edu/index.html">http://gage.cbcb.umd.edu/index.html</a>）   2012年，华大基因公司罗锐邦升级SOAP denovo到SOAP denovo2，发表在《BMC Giga Science》，题为“SOAPdenovo2: an empirically improved memory-efficient short-read de novo assembler”，SOAP denovo2有哪些升级？为了解决序列连续性、准确性、覆盖度，尤其是重复序列问题。优化之后的软件，reduces memory consumption in graph construction, resolves more repeat regions in contig assembly, increases coverage and length in scaffold construction, improves gap closing, and optimizes for large genome. 截至2014年12月18日，引用次数达到243次。（<a href="http://soap.genomics.org.cn/soapdenovo.html">http://soap.genomics.org.cn/soapdenovo.html</a>）   2014年12月，冷泉港Michael C Schatz教授对水稻3个品种分别进行测序，即pan-genome研究，发布在《genome biology》，标题“Whole genome <em>de novo</em> assemblies of three divergent strains of rice, <em>Oryza sativa</em>, document novel gene space of <em>aus</em> and <em>indica</em>”，使用ALLPATHS-LG组装，然后将quake矫正的数据分别使用SOAP denovo和SGA进行组装，最后发现ALLPATHS-LG的组装效果最好。作者认为We hypothesize that ALLPATHS-LG achieved superior results because the algorithm automatically measures many of the properties of the sequencing data, and could therefore self-adjust the various cutoffs used by the algorithm for error correction, contigging, and scaffolding.   <em>fenglei</em> <em>2014-12-18</em></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>SQL导入blast2go</title>
    <url>/2015/04/29/sql%E5%AF%BC%E5%85%A5blast2go/</url>
    <content><![CDATA[<p>1 安装mysql，参考前面博文。 2 进入mysql [fenglei@localhost scripts]$ <strong>mysql -P 33060 -u root -p</strong> Enter password: Welcome to the MySQL monitor. Commands end with ; or g. Your MySQL connection id is 5 Server version: 5.6.20 Source distribution Copyright © 2000, 2014, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type ‘help;’ or ‘h’ for help. Type ‘c’ to clear the current input statement. mysql&gt; <strong>insert into mysql.user(Host,User,Password) values(“localhost”,“blast2go”,password(“blast4it”));</strong> Query OK, 1 row affected, 3 warnings (0.05 sec) mysql&gt; <strong>flush privileges;</strong> Query OK, 0 rows affected (0.02 sec) mysql&gt;<strong>exit</strong> Bye [fenglei@localhost scripts]$ <strong>mysql -hlocalhost -u blast2go -pblast4it</strong> Warning: Using a password on the command line interface can be insecure. Welcome to the MySQL monitor. Commands end with ; or g. Your MySQL connection id is 6 Server version: 5.6.20 Source distribution Copyright © 2000, 2014, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type ‘help;’ or ‘h’ for help. Type ‘c’ to clear the current input statement.</p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>SSPACE: Can&#39;t locate getopts.pl</title>
    <url>/2017/08/28/sspace-cant-locate-getopts-pl/</url>
    <content><![CDATA[<p>问题：运行SSPACE_Standard_v3.0.pl报错。 Can’t locate <a href="http://getopts.pl">getopts.pl</a> in @INC (@INC contains: /xxx/SSPACE-STANDARD/dotlib/ /home/fenglei-cuhk/perl5/lib/perl5 /etc/perl /usr/local/lib/perl/5.18.2 /usr/local/share/perl/5.18.2 /usr/lib/perl5 /usr/share/perl5 /usr/lib/perl/5.18 /usr/share/perl/5.18 /usr/local/lib/site_perl .) at /home/xx/SSPACE-STANDARD/SSPACE_Standard_v3.0.pl line 124. 原因： <a href="http://getopts.pl">getopts.pl</a> is a Perl 4 core library but no longer included in current Perl 5 distributions. 解决办法： 在Linux命令行模式下输入“perl -MCPAN -e shell”进入perl界面，然后输入“install Perl4::CoreLibs”即可。</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>The Lander-Waterman model</title>
    <url>/2014/12/17/the-lander-waterman-model/</url>
    <content><![CDATA[<h3 id="lander-waterman-theory"><a class="markdownIt-Anchor" href="#lander-waterman-theory"></a> Lander-Waterman theory</h3>
<p>In 1988, <a href="http://en.wikipedia.org/wiki/Eric_Lander" title="Eric Lander">Eric Lander</a> and <a href="http://en.wikipedia.org/wiki/Michael_Waterman" title="Michael Waterman">Michael Waterman</a> published an important paper<a href="http://en.wikipedia.org/wiki/DNA_sequencing_theory#cite_note-landerwaterman-6">[6]</a> examining the covering problem from the standpoint of gaps. Although they focused on the so-called <a href="http://en.wikipedia.org/wiki/Gene_mapping" title="Gene mapping">mapping problem</a>, the abstraction to sequencing is much the same. They furnished a number of useful results that were adopted as the standard theory from the earliest days of “large-scale” genome sequencing.<a href="http://en.wikipedia.org/wiki/DNA_sequencing_theory#cite_note-fleischmann-7">[7]</a> Their model was also used in designing the <a href="http://en.wikipedia.org/wiki/Human_Genome_Project" title="Human Genome Project">Human Genome Project</a> and continues to play an important role in DNA sequencing.</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>topGO</title>
    <url>/2015/10/18/topgo/</url>
    <content><![CDATA[<p><strong>manual:</strong></p>
<ol>
<li><a href="http://www.bioconductor.org/packages/release/bioc/vignettes/topGO/inst/doc/topGO.pdf">http://www.bioconductor.org/packages/release/bioc/vignettes/topGO/inst/doc/topGO.pdf</a></li>
</ol>
<p><strong>PPT:</strong></p>
<ol>
<li><a href="http://cals.arizona.edu/~anling/MCB516/lecture22.pdf">http://cals.arizona.edu/~anling/MCB516/lecture22.pdf</a></li>
</ol>
<p><strong>code:</strong></p>
<ol>
<li><a href="http://baliga.systemsbiology.net/events/sysbio/sites/baliga.systemsbiology.net.events.sysbio/files/uploads/topGO%5C_FunctionalEnrichment.r">http://baliga.systemsbiology.net/events/sysbio/sites/baliga.systemsbiology.net.events.sysbio/files/uploads/topGO\_FunctionalEnrichment.r</a></li>
<li><a href="https://stat.ethz.ch/pipermail/bioconductor/2008-April/021773.html">https://stat.ethz.ch/pipermail/bioconductor/2008-April/021773.html</a></li>
</ol>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>Tophat: AttributeError: &#39;NoneType&#39; object has no attribute &#39;group&#39;</title>
    <url>/2014/09/15/tophat-attributeerror-nonetype-object-has-no-attribute-group/</url>
    <content><![CDATA[<p>I have installed boost (version 1.38), Eigen (eigen-eigen-1306d75b4a21.tar.gz) and Samtools(version 1.0). [Ref:<a href="http://ccb.jhu.edu/software/tophat/tutorial.shtml%5C">http://ccb.jhu.edu/software/tophat/tutorial.shtml\</a>] Then I downlaod Tophat 2.0.12 (binary), But error occured when I test the pipeline on a simple test data set. tophat -r 20 test_ref reads_1.fq reads_2.fq</p>
<span id="more"></span>
<p>=====<mark><mark><mark><mark><mark>ERROR MESSAGE</mark></mark></mark></mark></mark></p>
<p>[fenglei@localhost test_data]$ sh <a href="http://tophat.sh">tophat.sh</a></p>
<p>[2014-09-15 10:49:27] Beginning TopHat run (v2.0.12)</p>
<p>-----------------------------------------------</p>
<p>[2014-09-15 10:49:27] Checking for Bowtie</p>
<p>Bowtie version:        2.2.3.0</p>
<p>[2014-09-15 10:49:27] Checking for Samtools</p>
<p>Traceback (most recent call last):</p>
<p>File “/home/fenglei/local/app/tophat~/tophat”, line 4087, in</p>
<p>sys.exit(main())</p>
<p>File “/home/fenglei/local/app/tophat~/tophat”, line 3885, in main</p>
<p>check_samtools()</p>
<p>File “/home/fenglei/local/app/tophat~/tophat”, line 1559, in check_samtools</p>
<p>samtools_version_str, samtools_version_arr = get_samtools_version()</p>
<p>File “/home/fenglei/local/app/tophat~/tophat”, line 1541, in get_samtools_version</p>
<p>samtools_version_arr = [int(version_match.group(x)) for x in [1,2,3]]</p>
<p>AttributeError: ‘NoneType’ object has no attribute ‘group’</p>
<p>[fenglei@localhost test_data]$</p>
<p>====================================</p>
<p><strong>The reason: Tophat doesn’t support the most recent version of samtools.</strong></p>
<p>See this other thread: <a href="https://groups.google.com/forum/?utm_medium=email&amp;utm_source=footer#!topic/tuxedo-tools-users/b7I6YH5_0Ck">https://groups.google.com/forum/?utm_medium=email&amp;utm_source=footer#!topic/tuxedo-tools-users/b7I6YH5_0Ck</a></p>
<p><strong>Thanks to Jeff Hussmann. He had also run into this issue and attached a workaround patch to tophat’s samtools version detection.</strong></p>
<p>=<mark><mark><mark><mark><mark>workaround</mark></mark></mark></mark></mark>=======</p>
<p><strong>1537,1542c1537,1543</strong></p>
<p>&lt; version_match = re.search(r’Version:s+(d+).(d+).(d+)([a-zA-Z]?)‘, samtools_out) &lt; samtools_version_arr = [int(version_match.group(x)) for x in [1,2,3]] &lt; if version_match.group(4): &lt; samtools_version_arr.append(version_match.group(4)) &lt; else: &lt; samtools_version_arr.append(0) — &gt; version_match = re.search(r’Version:s+(d+).(d+).?(d*)([a-zA-Z]?)’, samtools_out) &gt; samtools_version_arr = [int(version_match.group(x)) for x in [1,2]] &gt; for possibly_blank_index in [3, 4]: &gt; if version_match.group(possibly_blank_index): &gt; samtools_version_arr.append(version_match.group(possibly_blank_index)) &gt; else: &gt; samtools_version_arr.append(0)</p>
<p><strong>1559c1560</strong></p>
<p>&lt; elif samtools_version_arr[1] &lt; 1 or samtools_version_arr[2] &lt; 7: — &gt; elif samtools_version_arr[0] &lt; 1 and (samtools_version_arr[1] &lt; 1 or samtools_version_arr[2] &lt; 7):</p>
<p>======================================</p>
<p>Now the tophat works well:</p>
<p>(15 Sep 2014)</p>
<p>======================================</p>
<p>[fenglei@localhost test_data]$ sh <a href="http://tophat.sh">tophat.sh</a>[2014-09-15 11:42:40] Beginning TopHat run (v2.0.12) ----------------------------------------------- [2014-09-15 11:42:40] Checking for Bowtie Bowtie version: 2.2.3.0 [2014-09-15 11:42:40] Checking for Samtools Samtools version: 1.0.0.0 [2014-09-15 11:42:40] Checking for Bowtie index files (genome)… Found both Bowtie1 and Bowtie2 indexes. [2014-09-15 11:42:40] Checking for reference FASTA file [2014-09-15 11:42:40] Generating SAM header for test_ref [2014-09-15 11:42:40] Preparing reads left reads: min. length=75, max. length=75, 100 kept reads (0 discarded) right reads: min. length=75, max. length=75, 100 kept reads (0 discarded) [2014-09-15 11:42:40] Mapping left_kept_reads to genome test_ref with Bowtie2 [2014-09-15 11:42:40] Mapping left_kept_reads_seg1 to genome test_ref with Bowtie2 (1/3) [2014-09-15 11:42:40] Mapping left_kept_reads_seg2 to genome test_ref with Bowtie2 (2/3) [2014-09-15 11:42:40] Mapping left_kept_reads_seg3 to genome test_ref with Bowtie2 (3/3) [2014-09-15 11:42:41] Mapping right_kept_reads to genome test_ref with Bowtie2 [2014-09-15 11:42:41] Mapping right_kept_reads_seg1 to genome test_ref with Bowtie2 (1/3) [2014-09-15 11:42:41] Mapping right_kept_reads_seg2 to genome test_ref with Bowtie2 (2/3) [2014-09-15 11:42:41] Mapping right_kept_reads_seg3 to genome test_ref with Bowtie2 (3/3) [2014-09-15 11:42:41] Searching for junctions via segment mapping [2014-09-15 11:42:41] Retrieving sequences for splices [2014-09-15 11:42:41] Indexing splices Building a SMALL index [2014-09-15 11:42:41] Mapping left_kept_reads_seg1 to genome segment_juncs with Bowtie2 (1/3) [2014-09-15 11:42:41] Mapping left_kept_reads_seg2 to genome segment_juncs with Bowtie2 (2/3) [2014-09-15 11:42:41] Mapping left_kept_reads_seg3 to genome segment_juncs with Bowtie2 (3/3) [2014-09-15 11:42:42] Joining segment hits [2014-09-15 11:42:42] Mapping right_kept_reads_seg1 to genome segment_juncs with Bowtie2 (1/3) [2014-09-15 11:42:42] Mapping right_kept_reads_seg2 to genome segment_juncs with Bowtie2 (2/3) [2014-09-15 11:42:42] Mapping right_kept_reads_seg3 to genome segment_juncs with Bowtie2 (3/3) [2014-09-15 11:42:42] Joining segment hits [2014-09-15 11:42:42] Reporting output tracks ----------------------------------------------- [2014-09-15 11:42:42] A summary of the alignment counts can be found in ./tophat_out/align_summary.txt [2014-09-15 11:42:42] Run complete: 00:00:02 elapsed [fenglei@localhost test_data]$</p>
<p>======================================</p>
<p><strong>Reference:</strong></p>
<p>[1] <a href="https://groups.google.com/forum/#!msg/tuxedo-tools-users/IMJucC83K60/n1--0DGLmxMJ">https://groups.google.com/forum/#!msg/tuxedo-tools-users/IMJucC83K60/n1--0DGLmxMJ</a></p>
<p>[2] <a href="https://groups.google.com/forum/#!msg/tuxedo-tools-users/IMJucC83K60/lHRE7K3V97QJ">https://groups.google.com/forum/#!msg/tuxedo-tools-users/IMJucC83K60/lHRE7K3V97QJ</a></p>
<p>[3] <a href="https://groups.google.com/forum/?utm%5C_medium=email&amp;utm%5C_source=footer#!topic/tuxedo-tools-users/BVNDDmInU0A">https://groups.google.com/forum/?utm\_medium=email&amp;utm\_source=footer#!topic/tuxedo-tools-users/BVNDDmInU0A</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Trinity need java 1.6 or Java 1.7</title>
    <url>/2014/12/23/trinity-need-java-1-6-or-java-1-7/</url>
    <content><![CDATA[<p>原来安装了java 1.8，但是trinity 软件需要java 1.6 or Java 1.7。 解决办法：</p>
<span id="more"></span>
<p>本文指导如何在linux中安装官方的Java开发工具包——JDK，内含Java运行环境Jre。因为版权等原因，很多Linux发行版安装的都是OpenJDK，可某些情况需要官方的JDK。 <strong>下载</strong> 在<a href="http://www.oracle.com/technetwork/java/javase/downloads/index.html">http://www.oracle.com/technetwork/java/javase/downloads/index.html</a>，点击大大的java图标，进入下载页面，选择下载jdk 7uxx，并解压到/usr/java目录：</p>
<p>1</p>
<p>sudo tar -zxvf jdk-7u25-linux-x64.tar.gz -C /usr/java</p>
<p>修改软链接到最新，结果如下：</p>
<p>1</p>
<p>2</p>
<p>3</p>
<p>4</p>
<p>5</p>
<p>$ls -lh /usr/java/</p>
<p>total 4.0K</p>
<p>lrwxrwxrwx. 1 root root 16 Mar 3 23:34 default -&gt; /usr/java/latest</p>
<p>drwxr-xr-x. 8 root root 4.0K Aug 19 21:03 jdk1.7.0_25</p>
<p>lrwxrwxrwx. 1 root root 21 Aug 19 21:04 latest -&gt; /usr/java/jdk1.7.0_25</p>
<p>参考资料：<a href="http://blog.shenwei.me/tag/java/">http://blog.shenwei.me/tag/java/</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>vim: error while loading shared libraries: libperl.so</title>
    <url>/2014/09/12/vim-error-while-loading-shared-libraries-libperl-so/</url>
    <content><![CDATA[<p>[fenglei@localhost ~]$ <strong>vi .bashrc</strong> vim: error while loading shared libraries: <a href="http://libperl.so">libperl.so</a>: cannot open shared object file: No such file or directory 出现类似错误是由于缺少相关的库文件（*.so文件）造成的 可能的原因是版本不匹配或者没有安装相应的rpm文件首先要执行的文件在那里，用which命令</p>
<span id="more"></span>
<p>[fenglei@localhost ~]$ <strong>which vi</strong> alias vi=‘vim’ /usr/bin/vim 即可看到vi命令在/usr/bin/vim路径然后使用l<a href="http://www.baidu.com/s?wd=dd%C3%FC%C1%EE&amp;ie=gbk&amp;tn=SE_hldp00990_u6vqbx10">dd命令</a>确认这个程序执行需要哪些动态链接库 [fenglei@localhost ~]$ <strong>ldd /usr/bin/vim</strong> linux-vdso.so.1 =&gt; (0x00007fff3a9a5000) libselinux.so.1 =&gt; /lib64/libselinux.so.1 (0x0000003c23c00000) libncurses.so.5 =&gt; /lib64/libncurses.so.5 (0x0000003c2e400000) libacl.so.1 =&gt; /lib64/libacl.so.1 (0x0000003c2e000000) libgpm.so.2 =&gt; /usr/lib64/libgpm.so.2 (0x0000003c23400000) <a href="http://libperl.so">libperl.so</a> <em>=&gt; not found</em> libresolv.so.2 =&gt; /lib64/libresolv.so.2 (0x0000003c24000000) libutil.so.1 =&gt; /lib64/libutil.so.1 (0x0000003c30800000) libc.so.6 =&gt; /lib64/libc.so.6 (0x0000003c22000000) libpython2.6.so.1.0 =&gt; /usr/lib64/libpython2.6.so.1.0 (0x0000003237800000) libm.so.6 =&gt; /lib64/libm.so.6 (0x0000003c23000000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x0000003c22800000) libtinfo.so.5 =&gt; /lib64/libtinfo.so.5 (0x0000003c2d800000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x0000003c22400000) /lib64/ld-linux-x86-64.so.2 (0x0000003c21c00000) libattr.so.1 =&gt; /lib64/libattr.so.1 (0x0000003c31000000) 可以确定为缺少这个文件而不能运行通过文件名，大致可以判断这个文件属于perl的rpm包 使用rpm -ql perl grep <a href="http://libperl.so">libperl.so</a>；或者直接进入perl的安装包。 通常可以找到这个文件(<a href="http://libperl.so">libperl.so</a>)的位置 [root@localhost perl]# <strong>ln -s /home/fenglei/local/app/perl/libperl.so /lib64/libperl.so</strong>   [fenglei@localhost ~]$ <strong>ldd /usr/bin/vim</strong> linux-vdso.so.1 =&gt; (0x00007fffdf7ff000) libselinux.so.1 =&gt; /lib64/libselinux.so.1 (0x0000003c23c00000) libncurses.so.5 =&gt; /lib64/libncurses.so.5 (0x0000003c2e400000) libacl.so.1 =&gt; /lib64/libacl.so.1 (0x0000003c2e000000) libgpm.so.2 =&gt; /usr/lib64/libgpm.so.2 (0x0000003c23400000) <a href="http://libperl.so">libperl.so</a> =&gt; /lib64/libperl.so (0x00007f045f7d5000) libresolv.so.2 =&gt; /lib64/libresolv.so.2 (0x0000003c24000000) libutil.so.1 =&gt; /lib64/libutil.so.1 (0x0000003c30800000) libc.so.6 =&gt; /lib64/libc.so.6 (0x0000003c22000000) libpython2.6.so.1.0 =&gt; /usr/lib64/libpython2.6.so.1.0 (0x0000003237800000) libm.so.6 =&gt; /lib64/libm.so.6 (0x0000003c23000000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x0000003c22800000) libtinfo.so.5 =&gt; /lib64/libtinfo.so.5 (0x0000003c2d800000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x0000003c22400000) /lib64/ld-linux-x86-64.so.2 (0x0000003c21c00000) libattr.so.1 =&gt; /lib64/libattr.so.1 (0x0000003c31000000) libnsl.so.1 =&gt; /lib64/libnsl.so.1 (0x0000003c32c00000) libcrypt.so.1 =&gt; /lib64/libcrypt.so.1 (0x0000003c2d400000) <a href="http://libfreebl3.so">libfreebl3.so</a> =&gt; /lib64/libfreebl3.so (0x0000003c2dc00000) 然后在运行ldd /usr/bin/vim确认是否找到了so文件 如果找到的话就ok了 OK!</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>为什么要对多重检验得到的P值进行校正</title>
    <url>/2020/08/05/%E4%B8%BA%E4%BB%80%E4%B9%88%E8%A6%81%E5%AF%B9%E5%A4%9A%E9%87%8D%E6%A3%80%E9%AA%8C%E5%BE%97%E5%88%B0%E7%9A%84p%E5%80%BC%E8%BF%9B%E8%A1%8C%E6%A0%A1%E6%AD%A3/</url>
    <content><![CDATA[<p>在生物学数据（例如转录组）分析中，对两组数据做比较，比较的结果包含数万个基因的倍数关系（Fold change）与 P 值，通常还会有一个 Q value，即对每个基因的 P value 进行校正。为什么要做校正？</p>
<p>上述提到的数万个基因分别做比较与统计学检验，就是一个多重检验的过程，而多重检验会增加一类错误的概率。通俗地说，本来原假设是小概率事件， 但是夜路走多了也会遇到鬼。抽样多了小概率事件发生几率就高了。</p>
<p>下面是摘抄自 Zhihu 的一段解释，帮助理解。</p>
<p>以猜硬币正反面的游戏为例，如果一人在连猜五次，每次都准确猜中。我们认为他在做假，因为如果他没做假的话，连续猜对五次的概率只有 1/32 = 0.03125，小于我们预先定义的小概率（比如说0.05）。（如果知道什么是p值的话，这里我们定义的零假设H0为某甲没有做假，p=0.03125表示我们拒绝 H0 只有约 3% 的犯错几率。如果不知道什么是 P 值的话也没关系，在这里并不重要。）<br />
上面这个判断没有问题，但如果涉及到多重比较（multiple comparison）的话就不一样了。前面的例子只用了一枚硬币，而这次我们改用 100 枚不同颜色的硬币（这就是所谓的多重比较），有红色硬币、黄色硬币、绿色硬币、粉色硬币、紫色硬币等等。实验中，我们让此人每枚硬币各猜五次，然后我们发现，在猜其他颜色的硬币时他都有猜错，但在猜绿色硬币时他连猜五次都猜对了。那么，我们是不是能像前面一样，认为他虽然在猜其他硬币时没做假，但在猜绿色硬币时做假了呢？简单计算一下就可以发现，当我们用100枚硬币做实验时，出现一枚或以上硬币五次都猜对的概率为 1-(1-1/32)^100 = 0.958。显然，这时我们就不能再说某甲在猜绿色硬币时做假了，即便单就那一枚绿色硬币来说，连续猜对五次的概率还是只有0.03125。<br />
避免此问题的方法包括控制 FWER（<a href="https://link.zhihu.com/?target=http%3A//en.wikipedia.org/wiki/Familywise_error_rate">Familywise error rate</a>）、FDR（<a href="https://link.zhihu.com/?target=http%3A//en.wikipedia.org/wiki/False_discovery_rate">False discovery rate</a>）等。最简单的控制FWER的方法是 Bonferroni 校正，是指 P 值应该除以比较的次数，在上面的例子中为100。</p>
<p>R 里面 <code>p.adjust</code> 函数可以对多重检验的 P value 进行校正。</p>
<p>p=c(0.0003,0.0001,0.02, 0.1, 0.3, 0.001)<br />
p.adjust(p, method=“fdr”, length(p))<br />
[1] 0.0009 0.0006 0.0300 0.1200 0.3000 0.0020<br />
p.adjust(p, method=“bonferroni”, length(p))<br />
[1] 0.0018 0.0006 0.1200 0.6000 1.0000 0.0060</p>
<p>END</p>
<p>参考资料</p>
<p><a href="https://zhuanlan.zhihu.com/p/95530040">https://zhuanlan.zhihu.com/p/95530040</a></p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>使用 Enrichment Map或ClueGO 做基因富集分析+GO网络</title>
    <url>/2020/09/04/%E4%BD%BF%E7%94%A8-enrichment-map-%E5%81%9A%E5%9F%BA%E5%9B%A0%E7%BD%91%E7%BB%9C/</url>
    <content><![CDATA[<p>对于一个基因列表，经过通路富集（Gene Ontology 或 KEGG pathways）往往富集到多个通路，数据仍然比较庞大，可以用 Enrichment Map 或 ClueGO 进一步精简，得到下面类似的网络图。</p>
<p><img src="https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fng.3785/MediaObjects/41588_2017_Article_BFng3785_Fig15_ESM.jpg?as=webp" alt="" /></p>
<p>Enrichment map for pathways enriched in susceptibility to ER-negative breast cancer. From: <a href="https://www.nature.com/articles/ng.3785">Identification of ten variants associated with risk of estrogen-receptor-negative breast cancer</a></p>
<p><img src="https://genehub.files.wordpress.com/2020/09/36897186.png?w=640" alt="" /></p>
<p>Enrichment Map方法：</p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200904111451.png?w=1024" alt="" /></p>
<p>准备工作</p>
<p>安装 Java。我操作系统是 Windows 10，Java官网下载 jdk-14.0.2_windows-x64_bin.exe，选择默认路径安装。最后安装路径在：C:\Program Files\Java\jdk-14.0.2 ，注意此时安装 Cytoscape 会报错“EXE4J_JAVA_HOME, No JVM could be found on your system”，表示找不到 java，原来需要设置环境变量。</p>
<p>将 Java 路径加入环境变量。在桌面右键点击“我的电脑”，选择“属性”，在出来的界面中左侧有“高级系统设置”字样，点击进去，即可在“高级”栏目下见到“环境变量字样”。</p>
<p>在环境变量中，要修改两个地方，一个是添加JAVA_HOME。选择“新建”，变量名填上JAVA_HOME，变量值填上“C:\Program Files\Java\jdk-14.0.2”，在java的安装过程中，默认一直下一步安装，所以装在C盘，如果在安装过程中改了目录，那可能是D盘或者E盘，那么变量值要做相应的更改。<br />
还要修改一个地方，就是Path，添加JAVA的变量值到Path中，选择Path，然后点“编辑”，在最后面添加如下语句“%JAVA_HOME%\bin”。</p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200904101004.png?w=810" alt="" /></p>
<p>按照上面的步骤设置好环境变量之后，Cytoscape 也能顺利安装了。进入 CytoScape 软件界面，上方栏目有个 App 字样，进去可以按照应用，例如 Enrichment Map，AutoAnnotate，BinGO等。</p>
<p>下面测试基因网络分析。</p>
<p>进入g:Profiler网站，提交基因列表，将对基因的Gene Ontology、KEGG这些信息进行注释。如下图所示结果。在Detailed Results 栏目下有一个 GEM 文件，将其下载，这个文件里面就是通路注释结果，包含“<a href="http://GO.ID">GO.ID</a> Description p.Val FDR Phenotype Genes”这些信息。另外在 Data source 栏目下有一个 combined_name.gmt 下载选项，这个 GMT 文件是“Gene Matrix Tranpose”，也可以用户自己做。（By default, the GSEA desktop software searches the MSigDB gene set database that includes pathways, published gene signatures, microRNA target genes and other gene set types. <strong>The user can also provide a custom database as a text-based ‘Gene Matrix Transposed’ (GMT) file</strong> where each line defines a pathway, with its name, identifier and a list of gene identifiers that match the input gene list.）</p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200904100014.png?w=1024" alt="" /></p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200904100026.png?w=1024" alt="" /></p>
<p>将上面的两个文件下载到本地之后，提交到 CytoScape 软件里面。</p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200904100206.png?w=1024" alt="" /></p>
<p>点击 Build 即可得到网络图。我遇到中间报错信息提示KEGG的问题，直接选择了跳过，也没影响网络生成。然后再在 Apps 里面选择“AutoAnnotate”，将网络进行 cluster 分析，便可以看到一些大圈圈将若干节点围成了不同的群落，只是图形不算美观，跟人家参考文献里面有差距。似乎不太好调整网络形状，几番尝试之后再AutoAnnotate界面有一个三横的按钮，点击进去有“Layout Clusters”，选择“CoSE Layout”，网络图好看很多。</p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200904100319.png?w=1024" alt="" /></p>
<p>上面简单测试了一下g:Profiler + Enrichiment Map + AutoAnnotate 进行网络构建。</p>
<p>问题：</p>
<p>1 如何只绘制某一方面的网络图，例如只关心细胞器/或某个通路？</p>
<p>2 如何将多个基因列表的网络图绘制在一起，用不同颜色标记不同的基因来源？</p>
<p>3 如何自己制作GMT文件</p>
<p>4 其他富集分析软件的结果应该也可以导入Cytoscape，如何对数据框进行调整，才可导入？</p>
<p>[2020.09.26 更新] <strong>ClueGO案例：</strong></p>
<p><img src="https://genehub.files.wordpress.com/2020/09/e5beaee4bfa1e688aae59bbe_20200916094951.png?w=1024" alt="" /></p>
<p>ClueGO的操作比Enrichment Map更方便，网络结果的调整也更人性化。</p>
<p>B站有一个ClueGO操作实践的视频：<a href="https://www.bilibili.com/video/BV1TK411W7TM">https://www.bilibili.com/video/BV1TK411W7TM</a> （作者：<a href="https://space.bilibili.com/198764903">野菜茎小甜饼</a>）</p>
<p>参考资料</p>
<p>[1] <a href="https://cloud.tencent.com/developer/news/96301">CytoScape 攻略</a></p>
<p>[2] <a href="https://www.jianshu.com/p/54e70ee78ef9"></a><a href="/Profiler%20%E5%9F%BA%E5%9B%A0%E5%8A%9F%E8%83%BD%E5%AF%8C%E9%9B%86%E5%88%86%E6%9E%90%E7%9A%84%E7%A4%BA%E4%BE%8B">g:Profiler 基因功能富集分析的示例</a></p>
<p>[3] <a href="http://www.360doc.com/content/19/1202/13/50736008_876897857.shtml">Enrichment Map 操作示例</a></p>
<p>[4] Enrichment Map tutorial: <a href="https://enrichmentmap.readthedocs.io/en/latest/QuickTour.html">https://enrichmentmap.readthedocs.io/en/latest/QuickTour.html</a></p>
<p>[5] AutoAnnotate layout: <a href="https://autoannotate.readthedocs.io/en/latest/GroupingAndLayout.html#cluster-aware-layouts">https://autoannotate.readthedocs.io/en/latest/GroupingAndLayout.html#cluster-aware-layouts</a></p>
<p>[6] Nature Protocol 2019: Pathway enrichment analysis and visualization of omics data using g:Profiler, GSEA, Cytoscape and EnrichmentMap <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6607905/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6607905/</a></p>
<p>[7] Enrichment Map usage, SlidShare: <a href="https://slideplayer.com/slide/3900605/">https://slideplayer.com/slide/3900605/</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>使用fastq-dump从NCBI的SRA数据库下载数据</title>
    <url>/2016/06/01/%E4%BD%BF%E7%94%A8fastq-dump%E4%BB%8Encbi%E7%9A%84sra%E6%95%B0%E6%8D%AE%E5%BA%93%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<p>测序类的论文，一般需要将原始测序reads数据上传到某个公开的数据库，然后在文章末尾标明数据存储位置和登录号。NCBI的SRA (Sequence Read Archive) 数据库(<a href="http://www.ncbi.nlm.nih.gov/sra/">http://www.ncbi.nlm.nih.gov/sra/</a>) 是最常用的存储测序数据的数据库。如何从SRA数据库下载他人公开的数据，以作己用呢？</p>
<blockquote>
<p>fastq-dump -X 5 -Z SRR492257 #直接看到DRR047093数据的前5条/对Reads，输出在屏幕</p>
</blockquote>
<blockquote>
<p>fastq-dump  -O ./data SRR492257 # 将fastq格式的Reads文件下载到./data目录，但是Read 1与Read2并排存储在fastq文件中，对后续分析造成不便。</p>
</blockquote>
<blockquote>
<p>fastq-dump --split-files -O ./data SRR492257 # 将Reads 1和Reads 2两个文件均下载到./data目录</p>
</blockquote>
<p>参考资料： <a href="https://github.com/ncbi/sra-tools/wiki/Downloads">https://github.com/ncbi/sra-tools/wiki/Downloads</a> <a href="http://www.ncbi.nlm.nih.gov/books/NBK158899/#SRA%5C_download.when%5C_to%5C_use%5C_a%5C_command%5C_line">http://www.ncbi.nlm.nih.gov/books/NBK158899/#SRA\_download.when\_to\_use\_a\_command\_line</a> <a href="https://www.biostars.org/p/19446/">https://www.biostars.org/p/19446/</a> <a href="http://blog.csdn.net/xubo245/article/details/50512018">http://blog.csdn.net/xubo245/article/details/50512018</a> <a href="http://www.bio-info-trainee.com/338.html">http://www.bio-info-trainee.com/338.html</a></p>
<hr />
<p>顺便学习上传数据到SRA： 目前，测序类的论文，一般需要将原始测序reads数据上传到某个公开的数据库，然后在文章末尾标明数据存储位置和登录号。NCBI的SRA (Sequence Read Archive) 数据库(<a href="http://www.ncbi.nlm.nih.gov/sra/">http://www.ncbi.nlm.nih.gov/sra/</a>) 是最常用的存储测序数据的数据库。然而要上传自己的数据到 NCBI SRA 对很多人而言，并不是一件容易的事。 要学会怎么上传数据到NCBI SRA，最直接的方式就是仔细阅读NCBI给的说明文档。这个链接（<a href="http://www.ncbi.nlm.nih.gov/books/NBK47529/">http://www.ncbi.nlm.nih.gov/books/NBK47529/</a>）的文档给出了详细步骤。仔细阅读，按照上面的步骤，结合具体操作时的网页上各处的说明，一般都可以顺利完成任务。 现实是，许多人遇到的主要困难是：不看说明文档或说明文档看不懂；测序数据相关的一些概念不懂，导致不知道该怎样填表格，比如不明白SE和PE的区别，insert size和read length分别是什么意思，MD5的意思，以及怎样获得一个文件的MD5值。 一般上传数据到NCBI SRA的过程需要6步：</p>
<ol>
<li>Create a <a href="https://submit.ncbi.nlm.nih.gov/subs/bioproject/">BioProject</a> for this research</li>
<li>Create a <a href="https://submit.ncbi.nlm.nih.gov/subs/biosample/">BioSample</a> submission for your biological sample(s)</li>
<li>Gather Sequence Data Files</li>
<li>Enter Metadata on SRA website
<ol>
<li>Create SRA submission</li>
<li>Create Experiment(s) and link to BioProject and BioSample</li>
<li>Create Run(s)</li>
</ol>
</li>
<li>Transfer Data files to SRA</li>
<li>Update Submission with PubMed links, Release Date, or Metadata Changes</li>
</ol>
<p>需要注意的一点是，上传的过程中很多地方一旦保存或提交就不可以修改，尤其是各处的Alias。但是，可以联系NCBI的工作人员修改内容。NCBI的工作效率是很高的，一般不超过48小时，就可以得到确认，并拿到登录号。</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>使用ReSeqTools/iTools进行fastq数据统计、质检、过滤</title>
    <url>/2015/01/02/%E4%BD%BF%E7%94%A8reseqtoolsitools%E8%BF%9B%E8%A1%8Cfastq%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1%E3%80%81%E8%B4%A8%E6%A3%80%E3%80%81%E8%BF%87%E6%BB%A4/</url>
    <content><![CDATA[<p>重测序分析集成工具包 linux 64位平台 静态编译 chmod 便可以直接运行了。 （ReSeqTools/iTools） 即在linux64机上只须</p>
<blockquote>
<ul>
<li>tar -zxvf ReSeqTools_XXX.tar.gz ;</li>
<li>cd iTools_Code; chmod 775 iTools ;</li>
<li>./ iTools -h ;</li>
<li>无须重新make</li>
</ul>
</blockquote>
<p>QQ交流群 群名称是Reseqtools QQ群号： 125293663</p>
<span id="more"></span>
<p>硕士毕业文章Thesis Disseration Paper （Master）: <a href="http://cdmd.cnki.com.cn/Article/CDMD-10561-1013318279.htm">http://cdmd.cnki.com.cn/Article/CDMD-10561-1013318279.htm</a> 或者进入中国知网 <a href="http://www.cnki.net/">http://www.cnki.net/</a> 搜： 基于重测序数据的群体SNP位点检测及基因型判断 小文章见这儿： <a href="http://www.geneticsmr.com//year2013/vol12-4/pdf/gmr3109.pdf">http://www.geneticsmr.com//year2013/vol12-4/pdf/gmr3109.pdf</a> The paper (title: ReSeqTools: an integrated toolkit for large-scale next-generation sequencing based resequencing analysis )is here: <a href="http://www.geneticsmr.com//year2013/vol12-4/pdf/gmr3109.pdf">http://www.geneticsmr.com//year2013/vol12-4/pdf/gmr3109.pdf</a> Join Communication &amp; Discussion QQ Group: 125293663 If you have any question ,contact the email:<a href="mailto:hewm2008@gmail.com">hewm2008@gmail.com</a>/hewm2008@qq.com and also join the QQ Group : 125293663 Fasta Fastq SOAP Sam Bam Gff CNS   内容摘抄自：<a href="https://github.com/BGI-shenzhen/Reseqtools/blob/master/README.md">https://github.com/BGI-shenzhen/Reseqtools/blob/master/README.md</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>使用scp命令从linux服务器传输文件到本地计算机</title>
    <url>/2014/12/31/%E4%BD%BF%E7%94%A8scp%E5%91%BD%E4%BB%A4%E4%BB%8Elinux%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BC%A0%E8%BE%93%E6%96%87%E4%BB%B6%E5%88%B0%E6%9C%AC%E5%9C%B0%E8%AE%A1%E7%AE%97%E6%9C%BA/</url>
    <content><![CDATA[<p>一、对于Mac OS：</p>
<p>进入终端，输入</p>
<p>$ scp <a href="mailto:usrname@192.168.1.111">usrname@192.168.1.111</a>:/home/usrname/file.name ./Desktop</p>
<p>然后输入用户密码，文件就传输到了本地桌面。</p>
<p>二、对于windows系统</p>
<p>使用SecureCRT软件，登录之后，使用sz命令即可。（s是send的意思。）</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>修改linux用户密码</title>
    <url>/2014/08/22/%E4%BF%AE%E6%94%B9linux%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81/</url>
    <content><![CDATA[<p>对于初学者来说,如何修改linux用户密码也不是件容易的事,其实非常简单,下面举例说明:</p>
<span id="more"></span>
<p>如果是以root身份登录,修改root密码.只要输入<br />
passwd<br />
就会出现:<br />
New password:<br />
Retype new password:<br />
按提示输入密码确认即可.<br />
如果想更改其他用户密码,只要输入passwd username即可.<br />
如:passwd kook<br />
New password:<br />
Retype new password:<br />
简单吧…</p>
<p>参考资料：<a href="http://www.jb51.net/LINUXjishu/11004.html">http://www.jb51.net/LINUXjishu/11004.html</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>免费下载英文文献的方法</title>
    <url>/2015/08/28/%E5%85%8D%E8%B4%B9%E4%B8%8B%E8%BD%BD%E8%8B%B1%E6%96%87%E6%96%87%E7%8C%AE%E7%9A%84%E6%96%B9%E6%B3%95/</url>
    <content><![CDATA[<p>一、国外代理下载。只需在文献网址里面插入代理网站的地址（<em><a href="http://sci-hub.org">sci-hub.org</a> 或者 sci-hub.club</em>），如下操作。</p>
<blockquote>
<p>原文献地址：<a href="http://www.plantcell.org/content/27/6/1595.full">http://www.plantcell.org/content/27/6/1595.full</a> 下载的地址：<a href="http://www.plantcell.org">http://www.plantcell.org</a>.<em><a href="http://sci-hub.org">sci-hub.org</a></em>/content/27/6/1595.full （代理网址可能无法长期使用。）</p>
</blockquote>
<p>二、丁香园论坛的“文献求助”功能。需要在www.dxy.cn注册账户，随后进入<a href="http://paper.pubmed.cn/%E5%8D%B3%E5%8F%AF%E6%8C%89%E7%85%A7%E6%8F%90%E7%A4%BA%E4%B8%8B%E8%BD%BD%E6%96%87%E7%AB%A0%EF%BC%8C%E5%8F%AF%E4%BB%A5%E5%A1%AB%E5%86%99%E6%96%87%E7%AB%A0%E6%A0%87%E9%A2%98%E6%88%96PMID%EF%BC%8C%E7%A8%8D%E7%AD%89%E7%89%87%E5%88%BB%E5%B0%B1%E8%83%BD%E6%94%B6%E5%88%B0pdf%E6%A0%BC%E5%BC%8F%E6%96%87%E7%AB%A0%E7%9A%84%E4%B8%8B%E8%BD%BD%E9%93%BE%E6%8E%A5%E3%80%82">http://paper.pubmed.cn/即可按照提示下载文章，可以填写文章标题或PMID，稍等片刻就能收到pdf格式文章的下载链接。</a></p>
<blockquote>
<p>文献下载地址：<a href="http://paper.pubmed.cn/">http://paper.pubmed.cn/</a></p>
</blockquote>
<p>三、购买下载账号。</p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>基于illumina测序数据，使用Jellyfish估计基因组大小</title>
    <url>/2014/12/17/%E5%9F%BA%E4%BA%8Eillumina%E6%B5%8B%E5%BA%8F%E6%95%B0%E6%8D%AE%EF%BC%8C%E4%BD%BF%E7%94%A8jellyfish%E4%BC%B0%E8%AE%A1%E5%9F%BA%E5%9B%A0%E7%BB%84%E5%A4%A7%E5%B0%8F/</url>
    <content><![CDATA[<p>一、数据 ① illumina测序数据：（细菌**<em>Staphylococcus aureus，</em>**基因组约3M，180bp文库，101PE测序，1294104条reads，测序碱基数据量约为130Mb，即基因组覆盖度45X。） <a href="http://gage.cbcb.umd.edu/data/Staphylococcus%5C_aureus/Data.original/frag%5C_1.fastq.gz">http://gage.cbcb.umd.edu/data/Staphylococcus\_aureus/Data.original/frag\_1.fastq.gz</a> <a href="http://gage.cbcb.umd.edu/data/Staphylococcus%5C_aureus/Data.original/frag%5C_2.fastq.gz">http://gage.cbcb.umd.edu/data/Staphylococcus\_aureus/Data.original/frag\_2.fastq.gz</a> ②  jellyfish 软件：（用来统计kmer频数。） <a href="ftp://ftp.genome.umd.edu/pub/jellyfish/jellyfish-2.1.4.tar.gz">ftp://ftp.genome.umd.edu/pub/jellyfish/jellyfish-2.1.4.tar.gz</a> ③jellyplot.pl软件：（用来画kmer图，以及估计基因组大小。） <a href="https://github.com/josephryan/estimate%5C_genome%5C_size.pl">https://github.com/josephryan/estimate\_genome\_size.pl</a> ④fastx toolkit：（用来转换fastq和fasta格式文件。） <a href="http://hannonlab.cshl.edu/">hannonlab.cshl.edu/</a><strong>fastx</strong>_<strong>toolkit</strong>/   ------------------ 下面是实际运行代码： cat frag_1.fastq frag_2.fastq &gt; all.fastq fastq_to_fasta -i all.fastq -o all.fasta jellyfish count -m 17 -s 100M -t 10 -C all.fasta jellyfish histo mer_counts.jf -o out.2.txt <a href="http://jellyplot.pl">jellyplot.pl</a> out.2.txt estimate_genome_size.pl -kmer 17 -peak 15 -fastq all.fastq.gz   结果：（预估基因组为7M，比实际大了一倍。可能是原始reads没有校正和过滤的原因。） $ estimate_genome_size.pl -kmer 17 -peak 15 -fastq all.fastq.gz # running version 0.04 of estimate_genome_size.pl # run with this command: estimate_genome_size.pl TOTAL_NTS: 131998608 Estimated Coverage: 17.7906976744186 Estimated Genome Size: 7419529.6 <a href="http://genehub.files.wordpress.com/2014/12/qqe688aae59c9620141217130925.jpg"><img src="http://genehub.files.wordpress.com/2014/12/qqe688aae59c9620141217130925.jpg?w=300" alt="QQ截圖20141217130925" /></a> 使用校正之后的数据，（使用quake.py进行校正<a href="http://gage.cbcb.umd.edu/data/Staphylococcus%5C_aureus%EF%BC%89">http://gage.cbcb.umd.edu/data/Staphylococcus\_aureus）</a> 估计基因组大小为： # running version 0.04 of estimate_genome_size.pl # run with this command: /home/fenglei/perl5/bin/estimate_genome_size.pl TOTAL_NTS: 59609610 Estimated Coverage: 15.3684210526316 Estimated Genome Size: 3878707.5 这次距离实际情况比较近。     =================== 附：jellyfish 参数意义 jellyfish count -m 17 -s 100M -t 10 -C all.fasta -m是kmer长度； -s是预估哈希表的大小，即G+G*c*e*k。G是Genome Size；c是coverage（genome survey测序通常低于100x）；e是测序错误率（illumina为1%）；k是kmer大小。 -C表示考虑DNA正义与反义链，遇到反义kmer时，计入正义kmer频数中。</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>基因组浏览器</title>
    <url>/2015/09/25/%E5%9F%BA%E5%9B%A0%E7%BB%84%E6%B5%8F%E8%A7%88%E5%99%A8/</url>
    <content><![CDATA[<p><strong>1 GBrowse</strong></p>
<blockquote>
<p><a href="http://gmod.org/wiki/GBrowse">http://gmod.org/wiki/GBrowse</a> <img src="http://gmod.org/mediawiki/images/thumb/0/04/GBrowseLogo.png/400px-GBrowseLogo.png" alt="" /></p>
</blockquote>
<p><strong>2. JBrowse</strong></p>
<blockquote>
<p><a href="http://jbrowse.org/">http://jbrowse.org/</a> [embed]<a href="https://youtu.be/NE8TBTbvDfM%5C%5B/embed%5C%5D">https://youtu.be/NE8TBTbvDfM\[/embed\]</a></p>
</blockquote>
<p><strong>3. UCSC</strong></p>
<blockquote>
<p><a href="https://genome.ucsc.edu/">https://genome.ucsc.edu/</a> <img src="https://genome.ucsc.edu/images/title.jpg" alt="" /></p>
</blockquote>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>基因组组装软件评估</title>
    <url>/2014/12/16/%E5%9F%BA%E5%9B%A0%E7%BB%84%E7%BB%84%E8%A3%85%E8%BD%AF%E4%BB%B6%E8%AF%84%E4%BC%B0/</url>
    <content><![CDATA[<p>比较下面8个软件，结论：AllPATHS-LG性能最优，组装的contig和scaffold比较长，错误率低；SOAP denovo组装得到的contig和scaffold几乎是几个软件里最长的，但是错误率也相对较高！   ABySS (Simpson et al. 2009) • ALLPATHS-LG (Gnerre et al. 2011) • Bambus2 (Koren et al. 2011) (<a href="http://www.cbcb.umd.edu/software/">http://www.cbcb.umd.edu/software/</a> bambus). • CABOG (Miller et al. 2008) • MSR-CA (<a href="http://www.genome.umd.edu/MSR%5C_CA%5C_MANUAL.htm">http://www.genome.umd.edu/MSR\_CA\_MANUAL.htm</a>) • SGA (Simpson and Durbin 2012) • SOAPdenovo (Li et al. 2010b) • Velvet (Zerbino and Birney 2008) ------------------------------------ <a href="http://gage.cbcb.umd.edu/index.html">http://gage.cbcb.umd.edu/index.html</a></p>
<h2 id="what-is-gage"><a class="markdownIt-Anchor" href="#what-is-gage"></a> What is GAGE?</h2>
<p>GAGE is an evaluation of the very latest large-scale genome assembly algorithms. We have organized this “bake-off” as an attempt to produce a realistic assessment of genome assembly software in a rapidly changing field of next-generation sequencing. The main results of GAGE have now been published in the journal Genome Research: <a href="http://genome.cshlp.org/content/early/2012/01/12/gr.131383.111">GAGE: A critical evaluation of genome assemblies and assembly algorithms</a>.</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>如何用GATK call snp</title>
    <url>/2015/06/15/%E5%A6%82%E4%BD%95%E7%94%A8gatk-call-snp/</url>
    <content><![CDATA[<h2 id="如何用gatk-call-snp"><a class="markdownIt-Anchor" href="#如何用gatk-call-snp"></a> <a href="http://www.cnblogs.com/freemao/p/3763885.html">如何用GATK call snp</a>（转自<a href="http://www.cnblogs.com/freemao/p/3763885.html%EF%BC%89">http://www.cnblogs.com/freemao/p/3763885.html）</a></h2>
<p>1， 什么是GATK？ The Genome Analysis Toolkit or GATK is a software package developed at the Broad Institute to analyse next-generation resequencing data. The toolkit offers a wide variety of tools, with a primary focus on variant discovery and genotyping as well as strong emphasis on data quality assurance. Its robust architecture, powerful processing engine and high-performance computing features make it capable of taking on projects of any size. 2， 如何用GATK call SNP？</p>
<span id="more"></span>
<p>用来call snp的数据为经过处理过的bam文件。如何处理另见博文。用到的工具为HaplotypeCaller。假如我有四个bam文件， LC17-1_L005.sorted.rmp.rg.recal.bam， LC17-2_L008.sorted.rmp.rg.recal.bam， RC17-1_L003.sorted.rmp.rg.recal.bam， RC17-3_L004.sorted.rmp.rg.recal.bam， 都是经过处理，符合GATK要求的bam文件，这四个文件都属于样本C17,我现在要用对样本C17 call snp， 具体命令如下： java -jar /share/Public/cmiao/GATK_tools/GenomeAnalysisTK.jar -nct 50 -T HaplotypeCaller -R RAP_cDAN.fasta  -I LC17-1_L005.sorted.rmp.rg.recal.bam -I LC17-2_L008.sorted.rmp.rg.recal.bam -I RC17-1_L003.sorted.rmp.rg.recal.bam -I RC17-3_L004.sorted.rmp.rg.recal.bam -o gatk.vcf 注意用来call snp的bam文件必须有index， 要不会提示没有index的报错。 以上几行命令要在同一行，所以看到每行最后有换行符，工具选用的是GATK中的HaplotypeCaller， -R后跟参考序列，-I 后是bam文件，这几个bam文件都属于一个sample, -o后跟输出文件名字。 -nct 是指定线程数，目前并不能多线程，只能用一个cpu。 结果文件就为gatk.vcf。 by freemao FAFU <a href="mailto:free_mao@qq.com">free_mao@qq.com</a></p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>学习笔记：使用MEGA构建进化树</title>
    <url>/2016/07/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%9A%E4%BD%BF%E7%94%A8mega%E6%9E%84%E5%BB%BA%E8%BF%9B%E5%8C%96%E6%A0%91/</url>
    <content><![CDATA[<p>参考资料： <a href="http://mbe.oxfordjournals.org/content/early/2013/03/13/molbev.mst012.full">Building Phylogenetic Trees from Molecular Data with MEGA</a> 如果需要对某个基因做进化树，首先需要得到其homologues，MEGA自带的blast可以做，提取fasta格式文件并作整理，序列名称遵循一定的规范，去掉其中多余字符。 导入序列之后，MEGA的菜单里alignment选项下有两个工具可以选择：clustal和muscle。推荐muscle，我经过实验测试发现muscle速度更快。如果比对的是编码基因的核酸序列，可见两个选项：<strong>Align DNA</strong> and **Align Codons，**就必须选择后者，即以氨基酸编码的顺序进行比对。 比对完毕的序列，缺口处会以“-”显示，可另存为*.meg格式的文件，或导出为新的fasta文件。随后在file选项下点击phylogenetic analysis，进入进化分析界面。在phylogeny选项下，有各种树选择：NJ、ML、MP等。 文中例子：构建MP树时候，有一个选项是是否选择删除所有的含有gap的column，文章作者认为不必要全部删除，有的可以留下。原文表述：<strong>Gaps/Missing Data Treatment</strong> determines how gaps are handled.<strong>Complete deletion</strong> means that MEGA5 ignores all columns in which there is a gap in any sequence. Unless there are very few gaps, that option can lose a lot of information because it removes a lot of sites from consideration. I prefer the <strong>Partial Deletion</strong> option in which sites with missing data are removed only as the need arises because that option retains more information.</p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>展示DNA序列多种比对（Color Align Conservation）</title>
    <url>/2016/07/29/%E5%B1%95%E7%A4%BAdna%E5%BA%8F%E5%88%97%E5%A4%9A%E7%A7%8D%E6%AF%94%E5%AF%B9%EF%BC%88color-align-conservation%EF%BC%89/</url>
    <content><![CDATA[<p><img src="https://genehub.files.wordpress.com/2016/07/qq20160729-0.png" alt="QQ20160729-0" /> 方法一、clustalx比对之后输出*.aln格式的比对序列，导入DNAman进行画图。 方法二、clustalx比对之后输出*.fasta格式的比对序列，导入在线网站进行画图：<a href="http://www.bioinformatics.org/sms2/color%5C_align%5C_cons.html">http://www.bioinformatics.org/sms2/color\_align\_cons.html</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>戴尔PowerEdge服务器命名规则和型号分类</title>
    <url>/2014/12/18/%E6%88%B4%E5%B0%94poweredge%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%91%BD%E5%90%8D%E8%A7%84%E5%88%99%E5%92%8C%E5%9E%8B%E5%8F%B7%E5%88%86%E7%B1%BB/</url>
    <content><![CDATA[<p>从第十代服务器开始，戴尔重新规范了服务器的名字，以现在的第十二代主流PowerEdge R620服务器为例： <strong>第一位是字母，R代表机架式服务器，其它有：</strong></p>
<ol>
<li>R：Rack，机架式服务器</li>
<li>T：Tower，塔式服务器</li>
<li>M：Modular，模块化的意思，实际上就是刀片服务器</li>
<li>C：比较特别的一个系列，为数据中心解决方案部门提出的高密度服务器，也称之为微服务器，命名方式也与其它系列不同。</li>
</ol>
<p><strong>第二位是数字：代表此服务器在整个产品线中的位置。6说明是主流机型，其它包括：</strong></p>
<ol>
<li>1和2系列是基础入门级的单路CPU服务器，是小型企业首台服务器的理想之选；</li>
<li>3、4、5系列为中高端的单路CPU和入门级的双路CPU服务器，可选的高级系统管理功能，能满足一般业务的需求，适合远程站点和较大公司部门使用，也可作为中小型企业的核心业务应用程序服务器；</li>
<li>6、7、8系列是主流的双路CPU和入门级的四路CPU服务器，拥有强大的性能，能够满足大部分企业级应用需求，适合需要卓越的虚拟化、系统管理能源效率的服务器机房、企业数据中心和远程站点使用；</li>
<li>9系列是最高端的四路CPU服务器。拥有强大的计算能力，支持超大内存。适合需要最高性能、可靠性和I/O可扩展性的关键任务应用程序。至于8路 CPU的服务器，戴尔曾经在第4代PowerEdge服务器中推出过对应产品。后续由于处理器超线程以及多核技术在服务器产品上的普及，戴尔逐步将其8路 服务器产品线过渡到4路多核服务器上，因此不再开发新的8路服务器产品。</li>
</ol>
<p><strong>第三位是数字：代表此服务器是第几代的服务器。</strong> 目前戴尔最新的服务器是第十二代，因此这个数字是2 <strong>最后一位数字，0代表是Intel的CPU，5代表是AMD的CPU</strong> 除此以外，对于某些特别的服务器，在最后还会标注几个字母来区分。例如R720xd代表此服务器能配置超高密度的磁盘（2U中配置高达26块2.5寸盘），M1000e则代表这是刀片服务器的机箱，等等。 怎么样，下次看到戴尔服务器的名字就知道服务器大概的性能和类型了吧？ 原文地址:  <a href="http://zh.community.dell.com/techcenter/w/techcenter%5C_wiki/180.poweredge.aspx">http://zh.community.dell.com/techcenter/w/techcenter\_wiki/180.poweredge.aspx</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>拟南芥</title>
    <url>/2016/08/26/%E6%8B%9F%E5%8D%97%E8%8A%A5/</url>
    <content><![CDATA[<p>神奇的模式植物–拟南芥</p>
<p>拟南芥与油菜、萝卜、卷心菜等同为十字花科植物，向下细分为鼠耳芥属。拟南芥又名鼠耳芥、阿拉伯芥、阿拉伯草，拉丁文名为Arabidopsis thaliala (L.) Heynh。拟南芥作为一种草本植物广泛分布于欧亚大陆和非洲西北部。在我国的<a href="http://www.hudong.com/wiki/%E5%86%85%E8%92%99" title="内蒙">内蒙</a>、新疆、<a href="http://www.hudong.com/wiki/%E9%99%95%E8%A5%BF" title="陕西">陕西</a>、甘肃、西藏、山东、江苏、<a href="http://www.hudong.com/wiki/%E5%AE%89%E5%BE%BD" title="安徽">安徽</a>、<a href="http://www.hudong.com/wiki/%E6%B9%96%E5%8C%97" title="湖北">湖北</a>、四川、云南等省区均有生长。我国古人常将身边的一些卑微、低贱之物“视若草芥”，拟南芥早先也就是一种无声无息、名不见经传的小草。拟南芥既不好吃、也不好看，对人类毫无经济价值。但近一百年来，随着生物学和经典遗传学的蓬勃发展，科学家们逐渐注意到它的研究价值。长期以来，科学家一直希望在植物中找到像动物中的黑腹果蝇（Drosophila melanogaster）那样繁殖快、易于在实验室培养、适于遗传操作的实验材料，进而从根本上改变植物遗传学研究的长期落后状况。   拟南芥植株较小（一个8cm见方的培养钵可种植4-10株）、生长周期短（从发芽到开花约4-6周）、结实多（每株植物可产生数千粒种子）。拟南芥的形态特征分明（图1），莲座叶着生在植株基部，呈倒卵形或匙形；茎生叶无柄，呈批针形或线形。侧枝着生在叶腋基部，主茎及侧枝顶部生有总状花序，四片白色匙形花瓣，四强雄蕊。长角果线形，长约1-1.5cm，每个果荚可着生50-60粒种子。</p>
<p><img src="http://www.genetics.ac.cn/kxcb/kpwz/201207/W020120709377873711250.jpg" alt="" /></p>
<p>图1 拟南芥的形态</p>
<p>这些特点使得拟南芥的突变表型易于观察，为突变体筛选提供了便利。拟南芥是典型的自交繁殖植物，易于保持遗传稳定性。同时，可以方便的进行人工杂交，利于遗传研究。   拟南芥的另一个优点是易于转化。经过不断的实践，浸花法（floral tip）已成为拟南芥转化最常用的方法。对生长5-6周已抽苔的拟南芥打顶来促进侧枝生长（图2A），待花序大量产生时将其在含有转化辅助剂silwet和蔗糖的农杆菌溶液中浸泡几分钟（图2B），3-4周后对转化植株收种子（图2C）。在含有合适抗生素的平板上对种子进行筛选，能够健康生长的幼苗为转基因植株（图2D）。这种转化方法不需要组织培养和再生植株的过程，操作简便、转化效率较高，为研究人员建立突变体库、改变目的基因的表达特征以及开展互补验证等实验提供了便利。   <img src="http://www.genetics.ac.cn/kxcb/kpwz/201207/W020120709377873727422.jpg" alt="" /></p>
<p>图2 拟南芥转化过程（浸花法）</p>
<p>拟南芥基因组小，由五对染色体组成。其基因组序列已于2000年由国际拟南芥基因组合作联盟联合完成，这是第一个实现全序列分析的植物基因组。拟南芥基因组约为12,500万碱基对，包含约2.6万个基因，编码约2.5万种蛋白质。通过物理（如辐射处理）、化学（如EMS诱变）及生物（如利用植物内源转座子或者根瘤农杆菌将DNA片段转入拟南芥基因组）的手段，已获得大量的发生在不同基因位点的突变体。研究人员建立了若干种质资源中心，方便了突变体的获取和交流。如今拟南芥已成为全球应用最广泛的模式植物，被誉为“植物中的果蝇”。   <img src="http://www.genetics.ac.cn/kxcb/kpwz/201207/W020120709377873733693.jpg" alt="" /></p>
<p>图3 微笑的拟南芥</p>
<p>经过科学家们长期的研究，对拟南芥发育过程的认识取得了长足的进步，其应用价值也逐渐得到认可，下面举两个例子。   增加粮食产量和提高粮食作物对于干旱等灾害天气的耐逆性是植物研究的重要问题。我国水资源短缺，而且水资源时空分布极不均衡，整个北方地区尤其是西北地区干旱缺水十分严重。近年来极端气候事件增加，对粮食生产造成很大威胁。因此，提高作物的抗旱能力对于保障我国农业经济的可持续发展和粮食安全具有重要意义。科学家从拟南芥的功能基因研究出发，在水稻中过量表达拟南芥HARDY（HRD）基因，最终实现了提高水稻的水分利用效率，增强抗旱能力[1]。拟南芥中功能获得性突变体hrd-D叶片深绿、根系发达、多个非生物胁迫相关基因的表达水平提高，抵抗干旱和高盐环境的能力显著增强，突变体中HRD基因表达量升高。HRD在水稻中的超表达可以增加水稻叶片的生物量和维管束鞘细胞的数目，提高光合效率，降低蒸腾，从而增强水分利用效率和抗旱能力。   生长素是一类低分子量的植物激素，它通过调节细胞分裂、伸长和分化对植物生长发育的各个方面发挥重要的调节作用。在拟南芥中生长素通过依赖于泛素分子的蛋白降解途径发挥功能，调控下游基因表达。早在1993年人们鉴定到拟南芥分枝增加的突变体axr1, 发现AXR1蛋白参与依赖于泛素分子的蛋白降解途径[2]。AXR1能够激活泛素样蛋白RUB1，并促进RUB1与SCFTIR1复合体中CUL1蛋白的结合。AXR1蛋白的突变使RUB1与CUL1的结合降低，SCF复合体功能降低，进而带来对生长素响应的降低[3]。随后在动物中鉴定了RUB1的同源物Nedd8，研究表明Nedd8同样是SCF复合体发挥功能所必需的[4]，而SCF功能紊乱与多种人类疾病如癌症、阿尔兹海默症等密切相关[5]。由此可见，拟南芥中生长素信号途径的研究对于认识人类某些疾病的发病机理提供了重要帮助。   模式植物的选择和利用对于开展遗传分析、基因克隆和功能研究意义重大，拟南芥由于其植株小、结实多、生命周期短、基因组简单、遗传操作简便，近四十年来由田野里不起眼的小草成为植物研究领域最耀眼的明星。全世界有超过六千家实验室正在对拟南芥的生长发育及其对环境应答的过程开展深入研究。它在粮食增产、农作物耐逆、环境保护等领域做出了重要贡献，让我们记住这棵小草，记住神奇的模式植物——拟南芥。</p>
<p>(李家洋研究组供稿)</p>
<p><strong>参考文献：</strong> 1.Karaba A., Dixit S., Greco R., et al. (2007) Improvement of water use efficiency in rice by expression of HARDY, an Arabidopsis drought and salt tolerance gene. Proc Natl Acad Sci USA 104: 15270-5. 2.Leyser H.M., Lincoln C.A., Timpte C., et al. (1993) Arabidopsis auxin-resistance gene AXR1 encodes a protein related to ubiquitin-activating enzyme E1. Nature 364: 161-4. 3.Parry G. and Estelle M. (2006) Auxin receptors: a new role for F-box proteins. Curr Opin Cell Biol 18: 152-6. 4.Petroski M.D. and Deshaies R.J. (2005) Function and regulation of cullin-RING ubiquitin ligases. Nat Rev Mol Cell Biol 6: 9-20. 5.Jones A.M., Chory J., Dangl J.L., et al. (2008) The impact of Arabidopsis on human health: diversifying our portfolio. Cell 2008. 133: 939-43.</p>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>拟南芥Arabidopsis的基因/蛋白/突变体之书写规范</title>
    <url>/2016/06/01/%E6%8B%9F%E5%8D%97%E8%8A%A5arabidopsis%E7%9A%84%E5%9F%BA%E5%9B%A0%E8%9B%8B%E7%99%BD%E7%AA%81%E5%8F%98%E4%BD%93%E4%B9%8B%E4%B9%A6%E5%86%99%E8%A7%84%E8%8C%83/</url>
    <content><![CDATA[<p>（2）拟南芥（<em>Arabidopsis thaliana</em>） 基因：野生型基因名用大写的斜体字母表示，如：<em>EMBRYO</em>、<em>DEFECTIVE 1</em>。野生型基因符号由三个斜体的大写字母组成，如：<em>EMB1</em>。突变体基因名用小写斜体字母表示，如：<em>de-etiolated 1</em>。突变体基因符号用相应基因座名称的三个小写斜体字母命名，如：<em>det1</em>。 蛋白质：用相应的基因符号命名，大写，正体，如：EMB1、EMB2、DET1、DET2。 表型：用基因名或一个描述性的短语表示表型。有时也可以用基因符号来命名表型（正体，首字母大写），并用上标“＋”或“－”代表野生型或突变型，如：Abc＋、Abc－。   参考资料： <a href="https://www.google.com.hk/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=5&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi-vLC3gYfNAhUGX5QKHWKoCysQFgg5MAQ&amp;url=http%3A%2F%2Fwww.medicine.sdu.edu.cn%2F0tongzhixinwen%2F2013%2F9%2Fcaoh%2Fzhuanzhu%2F2.doc&amp;usg=AFQjCNFH8gNip2KCNwWmqqgY1DNmhVzQYQ&amp;sig2=4fUsnPVhVfLdB0h%5C_c3oxqA">https://www.google.com.hk/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=5&amp;cad=rja&amp;uact=8&amp;ved=0ahUKEwi-vLC3gYfNAhUGX5QKHWKoCysQFgg5MAQ&amp;url=http%3A%2F%2Fwww.medicine.sdu.edu.cn%2F0tongzhixinwen%2F2013%2F9%2Fcaoh%2Fzhuanzhu%2F2.doc&amp;usg=AFQjCNFH8gNip2KCNwWmqqgY1DNmhVzQYQ&amp;sig2=4fUsnPVhVfLdB0h\_c3oxqA</a></p>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>无root权限安装Python</title>
    <url>/2016/02/26/%E6%97%A0root%E6%9D%83%E9%99%90%E5%AE%89%E8%A3%85python/</url>
    <content><![CDATA[<p>RedHat系统自带python2.6，一些用户程序的要求python2.7以上，但是2.6版本的python不能随便删除，因为系统程序会用到。 可以在用户目录下安装python2.7 方法： 1.安装python</p>
<blockquote>
<p>Python ： <a href="http://www.python.org/getit/">http://www.python.org/getit/</a></p>
<p>cd $HOME/local/app/</p>
<p>tar -zxvf Python-2.7.11.tgz</p>
<p>mv  Python-2.7.11 python</p>
<p>cd python</p>
<p>./configure –-prefix=<strong>$HOME/local</strong>（你准备安装的路径，可自己更改）</p>
<p>make &amp;&amp; make install</p>
</blockquote>
<p>2. 将指定路径下的lib和bin分别加入环境变量中：</p>
<blockquote>
<p>echo “PYTHONPATH=$HOME/local/lib/python2.7/site-packages” &gt;&gt; .bashrc</p>
<p>echo “export PATH=<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mi>O</mi><mi>M</mi><mi>E</mi><mi mathvariant="normal">/</mi><mi>l</mi><mi>o</mi><mi>c</mi><mi>a</mi><mi>l</mi><mi mathvariant="normal">/</mi><mi>a</mi><mi>p</mi><mi>p</mi><mi mathvariant="normal">/</mi><mi>p</mi><mi>y</mi><mi>t</mi><mi>h</mi><mi>o</mi><mi>n</mi><mo>:</mo></mrow><annotation encoding="application/x-tex">HOME/local/app/python:</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal" style="margin-right:0.08125em;">H</span><span class="mord mathnormal" style="margin-right:0.02778em;">O</span><span class="mord mathnormal" style="margin-right:0.10903em;">M</span><span class="mord mathnormal" style="margin-right:0.05764em;">E</span><span class="mord">/</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">o</span><span class="mord mathnormal">c</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord">/</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mord mathnormal">p</span><span class="mord">/</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">:</span></span></span></span>PATH” &gt;&gt; .bashrc</p>
<p>source ~/.bashrc</p>
</blockquote>
<p>这样就实现了在没有root权限的情况下安装python的模块。 3. 如何在无root权限下安装python模块呢？ 按照上面的方法安装python之后，再安装setuptools，（即easy_install），从而可以使用easy_install来自动安装python包。</p>
<blockquote>
<p>tar -zxvf setuptools-0.6c11.tar.gz</p>
<p>cd setuptools-0.6c11</p>
<p>/your_python_dir/bin/python2.7 <a href="http://setup.py">setup.py</a> build</p>
<p>/your_python_dir/bin/python2.7 <a href="http://setup.py">setup.py</a> install</p>
</blockquote>
<p>4. 安装其他python模块/套件 先使用easy_install安装pip工具：</p>
<blockquote>
<p>easy_install pip</p>
</blockquote>
<p>在安裝python套件的时候用pip比較好，pip會兼顧各個依存的套件版本，少用easy-install。 查看目前已有的模块：</p>
<blockquote>
<p>pip list</p>
</blockquote>
<p>pip查看需要更新的package</p>
<blockquote>
<p>pip list --outdated</p>
</blockquote>
<h3 id="下面是更详细的pip介绍"><a class="markdownIt-Anchor" href="#下面是更详细的pip介绍"></a> 下面是更详细的pip介绍：</h3>
<h3 id="pip安装"><a class="markdownIt-Anchor" href="#pip安装"></a> pip安装</h3>
<span id="more"></span>
<p>1<br />
2<br />
3</p>
<p>tar -xzvf pip-1.5.4.tar.gz<br />
cd pip-1.5.4<br />
python <a href="http://setup.py">setup.py</a> install</p>
<h2 id="pip使用详解"><a class="markdownIt-Anchor" href="#pip使用详解"></a> pip使用详解</h2>
<h3 id="pip安装包"><a class="markdownIt-Anchor" href="#pip安装包"></a> pip安装包</h3>
<p>1<br />
2<br />
3</p>
<p>pip install SomePackage<br />
[…]<br />
Successfully installed SomePackage</p>
<h3 id="pip查看已安装的包"><a class="markdownIt-Anchor" href="#pip查看已安装的包"></a> pip查看已安装的包</h3>
<p>1<br />
2<br />
3<br />
4<br />
5<br />
6<br />
7</p>
<p>pip show --files SomePackage<br />
Name: SomePackage<br />
Version: 1.0<br />
Location: /my/env/lib/pythonx.x/site-packages<br />
Files:<br />
…/somepackage/__init__.py<br />
[…]</p>
<h3 id="pip检查哪些包需要更新"><a class="markdownIt-Anchor" href="#pip检查哪些包需要更新"></a> pip检查哪些包需要更新</h3>
<p>1<br />
2</p>
<p>pip list --outdated<br />
SomePackage (Current: 1.0 Latest: 2.0)</p>
<h3 id="pip升级包"><a class="markdownIt-Anchor" href="#pip升级包"></a> pip升级包</h3>
<p>1<br />
2<br />
3<br />
4<br />
5<br />
6<br />
7</p>
<p>pip install --upgrade SomePackage<br />
[…]<br />
Found existing installation: SomePackage 1.0<br />
Uninstalling SomePackage:<br />
Successfully uninstalled SomePackage<br />
Running <a href="http://setup.py">setup.py</a> install for SomePackage<br />
Successfully installed SomePackage</p>
<h3 id="pip卸载包"><a class="markdownIt-Anchor" href="#pip卸载包"></a> pip卸载包</h3>
<p>1<br />
2<br />
3<br />
4<br />
5</p>
<p>pip uninstall SomePackage<br />
Uninstalling SomePackage:<br />
/my/env/lib/pythonx.x/site-packages/somepackage<br />
Proceed (y/n)? y<br />
Successfully uninstalled SomePackage</p>
<h2 id="常见错误"><a class="markdownIt-Anchor" href="#常见错误"></a> 常见错误</h2>
<p>1</p>
<p>ImportError No module named setuptools</p>
<p>解决办法：安装setuptools ===================== 下为卸载： 原文: <a href="http://www.macfans.com.cn/home.php?mod=space&amp;uid=190624&amp;do=blog&amp;id=111">http://www.macfans.com.cn/home.php?mod=space&amp;uid=190624&amp;do=blog&amp;id=111</a>   python很好用，尤其是用过easy_install的朋友更是觉得它的便捷， 卸载命令也很简单 easy_install -m package-name 但是面对源码安装的怎么办呢？   <a href="http://setup.py">setup.py</a> 帮助你纪录安装细节方便你卸载 python <a href="http://setup.py">setup.py</a> install --record log 这时所有的安装细节都写到 log 里了 想要卸载的时候 cat log xargs rm －rf 就可以干净卸载了</p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>植物基因组ncRNA预测（tRNA、rRNA、snRNA、miRNA）</title>
    <url>/2019/08/08/%E6%A4%8D%E7%89%A9%E5%9F%BA%E5%9B%A0%E7%BB%84ncrna%E9%A2%84%E6%B5%8B%EF%BC%88trna%E3%80%81rrna%E3%80%81snrna%E3%80%81mirna%EF%BC%89/</url>
    <content><![CDATA[<p>引用文献 <img src="https://genehub.files.wordpress.com/2019/08/e883a1e69da8ncrnae989b4e5ae9ae696b9e6b395.png" alt="胡杨ncRNA鉴定方法" /></p>
<h2 id="一-trna"><a class="markdownIt-Anchor" href="#一-trna"></a> 一、tRNA</h2>
<p>先安装tRNAscan-SE，然后运行如下命令即可。</p>
<p>/xxx/biosoftwares/tRNAscan-SE-2.0/tRNAscan-SE -G -o gDNA.tRNA.out -f gDNA.tRNA.scdstr -m gDNA.tRNA.stat genome.sm.fa</p>
<p>结果示意如下</p>
<p>Sequence tRNA Bounds tRNA Anti Intron Bounds Cove<br />
Name tRNA # Begin End Type Codon Begin End Score</p>
<hr />
<p>ChrM 1 12693 12766 Met CAT 0 0 63.37<br />
ChrM 2 75688 75758 Cys GCA 0 0 48.76<br />
ChrM 3 77742 77815 His GTG 0 0 56.52<br />
ChrM 4 90837 90909 Cys GCA 0 0 59.37<br />
ChrM 5 102551 102624 Asp GTC 0 0 68.25<br />
ChrM 6 184436 184507 Gly GCC 0 0 70.59<br />
ChrM 7 197972 198043 Glu TTC 0 0 65.49<br />
ChrM 8 198963 199035 Met CAT 0 0 70.15<br />
ChrM 9 237157 237228 Asn GTT 0 0 71.98<br />
ChrM 10 238160 238242 Tyr GTA 0 0 62.80<br />
ChrM 11 261058 261136 Lys TTT 261096 261101 34.22<br />
ChrM 12 288825 288906 Met CAT 0 0 73.07<br />
ChrM 13 312625 312696 Gln TTG 0 0 64.58<br />
ChrM 14 335330 335403 Met CAT 0 0 73.76<br />
ChrM 15 317035 316963 Phe AAA 0 0 30.83<br />
ChrM 16 285436 285349 Ser GCT 0 0 55.78<br />
ChrM 17 284968 284895 Phe GAA 0 0 67.07<br />
ChrM 18 284630 284556 Pro TGG 0 0 64.26<br />
ChrM 19 260713 260640 Trp CCA 0 0 76.23<br />
ChrM 20 3494 3422 Lys TTT 0 0 81.82</p>
<h2 id="二-rrna"><a class="markdownIt-Anchor" href="#二-rrna"></a> 二、rRNA</h2>
<p>不同植物中的rRNA序列高度保守，基于blast比对即可预测新物种的rRNA。植物基因组rRNA包含18S、28S、5S和5.8S四种。我下载了大豆或拟南芥的rRNA序列作为比对文件。</p>
<p>&gt;5S rRNA 556bp X15199.1 Soybean 5S rDNA gene for 5S rRNA</p>
<blockquote>
<p>5.8S rRNA Arabidopsis thaliana 15172 AT2G01020.1 Chr2+ 5782-5945<br />
18S rRNA 1807bp X02623.1 Soybean (Glycine max) 18S ribosomal RNA<br />
28S rRNA XR_003264281.1 PREDICTED: Glycine max 28S ribosomal RNA (LOC112999102), rRNA</p>
</blockquote>
<p>比对方法如下，结果还需要根据实际情况进行过滤，将部分匹配的基因组片段过滤掉即可。</p>
<p>blastn -db /xxx_references/index/genome.sm.fa -query Glycine_max_rRNA.fa -evalue 1e-5 -outfmt 7 -num_threads 4 -out Glycine_max_rRNA.fa__genome.7<br />
blastn -db /xxx_references/index/genome.sm.fa -query Glycine_max_rRNA.fa -evalue 1e-5 -outfmt 0 -num_threads 4 -out Glycine_max_rRNA.fa__genome.0</p>
<p>三、snRNA snRNA是真核细胞核内的一组小分子RNA，分子较小，约含50—200nt，其主要作用是与有关蛋白结合形成小核糖核蛋白体(snRNP)，对RNA的前体进行加工。snRNA在核内转录，但snRNP在胞浆组装，发挥功能则又在核内，所以需要跨核膜转运。 snRNA的特点 ① 高度保守，如人和爪蟾的U1snRNA有90%的序列相同。② 其长度在哺乳动物中约为100-215个核苷酸，共分为7类，由于含U丰富，故编号为U1~U7。③ 分析方法是用rfam数据库（cm格式）作参考，通过cmscan比对程序进行比对预测。 先安装infernal程序（内置cmscan）。</p>
<p>wget <a href="http://eddylab.org/infernal/infernal-1.1.2.tar.gz">http://eddylab.org/infernal/infernal-1.1.2.tar.gz</a><br />
`tar -zxvf infernal-1.1.2.tar.gz <br />
cd infernal-1.1.2<br />
./configure  --prefix=/home/user/local<br />
make<br />
make install<br />
cd easel; make install</p>
<h1 id="测试"><a class="markdownIt-Anchor" href="#测试"></a> 测试`</h1>
<p>$ cmscan --version<br />
Failed to parse command line: No such option “–version”.<br />
Usage: cmscan [-options] <cmdb> <seqfile><br />
where basic options are:<br />
-h        : show brief help on version and usage<br />
-g        : configure CM for glocal alignment [default: local]<br />
-Z <x>    : set search space size in *Mb* to <x> for E-value calculations  (x&gt;0)<br />
–devhelp : show list of otherwise hidden developer/expert options<br />
To see more help on available options, do cmscan -h</p>
<p>再下载rfam数据库，并将Rfam.cm做成索引文件。</p>
<p>wget <a href="ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.1/Rfam.clanin">ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.1/Rfam.clanin</a><br />
wget <a href="ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.1/Rfam.cm.gz">ftp://ftp.ebi.ac.uk/pub/databases/Rfam/14.1/Rfam.cm.gz</a><br />
gunzip Rfam.cm.gz<br />
cmpress <a href="http://Rfam.cm">Rfam.cm</a></p>
<h1 id="出现如下文件"><a class="markdownIt-Anchor" href="#出现如下文件"></a> 出现如下文件</h1>
<p>ls Rfam.*<br />
Rfam.clanin <a href="http://Rfam.cm">Rfam.cm</a> Rfam.cm.i1f Rfam.cm.i1i Rfam.cm.i1m Rfam.cm.i1p</p>
<p>计算基因组大小，后面cmscan要用到-G参数</p>
<p>esl-seqstat my-genome.fa</p>
<p>比如基因组1000M，那么-G参数为 1000M*2/1M=2000，这个数据根据实际情况调整。 运行比对程序进行ncRNA预测</p>
<p># Rfam12.2.claninfo 为下载的claninfo文件，需提供所在路径</p>
<h1 id="rfamcm"><a class="markdownIt-Anchor" href="#rfamcm"></a> <a href="http://Rfam.cm">Rfam.cm</a> 下载的cm文件</h1>
<h1 id="my-genomefa-待查询序列"><a class="markdownIt-Anchor" href="#my-genomefa-待查询序列"></a> my-genome.fa 待查询序列</h1>
<h1 id="my-genomecmscan-输出结果"><a class="markdownIt-Anchor" href="#my-genomecmscan-输出结果"></a> my-genome.cmscan 输出结果</h1>
<h1 id="my-genometblout-有一个输出结果"><a class="markdownIt-Anchor" href="#my-genometblout-有一个输出结果"></a> my-genome.tblout 有一个输出结果</h1>
<h1 id="对500m大小的输入序列48线程需要7个小时最好放入后台"><a class="markdownIt-Anchor" href="#对500m大小的输入序列48线程需要7个小时最好放入后台"></a> 对500M大小的输入序列，48线程，需要7个小时，最好放入后台</h1>
<h1 id="esl-seqstat-my-genomefa-awk-if0~total-print-int421000000-1751"><a class="markdownIt-Anchor" href="#esl-seqstat-my-genomefa-awk-if0~total-print-int421000000-1751"></a> esl-seqstat my-genome.fa  awk ‘{if($0~/^Total/) print int($4*2/1000000);}’ -----&gt; 1751</h1>
<p>cmscan -Z 1751 --cut_ga --rfam --nohmmonly --tblout my-genome.tblout --fmt 2 --clanin Rfam.clanin <a href="http://Rfam.cm">Rfam.cm</a> my-genome.fa &gt; my-genome.cmscan</p>
<p>cmscan结果文件示意如下，包含预测的ncRNA列表和RNA比对结构示意，其实不仅包含了snRNA，还有miRNA、rRNA和tRNA。 另有一个my-genome.tblout文件，就是tab分割的表格，更加简洁。</p>
<p>Query: scaffold4 [L=2607366]<br />
Hit scores:<br />
rank E-value score bias modelname start end mdl trunc gc description</p>
<hr />
<p>(1) ! 6.3e-19 81.7 0.0 MIR408 2312792 2312644 - cm no 0.48 microRNA MIR408<br />
(2) ! 1.9e-17 88.4 0.0 snoZ107_R87 2081687 2081578 - cm no 0.46 Small nucleolar RNA Z107/R87<br />
(3) ! 2.4e-16 73.0 0.0 MIR164 1105583 1105483 - cm no 0.54 microRNA MIR164<br />
(4) ! 1.2e-13 71.7 0.0 snoR30 2081522 2081420 - cm no 0.44 Small nucleolar RNA R30/Z108<br />
(5) ! 1.3e-11 65.1 0.0 tRNA 2140920 2140992 + cm no 0.59 tRNA<br />
(6) ! 1.3e-11 65.1 0.0 tRNA 2245335 2245407 + cm no 0.59 tRNA<br />
(7) ! 1.6e-11 64.8 0.0 tRNA 223678 223759 + cm no 0.56 tRNA<br />
(8) ! 1.7e-11 64.7 0.0 tRNA 374728 374800 + cm no 0.56 tRNA<br />
(9) ! 4e-11 63.3 0.0 tRNA 482023 481943 - cm no 0.53 tRNA<br />
(10) ! 7.3e-11 71.3 0.0 snoR41 705999 705902 - cm no 0.40 Small nucleolar RNA R41<br />
(11) ! 3.2e-10 60.1 0.0 tRNA 624224 624152 - cm no 0.58 tRNA<br />
(12) ! 4.3e-10 59.6 0.0 tRNA 793379 793309 - cm no 0.59 tRNA<br />
(13) ! 1.7e-08 53.9 0.0 tRNA 767498 767569 + cm no 0.57 tRNA<br />
(14) ! 0.00018 43.5 0.1 SNORD34 2081329 2081243 - cm no 0.33 Small nucleolar RNA SNORD34</p>
<p>Hit alignments:</p>
<blockquote>
<blockquote>
<p>MIR408 microRNA MIR408<br />
rank E-value score bias mdl mdl from mdl to seq from seq to acc trunc gc</p>
</blockquote>
</blockquote>
<hr />
<p>(1) ! 6.3e-19 81.7 0.0 cm 1 136 [] 2312792 2312644 - … 0.95 no 0.48</p>
<p>v NC<br />
::::::::::::::::&lt;&lt;&lt;-&lt;&lt;&lt;&lt;&lt;&lt;&lt;-&lt;&lt;&lt;&lt;&lt;&lt;-&lt;&lt;&lt;&lt;&lt;-&lt;—&lt;&lt;_____________…______________ CS<br />
MIR408 1 aauUGGugAugAgAugGAGACaGGGAagAgGCAGaGCAuGaGAUGGaGCUaucAAcaAau…ugUGAgAaaaagaU 74<br />
A+U G+GA +AGA + AG AGGGAA AGGCAGAGCAUG :AUG AGC AUCAACA A GUGAG +AA++<br />
scaffold4 2312792 AGUCAGAGACAAGACAAAGGUAGGGAACAGGCAGAGCAUG-GAUGGAGCCAUCAACAGAAuagagucaagaaaccgagAGUGAGGGAAGA-- 2312704<br />
****************************************.***************88779*************9988777777777766… PP</p>
<p>v NC<br />
______________&gt;&gt;----&gt;&gt;&gt;&gt;&gt;&gt;-&gt;&gt;&gt;&gt;&gt;&gt;-&gt;&gt;&gt;&gt;&gt;&gt;&gt;-&gt;&gt;&gt;::::::::::::::::: CS<br />
MIR408 75 GgaauUGUUgUuGCuCcCuCCCaUGCACUGCcUCuUCCCuGGCUCCuuucuCuccucuuUuu 136</p>
<ul>
<li>++UGUU +GCU C + :CAUGCACUGCCUCUUCCCU GCU U +U+U+C+ U+U +<br />
scaffold4 2312703 -AGUCUGUUACGGCUUC-AAUCAUGCACUGCCUCUUCCCUGGCUCUAUCUUUUUCCAUCUCC 2312644<br />
.8899**********99.999***********************8899999999******** PP</li>
</ul>
<blockquote>
<blockquote>
<p>snoZ107_R87 Small nucleolar RNA Z107/R87<br />
rank E-value score bias mdl mdl from mdl to seq from seq to acc trunc gc</p>
</blockquote>
</blockquote>
<hr />
<p>(2) ! 1.9e-17 88.4 0.0 cm 1 117 [] 2081687 2081578 - … 0.94 no 0.46</p>
<p>NC<br />
&lt;&lt;&lt;&lt;&lt;&lt;________________.___________________________________________________________________ CS<br />
snoZ107_R87 1 GAugGCaGUGAuGACUuGGUAA.uAUUCAAGCUCAACAGACCaaAuuacAGgucUUUCUCuauggcuuuuccuaugGGAUuGaUUUGUaU 89<br />
GAU::CAGUGAUGAC UAA +AUUCAAGCUCAACAGACC+ AUU CA G +UUUCUCU+U ++U G GAUU UUUG +U<br />
scaffold4 2081687 GAUCACAGUGAUGACCACAUAAaAAUUCAAGCUCAACAGACCGGAUUGCACGGUUUUCUCUCU-------UUUGGGAGAUUACUUUGCGU 2081605<br />
***************999987615677*******************************99665…9999**************** PP</p>
<p>NC<br />
______________________&gt;&gt;&gt;&gt;&gt;&gt; CS<br />
snoZ107_R87 90 GcCGAUaaUcCCGCUGAACuGAGCcaUC 117<br />
G+CGA A CCCGCUGAACUGAG::AUC<br />
scaffold4 2081604 GUCGAC-ACCCCGCUGAACUGAGUGAUC 2081578<br />
*****8.799****************** PP</p>
<p>如何对结果进行分类？首先下载Rfam家族的注释，点击<a href="http://rfam.xfam.org/search#tabview=tab5">http://rfam.xfam.org/search#tabview=tab5</a>，选择所有复选框，提交，把得到的表格拷贝下来，整理成TAB键分割的格式。并把第三列拆开，取出类型, 存储为 <code>Rfam_anno.txt</code>。</p>
<p>Accession ID Type Description<br />
RF00001 5S_rRNA Gene; rRNA 5S ribosomal RNA<br />
RF00002 5_8S_rRNA Gene; rRNA 5.8S ribosomal RNA<br />
RF00003 U1 Gene; snRNA; splicing U1 spliceosomal RNA<br />
RF00004 U2 Gene; snRNA; splicing U2 spliceosomal RNA<br />
RF00005 tRNA Gene; tRNA tRNA<br />
RF00006 Vault Gene Vault RNA<br />
RF00007 U12 Gene; snRNA; splicing U12 minor spliceosomal RNA<br />
RF00008 Hammerhead_3 Gene; ribozyme Hammerhead ribozyme (type III)<br />
RF00009 RNaseP_nuc Gene; ribozyme Nuclear RNase P<br />
RF00010 RNaseP_bact_a Gene; ribozyme Bacterial RNase P class A<br />
RF00011 RNaseP_bact_b Gene; ribozyme Bacterial RNase P class B<br />
RF00012 U3 Gene; snRNA; snoRNA; CD-box Small nucleolar RNA U3<br />
RF00013 6S Gene 6S / SsrS RNA<br />
RF00014 DsrA Gene; sRNA DsrA RNA<br />
RF00015 U4 Gene; snRNA; splicing U4 spliceosomal RNA<br />
RF00016 SNORD14 Gene; snRNA; snoRNA; CD-box Small nucleolar RNA SNORD14<br />
RF00017 Metazoa_SRP Gene Metazoan signal recognition particle RNA</p>
<p>grep其中snRNA如下</p>
<p>$ cat xfam_family_types.tab  grep snRNA  awk -F “\t” ‘{print $3}’  sort  uniq<br />
Cis-reg<br />
Gene; antisense<br />
Gene; snRNA<br />
Gene; snRNA; snoRNA; CD-box<br />
Gene; snRNA; snoRNA; HACA-box<br />
Gene; snRNA; snoRNA; scaRNA<br />
Gene; snRNA; splicing<br />
Gene; sRNA</p>
<p>将CD-box、HACA-box和splicing对应的部分统计出来就可以做成如下文献对应的图了。 <img src="https://genehub.files.wordpress.com/2019/08/e883a1e69da8ncrnae989b4e5ae9ae7bb93e69e9c.png" alt="胡杨ncRNA鉴定结果" /></p>
<h2 id="四-mirna"><a class="markdownIt-Anchor" href="#四-mirna"></a> 四、miRNA</h2>
<p>可以直接用上面的结果，也可以用miRNA测序的数据。   参考资料： [1] Chen Tong: <a href="http://blog.genesino.com/2017/06/Rfam/">http://blog.genesino.com/2017/06/Rfam/</a> [2] Chen Lianfu: <a href="http://www.chenlianfu.com/?p=2185">http://www.chenlianfu.com/?p=2185</a> [3] tiehan: <a href="http://blog.sina.com.cn/s/blog%5C_670445240102uxhu.html">http://blog.sina.com.cn/s/blog\_670445240102uxhu.html</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>植物种子萌发</title>
    <url>/2015/05/10/%E6%A4%8D%E7%89%A9%E7%A7%8D%E5%AD%90%E8%90%8C%E5%8F%91/</url>
    <content><![CDATA[<p>萌发实验 选取发育良好的 30 粒成熟种子或果实，进行消毒（用 0.05%高锰酸甲浸泡 15 分 钟）后再用无菌水冲洗干净，播种于花盆中，播深为 0.5cm 左右，在室温下测定种子 的萌发率，重复 3 次。 贺慧. <em>阿拉善主要荒漠植物种子 (果实) 形态结构和萌发特性的适应性研究</em>. Diss. 内蒙古农业大学, 2008.</p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>沙漠中那道美丽的风景线</title>
    <url>/2016/01/04/%E6%B2%99%E6%BC%A0%E4%B8%AD%E9%82%A3%E9%81%93%E7%BE%8E%E4%B8%BD%E7%9A%84%E9%A3%8E%E6%99%AF%E7%BA%BF/</url>
    <content><![CDATA[<p>沙漠中那道美丽的风景线</p>
<p>文章来源：新疆生态与地理研究所</p>
<p>发布时间：2010-10-28</p>
<p>【字号： 小  中  大 】</p>
<p>荒芜的沙漠，并不只有一望无际的沙。即使在冬季也会有道风景让你眼前一亮，那就是一株株沙漠中的常青树。不要以为只有裸子植物才会不畏寒冬，即使有些被子植物，在严寒下仍旧可以绽放它那娇艳欲滴却又写满沧桑的绿，比如沙冬青。 沙冬青，姓沙，名冬青，多么富有寓意，名字就告诉别人它们是沙漠中常绿的成员。现在，我们就来扒一扒沙冬青的故事。 沙冬青属植物出身豆科，兄弟两个。一个蒙古沙冬青（也称沙冬青或蒙古黄花木，蒙古语称萌合—哈日尕纳），在我国主要分布于内蒙古西部的库布齐沙漠、乌兰布和沙漠以及狼山和贺兰山山前的荒漠平原、内蒙古南部的戈壁荒漠。此外，甘肃中条山附近亦有分布。国外仅分布到蒙古国的南部以及与内蒙古相邻地区。垂直分布范围在1000-2200米之间，生长在石质、沙砾质、沙质（覆沙）荒漠地带，常常在低山带或山前、山间谷地形成带状或团状群落。另一个是新疆沙冬青（又称小沙冬青、矮沙冬青或矮黄花木，柯尔克孜语称忒斯肯），分布区位于亚洲中部地区的喀什噶尔和伊朗之间。新疆沙冬青在中国分布面积十分狭小，仅见于新疆西南部天山南麓乌恰县的西南部山地（乌恰－康苏间和巴音布鲁提山）。邻国吉尔吉斯斯坦有少量分布，垂直分布在海拔1800-2800米的干旱山谷地带的山坡、残丘或干河床上生卵石河床上或剥蚀严重的石质坡地。 从形态上来看，蒙古沙冬青和新疆沙冬青的主要区别为：蒙古沙冬青叶常为复叶，具3小叶；新疆沙冬青的叶常为单叶，极少有3小叶。植株相对较矮。 沙冬青是亚洲中部的旱生植物区系中的特有成份，是在亚热带常绿阔叶林南退后，历尽沧桑，残留在中亚适应旱化环境的第三纪残遗种群，被称为荒漠中的活化石。在研究豆科植物的系统发育、古植物区系、古气候变化和古地理环境变迁、特别是研究亚洲中部荒漠植被的起源和形成等方面有重要的价值，已被列为国家级珍稀濒危和重点保护植物物种。 为什么沙冬青对土壤水分亏缺、高温寒冷和风蚀沙埋等极端环境有特殊的忍耐力呢？这得从沙冬青的生理结构说起。 沙冬青具有的典型的超旱生结构，叶片上表皮毛密集，角质层很厚。叶片细胞在冬季大量出现抗冻蛋白，以应对低温对植株造成的冻害，使得沙冬青具有很强的抗旱抗寒性。 沙冬青在固定、半固定沙丘、基岩裸露的山顶和石缝中以及干旱的黄土丘陵顶部都能正常生长。此外，它耐沙埋，枝条被沙埋后生长更好，分枝萌生力强，抗风蚀，其根部外露，地上部分仍然正常生长。沙冬青属的冠幅较大，尤其是生长在半固定沙丘的沙冬青，地上部分分枝多，阻沙能力强，其周围可形成一个极大的沙堆。两种沙冬青群落具有较强的相似性，共有的科属较多，均表现出草原化荒漠的特征。二者地理成分组成都以温带分布和泛地中海分布为主。二者生活型谱基本相同，灌木、半灌木及多年生草本占有较大比重，都以旱生和超旱生的物种为主。二者结构均较简单，群落均一性差，物种丰富度、盖度都较低，反映出二者对于干旱荒漠环境的适应。 两种沙冬青群落也有许多不同之处：从区系上看，蒙古沙冬青群落要比新疆沙冬青群落更复杂，组成的物种数也较多。二者共有的科属虽然较多，但共有的种数较少。前者群落均一性差于后者，前者灌木、半灌木及多年生草本生活型的比重低于后者。与前者相比，新疆沙冬青群落旱化程度较高，二者的常见种存在差异，群落类型上前者多于后者，前者结构比后者复杂，但不是普遍现象，前者的物种丰富度和盖度总体上高于后者，这些差异反映了二者在分布及生境上的差异。新疆沙冬青荒漠所处海拔要高于蒙古沙冬青荒漠，且蒙古沙冬青荒漠处于荒漠带与草原带交汇地，也是各种区系相互交汇的地区，且由于其位于荒漠带的东部水分条件较好，造成了二者之间的差异。 两种沙冬青都被列入《中国植物红皮书》，为重点保护对象，但是，新疆沙冬青自然分布的数量比蒙古沙冬青要少得多，而且新疆沙冬青种群自然繁衍较为困难，仅仅靠种子更新。荚果在种子成熟前蛀虫率达90％以上，极少数完好种子成熟后又遭鸟食，落入土中的完好种子只有3％左右。自然分布区环境恶劣，年降水量少于250毫米。夏季酷热，冬季寒冷，多风沙，土层薄，大部分种子不能发育成幼苗，只有极个别在一定的环境中才能长成植株。天然繁殖具有小片状零散分布和沿季节水径流方向条状分布的特点。因此，更应重视对新疆沙冬青的保护。与蒙古沙冬青相比，新疆沙冬青群落更容易被破坏，且由于他的分布海拔较高，土壤贫瘠，降水量少，一旦破坏很难自然恢复。 令人欣慰的是，两种沙冬青都已异地保育成功，不仅吐鲁番沙漠植物园大量种植，甘肃民勤沙生植物园、宁夏沙坡头沙漠研究站等地也引种成功。 <img src="http://www.cas.cn/kxcb/kpwz/201010/W020101028421554162420.jpg" alt="" /> 沙冬青植物属的枝叶含多种生物碱，牲畜不啃食，但可供药用。具有祛风湿、舒筋活血、止痛的作用，可治冻伤，还可作杀虫剂。沙冬青属植物是西北荒漠区有开发潜力的油脂植物资源，种子含油量为13.4%，其亚油酸含量达87.5%。 <img src="http://www.cas.cn/kxcb/kpwz/201010/W020101028421554160469.jpg" alt="" /> 蒙古沙冬青 <img src="http://www.cas.cn/kxcb/kpwz/201010/W020101028421554168804.jpg" alt="" /> 新疆沙冬青</p>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>硬实种子的处理与催芽</title>
    <url>/2015/12/07/%E7%A1%AC%E5%AE%9E%E7%A7%8D%E5%AD%90%E7%9A%84%E5%A4%84%E7%90%86%E4%B8%8E%E5%82%AC%E8%8A%BD/</url>
    <content><![CDATA[<p>1.1热水浸种 分别用始温70度、80度、90度、1OO度浸泡硬实种子。24h观测浸种效果，发现1O0度水浸泡对硬实有较好的软化作用，但对正常种子的伤害较大;90度水既能软化种皮又对种子伤害较小，相对效果较好，但仍有一小部分硬实不能吸胀;70度水对硬实种皮软化效果差，但能使非硬实种子免受伤害。由于刺槐种子硬实和非硬实混杂，建议生产上采用逐次增温的方法处理其种子，这样效果最好。即先用始温7O度热水浸种24h,将吸胀种子筛选出催芽，未吸胀种子用始温90度水浸种24h，选出吸胀种子催芽，最后对未吸胀种子用1OO度水温处理，亦能获得较好的发芽结果。 在浸种时，种子与水的容积比以1:3为宜。将热水倒入盛种子的容器中，不断搅拌使其自然冷却。浸种过程中，要每隔12h换1次冷水。 1.2酸蚀种子 用98%浓硫酸分别处理硬实种子3Omin、2Omin、1Omin，浸种后摆盘进行发芽试验。结果表明，处理2Omin的效果最好，发芽率可达70%以上，活力指数也比较高。处理30分钟的发芽率次之，处理10min的发芽率最低。故用浓硫酸处理硬实种子时间以20min为佳。 2种子催芽 目前常用&quot;生豆芽&quot;法和层积催芽法，以层积催芽法效果好。把经过浸种的种子捞出，混以3倍湿沙(沙子的湿度为其饱和含水量的60%)。为了保持种子的湿度，上面要加覆盖物，再将种沙混合物放在温暖处催芽，并插入温度计，以观测催芽温度。刺槐种子一般在25度左右发芽快而整齐。如果超过35度，发芽受到抑制，因此，催芽的温度以不超过25度为宜。 转自：<a href="http://www.ly.lf.gov.cn/ArticleShow.asp?ArticleID=2191">http://www.ly.lf.gov.cn/ArticleShow.asp?ArticleID=2191</a></p>
]]></content>
      <categories>
        <category>未分类</category>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>英文Email写作：如何开头</title>
    <url>/2016/03/17/%E8%8B%B1%E6%96%87email%E5%86%99%E4%BD%9C%EF%BC%9A%E5%A6%82%E4%BD%95%E5%BC%80%E5%A4%B4/</url>
    <content><![CDATA[<p><strong>Here are some example opening sentences for emails:</strong> <em>I hope you enjoyed your holiday and are finding it easy to settle back in to work.</em> <em>It was good to meet you in [place]. I hope you had a safe journey home.</em> <em>Thank you very much for your email. I am glad to hear that you and your family are well.</em> <em>Thank you for your prompt reply.</em> <em>I apologise for not replying sooner, but I have been very busy these last few weeks.</em> <em>Thank you for your email of [date]. Please find my reply to your query below.</em> <em>I am writing with regard to XXXX.</em> <em>Thank you for getting in touch with us about XXXX.</em> (Less formal, more friendly) <em>Thank you for contacting us regarding XXXX.</em> (More formal) <em>With reference to your email of [date], I would like to bring the following to your attention.</em> <em>As a follow-up to our phone call this morning, I would like summarise the key issues.</em> <em>Re the question you raised in your previous email, please find my explanation below.</em> <em>Following our meeting on [date] / in [place], please find below a summary of the points we discussed.</em> <em>In reply to your query regarding XXXX, I would like to make the following points.</em> <strong>Phrases best avoided:</strong> <em>I hope this email finds you well.</em> <em>Please be informed that…</em> <em>Please be advised as follows.</em> <em>This email concerns…</em> 参考资料：<a href="http://blog.harwardcommunications.com/2012/11/06/how-to-start-emails/">http://blog.harwardcommunications.com/2012/11/06/how-to-start-emails/</a></p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>质粒DNA测序结果分析</title>
    <url>/2020/01/20/%E8%B4%A8%E7%B2%92dna%E6%B5%8B%E5%BA%8F%E7%BB%93%E6%9E%9C%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<p>目的基因的克隆，简要过程如下，构建的阳性克隆需要经过 Sanger 测序验证。对于 Sanger 测序，一般一个反应（一个引物往后延伸）测的比较准确的长度大概是 800 bp，如果大于这个长度，就需要设计多条引物，用多个反应分区段测定。 <img src="https://genehub.files.wordpress.com/2020/01/cloning_dna-_science_learning_hub.jpg" alt="cloning_dna-_Science_Learning_Hub" />   测序结果解压后一般有两个类型的文件：ab1后缀的谱图文件和seq后缀的序列文件。 ab1格式的谱图可以用BioEdit软件打开，界面如下。一般在 20 bp ~ 900 bp 的测序区间是比较准确的。 <img src="https://genehub.files.wordpress.com/2020/01/ab1.png" alt="ab1" /> 以.seq为后缀的序列文件可以直接用 EditPlus、SnapGene 之类的序列编辑软件打开，也可以用电脑自带的记事本和写字板打开，拷贝出来用于序列分析。 可用 DNAstar 软件中的 MegAlign 软件将测序文件和模板序列进行比对，如果没有问题就可以放心就行后面的操作了。依次点击 MegAlign -&gt; File -&gt; Enter Sequences -&gt; 选择seq后缀的文件 -&gt; 打开，即可将测序文件导入软件，再以同样的方式导入fasta格式的参考序列，并选择 Align -&gt; By Clustal W Method，即可看到序列比对结果。注意反向引物的测序序列需要自己先反转（网页工具：<a href="http://www.bioinformatics.org/sms/rev%5C_comp.html%EF%BC%89%EF%BC%8C%E5%8F%8D%E8%BD%AC%E5%90%8E%E7%9A%84%E5%BA%8F%E5%88%97%E5%8F%A6%E5%AD%98%E4%B8%80%E4%B8%AA%E6%96%B0%E6%96%87%E4%BB%B6%E6%89%8D%E5%8F%AF%E4%BB%A5%E5%AF%BC%E5%85%A5%EF%BC%8C%E5%90%A6%E5%88%99%E5%8F%8D%E5%90%91%E5%BC%95%E7%89%A9%E6%B5%8B%E5%BA%8F%E7%9A%84%E7%BB%93%E6%9E%9C%E4%B8%8E%E5%8F%82%E8%80%83%E5%BA%8F%E5%88%97%E6%96%B9%E5%90%91%E4%B8%8D%E4%B8%80%E8%87%B4%EF%BC%8C%E8%BD%AF%E4%BB%B6%E4%B8%8D%E8%83%BD%E6%AF%94%E5%AF%B9%E3%80%82%E9%99%A4%E4%BA%86">http://www.bioinformatics.org/sms/rev\_comp.html），反转后的序列另存一个新文件才可以导入，否则反向引物测序的结果与参考序列方向不一致，软件不能比对。除了</a> MegAlign，还有其他序列比对软件可以做，例如windows系统的ClustalX；或者网页版的 ClustalW（<a href="https://www.genome.jp/tools-bin/clustalw%EF%BC%89%E4%B9%9F%E5%8F%AF%E4%BB%A5%E5%81%9A%E5%8F%8C%E5%BA%8F%E5%88%97%E6%AF%94%E5%AF%B9%E3%80%82">https://www.genome.jp/tools-bin/clustalw）也可以做双序列比对。</a> <img src="https://genehub.files.wordpress.com/2020/01/e5beaee4bfa1e688aae59bbe_20200120113453.png" alt="微信截图_20200120113453" />   如果要对比对结果进行图形化展示，可以用 Color Align Conservation （<a href="http://www.bioinformatics.org/sms2/color%5C_align%5C_cons.html%EF%BC%89%E5%87%BA%E5%9B%BE%E3%80%82%E4%B8%8B%E9%9D%A2%E6%98%AF%E7%BD%91%E9%A1%B5%E6%8F%90%E4%BE%9B%E7%9A%84%E8%9B%8B%E7%99%BD%E8%B4%A8%E5%BA%8F%E5%88%97%E4%BD%9C%E4%B8%BA%E6%A1%88%E4%BE%8B%EF%BC%8C%E5%AF%B9%E4%BA%8EDNA%E5%BA%8F%E5%88%97%E4%B9%9F%E6%98%AF%E7%B1%BB%E4%BC%BC%E7%9A%84%E3%80%82">http://www.bioinformatics.org/sms2/color\_align\_cons.html）出图。下面是网页提供的蛋白质序列作为案例，对于DNA序列也是类似的。</a> <img src="https://genehub.files.wordpress.com/2020/01/e5beaee4bfa1e688aae59bbe_20200120114724.png" alt="微信截图_20200120114724" /></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>转录组数据分析</title>
    <url>/2015/09/25/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/</url>
    <content><![CDATA[<ul>
<li><strong>1. filtering</strong></li>
</ul>
<blockquote>
<p>fastqc, iTools, …</p>
</blockquote>
<ul>
<li><strong>2. aligment</strong></li>
</ul>
<blockquote>
<p>HTSAT, TopHat</p>
</blockquote>
<ul>
<li><strong>3. assembly</strong></li>
</ul>
<blockquote>
<p>cufflinks</p>
</blockquote>
<ul>
<li><strong>4. merge</strong></li>
</ul>
<blockquote>
<p>cuffmerge</p>
</blockquote>
<ul>
<li><strong>5. Differential expression</strong></li>
</ul>
<blockquote>
<p>cuffdiff (good for time points &amp; with biological repeats) DEseq (good for pairwise samples) edegR</p>
</blockquote>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>转录组数据分析之HISAT比对</title>
    <url>/2015/03/21/%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90%E4%B9%8Bhisat%E6%AF%94%E5%AF%B9/</url>
    <content><![CDATA[<p>HISAT全称为Hierarchical Indexing for Spliced Alignment of Transcripts，由约翰霍普金斯大学开发。它取代Bowtie/TopHat程序，能够将RNA-Seq的读取与基因组进行快速比对。这项成果发表在3月9日的《Nature Methods》上。 HISAT利用大量FM索引，以覆盖整个基因组。以人类基因组为例，它需要48,000个索引，每个索引代表~64,000 bp的基因组区域。这些小的索引结合几种比对策略，实现了RNA-Seq读取的高效比对，特别是那些跨越多个外显子的读取。尽管它利用大量索引，但HISAT只需要4.3 GB的内存。这种应用程序支持任何规模的基因组，包括那些超过40亿个碱基的。 第一步：建立数据库索引 命令：hisat-build genome.fa genome 将得到<code>NAME.1.bt2</code>, <code>NAME.2.bt2</code>,<code>NAME.3.bt2</code>, <code>NAME.4.bt2</code>, <code>NAME.5.bt2</code>, <code>NAME.6.bt2</code>, <code>NAME.rev.1.bt2</code>, <code>NAME.rev.2.bt2</code>, <code>NAME.rev.5.bt2</code>, and <code>NAME.rev.6.bt2 这六个文件。</code> 第二步：将转录组数据比对到基因组 命令：hisat -p 8 --phred64 -x genome -1 reads.1.fq.gz -2 reads.2.fq.gz -S out.sam [使用拟南芥转录组数据，该步骤6分钟即可完成，而原来的TopHat需要1小时。] 第三步：将sam转为bam文件，并对bam文件进行排序。 第四部：使用cufflinks进行下游分析。</p>
]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>转：如何上传代码到github</title>
    <url>/2020/08/09/%E8%BD%AC%EF%BC%9A%E5%A6%82%E4%BD%95%E4%B8%8A%E4%BC%A0%E4%BB%A3%E7%A0%81%E5%88%B0github/</url>
    <content><![CDATA[<p>自从使用github以来，一直都是在<a href="https://link.jianshu.com?t=https://github.com/">github网站</a>在线上传文件到仓库中，但是有时因为网络或者电脑的原因上传失败。最重要的原因是我习惯本地编辑，完成以后再一起上传github。看过了几个教程，总结出最适合自己的比较简单的方法。</p>
<p>两种方法上传本地文件到github</p>
<h4 id="1-github在线上传文件夹"><a class="markdownIt-Anchor" href="#1-github在线上传文件夹"></a> 1. github在线上传文件夹</h4>
<p>在线上传也可以上传完整的文件夹结构，直接拖拽到上传文件页面的框中即可。</p>
<h5 id="11点击上传文件"><a class="markdownIt-Anchor" href="#11点击上传文件"></a> 1.1点击上传文件</h5>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150553.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150553.png?w=1024" alt="" /></a></p>
<p>点击上传</p>
<h5 id="12-直接拖拽"><a class="markdownIt-Anchor" href="#12-直接拖拽"></a> 1.2 直接拖拽</h5>
<p>直接拖拽即可上传文件夹及文件夹里面的文件。如果点击* choose your files *就只能上传单个文件。</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150605.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150605.png?w=1024" alt="" /></a></p>
<p>直接拖拽</p>
<h4 id="2-通过git工具上传本地文件夹本地项目"><a class="markdownIt-Anchor" href="#2-通过git工具上传本地文件夹本地项目"></a> 2. 通过git工具上传本地文件夹（本地项目）</h4>
<h5 id="21-下载git工具"><a class="markdownIt-Anchor" href="#21-下载git工具"></a> 2.1 下载<a href="https://link.jianshu.com?t=https://git-scm.com/downloads">git工具</a></h5>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207145151.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207145151.png?w=465" alt="" /></a></p>
<p>选择对应版本下载</p>
<h5 id="22-下载完成后安装完成注意在安装过程中可以选择创建桌面快捷方式"><a class="markdownIt-Anchor" href="#22-下载完成后安装完成注意在安装过程中可以选择创建桌面快捷方式"></a> 2.2 下载完成后安装完成，注意在安装过程中可以选择创建桌面快捷方式</h5>
<p><img src="//upload-images.jianshu.io/upload_images/3067059-fa7d131432a1232e.png?imageMogr2/auto-orient/stripimageView2/2/w/503/format/webp" alt="" /></p>
<p>桌面快捷方式</p>
<h5 id="23-绑定用户"><a class="markdownIt-Anchor" href="#23-绑定用户"></a> 2.3 绑定用户</h5>
<p>打开git-bash.exe（直接在桌面上点击右键，或者点击开始按钮找到Git Bash）</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207144957.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207144957.png?w=395" alt="" /></a></p>
<p>运行gitBash.gif</p>
<p>在打开的GIt Bash中输入以下命令（用户和邮箱为你github注册的账号和邮箱）</p>
<p>$ git config --global <a href="http://user.name">user.name</a> “hanyuntao”<br />
$ git config --global user.email “<a href="mailto:hanyuntaocn@163.com">hanyuntaocn@163.com</a>”</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207145430.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207145430.png?w=763" alt="" /></a></p>
<p>Paste_Image.png</p>
<h5 id="24-设置ssh-keygit中sshkey有何作用"><a class="markdownIt-Anchor" href="#24-设置ssh-keygit中sshkey有何作用"></a> 2.4 设置SSH key（<a href="https://link.jianshu.com?t=https://segmentfault.com/q/1010000000118744">git中sshkey有何作用？</a>）</h5>
<h6 id="241-生成ssh-key"><a class="markdownIt-Anchor" href="#241-生成ssh-key"></a> 2.4.1 生成ssh key</h6>
<p>首先检查是否已生成密钥<code>cd ~/.ssh</code>，如果返回的<code>ls</code>有3个文件,则密钥已经生成。</p>
<p>密钥生成</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207145728.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207145728.png?w=874" alt="" /></a></p>
<p>如果没有密钥，则通过</p>
<p>$ ssh-keygen -t rsa -C “<a href="mailto:hanyuntaocn@163.com">hanyuntaocn@163.com</a>”</p>
<p>生成，生成过程中一路按3次回车键就好了。（默认路径，默认没有密码登录）<br />
生成成功后，去对应目录C:\Users\hyt.ssh里（hyt为电脑用户名，每个人不同）用记事本打开id_rsa.pub，得到ssh key公钥。</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150754.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150754.png?w=768" alt="" /></a></p>
<p>ssh key公钥</p>
<h6 id="242-为github账号配置ssh-key"><a class="markdownIt-Anchor" href="#242-为github账号配置ssh-key"></a> 2.4.2 为github账号配置ssh key</h6>
<p>切换到github，展开个人头像的小三角，点击settings，然后打开SSH keys菜单， 点击Add SSH key新增密钥，填上标题（最好跟本地仓库保持一致）。</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150300.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150300.png?w=1024" alt="" /></a></p>
<p>设置sshkey.gif</p>
<p>接着将id_rsa.pub文件中key粘贴到此，最后Add key生成密钥吧。\</p>
<h4 id="25-上传本地项目到github"><a class="markdownIt-Anchor" href="#25-上传本地项目到github"></a> 2.5 上传本地项目到github</h4>
<h5 id="251-创建一个本地项目"><a class="markdownIt-Anchor" href="#251-创建一个本地项目"></a> 2.5.1 创建一个本地项目</h5>
<p>这是我自己创建的几个文件夹及文件。</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150936.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207150936.png?w=778" alt="" /></a></p>
<p>本地项目</p>
<h5 id="252-建立本地仓库"><a class="markdownIt-Anchor" href="#252-建立本地仓库"></a> 2.5.2 建立本地仓库</h5>
<p>1.首先进入text文件夹</p>
<p>cd d:text</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207151042.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207151042.png?w=480" alt="" /></a></p>
<p>首先进入text文件夹</p>
<p>2.执行指令：<code>git init</code></p>
<p>执行git init</p>
<p>初始化成功后你会发现项目里多了一个隐藏文件夹.git</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207151137.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207151137.png?w=799" alt="" /></a></p>
<p>隐藏的文件夹</p>
<p>3.执行指令：<code>git add .</code><br />
将所有文件添加到仓库</p>
<p>执行git add .</p>
<p>4.执行指令：<code>git commit -m &quot;submitted&quot;</code><br />
双引号内是提交注释。</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207151233.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207151233.png?w=1024" alt="" /></a></p>
<p>提交文件</p>
<h5 id="253-关联github仓库"><a class="markdownIt-Anchor" href="#253-关联github仓库"></a> 2.5.3 关联github仓库</h5>
<p>1.到github text仓库复制仓库地址</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207151406.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207151406.png?w=1024" alt="" /></a></p>
<p>复制仓库地址<br />
2.执行指令：<code>git remote add origin https://github.com/hanyuntao/text.git</code></p>
<p>执行指令</p>
<h5 id="254-上传本地代码"><a class="markdownIt-Anchor" href="#254-上传本地代码"></a> 2.5.4 上传本地代码</h5>
<p>执行指令：<code>git push -u origin master</code></p>
<p>执行指令</p>
<blockquote>
<p>备注：github对应的文件夹里面不能有相同的文件名或文件夹，否则出错。我之前在网页版本上传了几个文件，但是网页版本无法上传文件夹，所以使用windows桌面客户端，要清理掉网页版已经上传的几个文件，才能用上面的代码上传。</p>
</blockquote>
<h5 id="255完成了"><a class="markdownIt-Anchor" href="#255完成了"></a> 2.5.5完成了</h5>
<p>可以看到我们的本地项目已经上传到了github上了。</p>
<p><a href="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207152041.png"><img src="https://genehub.files.wordpress.com/2020/12/e5beaee4bfa1e688aae59bbe_20201207152041.png?w=1024" alt="" /></a></p>
<p>完成了</p>
<p>** 注意：git是不能管理空的文件夹的，文件夹里必须有文件才能上传。 **</p>
<p>参考资料：?</p>
<ul>
<li>如何<strong>更新代码？</strong></li>
</ul>
<p>第一步：查看当前的git仓库状态，可以使用git status，会列出当前目录下的文件与本地git仓库里面列出的文件的不同之处。</p>
<p>git status</p>
<p>第二步：更新本地git仓库</p>
<p>git add *</p>
<p>第三步：接着输入git commit -m “Updated”</p>
<p>git commit -m “Updated”</p>
<p>第四步：先git pull,拉取当前分支最新代码（也就是获取GitHub上的最新代码信息，更新本地代码）</p>
<p>git pull</p>
<p>第五步：push到远程master分支上（修改本地代码后，再更新GitHub上的代码）</p>
<p>git push origin master</p>
<p>不出意外，打开GitHub已经同步了。</p>
<p>总之，先pull，再push。</p>
]]></content>
      <categories>
        <category>Linux</category>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>转：瀚海常青树沙冬青</title>
    <url>/2017/03/01/%E8%BD%AC%EF%BC%9A%E7%80%9A%E6%B5%B7%E5%B8%B8%E9%9D%92%E6%A0%91%E6%B2%99%E5%86%AC%E9%9D%92/</url>
    <content><![CDATA[<p>瀚海常青树沙冬青</p>
<p>2010-10-15 编辑： 【大 中 小】</p>
<p>自落叶阔叶树种称霸北方大地后，北方的冬天就增添了一片萧煞的沉闷，与绿色的南方形成鲜明的对比。 然而，我国北方的沙漠中，却独有一种常绿的阔叶木本植物，它叫做沙冬青。一听名字，就知道是沙漠中冬天仍保持绿色的植物。 沙冬青是豆科的一个属，生长在我国西北荒漠、半荒漠地区的沙冬青，只有两个种。一种叫蒙古沙冬青，主要分布在内蒙古的库布齐沙带、乌兰布和沙漠、腾格里沙漠；另一种叫新疆沙冬青，又叫矮沙冬青或小沙冬青，仅分布在我国新疆喀什地区的康苏一带，数量已经很少，已处于绝灭状态，被列为国家二级重点保护植物。沙冬青与胡杨一样，是第三纪的古老植物，在地球上已经存在了几千万年，也有“活化石”之称。 蒙古沙冬青高1~1.5米，叶片肥厚，常年保持绿色，不过冬天的绿略有一些灰暗。它从4月进入花期后，花期长近两个月，为中型花，色泽金黄。初夏时间，满树金黄花的沙冬青，点缀在无垠的沙海中，令人留连忘返。由于沙冬青常绿、花艳的特点，除可用于治理、美化沙漠外，也可作为一种观赏价值很高的树种应用于城市的园林建设，特别是作为绿篱使用。当你倘佯在金黄的绿萌夹道中时，一定会有心旷神怡的感觉。 过去，沙冬青被称为“不挪窝的植物”，生长再好，移植后很快就会死亡，为此影响了它在庭院中的应用。经过科学家们的努力，沙冬青带土移植已宣告成功，沙冬青由沙漠走向城市很快就会实现了。 新疆沙冬青却没有蒙古沙冬青好侍弄，它的身高不过50厘米，而且对原生地的留恋远超出蒙古沙冬青。迁地保护，并发展人工种群大约也是防止它的灭绝的唯一途径。目前，在新疆吐鲁番沙漠植物园已经有了新疆沙冬青的身影。我们想，新疆沙冬青告别过去，走向新生终究会实现。它会像它的兄弟蒙古沙冬青一样，既为生物多样性的保护尽到自己的职责，又为美化人们的生活做出自己的奉献。</p>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>转：自动化运行OrthoMCL</title>
    <url>/2019/04/01/%E8%BD%AC%EF%BC%9A%E8%87%AA%E5%8A%A8%E5%8C%96%E8%BF%90%E8%A1%8Corthomcl/</url>
    <content><![CDATA[<p>OrthoMCL (<a href="https://link.jianshu.com/?t=http://orthomcl.org/orthomcl/">http://orthomcl.org/orthomcl/</a>) 是现在用的最多的一款来找直系同源基因（Orthologs）以及旁系同源基因 (Paralog) 的软件。</p>
<p>OrthoMCL 的最新版本是2013年7月公布的v2.0版本，已经很久没更新过了。根据官网的教程至少得十多步才能完成整个运行流程，包括Mysql数据库配置、修改OrthoMCL配置文件、转换序列格式、过滤、比对、解析结果和聚类等步骤，特别麻烦。 OrthoMCL Pipeline (<a href="https://link.jianshu.com?t=https://github.com/apetkau/orthomcl-pipeline">https://github.com/apetkau/orthomcl-pipeline</a>) 可以很好的帮我们解决这个痛点。Pipeline安装有点复杂，但是安装完成后，使用就方便了。</p>
<p>作者：亮亮就是亮 链接：<a href="https://www.jianshu.com/p/449a51fa3d18">https://www.jianshu.com/p/449a51fa3d18</a> 来源：简书 简书著作权归作者所有，任何形式的转载都请联系作者获得授权并注明出处。</p>
<p>使用OrthoMCL Pipeline 来自动化运行OrthoMCL，简化操作步骤。</p>
<h2 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h2>
<p>1</p>
<p>git clone <a href="https://github.com/apetkau/orthomcl-pipeline.git">https://github.com/apetkau/orthomcl-pipeline.git</a></p>
<p>或者直接下载：<a href="https://github.com/apetkau/orthomcl-pipeline">https://github.com/apetkau/orthomcl-pipeline</a></p>
<h3 id="perl模块"><a class="markdownIt-Anchor" href="#perl模块"></a> Perl模块</h3>
<p>通过<code>cpanm</code>安装</p>
<p>1</p>
<p>cpanm BioPerl DBD::mysql DBI Parallel::ForkManager YAML::Tiny Set::Scalar Text::Table Exception::Class Test::Most Test::Warn Test::Exception Test::Deep Moose SVG Algorithm::Combinatorics</p>
<p>我是在linux命令行界面输入 perl -MCPAN -e shell ，使用instlall DBI这样的命令安装perl模块的。</p>
<h3 id="依赖软件"><a class="markdownIt-Anchor" href="#依赖软件"></a> 依赖软件</h3>
<ul>
<li><a href="http://orthomcl.org/common/downloads/software/v2.0/">OrthoMCL</a> 或 <a href="https://github.com/apetkau/orthomclsoftware-custom">OrthoMCL Custom</a> （能够自定义序列识别符的修改版本）。OrhtoMCL下载并解压之后，bin目录下的Perl程序首行是#!/usr/bin/perl，我将其全部改为用户的perl了，因为我自己安装的perl位置是/home/fenglei/local/bin/perl。</li>
<li><a href="http://blast.ncbi.nlm.nih.gov/Blast.cgi?CMD=Web&amp;PAGE_TYPE=BlastDocs&amp;DOC_TYPE=Download">BLAST</a> (blastall, formatdb) 注意不是NCBI-blast+, 推荐使用<code>2.2.26</code>版本。由于我之前下载过interproscan，在interproscan安装目录下游blastall和formatdb等程序，直接将其路径加入环境变量即可！</li>
<li><a href="http://www.micans.org/mcl/index.html">MCL</a></li>
</ul>
<p>依赖环境解决后能够顺利运行设置脚本</p>
<p>1<br />
2<br />
3<br />
4<br />
5<br />
6<br />
7<br />
8<br />
9</p>
<p>$ perl scripts/orthomcl-pipeline-setup.pl<br />
Checking for Software dependencies…<br />
Checking for OthoMCL … OK<br />
Checking for formatdb … OK<br />
Checking for blastall … OK<br />
Checking for mcl … OK<br />
Wrote new configuration to orthomcl-pipeline/scripts/…/etc/orthomcl-pipeline.conf<br />
Wrote executable file to orthomcl-pipeline/scripts/…/bin/orthomcl-pipeline<br />
Please add directory orthomcl-pipeline/scripts/…/bin to PATH</p>
<h3 id="数据库设置"><a class="markdownIt-Anchor" href="#数据库设置"></a> 数据库设置</h3>
<h4 id="创建orthomcl用户"><a class="markdownIt-Anchor" href="#创建orthomcl用户"></a> 创建orthomcl用户</h4>
<p>1<br />
2<br />
3<br />
4<br />
5</p>
<p>$ mysql -u root -p<br />
Enter password:<br />
mysql&gt; GRANT SELECT, INSERT, UPDATE, DELETE, CREATE, CREATE VIEW, INDEX, DROP on . to orthomcl;  #创建用户并授权<br />
mysql&gt; set password for orthomcl@localhost = password(‘orthomcl’);  #设置用户密码<br />
mysql&gt; quit;</p>
<h4 id="创建数据库并生成配置脚本"><a class="markdownIt-Anchor" href="#创建数据库并生成配置脚本"></a> 创建数据库并生成配置脚本</h4>
<p>1<br />
2<br />
3<br />
4</p>
<p>$ perl scripts/orthomcl-setup-database.pl --user orthomcl --password orthomcl --host localhost --database orthomcl --outfile orthomcl.conf<br />
Connecting to mysql and creating database **orthmcldb** on host orthodb with user orthomcl …OK<br />
database orthmcl created …OK<br />
Config file **orthomcl.conf** created.</p>
<p>若已有orthomcl数据库，则可添加<code>--no-create-database</code>参数，不新建数据库。</p>
<h2 id="测试数据"><a class="markdownIt-Anchor" href="#测试数据"></a> 测试数据</h2>
<p>1<br />
2<br />
3<br />
4<br />
5<br />
6<br />
7<br />
8<br />
9</p>
<p>$ perl t/test_pipeline.pl -m orthomcl.conf -s fork -t /tmp<br />
Test using scheduler fork</p>
<p>TESTING NON-COMPLIANT INPUT<br />
TESTING FULL PIPELINE RUN 3<br />
README:<br />
Tests case of one gene (in 1.fasta and 2.fasta) not present in other files.<br />
ok 1 - Expected matched returned groups file<br />
…</p>
<h2 id="运行"><a class="markdownIt-Anchor" href="#运行"></a> 运行</h2>
<p>1<br />
2<br />
3<br />
4</p>
<p>$ ./bin/orthomcl-pipeline<br />
Error: no input-dir defined<br />
Usage: orthomcl-pipeline -i [input dir] -o [output dir] -m [orthmcl config] [Options]<br />
…</p>
<p>1</p>
<p>加上–nocompliant就可以将输入文件中的基因名自动调整为具备唯一性的字符串（and <code>--nocompliant</code> adjusts gene names in fasta files to make them unique.）。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ ./bin/orthomcl-pipeline -i ~/test_data/zbl -o ~/test_data/zbl-out -m orthomcl.conf --nocompliant</span><br></pre></td></tr></table></figure>
<p>zbl文件夹里面放入fasta格式的蛋白序列文件，一个基因组一个文件，例如genome1.fasta, genome2.fasta, 文件后缀名必需是.fasta。zbl-out文件夹里面是所有的结果，包括聚类完成的groups文件，orthologs文件，inparalogs文件以及coorthologs文件。</p>
<h2 id="参考来源"><a class="markdownIt-Anchor" href="#参考来源"></a> 参考来源</h2>
<p><a href="https://github.com/apetkau/orthomcl-pipeline/blob/master/INSTALL.md">https://github.com/apetkau/orthomcl-pipeline/blob/master/INSTALL.md</a> <a href="https://www.jianshu.com/p/449a51fa3d18">https://www.jianshu.com/p/449a51fa3d18 （亮亮就是亮）</a> <a href="https://sr-c.github.io/2018/09/18/OrthoMCL-Pipeline/">https://sr-c.github.io/2018/09/18/OrthoMCL-Pipeline/</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>生物进化之选择压力分析：Ka/Ks比率</title>
    <url>/2016/06/09/%E8%BF%9B%E5%8C%96%E5%8E%8B%E5%8A%9B%E5%88%86%E6%9E%90%EF%BC%9Akaks%E6%AF%94%E7%8E%87/</url>
    <content><![CDATA[<h3 id="背景知识"><a class="markdownIt-Anchor" href="#背景知识"></a> <strong>背景知识</strong></h3>
<p>In <a href="https://en.wikipedia.org/wiki/Genetics" title="Genetics">genetics</a>, the <strong>Ka/Ks ratio</strong> is an indicator of <a href="https://en.wikipedia.org/wiki/Selective_pressure" title="Selective pressure">selective pressure</a> (the force applied by <a href="https://en.wikipedia.org/wiki/Natural_selection" title="Natural selection">natural selection</a>) acting on a protein-coding gene. It is calculated as the ratio of the number of <a href="https://en.wikipedia.org/wiki/Nonsynonymous_substitution" title="Nonsynonymous substitution">nonsynonymous substitutions</a> per non-synonymous site (Ka), in a given period of time, to the number of <a href="https://en.wikipedia.org/wiki/Synonymous_substitution" title="Synonymous substitution">synonymous substitutions</a> per synonymous site (Ks), in the same period. <a href="https://en.wikipedia.org/wiki/Homologous_gene" title="Homologous gene">Homologous genes</a> with a Ka/Ks ratio above 1 are evolving under <a href="https://en.wikipedia.org/wiki/Directional_selection" title="Directional selection">positive selection</a>, meaning that at least some of the <a href="https://en.wikipedia.org/wiki/Mutation" title="Mutation">mutations</a> concerned must be advantageous. If all the mutations are neutral or disadvantageous, the ratio will be in the range 0 to 1. However, if some of the mutations are advantageous and some disadvantageous, the ratio could be less than 1.</p>
<h3 id="方法软件"><a class="markdownIt-Anchor" href="#方法软件"></a> 方法/软件</h3>
<p>Conclusions one may draw from dN/dS ratios (aka. ~Ka/Ks): <strong><em>Neutral Evolution (drift):</em></strong> dN/dS ratio = 1 implies there has been equal numbers of synonymous (dna substitutions that do not affect the protein sequence) and non-synonymous changes (dna substitutions that do affect the protein sequence) during the time between ancestral to the modern versions of the protein. <strong><em>Positive Selection (adaptive evolution):</em></strong> dN/dS ratio &gt; 1 implies there has been more non-synonymous changes than synonymous changes. There has been evolutionary pressure to escape from the ancestral state - i.e. positive selection pressure. This can occur for example in paralogues that are required to serve a novel function, or in proteins of parasites that need to escape host immune recognition (e.g. changes to avoid MHC-1 binding to evade T-cell attack). <strong><em>Negative Selection (conservation):</em></strong> dN/dS ratio &lt; 1 implies there has been more synonymous changes than non-synonymous changes. There has been evolutionary pressure to conserve the ancestral state - i.e. negative selection pressure. This can occur for example in orthologues that are required to maintain (conserve) some function encoded in the protein sequence, since changes from this state would lead to disruption of function. <strong>Useful Tips:</strong></p>
<ul>
<li>Algorithms can either run on multiple sequences, or just a pair of sequences. In either case the input sequences used to derive a dN/dS ratio must share ancestry - too divergent and there is a problem with multiple substitutions, too recent and you will not have sufficient enough observed changes to draw conclusions from.</li>
<li>dN/dS can be used to compare whole proteins or regions within proteins (a sliding dN/dS value across the protein)</li>
<li>A dN/dS ratio calculated for a whole protein is often an underestimate (lower than it should be) due to the variety of domains that constitute each protein, for instance a alpha-helix structure may always be required in a set of proteins that perform a variety of different functions.</li>
<li>The only sequence changes considered are substitutions (not duplications, or inversions etc.)</li>
<li>Significance of a given dN/dS ratio can be assessed using Fishers exact test: <a href="https://code.google.com/p/kaks-calculator/wiki/FAQ">read this</a></li>
</ul>
<p><strong>Software:</strong> Here are my recommendations for software ordered by how flexible they are:</p>
<ul>
<li><a href="http://www.mathworks.co.uk/help/bioinfo/ref/dnds.html">MATLAB’s Bioinformatics Toolbox:</a> Here you have the greatest variety of alternative algorithms, operating system compatibility, sliding vs. whole protein analysis, API to Genbank, etc (<a href="http://www.mathworks.co.uk/products/bioinfo/code-examples.html?file=/products/demos/shipping/bioinfo/dndsdemo.html">Here’s</a> a great tutorial for using their dN/dS tool). Just remember MATLAB is not free.</li>
<li><a href="https://code.google.com/p/kaks-calculator/wiki/KaKs_Calculator">KaKs Calculator:</a> If you only care about <strong>whole protein</strong> dN/dS, many options are available with the Ka/Ks calculator - they also compute statistical significance using Fisher’s exact test. I can also provide an R script that generates error bars from the output, just ask.</li>
<li><a href="http://abacus.gene.ucl.ac.uk/software/paml.html">PAML:</a> If you have &gt;2 sequences per protein that you wish to get a dN/dS value from, then many options are available with PAML. This is often used in published papers, but it’s not recommended if you only have a pair of sequences per protein.</li>
<li>
<ul>
<li><a href="http://code.google.com/p/kaks-calculator">KaKs_Calculator</a></li>
<li><a href="http://services.cbu.uib.no/tools/kaks">Free online server tool that calculates KaKs ratios among multiple sequences</a></li>
<li><a href="http://cran.r-project.org/web/packages/seqinr/index.html">SeqinR: A free and open biological sequence analysis package for the R language that includes KaKs calculation</a></li>
</ul>
</li>
</ul>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p><a href="https://en.wikipedia.org/wiki/Ka/Ks%5C_ratio">https://en.wikipedia.org/wiki/Ka/Ks\_ratio</a><br />
<a href="https://www.biostars.org/p/5817/">https://www.biostars.org/p/5817/</a></p>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>进化树的构建</title>
    <url>/2015/11/19/%E8%BF%9B%E5%8C%96%E6%A0%91%E7%9A%84%E6%9E%84%E5%BB%BA/</url>
    <content><![CDATA[<p>一、序列收集</p>
<blockquote>
<p>核酸序列与蛋白序列均可。寻找同源序列可以用NCBI的blast工具。随后保存为fasta格式。使用Editplus对序列文件编辑，将基因名称同修改为统一格式，去掉不必要的字符。</p>
</blockquote>
<p>二、序列比对</p>
<blockquote>
<p>使用Clustalx导入上述fasta格式文件。如果遇到打不开的问题，可能是文件存储路径有中文或空格，注意改正。比对之后另存为新的fasta文件。改文件将包含许多“-”，使各个基因的保守序列对其。 参考资料：<a href="http://liucheng.name/411/">http://liucheng.name/411/</a></p>
</blockquote>
<p>三、序列切割</p>
<blockquote>
<p>使用Mega打开新的Fasta文件，删除含有空格的列。</p>
</blockquote>
<p>四、构建进化树</p>
<blockquote>
<p>然后在Mega软件主界面点击“Phylogeny”图表，选择构建进化树的类型，比如Maxmium Likelihood还是Neighbor-Joining；并且记得勾选bootstrap选项。 参考资料：<a href="http://liucheng.name/603/">http://liucheng.name/603/</a></p>
</blockquote>
<span id="more"></span>
<p>参考资料： <a href="http://abc.cbi.pku.edu.cn/talk/phylogeny-huang-by.pdf">http://abc.cbi.pku.edu.cn/talk/phylogeny-huang-by.pdf</a> ========================================================= 参考资料：<a href="http://liucheng.name/577/">http://liucheng.name/577/</a> 柳城：</p>
<h1 id="系统进化树构建及数据分析的简介"><a class="markdownIt-Anchor" href="#系统进化树构建及数据分析的简介"></a> 系统进化树构建及数据分析的简介</h1>
<h2 id="一-引言"><a class="markdownIt-Anchor" href="#一-引言"></a> 一、引言</h2>
<p>开始动笔写这篇短文之前，我问自己，为什么要写这样的文章？写这样的文章有实际的意义吗？我希望能够解决什么样的问题？带着这样的疑惑，我随手在丁香园（DXY）上以关键字“进化 分析 求助”进行了搜索，居然有289篇相关的帖子（2006年9月12日）。而以关键字“进化分析”和“进化”为关键字搜索，分别找到2,733和7,724篇相关的帖子。考虑到有些帖子的内容与分子进化无关，这里我保守的估计，大约有 3,000~4,000篇帖子的内容，是关于分子进化的。粗略地归纳一下，我大致将提出的问题分为下述的几类：</p>
<h3 id="1涉及基本概念"><a class="markdownIt-Anchor" href="#1涉及基本概念"></a> 1．涉及基本概念</h3>
<p>例如，“分子进化与生物进化是不是一个概念”，“关于微卫星进化模型有没有什么新的进展”以及“关于Kruglyak的模型有没有改进的出现”，等等。</p>
<h3 id="2关于构建进化树的方法的选择"><a class="markdownIt-Anchor" href="#2关于构建进化树的方法的选择"></a> 2．关于构建进化树的方法的选择</h3>
<p>例如，“用boostrap NJ得到XX图，请问该怎样理解？能否应用于文章？用boostrap test中的ME法得到的是XXX树，请问与上个树比，哪个更好”，等等。</p>
<h3 id="3关于软件的选择"><a class="markdownIt-Anchor" href="#3关于软件的选择"></a> 3．关于软件的选择</h3>
<p>例如，“想做一个进化树，不知道什么软件能更好的使用且可以说明问题，并且有没有说明如何做”，“拿到了16sr RNA数据，打算做一个<a href="http://liucheng.name/tag/%e7%b3%bb%e7%bb%9f%e8%bf%9b%e5%8c%96%e6%a0%91/" title="View all posts in 系统进化树">系统进化树</a>分析，可是原来没有做过这方面的工作啊，都要什么软件”，“请问各位高手用clustalx做出来的进化树与 phylip做的有什么区别”，“请问有做过进化树分析的朋友，能不能提供一下，做树的时候参数的设置，以及代表的意思。还有各个分支等数值的意思，说明的问题等”，等等。</p>
<h3 id="4蛋白家族的分类问题"><a class="markdownIt-Anchor" href="#4蛋白家族的分类问题"></a> 4．蛋白家族的分类问题</h3>
<p>例如，“搜集所有的关于一个特定domain的序列，共141条，做的进化树不知具体怎么分析”，等等。</p>
<h3 id="5新基因功能的推断"><a class="markdownIt-Anchor" href="#5新基因功能的推断"></a> 5．新基因功能的推断</h3>
<p>例如，“根据一个新基因A氨基酸序列构建的系统发生树，这个进化树能否说明这个新基因A和B同源，属于同一基因家族”，等等。</p>
<h3 id="6计算基因分化的年代"><a class="markdownIt-Anchor" href="#6计算基因分化的年代"></a> 6．计算基因分化的年代</h3>
<p>例如，“想在基因组水平比较两个或三个比较接近物种之间的进化年代的远近，具体推算出他们之间的分歧时间”，“如何估计病毒进化中变异所需时间”，等等。</p>
<h3 id="7进化树的编辑"><a class="markdownIt-Anchor" href="#7进化树的编辑"></a> 7．进化树的编辑</h3>
<p>例如生成的进化树图片，如何进行后续的编辑，比如希望在图片上标注某些特定的内容，等等。 由于相关的帖子太多，作者在这里对无法阅读全部的相关内容而致以歉意。同时，作者归纳的这七个问题也并不完全代表所有的提问。对于问题1所涉及到的基本的概念，作者推荐读者可参考由Masatoshi Nei与Sudhir Kumar所撰写的《分子进化与系统发育》（Molecular Evolution and Phylogenetics）一书，以及相关的分子进化方面的最新文献。对于问题7，作者之一lylover一般使用Powerpoint进行编辑，而 Photoshop、Illustrator及Windows自带的画图工具等都可以使用。 这里，作者在这里对问题2-6进行简要地解释和讨论，并希望能够初步地解答初学者的一些疑问。</p>
<h2 id="二-方法的选择"><a class="markdownIt-Anchor" href="#二-方法的选择"></a> 二、方法的选择</h2>
<p>首先是方法的选择。基于距离的方法有UPGMA、ME（Minimum Evolution，最小进化法）和NJ（Neighbor-Joining，邻接法）等。其他的几种方法包括MP（Maximum parsimony，最大简约法）、ML（Maximum likelihood，最大似然法）以及贝叶斯（Bayesian）推断等方法。其中UPGMA法已经较少使用。 一般来讲，如果模型合适，ML的效果较好。对近缘序列，有人喜欢MP，因为用的假设最少。MP一般不用在远缘序列上，这时一般用NJ或ML。对相似度很低的序列，NJ往往出现Long-branch attraction（LBA，长枝吸引现象），有时严重干扰进化树的构建。贝叶斯的方法则太慢。对于各种方法构建<a href="http://liucheng.name/tag/%e5%88%86%e5%ad%90%e8%bf%9b%e5%8c%96%e6%a0%91/" title="View all posts in 分子进化树">分子进化树</a>的准确性，一篇综述（Hall BG. Mol Biol Evol 2005, 22(3):792-802）认为贝叶斯的方法最好，其次是ML，然后是MP。其实如果序列的相似性较高，各种方法都会得到不错的结果，模型间的差别也不大。 对于NJ和ML，是需要选择模型的。对于各种模型之间的理论上的区别，这里不作深入的探讨，可以参看Nei的书。对于蛋白质序列以及DNA序列，两者模型的选择是不同的。以作者的经验来说，对于蛋白质的序列，一般选择Poisson Correction（泊松修正）这一模型。而对于核酸序列，一般选择Kimura 2-parameter（Kimura-2参数）模型。如果对各种模型的理解并不深入，作者并不推荐初学者使用其他复杂的模型。 Bootstrap几乎是一个必须的选项。一般Bootstrap的值&gt;70，则认为构建的进化树较为可靠。如果Bootstrap的值太低，则有可能进化树的拓扑结构有错误，进化树是不可靠的。 对于进化树的构建，如果对理论的了解并不深入，作者推荐使用缺省的参数。需要选择模型的时候（例如用NJ或者ML建树），对于蛋白序列使用Poisson Correction模型，对于核酸序列使用Kimura-2参数模型。另外需要做Bootstrap检验，当Bootstrap值过低时，所构建的进化树其拓扑结构可能存在问题。并且，一般推荐用两种不同的方法构建进化树，如果所得到的进化树类似，则结果较为可靠。</p>
<h2 id="三-软件的选择"><a class="markdownIt-Anchor" href="#三-软件的选择"></a> 三、软件的选择</h2>
<p>表1中列出了一些与构建分子进化树相关的软件。 构建NJ树，可以用PHYLIP（写得有点问题，例如比较慢，并且Bootstrap检验不方便）或者MEGA。MEGA是Nei开发的方法并设计的图形化的软件，使用非常方便。作者推荐MEGA软件为初学者的首选。虽然多雪列比对工具ClustalW/X自带了一个NJ的建树程序，但是该程序只有p- distance模型，而且构建的树不够准确，一般不用来构建进化树。 构建MP树，最好的工具是PAUP，但该程序属于商业软件，并不对学术免费。因此，作者并不建议使用PAUP。而MEGA和PHYLIP也可以用来构建进化树。这里，作者推荐使用MEGA来构建MP树。理由是，MEGA是图形化的软件，使用方便，而PHYLIP则是命令行格式的软件，使用较为繁琐。对于近缘序列的进化树构建，MP方法几乎是最好的。 构建ML树可以使用PHYML，速度最快。或者使用Tree-puzzle，速度也较快，并且该程序做蛋白质序列的进化树效果比较好。而PAML则并不适合构建进化树。ML的模型选择是看构出的树的likelihood值，从参数少，简单的模型试起，到likelihood值最大为止。ML也可以使用 PAUP或者PHYLIP来构建。这里作者推荐的工具是BioEdit。BioEdit集成了一些PHYLIP的程序，用来构建进化树。Tree- puzzle是另外一个不错的选择，不过该程序是命令行格式的，需要学习DOS命令。PHYML的不足之处是没有win32的版本，只有适用于64位的版本，因此不推荐使用。值得注意的是，构建ML树，不需要事先的多序列比对，而直接使用FASTA格式的序列即可。 贝叶斯的算法以MrBayes为代表，不过速度较慢。一般的进化树分析中较少应用。由于该方法需要很多背景的知识，这里不作介绍。 <strong>表1 构建分子进化树相关的软件</strong> 软件        网址        说明 ClustalX        <a href="http://bips.u-strasbg.fr/fr/Documentation/ClustalX/">http://bips.u-strasbg.fr/fr/Documentation/ClustalX/</a>                                  图形化的多序列比对工具 ClustalW        <a href="http://www.cf.ac.uk/biosi/research/biosoft/Downloads/clustalw.html">http://www.cf.ac.uk/biosi/resear … loads/clustalw.html</a>        命令行格式的多序列比对工具 GeneDoc        <a href="http://www.psc.edu/biomed/genedoc/">http://www.psc.edu/biomed/genedoc/</a>                                              多序列比对结果的美化工具（可以导入fasta格式的文件，出来的图可用于发表，我用过） BioEdit        <a href="http://www.mbio.ncsu.edu/BioEdit/bioedit.html">http://www.mbio.ncsu.edu/BioEdit/bioedit.html</a>                                     序列分析的综合工具 MEGA        <a href="http://www.megasoftware.net/">http://www.megasoftware.net/</a>                                                            图形化、集成的进化分析工具，不包括ML PAUP        <a href="http://paup.csit.fsu.edu/">http://paup.csit.fsu.edu/</a>                                                                       商业软件，集成的进化分析工具 PHYLIP        <a href="http://evolution.genetics.washington.edu/phylip.html">http://evolution.genetics.washington.edu/phylip.html</a>                             免费的、集成的进化分析工具 PHYML        <a href="http://atgc.lirmm.fr/phyml/">http://atgc.lirmm.fr/phyml/</a>                                                                  最快的ML建树工具 PAML        <a href="http://abacus.gene.ucl.ac.uk/software/paml.html">http://abacus.gene.ucl.ac.uk/software/paml.html</a>                                      ML建树工具 Tree-puzzle        <a href="http://www.tree-puzzle.de/">http://www.tree-puzzle.de/</a>                                                          较快的ML建树工具 MrBayes        <a href="http://mrbayes.csit.fsu.edu/">http://mrbayes.csit.fsu.edu/</a>                                                              基于贝叶斯方法的建树工具 MAC5        <a href="http://www.agapow.net/software/mac5/">http://www.agapow.net/software/mac5/</a>                                              基于贝叶斯方法的建树工具 TreeView        <a href="http://taxonomy.zoology.gla.ac.uk/rod/treeview.html">http://taxonomy.zoology.gla.ac.uk/rod/treeview.html</a>                          进化树显示工具 （加红色标注的为最通用的分析软件） 需要注意的几个问题是，其一，如果对核酸序列进行分析，并且是CDS编码区的核酸序列，一般需要将核酸序列分别先翻译成氨基酸序列，进行比对，然后再对应到核酸序列上。这一流程可以通过MEGA 3.0以后的版本实现。MEGA3现在允许两条核苷酸，先翻成蛋白序列比对之后再倒回去，做后续计算。 其二，无论是核酸序列还是蛋白序列，一般应当先做成 FASTA格式。FASTA格式的序列，第一行由符号“&gt;”开头，后面跟着序列的名称，可以自定义，例如user1，protein1等等。将所有的FASTA格式的序列存放在同一个文件中。文件的编辑可用Windows自带的记事本工具，或者EditPlus（google搜索可得）来操作。 另外，构建NJ或者MP树需要先将序列做多序列比对的处理。作者推荐使用ClustalX进行多序列比对的分析。多序列比对的结果有时需要后续处理并应用于文章中，这里作者推荐使用GeneDoc工具。而构建ML树则不需要预先的多序列比对。 因此，作者推荐的软件组合为：MEGA + ClustalX + GeneDoc + BioEdit。</p>
<h2 id="四-数据分析及结果推断"><a class="markdownIt-Anchor" href="#四-数据分析及结果推断"></a> 四、数据分析及结果推断</h2>
<p>一般碰到的几类问题是，（1）推断基因/蛋白的功能；（2）基因/蛋白家族分类；（3）计算基因分化的年代。关于这方面的文献非常多，这里作者仅做简要的介绍。 推断基因/蛋白的功能，一般先用BLAST工具搜索同一物种中与不同物种的同源序列，这包括直向同源物（ortholog）和旁系同源物（paralog）。如何界定这两种同源物，网上有很多详细的介绍，这里不作讨论。然后得到这些同源物的序列，做成FASTA格式的文件。一般通过NJ构建进化树，并且进行Bootstrap分析所得到的结果已足够。如果序列近缘，可以再使用MP构建进化树，进行比较。如果序列较远源，则可以做ML树比较。使用两种方法得到的树，如果差别不大，并且Bootstrap总体较高，则得到的进化树较为可靠。 基因/蛋白家族分类。这方面可以细分为两个问题。一是对一个大的家族进行分类，另一个就是将特定的一个或多个基因/蛋白定位到已知的大的家族上，看看属于哪个亚家族。例如，对驱动蛋白（kinesin）超家族进行分类，属于第一个问题。而假如得到一个新的驱动蛋白的序列，想分析该序列究竟属于驱动蛋白超家族的14个亚家族中的哪一个，则属于后一个问题。这里，一般不推荐使用MP的方法。大多数的基因/蛋白家族起源较早，序列分化程度较大，相互之间较为远源。这里一般使用NJ、ME或者ML的方法。 计算基因分化的年代。这个一般需要知道物种的核苷酸替代率。常见物种的核苷酸替代率需要查找相关的文献。这里不作过多的介绍。一般对于这样的问题，序列多数是近缘的，选择NJ或者MP即可。 如果使用MEGA进行分析，选项中有一项是“Gaps/Missing Data”，一般选择“Pairwise Deletion”。其他多数的选项保持缺省的参数。</p>
<h2 id="五-总结"><a class="markdownIt-Anchor" href="#五-总结"></a> 五、总结</h2>
<p>在实用中，只要方法、模型合理，建出的树都有意义，可以任意选择自己认为好一个。最重要的问题是：你需要解决什么样的问题？如果分析的结果能够解决你现有的问题，那么，这样的分析足够了。因此，在做进化分析前，可能需要很好的考虑一下自己的问题所在，这样所作的分析才有针对性。 六、致谢 本文由mediocrebeing在2005年9月8日所发起的讨论《关于建树的经验》扩充、修改而来。文章的作者按原贴ID出现先后排名，由 lylover执笔。作者同时感谢所有参与讨论的战友。作者lylover感谢中国科大细胞动力学实验室的金长江博士所给的一些有益的建议。 来源:丁香园(mediocrebeing, rodger, lylover , klaus, oldfish, yzwpf)</p>
<p><a href="http://www.wumii.com/item/dr005pgc">22</a></p>
<p>无觅猜您也喜欢：</p>
<p><a href="http://liucheng.name/603/" title="图文讲解MEGA4.1建进化树步骤"><img src="http://wumii-cc.wumii.cn/site_images/ti/6SPXZBmv.png?i=IkN1cfoI" alt="" /></a></p>
<p>图文讲解MEGA4.1建进化树步骤</p>
<p><a href="http://liucheng.name/612/" title="MEGA4的中文使用说明"><img src="http://wumii-cc.wumii.cn/site_images/ti/fO86xoNB.png?i=EBRfYZCy" alt="" /></a></p>
<p>MEGA4的中文使用说明</p>
<p><a href="http://liucheng.name/491/" title="phylip软件包建进化树"><img src="http://wumii-cc.wumii.cn/resources/images/related_item_default/21.jpg" alt="" /></a></p>
<p>phylip软件包建进化树</p>
<p><a href="http://liucheng.name/565/" title="COBALT：NCBI在线蛋白多序列比对（比ClustalW还强大的工具）"><img src="http://wumii-cc.wumii.cn/site_images/ti/cUtaNae8.jpg?i=tYpYK9hP" alt="" /></a></p>
<p>COBALT：NCBI在线蛋白多序列比对（比ClustalW还强大的工具）</p>
<p><a href="http://liucheng.name/515/" title="【生物信息学教程】5：分子进化"><img src="http://wumii-cc.wumii.cn/resources/images/related_item_default/56.jpg" alt="" /></a></p>
<p>【生物信息学教程】5：分子进化</p>
<p><a href="http://www.wumii.com/widget/relatedItems" title="无觅关联推荐">无觅关联推荐[?]</a></p>
<h3 id="有点相关的文章"><a class="markdownIt-Anchor" href="#有点相关的文章"></a> 有点相关的文章</h3>
<ul>
<li><a href="http://liucheng.name/565/">COBALT：NCBI在线蛋白多序列比对（比ClustalW还强大的工具）</a> (1.000)</li>
<li><a href="http://liucheng.name/603/">图文讲解MEGA4.1建进化树步骤</a> (1.000)</li>
<li><a href="http://liucheng.name/612/">MEGA4的中文使用说明</a> (1.000)</li>
<li><a href="http://liucheng.name/329/">LIUCHENG.NAME教程：如何把clusterX的结果转为漂亮的图片</a> (0.537)</li>
<li><a href="http://liucheng.name/347/">图解：如何在NCBI上找到HNF-4基因第4个外显子的序列</a> (0.537)</li>
<li><a href="http://liucheng.name/517/">【生物信息学教程】6.2：人类和鼠类公共物理图谱数据库的使用</a> (RANDOM - 0.500)</li>
</ul>
]]></content>
      <categories>
        <category>Bioinformatics</category>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title>鼠标在谷歌浏览器中出现回滚现象</title>
    <url>/2016/10/27/%E9%BC%A0%E6%A0%87%E5%9C%A8%E8%B0%B7%E6%AD%8C%E6%B5%8F%E8%A7%88%E5%99%A8%E4%B8%AD%E5%87%BA%E7%8E%B0%E5%9B%9E%E6%BB%9A%E7%8E%B0%E8%B1%A1/</url>
    <content><![CDATA[<p>刚买不久的罗技M275无线鼠标，最近使用谷歌浏览器，用滑动鼠标滚轮使页面上下移动的时候总出现回滚现象。简直不能忍。 网上搜索之后，有人说是受潮了。我想有可能，因为之前鼠标一直放在干燥的办公室中，最近确实带回家用过两天，广东的气候本来就潮湿，家里由于没有抽湿系统，东西十分容易受潮。于是用吹风机对着鼠标吹到发热，结果冷下来之后也没有解决问题。 我怀疑是不是几周前摔到地上摔坏了内部零件，想拆开鼠标看看，结果还不知道怎么拆，因为看不到螺丝孔。谷歌一搜索logitech M280（M275的升级款），首先看到有人在抱怨同样的问题，另外看到了Youtube上面有M280拆开的视频：原来拿下电池之后，有一张塑料标签纸，要把塑料标签纸揭掉，方才看到螺丝。于是顺利拆开，发现并无损坏。这下咋办，先放到实验室的硅胶干燥剂中干燥一下。过会儿拿出来组装完毕，问题仍然没有解决，鼠标滚轮依然有回滚现象。 只能继续在网上搜索一下，有人说是谷歌浏览器的设置问题，如下摘录的文字所示，进入特定的设置页面，将“平滑滚动 ”设置为关闭，马上就恢复正常了！</p>
<hr />
<p>参考：<a href="https://ii-i.org/archives/875">https://ii-i.org/archives/875</a> 在更新谷歌浏览器Chrome 49版本后，默认的是开启了平滑滚动功能的，这个平滑滚动有的朋友喜欢，有的朋友不喜欢，如果你需要停用平滑滚动功能，只需要在下面这个页面停用即可。 <code>chrome://flags/#disable-smooth-scrolling</code></p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>Notes | 更换硬盘之后 Hexo 博客重建，恢复博客，并切换到 Next 主题</title>
    <url>/2022/07/14/Notes-Reinstall-Hexo-and-how-to-set-up/</url>
    <content><![CDATA[<p>之前总结过 Hexo 架构的博客，即在本地撰写博客，都保存在 Hexo 目录下，然后使用 git desktop 软件推送博客到 github 的个人博客，就可以在网络访问。那么如果电脑重装，导致本地 Hexo 也需要重新配置，才能继续使用“推送”功能。现在记录配置的过程。</p>
<span id="more"></span>
<h3 id="重装系统之前注意备份本地的-hexo-目录"><a class="markdownIt-Anchor" href="#重装系统之前注意备份本地的-hexo-目录"></a> 重装系统之前注意备份本地的 Hexo 目录</h3>
<p>首先，最重要的一点：在重装系统之前，备份保存硬盘里 hexo 博客文件夹，就是 hexo 博客存储的文件夹。因为不知道哪些文件需要用，所以我把整个文件夹都保存下来。以下方法只适用于没有删除 hexo blog 文件夹。因为重装系统后，Hexo 相关依赖插件/软件和在C盘的缓存资料都会被删除，以至于Hexo的相关命令都无法运行。所有，在重装系统后，都要重新部署 Hexo。但是重新部署并不难，只需要几个步骤就行。因为我的 hexo blog 文件夹不存储于C盘，并没有因为重装系统被删掉。注：最关键的文档就是 Hexo/source/_posts 目录下面的 markdown 格式的博客文档。</p>
<h3 id="安装软件-git-和-nodejs"><a class="markdownIt-Anchor" href="#安装软件-git-和-nodejs"></a> 安装软件 git 和 Node.js</h3>
<p>git下载地址：git官网<br />
Node.js下载地址：Node.js官网</p>
<h3 id="配置-ssh-key并提交到-github-个人账户中"><a class="markdownIt-Anchor" href="#配置-ssh-key并提交到-github-个人账户中"></a> 配置 SSH Key，并提交到 github 个人账户中</h3>
<p>在 Git Bash 客户端，输入：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">git config --global user.name &quot;这里输入在GitHub的账户名&quot;</span><br><span class="line">git config --global user.email &quot;这里输入在GitHub的注册邮箱名&quot;</span><br><span class="line">ssh-keygen -t rsa -C &quot;这里输入在 GitHub 的注册邮箱&quot;</span><br></pre></td></tr></table></figure>
<p>接着在 Git Bash 客户端，输入命令行：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cat id_ras.pub</span><br></pre></td></tr></table></figure>
<p>这样会显示公钥文件内容，把它复制到剪贴板。</p>
<p>登录 GitHub 网站的个人账户，点击右上角个人头像的下拉菜单，依次点击 Settings &gt; SSH and GPG Keys，在 SSH Keys 页面右上角有个 New SSH Key 按钮，点击该按钮后，粘贴上刚才复制的公钥内容。这样，SSH Key 就配置好了。</p>
<p>思考：我当时按照这个配置的，但是忘记看一下重装之前的SSH Key是不是还在，是否有必要重新配置，下次重装时要看一下。</p>
<h3 id="3安装hexo"><a class="markdownIt-Anchor" href="#3安装hexo"></a> 3.安装hexo</h3>
<p>在 Git Bash 客户端输入:</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install hexo-cli -g</span><br></pre></td></tr></table></figure>
<h3 id="新建本地博客"><a class="markdownIt-Anchor" href="#新建本地博客"></a> 新建本地博客</h3>
<p>经过以上准备工作，我们就可以利用安装好的工具进行网站的搭建。网站的搭建基本可以分为两大步骤：通过Hexo生成静态网页文件和在Github Pages上进行部署。</p>
<p>现在电脑上选择一个合适的目录进行Hexo工程的初始化工作，这个目录是生成静态网页文件的关键，建议时常备份。我这里将目录选择为D:Hexo，在这个目录下点击鼠标右键，选择“Git Bash Here”，打开命令行终端，输入Hexo的初始化命令：“<code>hexo init</code>”，hexo 将会下载一些文件到这个目录中，见下示意图。</p>
<p>这里参考以前我新建 hexo 博客的步骤就行：<a href="https://genehub.wordpress.com/2020/12/07/%e4%bd%bf%e7%94%a8-github-hexo-%e5%bb%ba%e7%ab%8b%e4%b8%aa%e4%ba%ba%e5%8d%9a%e5%ae%a2/">https://genehub.wordpress.com/2020/12/07/使用-github-hexo-建立个人博客/</a></p>
<h3 id="更换渲染器"><a class="markdownIt-Anchor" href="#更换渲染器"></a> 更换渲染器</h3>
<p><font color=green>自 2020 年 12 月 7 日开始使用 Hexo 建立博客，设置主题为 maupassant，博客推送到 github，使用一直很方便。由于 2022 年 5 月份对电脑的硬盘升级，本地的 Hexo 需要重装，一直到 2022 年 7 月 14 日才开始处理，本来以为将原来备份的 Hexo 目录直接拷贝到新的硬盘就可以，哪知道不是这么简单。安装好 node.js 和 git 之后，要重新新建 Hexo，并设置主题。但是原来的 maupassant 主题已经无法使用了，所以新找了 NexT 主题也勉强可以用，只是默认的渲染工具不好用，我更换成了 hexo-renderer-markdown-it-plus。至此，新博客的架构已经搭建好，并且可以在本地用 localhost/4000 成功访问。将旧备份目录下的 markdown 格式的原始博文拷贝到 Hexo/source/_posts 目录下，就能看到。</font></p>
<p>Hexo 作为一个优秀的 Markdown 博客框架，自然也诞生了很多适用的 Markdown 渲染器，这里对比分析一下 Hexo 下几种常用的Markdown渲染器：hexo-renderer-marked，hexo-renderer-kramed，hexo-renderer-pandoc，hexo-renderer-markdown-it，hexo-renderer-markdown-it-plus，本文使用的渲染器为：hexo-renderer-markdown-it-plus。</p>
<p><s>修改 markdown 渲染器为 hexo-renderer-pandoc。值得注意的是需要将旧渲染器 marked 卸载掉再安装，另外系统中需要有 pandoc 这个软件来辅助转化。</s></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm un hexo-renderer-marked --save</span><br><span class="line">npm i hexo-renderer-pandoc --save   ###  非常难用！！！</span><br><span class="line">npm un hexo-renderer-pandoc --save</span><br><span class="line">npm i hexo-renderer-markdown-it-plus --save</span><br></pre></td></tr></table></figure>
<h3 id="添加博客关键词搜索器方便对文章进行检索"><a class="markdownIt-Anchor" href="#添加博客关键词搜索器方便对文章进行检索"></a> 添加博客关键词搜索器，方便对文章进行检索</h3>
<p>NexT 主题自带了一个搜索功能 Local Search，即在编译文件时本地生成一个数据库，放在网站根目录下，用户借助此数据库进行搜索查询。 安装：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb</span><br></pre></td></tr></table></figure>
<p>在 NexT 的配置文件中打开：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">local_search:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure>
<h3 id="切换新主题next"><a class="markdownIt-Anchor" href="#切换新主题next"></a> 切换新主题：NexT</h3>
<p>原计划用以前的主题 maupassant，结果这次安装不成功，寻找了一番之后发现 NexT 也比较符合我的要求。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># how to use next: https://theme-next.iissnan.com/getting-started.html</span><br><span class="line">git clone https://github.com/iissnan/hexo-theme-next themes/next</span><br></pre></td></tr></table></figure>
<p>next 主题自带四种样式。在主题配置文件/next/_config.yml中查找：scheme，找到如下代码。<br />
将默认的 Muse 注释掉，将 Pisces 取消注释。我觉得 Pisces 主题会将博客和目录信息列在左侧，看着顺眼一些。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Schemes</span><br><span class="line">#scheme: Muse</span><br><span class="line">#scheme: Mist</span><br><span class="line">scheme: Pisces</span><br><span class="line">#scheme: Gemini</span><br></pre></td></tr></table></figure>
<p>选择你喜欢的一种样式，去掉前面的 #，其他主题前加上 # 即可。</p>
<blockquote>
<p>注意：Hexo 目录下面有一个 <code>_config.yml</code> 文件，我们称其为“站点配置文件”；next 目录下面也有一个<code>_config.yml</code> 文件，我们称其为“主题配置文件”，通过这两个文件的修改可以对网站框架和细节进行诸多配置，要注意区分。</p>
</blockquote>
<h3 id="更换网站图标"><a class="markdownIt-Anchor" href="#更换网站图标"></a> 更换网站图标</h3>
<p>网站图标就是浏览器标签页显示的一个小 logo，比如谷歌就是彩色的字母 G，百度就是一个动物脚印。我设置为大写字母 F，并自己着色，存为 ico 格式，并有 16x16 和 32x32 两个尺寸。</p>
<p>将自己的图标置于 D:/Hexo/themes/next/images 下面。</p>
<p>修改 D:/Hexo/themes/next/_config.yml 文件。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">favicon:</span><br><span class="line">  #small: /images/favicon-16x16-next.png</span><br><span class="line">  small: /images/favicon16.ico</span><br><span class="line">  #medium: /images/favicon-32x32-next.png</span><br><span class="line">  medium: /images/favicon32.ico</span><br><span class="line">  apple_touch_icon: /images/apple-touch-icon-next.png</span><br><span class="line">  safari_pinned_tab: /images/logo.svg</span><br><span class="line">  #android_manifest: /images/manifest.json</span><br><span class="line">  #ms_browserconfig: /images/browserconfig.xml</span><br></pre></td></tr></table></figure>
<h3 id="在主页添加新栏目about-categories-tags"><a class="markdownIt-Anchor" href="#在主页添加新栏目about-categories-tags"></a> 在主页添加新栏目（about、categories、tags）</h3>
<p>Next 主题刚安装之后，会有 Home、Arichve 两个栏目。上面介绍启动 search 功能，多了一个 search 栏目。我想增加 About 栏目，作为作者的自我介绍，怎么做呢？</p>
<p>hexo的next创建关于我<br />
关于我创建步骤<br />
1、新建一个about页面,命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">hexo new page &quot;about&quot;</span><br></pre></td></tr></table></figure>
<p>在myBlog/source下会新生成一个新的文件夹about<br />
，在该文件夹下会有一个index.md文件</p>
<p>2、菜单显示about链接，在主题的 themes/next/_configy.yml 设置中将 menu中about前面的注释去掉</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">home: /</span><br><span class="line">archives: /archives/</span><br><span class="line">categories: /categories/</span><br><span class="line">tags: /tags/</span><br><span class="line">about: /about/</span><br></pre></td></tr></table></figure>
<p>一些其他设置：设置菜单项的显示文本和图标</p>
<p>NexT 使用的是 Font Awesome 提供的图标， Font Awesome 提供了 600+ 的图标，可以满足绝大的多数的场景，同时无须担心在 Retina 屏幕下图标模糊的问题。</p>
<p>设置菜单项的显示中文文本：</p>
<p>打开 themes/next/languages/zh-Hans.yml 文件,搜索 menu 关键字，修改对应中文或者新增。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">menu:</span><br><span class="line">  home: 首页</span><br><span class="line">  archives: 归档</span><br><span class="line">  categories: 分类</span><br><span class="line">  tags: 标签</span><br><span class="line">  about: 关于</span><br><span class="line">  search: 搜索</span><br><span class="line">  schedule: 日程表</span><br><span class="line">  sitemap: 站点地图</span><br><span class="line">  commonweal: 公益404</span><br><span class="line">  # 新增menu</span><br><span class="line">  catalogue: 目录</span><br></pre></td></tr></table></figure>
<p>设定菜单项的文件目录和对应图标（新版两项合并）。</p>
<p>打开 themes/next/_config.yml 文件，搜索 menu_icons 关键字，修改对应图标名称或者新增对应 menu 的图标。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># ---------------------------------------------------------------</span><br><span class="line"># Menu Settings</span><br><span class="line"># ---------------------------------------------------------------</span><br><span class="line"></span><br><span class="line"># When running the site in a subdirectory (e.g. domain.tld/blog), remove the leading slash from link value (/archives -&gt; archives).</span><br><span class="line"># Usage: `Key: /link/ || icon`</span><br><span class="line"># Key is the name of menu item. If translate for this menu will find in languages - this translate will be loaded; if not - Key name will be used. Key is case-senstive.</span><br><span class="line"># Value before `||` delimeter is the target link.</span><br><span class="line"># Value after `||` delimeter is the name of FontAwesome icon. If icon (with or without delimeter) is not specified, question icon will be loaded.</span><br><span class="line">menu:</span><br><span class="line">  home: / || home</span><br><span class="line">  archives: /archives/ || history</span><br><span class="line">  categories: /categories/ || list</span><br><span class="line">  tags: /tags/ || tags</span><br><span class="line">  tools: /categories/工具资源/ || briefcase</span><br><span class="line">  about: /about/ || user</span><br><span class="line">  #schedule: /schedule/ || calendar</span><br><span class="line">  #sitemap: /sitemap.xml || sitemap</span><br><span class="line">  #commonweal: /404/ || heartbeat</span><br><span class="line"></span><br><span class="line"># Enable/Disable menu icons.</span><br><span class="line"># Icon Mapping:</span><br><span class="line">#   Map a menu item to a specific FontAwesome icon name.</span><br><span class="line">#   Key is the name of menu item and value is the name of FontAwesome icon. Key is case-senstive.</span><br><span class="line">#   When an question mask icon presenting up means that the item has no mapping icon.</span><br><span class="line">menu_icons:</span><br><span class="line">  enable: true</span><br></pre></td></tr></table></figure>
<p>除了 home， archives , / 后面都需要手动创建这个页面</p>
<p>2.3 创建菜单项对应文件目录,以分类为例<br />
在终端窗口下，定位到 Hexo 站点目录下。使用 hexo new page 新建一个页面，命名为 categories ：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cd your-hexo-site</span><br><span class="line">$ hexo new page categories</span><br></pre></td></tr></table></figure>
<p>编辑刚新建的页面,设置分类</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">---</span><br><span class="line">title: 分类</span><br><span class="line">date: 2014-12-22 12:39:04</span><br><span class="line">categories: Testing #分类名</span><br><span class="line">type: &quot;categories&quot;</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<h3 id="使用技巧主页显示文章摘要方法"><a class="markdownIt-Anchor" href="#使用技巧主页显示文章摘要方法"></a> 使用技巧：主页显示文章摘要方法</h3>
<p>我发现使用 Next 主题的时候，博客主页会显示整个博文，而不是像之前的 maupassant 主题那中自动摘取博文的前一部分作为摘要。那么如何设置显示摘要呢？探索一番发现在 config 文件是没法设置的，要手动去每篇博文的 markdown 文件添加分隔符 <code>&lt;!--more--&gt;</code> 进行手动截断。当然也可以添加其他元素，比如 description，由于我没用到，这里不做记录。</p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p><a href="https://theme-next.iissnan.com/getting-started.html">Hexo 博客 NexT 主题的安装</a><br />
<a href="http://home.ustc.edu.cn/~liujunyan/blog/hexo-next-theme-config/">Hexo 博客 NexT 主题的安装使用</a><br />
<a href="https://zhuanlan.zhihu.com/p/30836436">Hexo 博客 NexT 主题对菜单栏的设置</a><br />
<a href="https://www.jianshu.com/p/e4330a081030">Hexo 博客 NexT 主题下创建“About”页面——作者介绍页</a><br />
<a href="https://blog.51cto.com/u_15065852/4264634">Hexo 博客 NexT 主题下如何添加分类、标签</a><br />
<a href="https://bugwz.com/2019/09/17/hexo-markdown-renderer/#%E4%B8%80-%E5%BC%95%E8%A8%80">Hexo 的多种 Markdown 渲染器对比分析</a></p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>Notes | 群晖 Synology NAS 新硬盘的安装</title>
    <url>/2022/06/10/NAS-adding-new-harddisks-20220608/</url>
    <content><![CDATA[<p>新买一个 8 TB 硬盘，需要插入群晖 NAS 的空盘位，并且作为独立的一个存储空间用来备份文件，跟之前的两个存储空间不影响。</p>
<span id="more"></span>
<p>这篇文章很好：<a href="http://blog.kungge.com/p/nas-disk/">http://blog.kungge.com/p/nas-disk/</a>，他介绍了“物理硬盘-存储池-存储空间-共享文件夹”这个四层逻辑，帮助我们理解 NAS 的系统结构和存储逻辑。</p>
<p>新增硬盘步骤简述：</p>
<ol>
<li>
<p>关闭NAS - 插入新硬盘 - 再次开机</p>
</li>
<li>
<p>增加存储池</p>
</li>
</ol>
<p>主菜单 - 存储管理器 - “HDD/SDD” - 增加硬盘 - shr模式</p>
<p>此时在存储管理器能见到一个新的存储池，名为“存储池3”，但是在系统文件夹（File Station）页面还没入口往里面存数据。</p>
<ol start="3">
<li>新建存储空间</li>
</ol>
<p>主菜单 - 存储管理器 - “新增” - 创建存储空间 - 选择刚才新增的那个存储池 - “Brtfs文件系统”（是不是选ext4文件系统也可？），会见到需要填写存储池大小，我就选了最大化，即将刚才新增的硬盘全部用于这个存储空间，此时就在“存储池3”下面见到“存储空间3”，但是在系统文件夹（File Station）页面还没入口往里面存数据。</p>
<ol start="4">
<li>创建共享文件夹</li>
</ol>
<p>主菜单 - 控制面板 - 共享文件夹 - “新增” - 命名，比如“my-data-disk3”就可以了。</p>
]]></content>
      <categories>
        <category>Notes</category>
      </categories>
  </entry>
  <entry>
    <title>Python IDE： Spyder 的安装与使用</title>
    <url>/2022/07/31/Python-IDE-Spyder/</url>
    <content><![CDATA[<p>工作中大量用到 R 画图，R 的 IDE 是 RStudio， 用得非常习惯，越用越喜欢，在想Python有没有IDE呢，一查发现 RStudio 可以直接作为 Python 的 IDE，竟然一直没发现。不过试用了一下感觉不好用。又经网友指路找到 Spyder，这个好用。 ​​​</p>
<span id="more"></span>
<p>Spyder 的默认界面如下，其实与 RStudio 很相似，甚至可以在 “View - Windows layouts” 菜单里面直接设置为 Rstudio 风格。</p>
<p><img src="https://raw.githubusercontent.com/spyder-ide/spyder/5.x/img_src/screenshot.png" alt="" /><br />
<img src="https://wx3.sinaimg.cn/large/65ba09d9gy1h45pxxoglyj217n0t3wsy.jpg" alt="" /></p>
<p>怎么安装 Spyder 呢？需要先安装 Anaconda 3. 去Anaconda 官网下载 wondows 版本，然后安装即可。安装好之后就是下面的界面。</p>
<p><img src="https://cdn-images-1.medium.com/max/2000/1*8VwF5RUh4vEf4FfrKMw7qg.png" alt="" /></p>
<p>然后在 Anaconda 界面下直接安装 Spyder，感觉跟 CytoScape 安装 App 是类似的操作。</p>
<p>下次打开 Spyder，可以直接在 Windows 桌面的搜索框检索 “Spyder” 即可。</p>
<p><strong>网路教程</strong></p>
<p>检索资料的过程中找到一个厦门大学图书馆的中文pdf格式教程，比较细心的介绍了Anaconda和Spyder，但是超链接似乎没法显示。</p>
<center><embed src="https://library.xmu.edu.cn/__local/3/30/15/EAA09B3D9ACCA198730A19458EB_7E777360_3AC94C.pdf?e=.pdf" width="850" height="600"></center>
<p><strong>参考资料</strong></p>
<ol>
<li><a href="https://www.zhihu.com/question/30722156">知乎：Python有没有一个类似RStudio一样的IDE？</a></li>
<li><a href="https://www.bilibili.com/video/BV1xp4y1Y7N5">哔哩哔哩: 介绍Spyder （Python IDE）by GANYU WANG</a></li>
<li><a href="https://library.xmu.edu.cn/__local/3/30/15/EAA09B3D9ACCA198730A19458EB_7E777360_3AC94C.pdf?e=.pdf">Anaconda 安装以及Spyder使用 - 厦门大学图书馆</a></li>
<li><a href="https://blog.csdn.net/RObot_123/article/details/103019588">CSDN 博客：安装 Anaconda3 Python3.6 Spyder3 详细教程</a></li>
</ol>
]]></content>
      <categories>
        <category>Python</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo：再记基因的正向选择分析</title>
    <url>/2022/08/16/positive-selection-of-orthologous-genes/</url>
    <content><![CDATA[<p>去年做的分析现在回去看有点记不清了，重温正向选择分析。多个基因组（比如A、B、C、D、E 这五个物种）的比较分析，假如有 5000 个单拷贝同源基因（single-copy orthologous），怎么找出哪些基因在 A 物种具有正向选择呢？</p>
<span id="more"></span>
<h3 id="简要的流程之前的笔记已经纪录过这里再总结一次"><a class="markdownIt-Anchor" href="#简要的流程之前的笔记已经纪录过这里再总结一次"></a> 简要的流程（之前的笔记已经纪录过，这里再总结一次。）</h3>
<ol>
<li>
<p>鉴定单拷贝基因。先整理各个物种的蛋白序列、CDS 序列和gff 文件，然后运行 OrthoFinder 流程。</p>
</li>
<li>
<p>单拷贝基因的序列比对。对于每一个单拷贝基因，用蛋白序列做比对，然后基于蛋白序列的比对情况将 DNA 序列比对，这个过程叫做 codon alignment，并且可以借助工具去掉 gaps，最后得到 PAML 格式的比对结果。这一步我主要参考了 <a href="doi.org/10.1007/978-1-4939-1438-8_4">Jeffares et al</a> ，它介绍了 PAL2NAL 这样便捷的 codon alignment 工具，同时其附件甚至有提供 demo data 和  paml 程序的 <a href="https://static-content.springer.com/esm/chp%3A10.1007%2F978-1-4939-1438-8_4/MediaObjects/217442_2_En_4_MOESM1_ESM.pdf">Jeffares et al 示范代码</a>。另外，这里涉及到几千个单拷贝基因的分别比对，我是使用 shell 脚本的循环功能来完成的，需要结合工作目录保存的脚本。</p>
</li>
<li>
<p>使用 PAML 程序下面的 codeml 命令来计算正向选择。简单提一下原理，涉及到统计学知识，我们最初的问题是“某单拷贝基因在指定的物种有没有经历正向选择”，那么先假设没有正向选择（null model），计算似然值（likelihood value）lnL0；再假设有正向选择（alternative model），计算似然值 lnL1；然后用卡方检验计算 lnL0 与 lnL1 的差异显著性，如果小于 0.05，那么假设是成立的，认为基因经历了正向选择。</p>
</li>
</ol>
<p>上面步骤 3 的 codeml 由于参数比较多，初看上去很费脑。下面先贴上我自己用到的两个 codeml 配置文件。</p>
<p><strong>Null model:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># cat codeml-branch_site_model_A_null.ctl</span><br><span class="line">      seqfile = all_aligned_codon.paml      * sequence data filename</span><br><span class="line">     treefile = unrooted_tree_5.txt      * tree structure file name</span><br><span class="line">      outfile = legume_genes.branch_site_model_A_null.mcl           * main result file name</span><br><span class="line">      runmode = 0  * 0: user tree;  1: semi-automatic;  2: automatic</span><br><span class="line">                   * 3: StepwiseAddition; (4,5):PerturbationNNI; -2: pairwise</span><br><span class="line">      seqtype = 1  * 1:codons; 2:AAs; 3:codons--&gt;AAs</span><br><span class="line">    CodonFreq = 2  * 0:1/61 each, 1:F1X4, 2:F3X4, 3:codon table</span><br><span class="line">        ndata = 3197 * number of gene alignments to be analysed 注意这里的数字，如果设置有误，最后也会报错</span><br><span class="line">        clock = 0  * 0:no clock, 1:clock; 2:local clock; 3:CombinedAnalysis</span><br><span class="line">        model = 2  * models for codons: 0:one, 1:b, 2:2 or more dN/dS ratios for branches</span><br><span class="line">      NSsites = 2  * 0:one w;1:neutral;2:selection; 3:discrete;4:freqs;</span><br><span class="line">                   * 5:gamma;6:2gamma;7:beta;8:beta&amp;w;9:beta&amp;gamma;</span><br><span class="line">                   * 10:beta&amp;gamma+1; 11:beta&amp;normal&gt;1; 12:0&amp;2normal&gt;1;</span><br><span class="line">                   * 13:3normal&gt;0</span><br><span class="line">        icode = 0  * 0:universal code; 1:mammalian mt; 2-10:see below</span><br><span class="line">    fix_omega = 1  * 1: omega or omega_1 fixed, 0: estimate </span><br><span class="line">        omega = 1  * initial or fixed omega, for codons or codon-based AAs</span><br><span class="line">    cleandata = 0  * remove sites with ambiguity data (1:yes, 0:no)?</span><br><span class="line">* Genetic codes: 0:universal, 1:mammalian mt., 2:yeast mt., 3:mold mt.,</span><br><span class="line">* 4: invertebrate mt., 5: ciliate nuclear, 6: echinoderm mt., </span><br><span class="line">* 7: euplotid mt., 8: alternative yeast nu. 9: ascidian mt., </span><br><span class="line">* 10: blepharisma nu.</span><br><span class="line">* These codes correspond to transl_table 1 to 11 of GENEBANK.</span><br></pre></td></tr></table></figure>
<p><strong>Alternative model:</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#cat codeml-branch_site_model_A.ctl</span><br><span class="line">      seqfile = all_aligned_codon.paml      * sequence data filename</span><br><span class="line">     treefile = unrooted_tree_5.txt      * tree structure file name</span><br><span class="line">      outfile = legume_genes.branch_site_model_A.mcl           * main result file name</span><br><span class="line">      runmode = 0  * 0: user tree;  1: semi-automatic;  2: automatic</span><br><span class="line">                   * 3: StepwiseAddition; (4,5):PerturbationNNI; -2: pairwise</span><br><span class="line">      seqtype = 1  * 1:codons; 2:AAs; 3:codons--&gt;AAs</span><br><span class="line">    CodonFreq = 2  * 0:1/61 each, 1:F1X4, 2:F3X4, 3:codon table</span><br><span class="line">        ndata = 3195 * number of gene alignments to be analysed</span><br><span class="line">        clock = 0  * 0:no clock, 1:clock; 2:local clock; 3:CombinedAnalysis</span><br><span class="line">        model = 2  * models for codons: 0:one, 1:b, 2:2 or more dN/dS ratios for branches</span><br><span class="line">      NSsites = 2  * 0:one w;1:neutral;2:selection; 3:discrete;4:freqs;</span><br><span class="line">                   * 5:gamma;6:2gamma;7:beta;8:beta&amp;w;9:beta&amp;gamma;</span><br><span class="line">                   * 10:beta&amp;gamma+1; 11:beta&amp;normal&gt;1; 12:0&amp;2normal&gt;1;</span><br><span class="line">                   * 13:3normal&gt;0</span><br><span class="line">        icode = 0  * 0:universal code; 1:mammalian mt; 2-10:see below</span><br><span class="line">    fix_omega = 0  * 1: omega or omega_1 fixed, 0: estimate </span><br><span class="line">        omega = 1.5 * initial or fixed omega, for codons or codon-based AAs</span><br><span class="line">    cleandata = 0  * remove sites with ambiguity data (1:yes, 0:no)?</span><br><span class="line">* Genetic codes: 0:universal, 1:mammalian mt., 2:yeast mt., 3:mold mt.,</span><br><span class="line">* 4: invertebrate mt., 5: ciliate nuclear, 6: echinoderm mt., </span><br><span class="line">* 7: euplotid mt., 8: alternative yeast nu. 9: ascidian mt., </span><br><span class="line">* 10: blepharisma nu.</span><br><span class="line">* These codes correspond to transl_table 1 to 11 of GENEBANK.</span><br></pre></td></tr></table></figure>
<h3 id="记录几个要点"><a class="markdownIt-Anchor" href="#记录几个要点"></a> 记录几个要点</h3>
<ol>
<li>
<p>Null model 的参数是“model=2, NSsites=2, fix_omega=1, omega=1”；而 Alternative model 的参数只需要将上一步的 fix_omega 改成 0，即可以改成“model=2, NSsites=2, fix_omega=0, omega=1.5”。（这个步骤，我参考了几个资料，后面会逐个列出。）</p>
</li>
<li>
<p>model 和 NSsites 是 codeml 程序中最重要的两个参数。在<a href="https://static-content.springer.com/esm/chp%3A10.1007%2F978-1-4939-1438-8_4/MediaObjects/217442_2_En_4_MOESM1_ESM.pdf">Jeffares et al 示范代码</a>中，作者说“ The two most important options are model and NSsites. The first option tells CODEML whether ω should be allowed to vary among branches in the tree, and the second option tells CODEML whether ω should be allowed to vary among sites.” model 为 0 的时候，认为不同分支具有相同的 ω；NSsites 为 0，认为不同的位点具有相同的 ω。作者示例演示将 model 和 NSsites 均设置为 0，计算 3261 个单拷贝基因分别在 6 个物种的平均 ω 值（estimate average ω values (model M0) for each ortholog），这样就得到 3261 个 ω 值，绘制数值的分布图可知ω值基本都小于1，这是合理的，因为绝大多数基因就处于纯化选择（As discussed in the introduction, most sites in most proteins are under strong purifying selection and usually average ω &lt; 1.）。</p>
</li>
<li>
<p>Chenlianfu 的博客中也提到了正向选择基因鉴定方法，这与上面 Jeffares et al 的方法是一致的。Chenlianfu：“指定分化枝上的正选择基因鉴定方法，经过上一步初步鉴定后，设置 model = 2、NSsites = 2、fix_omega = 0、omega = 2.0 运行codeml命令（branch-site model A）；再设置 model = 2、NSsites = 2、fix_omega = 1、omega = 1 运行 codeml 命令（modified branch-site model A / null model）。进行这两种模型分析时，要求输入的树文件中对目标分化枝进行标注。对这两种模型进行 LRT 分析，计算 2Δl = 2(l1-l0)，注意是前者的似然值减后者（null model）的似然值；再使用自由度为 1 的卡方检验，通过命令“chi2 1 2Δl”计算出的值再除以 2，即得到 p 值。”</p>
</li>
<li>
<p>注意在位点模型时，即 model = 0，此时 NSsites 可以同时设置多个数值，例如 NSsites = 0 1 2 7 8。意义是什么？在我之前的笔记中有“PAML 分析四大模型”章节专门记录。M1a (NSsites=1)与 M2a (NSsites=2)是一对；M7 (NSsites=7) 与 M8 (NSsites=8) 也是一对。Chenlianfu 的<a href="http://www.chenlianfu.com/?p=3036">博文</a>中提到 M7 与 M8 参数更宽松，将得到更多结果。这个可以用于初步分析担某基因是否存在正向选择，不限定某个进化枝。</p>
</li>
<li>
<p><a href="https://doi.org/10.1093%2Fgbe%2Fevx056">Feng et al</a> 研究 3R-MYB 基因家族的进化时，分析了 3R-MYB 的 dS 值（synonymous substitutions per synonymous site，同义替换率，也可记作 Ks），方法为：PAML v. 4.8a (Yang 2007) was used on the nucleotide alignments described in the positive selection test (above) to calculate pairwise synonymous distances (dS, synonymous substitutions per synonymous site) with one ratio model (M0)。M0 指的是 [NSsites=0]，pairwise synonymous distances 指的是 [runmodel=-2]。我用自己的数据做个测试，看看得到结果是怎么样的。注意 M0 的意思是“假设所有位点具有相同的 dN/dS 值”。假设基因突变的速率是一定的，同义突变不会导致氨基酸的变化，那么同源基因之间随着植物漫长的进化将逐渐积累同义突变，因此同义突变率可以反映出两个基因分开的时间。基因家族分析中，假设有数百个基因，可以分别计算 dS 值，然后对 dS 值做分布图，并且还可以对 dS 的分布做正态拟合，看看分布规律，作者原文描述为“Normal distributions were fit to the dS distributions of the six groups.”。</p>
</li>
</ol>
<center>
<img src="https://i.imgur.com/1ioOGTD.jpeg" width=500 />
</center>
<center>
<img src="https://i.imgur.com/K8fUb0A.jpeg" width=500 />
</center>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料：</h3>
<ol>
<li><a href="https://static-content.springer.com/esm/chp%3A10.1007%2F978-1-4939-1438-8_4/MediaObjects/217442_2_En_4_MOESM1_ESM.pdf">Jefares et al., “A worked example of estimating ω and testing for adaptive evolution in six parasite species”, filetype: PDF</a></li>
<li><a href="http://www.chenlianfu.com/?p=3036">陈连福：指定分化枝上的正选择基因鉴定方法</a></li>
<li><a href="https://www.bilibili.com/video/BV1Qx411m7Bn">Bilibili：PAML 视频教程 利用 codeml 计算 dN/dS</a></li>
</ol>
]]></content>
      <categories>
        <category>Bioinfo</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | 时间序列分析</title>
    <url>/2022/08/29/Time-Series-Clustering/</url>
    <content><![CDATA[<p>在转录组或蛋白组实验中，如果涉及到以时间为序的多组样品，基因的表达谱会随时间变化，依据算法将相似表达模式的基因聚类，则称之为时间序列分析（Time Series Clustering, or Time Course Clustering）。对于转录组数据的分析，最常见的手段是差异基因表达（Differentially expressed genes），一般设定 fold change 阈值为 1.5 或者 2，P value 阈值为 0.05，这种筛选方法并不是适用所有实验设计，比如在某个处理下，植物基因缓慢提高，呈现 1, 1.1, 1.3, 1.5, 1.8 这样的趋势，这种情况下时间序列分析可以找出这些基因。</p>
<span id="more"></span>
<h3 id="从一篇文章案例谈起"><a class="markdownIt-Anchor" href="#从一篇文章案例谈起"></a> 从一篇文章案例谈起</h3>
<p>下面这张图来自 2014 年发表在 Nature Biotechnology 杂志的一篇文章《<a href="https://www.nature.com/articles/nbt.3019">Comparative analyses of C<sub>4</sub> and C<sub>3</sub> photosynthesis in developing leaves of maize and rice</a>》。作者将玉米与水稻的叶片分成若干段，并分别做转录组测序，针对叶片分段开展聚类分析，将类别定义为 K。设定 K 为 50，并采用 K-means 算法进行聚类，再计算各个类别之间的相关系数，如果两个类的相关系数大于 0.9 则合并之，最终得到 30 个 clusters，如下图一；对每个 clusters 进行功能富集分析，发现其中四个包含作者感兴趣的光合作用，如图二。（原文：<a href="https://www.nature.com/articles/nbt.3019#Sec11"><strong>Co-clustering the fitted maize and rice gene expressions</strong></a> After establishing the unified gradients, U and V, we fit the expression patterns, , and using gene expressions Xg and Yh for each gene μ of maize and each gene h of rice, respectively. Before clustering, genes with no clearly defined expression patterns were removed because these genes are of much less interest in the scope of our study due to low expression and/or their noisy nature. Genes whose correlations between observed patterns and fitted ones are &gt;0.6 are kept in the cluster analysis. To obtain data vectors to cluster the expression patterns of all selected maize and rice genes, we took N = 15 points on the fitted expression profiles for each gene. These points correspond to the same N equally spaced gradients. Hence, only the region shared between maize and rice observed profiles is used for cluster analysis. A hybrid hierarchical clustering algorithm was used for the cluster analysis. First we performed K-means clustering based on Pearson correlation with K = 50 (Supplementary Fig. 11). We then merged two clusters with highest correlation based on average linkage at a time. We stopped the merging when none of any two different clusters had an average correlation above 0.9. We obtained K = 30 clusters for the final result (Supplementary Fig. 3).）</p>
<center>
<img src="https://i.imgur.com/R8Sd89M.jpeg" width=600 />
</center>
<center>
<img src="https://i.imgur.com/6B8UxIQ.jpeg" width=600 />
</center>
<h3 id="常用时间序列分析工具"><a class="markdownIt-Anchor" href="#常用时间序列分析工具"></a> 常用时间序列分析工具</h3>
<p>上面的文章案例中对时间序列分析采用的是 K-means 聚类算法（hard clustering），但是我看后来其他文献中用 Fuzzy C-means 聚类算法（soft clustering）的比较多。目前最常见的软件是 Mfuzz（2007年至2022年被引用次数：677），另外 TCseq 也同样可用（2019年至2022年被引用次数：33），这两个软件都有 R 包，比较持续的更新以及相应的 demo，使用还是比较方便的。</p>
<p>Mfuzz 要求的输入文件是 RPKM 这样的基因表达值，对于转录组测序常见的生物学重复，需要自己先计算平均值，做成下文的 Mfuzz 输入文件。TCseq 要求的输入文件是基因的 read counts，样品分组信息，以及基因的 start &amp; end 信息，该程序包会自动进行基因表达值的计算。</p>
<h3 id="mfuzz-操作示范"><a class="markdownIt-Anchor" href="#mfuzz-操作示范"></a> Mfuzz 操作示范</h3>
<p>对于 Mfuzz 软件的操作，已有博主做了很好的中文总结，比如《<a href="https://cloud.tencent.com/developer/article/1845577">小明的数据分析——使用 R 语言的 Mfuzz 包进行基因表达的时间趋势分析并划分聚类群</a>》</p>
<p><a href="https://www.sciencedirect.com/science/article/pii/S2211124717317953?via%3Dihub">Gao et al. (2017)</a> 基于蛋白质谱的方法，研究了小鼠胚胎着床前发育过程中的蛋白质组。共涉及了 6 个发育阶段，受精卵（Zygote）、二分胚（2-cell）、四分胚（4-cell）、八分胚（8-cell）、桑葚胚（Morula）和囊胚（Blastocyst）。为了将蛋白质功能与胚胎发育相结合，作者首先表征了蛋白质丰度与胚胎发育阶段的时间关系，根据所有蛋白质在每个阶段的丰度信息，通过 Mfuzz 包对这些蛋白质执行了时间序列的聚类。最终获得了 10 组聚类群（即 10 组蛋白群），代表了胚胎蛋白质的 10 种动力学模式，并在随后对这 10 组蛋白群的丰度变化与其功能展开了更细致的讨论（如基因集富集分析，蛋白网络分析等）。所示的蛋白质表达矩阵文件内容如下，第一列为蛋白质名称，随后几列依次为这些蛋白质在小鼠受精卵（Zygote）、二分胚（2-cell）、四分胚（4-cell）、八分胚（8-cell）、桑葚胚（Morula）和囊胚（Blastocyst）时期的相对丰度数值。Gao et al. (2017) 的蛋白质表达矩阵表格可以在原文献的补充材料 <a href="https://www.cell.com/cms/10.1016/j.celrep.2017.11.111/attachment/bc1eedf3-89d1-473f-9b66-b44a17994029/mmc2.xlsx">Table S1</a> 中自行下载（Excel表格中，Sheet名称为“union_all_protein_exp_cluster”）。</p>
<center>
<img src="https://i.imgur.com/gU6Nhi5.png" width=600 />
</center>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#使用 Bioconductor 安装 Mfuzz 包</span><br><span class="line">#install.packages(&#x27;BiocManager&#x27;)</span><br><span class="line">#BiocManager::install(&#x27;Mfuzz&#x27;)</span><br><span class="line"> </span><br><span class="line">#加载 Mfuzz 包</span><br><span class="line">library(Mfuzz)</span><br><span class="line"> </span><br><span class="line">#读取矩阵表格，在我网盘中，示例数据为“mmc2.union_all_protein_exp.txt”</span><br><span class="line">#该示例中，行为基因或蛋白名称，列为时间样本（按时间顺序提前排列好，若存在生物学重复需提前取均值）</span><br><span class="line">protein &lt;- read.delim(&#x27;mmc2.union_all_protein_exp.txt&#x27;, row.names = 1, check.names = FALSE)</span><br><span class="line">protein &lt;- as.matrix(protein)</span><br><span class="line"> </span><br><span class="line">#构建对象</span><br><span class="line">mfuzz_class &lt;- new(&#x27;ExpressionSet&#x27;,exprs = protein)</span><br><span class="line"> </span><br><span class="line">#预处理缺失值或者异常值</span><br><span class="line">mfuzz_class &lt;- filter.NA(mfuzz_class, thres = 0.25)</span><br><span class="line">mfuzz_class &lt;- fill.NA(mfuzz_class, mode = &#x27;mean&#x27;)</span><br><span class="line">mfuzz_class &lt;- filter.std(mfuzz_class, min.std = 0)</span><br><span class="line"> </span><br><span class="line">#标准化数据</span><br><span class="line">mfuzz_class &lt;- standardise(mfuzz_class)</span><br><span class="line"> </span><br><span class="line">#Mfuzz 基于 fuzzy c-means 的算法进行聚类，详情 ?mfuzz</span><br><span class="line">#需手动定义目标聚类群的个数，例如这里我们为了重现原作者的结果，设定为 10，即期望获得 10 组聚类群</span><br><span class="line">#需要设定随机数种子，以避免再次运行时获得不同的结果</span><br><span class="line">set.seed(123)</span><br><span class="line">cluster_num &lt;- 10</span><br><span class="line">mfuzz_cluster &lt;- mfuzz(mfuzz_class, c = cluster_num, m = mestimate(mfuzz_class))</span><br><span class="line"> </span><br><span class="line">#作图，详情 ?mfuzz.plot2</span><br><span class="line">#time.labels 参数设置时间轴，需要和原基因表达数据集中的列对应</span><br><span class="line">#颜色、线宽、坐标轴、字体等细节也可以添加其他参数调整，此处略，详见函数帮助</span><br><span class="line">mfuzz.plot2(mfuzz_class, cl = mfuzz_cluster, mfrow = c(2, 5), time.labels = colnames(protein))</span><br><span class="line"></span><br><span class="line">#查看每个聚类群中各自包含的蛋白数量</span><br><span class="line">cluster_size &lt;- mfuzz_cluster$size</span><br><span class="line">names(cluster_size) &lt;- 1:cluster_num</span><br><span class="line">cluster_size</span><br><span class="line"> </span><br><span class="line">#查看每个蛋白所属的聚类群</span><br><span class="line">head(mfuzz_cluster$cluster)</span><br><span class="line"> </span><br><span class="line">#Mfuzz 通过计算一个叫 membership 的统计量判断蛋白质所属的聚类群，以最大的 membership 值为准</span><br><span class="line">#查看各蛋白的 membership 值</span><br><span class="line">head(mfuzz_cluster$membership)</span><br><span class="line"></span><br><span class="line">#最后，提取所有蛋白所属的聚类群，并和它们的原始表达值整合在一起</span><br><span class="line">protein_cluster &lt;- mfuzz_cluster$cluster</span><br><span class="line">protein_cluster &lt;- cbind(protein[names(protein_cluster), ], protein_cluster)</span><br><span class="line">head(protein_cluster)</span><br><span class="line">write.table(protein_cluster, &#x27;protein_cluster.txt&#x27;, sep = &#x27;\t&#x27;, col.names = NA, quote = FALSE)</span><br><span class="line"> </span><br><span class="line">#如果您想提取数据分析过程中，标准化后的表达值（绘制曲线图用的那个值，而非原始蛋白表达值）</span><br><span class="line">protein_cluster &lt;- mfuzz_cluster$cluster</span><br><span class="line">protein_standard &lt;- mfuzz_class@assayData$exprs</span><br><span class="line">protein_standard_cluster &lt;- cbind(protein_standard[names(protein_cluster), ], protein_cluster)</span><br><span class="line">head(protein_standard_cluster)</span><br><span class="line">#write.table(protein_standard_cluster, &#x27;protein_standard_cluster.txt&#x27;, sep = &#x27;\t&#x27;, col.names = NA, quote = FALSE)</span><br></pre></td></tr></table></figure>
<center>
<img src="https://i.imgur.com/KcBEshg.png" width=600 />
</center>
<center>
<img src="https://i.imgur.com/FpLfDfh.png" width=600 />
</center>
<center>
<img src="https://i.imgur.com/VuEOnuQ.png" width=600 />
</center>
<h3 id="tcseq-操作示范"><a class="markdownIt-Anchor" href="#tcseq-操作示范"></a> TCseq 操作示范</h3>
<p>我在<a href="https://bioinfx.github.io/2021/09/16/Bioinfo-TCseq-Time-Course-sequencing-data-analysis/">自己的项目中</a>已经用过 TCseq，用这个的原因是当时找到了原作者撰写的 <a href="https://rdrr.io/bioc/TCseq/f/inst/doc/TCseq.pdf">demo 文档</a>，并且发现作者有保持更新，按照他们提供的代码操作能顺利得到结果。</p>
<p>下面的示例摘抄自《<a href="https://cloud.tencent.com/developer/article/1845579?from=article.detail.1845577">小明的数据分析笔记本——使用 R 语言的 TCseq 包分析基因表达的时间趋势并划分聚类群</a>》，通过一个涉及时间序列的蛋白质组学数据集，演示如何在 R 语言中使用 TCseq 包分析蛋白质表达的时间趋势，并根据时间表达模式的相似性实现聚类的过程。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#使用 Bioconductor 安装 TCseq 包</span><br><span class="line">#install.packages(&#x27;BiocManager&#x27;)</span><br><span class="line">#BiocManager::install(&#x27;TCseq&#x27;)</span><br><span class="line"> </span><br><span class="line">#加载 TCseq 包</span><br><span class="line">library(TCseq)</span><br><span class="line"> </span><br><span class="line">#以本示例的蛋白表达矩阵为例，行为基因或蛋白名称，列为时间样本</span><br><span class="line">#每一列是独立的时间单位，按时间顺序提前排列好，若存在生物学重复（即一个时间点对应多个样本时）建议提前取均值</span><br><span class="line">protein &lt;- read.delim(&#x27;protein_exp.txt&#x27;, row.names = 1, check.names = FALSE)</span><br><span class="line">protein &lt;- as.matrix(protein)</span><br><span class="line"> </span><br><span class="line">#聚类，详情 ?timeclust</span><br><span class="line">#algo 用于指定聚类方法，例如基于 fuzzy c-means 的算法进行聚类，此时需要设定随机数种子，以避免再次运行时获得不同的结果</span><br><span class="line">#k 用于指定期望获得的聚类群数量，例如这里预设为 10</span><br><span class="line">#standardize 用于 z-score 标准化变量</span><br><span class="line">set.seed(123)</span><br><span class="line">cluster_num &lt;- 10</span><br><span class="line">tcseq_cluster &lt;- timeclust(protein, algo = &#x27;cm&#x27;, k = cluster_num, standardize = TRUE)</span><br><span class="line"> </span><br><span class="line">#作图，详情 ?timeclustplot</span><br><span class="line">#颜色、线宽、坐标轴、字体等细节可以在函数中调整，具体参数详见函数帮助</span><br><span class="line">p &lt;- timeclustplot(tcseq_cluster, value = &#x27;z-score&#x27;, cols = 3, </span><br><span class="line">    axis.line.size = 0.6, axis.title.size = 8, axis.text.size = 8, </span><br><span class="line">    title.size = 8, legend.title.size = 8, legend.text.size = 8)</span><br><span class="line"> </span><br><span class="line">#上述获得了 10 组聚类群</span><br><span class="line">#如果绘制单个的聚类群，例如 cluster 2，直接在作图结果中输入下标选取</span><br><span class="line">p[2]</span><br></pre></td></tr></table></figure>
<center>
<img src="https://i.imgur.com/76tALVo.png" width=600 />
</center>
<p>提取各聚类群的样本或变量名称和数值：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#查看每个蛋白所属的聚类群，展示前几个为例</span><br><span class="line">head(tcseq_cluster@cluster)</span><br><span class="line"> </span><br><span class="line">#统计每个聚类群中各自包含的蛋白数量</span><br><span class="line">table(tcseq_cluster@cluster)</span><br><span class="line"> </span><br><span class="line">#上述聚类过程中，通过计算 membership 值判断蛋白质所属的聚类群，以最大的 membership 值为准</span><br><span class="line">#查看本次计算的各蛋白的 membership 值，展示前几个为例</span><br><span class="line">head(tcseq_cluster@membership)</span><br><span class="line"> </span><br><span class="line">#上述聚类过程中，我们在聚类函数 timeclust() 中指定了对蛋白表达值的 z-score 标准化</span><br><span class="line">#如果您想查看标准化后的表达值（也即绘制曲线图用的那个值，而非原始的蛋白表达值），展示前几个为例</span><br><span class="line">head(tcseq_cluster@data)</span><br><span class="line"> </span><br><span class="line">#啥？您若问原始的蛋白表达值在哪里看？一开始的输入数据就是啊......</span><br><span class="line"></span><br><span class="line">#最后，提取所有蛋白所属的聚类群，并和它们的原始表达值整合在一起</span><br><span class="line">protein_cluster &lt;- tcseq_cluster@cluster</span><br><span class="line">protein_cluster &lt;- cbind(protein[names(protein_cluster), ], protein_cluster)</span><br><span class="line">head(protein_cluster)</span><br><span class="line">write.table(protein_cluster, &#x27;protein_cluster.txt&#x27;, sep = &#x27;\t&#x27;, col.names = NA, quote = FALSE)</span><br></pre></td></tr></table></figure>
<center>
<img src="https://i.imgur.com/V5azlwI.png" width=600 />
</center>
<center>
<img src="https://i.imgur.com/VuEOnuQ.png" width=600 />
</center>
<h3 id="经验小结"><a class="markdownIt-Anchor" href="#经验小结"></a> 经验小结</h3>
<ol>
<li>时间序列分析不仅仅应用于以时间为序的样品，也可以用于不同浓度梯度处理的样品，比如梯度植物激素处理的植物；可用于植物的不同部位或器官；甚至不同的品种。</li>
<li>对于 clusters 的数目问题，Mfuzz 和 TCseq 都是手动设定，具有很大的主观性，设定太多会导致某些 clusters 很相近，设定太小会导致个别 clusters 的趋势不够一致。此时可参考本文案例中 NBT 那个文章，对 clusters 相互之间计算相关系数，如果大于 0.9 则可以合并。</li>
<li>对于同一批数据，用 TCseq 分析测试的时候，我发现多次运行同样的命令得到的结果有不同，首先是 cluster #1 #2 #3 这些 clusters 的顺序可能会变化；其次就是 clusters 包含的基因有细微差别（由于采用的是模糊聚类算法？）。这个现象在上文 Mfuzz 示例中有体现，复现 Cell Reports 文章的数据过程中，同样的 clusters 数目，那些 clusters 的顺序是不一样的，如果更进一步去比较 clusters 包含的基因 ID，可能也存在少许差别。所以分析过程中应该及时保存代码和导出数据结果表。</li>
<li>TCseq demo 文档里提到要求准备 gene counts 作为输入文件，从上面 TCseq 的示例来看，其实经过预先校正的 RPKM 表达值也是可以的。</li>
</ol>
<h3 id="如何自己绘制基因表达趋势图"><a class="markdownIt-Anchor" href="#如何自己绘制基因表达趋势图"></a> 如何自己绘制基因表达趋势图</h3>
<p>本文最开始引用的 NBT 杂志那个基因时序分析的基因表达趋势图怎么做？可以用 ggplot 来绘制，灰色线条是每一个基因单独的表达趋势，用 geom_line 即可；红色线条是基因平均值，用 geom_smooth 绘制。这个过程中麻烦一点的地方就是如何从基因 RPKM 表达值表格（下面代码中的 individual_cluster 数据框），转换成 ggplot 可以识别的数据框，需要先对 RPKM 做 Z-score 转换，再逐个基因转换成 ggplot 可读的数据格式，并对这若干个基因的数据合并（下面代码中的 df 数据框），同时还要对每个时间点的基因表达值计算平均值并转换成数据框（下面代码中的 k 数据框），基于 df 和 k 两个数据框即可画图，效果如下图所示。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#### 20220829 用Gao et al 的数据绘制个别clusters的基因趋势图</span><br><span class="line">library(ggplot2)</span><br><span class="line">library(dplyr)     # 筛选表格数据</span><br><span class="line">library(patchwork) # 如果需要拼图</span><br><span class="line">TenClusters &lt;- read.table(&quot;gao_et_al_protein_10_clusters_demo_data.txt&quot;, sep = &quot;\t&quot;, header = TRUE)</span><br><span class="line">head(TenClusters)</span><br><span class="line">individual_cluster &lt;- TenClusters %&gt;% filter(cluster==9)</span><br><span class="line">head(individual_cluster)</span><br><span class="line">#Gene_Name    zygote   X2.cell   X4.cell   X8.cell   morula blastocyst cluster</span><br><span class="line">#1      Rer1 0.8666539 0.8672568 0.8379625 0.9981545 1.043738   1.386234       9</span><br><span class="line">#2     Ckap2 0.8241345 0.8702265 1.0013516 0.9844172 1.001041   1.318829       9</span><br><span class="line">cluster.fpkm &lt;- individual_cluster[,2:7]</span><br><span class="line">#cluster1.fpkm</span><br><span class="line">row.names(cluster.fpkm) &lt;- individual_cluster[,1]</span><br><span class="line">colnames(cluster.fpkm) &lt;- c(1,2,3,4,5,6)</span><br><span class="line">b &lt;- cluster.fpkm</span><br><span class="line">c &lt;- data.matrix(b)</span><br><span class="line">d=t(c)</span><br><span class="line">e=scale(d, center=T, scale=T)   # 将 FPKM 计算 Z score</span><br><span class="line">zscore=t(e)                     # 回到行为基因，列为样品，的数据框</span><br><span class="line">f &lt;- data.frame(zscore)  ## colnames成了 X1 X2 X3 这样的格式, 下面手动命名为 1 2 3 这样</span><br><span class="line">colnames(f) &lt;- c(1,2,3,4,5,6)</span><br><span class="line">g = t(f)                 ## 又转置一次</span><br><span class="line">#&gt; head(f)</span><br><span class="line">#                1          2            3            4           5        6</span><br><span class="line">#Rer1   -0.6464415 -0.6435188 -0.785533163 -0.008946659 0.212036554 1.872404</span><br><span class="line">#Ckap2  -1.0164865 -0.7500791  0.007811928 -0.090067076 0.006016526 1.842804</span><br><span class="line">h &lt;- as.data.frame(g)</span><br><span class="line">head(h)</span><br><span class="line">df &lt;- data.frame(            # 将第一个基因单独制作成方便 ggplot 读取的格式，命名为数据框 df</span><br><span class="line">  time = c(1,2,3,4,5,6),</span><br><span class="line">  gene = names(h[1]),</span><br><span class="line">  zscore = h[1]</span><br><span class="line">)</span><br><span class="line">colnames(df) &lt;- c(&quot;time&quot;, &quot;gene&quot;, &quot;zscore&quot;)</span><br><span class="line">#</span><br><span class="line">for (i in 2:ncol(h)) &#123;</span><br><span class="line">  subdf &lt;- data.frame(</span><br><span class="line">    time = c(1,2,3,4,5,6),</span><br><span class="line">    gene = names(h[i]),</span><br><span class="line">    zscore = h[i]</span><br><span class="line">  )</span><br><span class="line">  colnames(df) &lt;- c(&quot;time&quot;, &quot;gene&quot;, &quot;zscore&quot;)</span><br><span class="line">  colnames(subdf) &lt;- c(&quot;time&quot;, &quot;gene&quot;, &quot;zscore&quot;)</span><br><span class="line">  df &lt;- union(df, subdf)   # 从第二个基因开始，依次合并到 df 数据框里面。</span><br><span class="line">  # 每个基因建立一个 Zscore 数据框，依次用数据框合并的方式，将所有基因的数据框合并。</span><br><span class="line">  colnames(df) &lt;- c(&quot;time&quot;, &quot;gene&quot;, &quot;zscore&quot;)</span><br><span class="line">&#125;</span><br><span class="line">#head(df)</span><br><span class="line">#&gt; head(df, n=20)</span><br><span class="line">#       time   gene       zscore</span><br><span class="line">#1...1     1   Rer1 -0.646441480</span><br><span class="line">#2...2     2   Rer1 -0.643518806</span><br><span class="line">#3...3     3   Rer1 -0.785533163</span><br><span class="line">#4...4     4   Rer1 -0.008946659</span><br><span class="line">#5...5     5   Rer1  0.212036554</span><br><span class="line">#6...6     6   Rer1  1.872403554</span><br><span class="line">#1...7     1  Ckap2 -1.016486464</span><br><span class="line">#2...8     2  Ckap2 -0.750079108</span><br><span class="line">#3...9     3  Ckap2  0.007811928</span><br><span class="line">#4...10    4  Ckap2 -0.090067076</span><br><span class="line">#5...11    5  Ckap2  0.006016526</span><br><span class="line">#6...12    6  Ckap2  1.842804194</span><br><span class="line">#1...13    1   Safb -0.759950153</span><br><span class="line">#2...14    2   Safb -0.874711572</span><br><span class="line">#3...15    3   Safb -0.071782045</span><br><span class="line">#4...16    4   Safb -0.298405705</span><br><span class="line">#5...17    5   Safb  0.121105813</span><br><span class="line">#6...18    6   Safb  1.883743663</span><br><span class="line"># ggplot() +   # 显示各个基因的表达趋势</span><br><span class="line">#   geom_line(data = df, aes(x=time, y=zscore, group=gene), colour=&quot;darkgrey&quot;, size=1) +</span><br><span class="line">#   ylim(-3,3) +</span><br><span class="line">#   theme_bw() +</span><br><span class="line">#   theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = &quot;black&quot;))</span><br><span class="line">#  计算不同基因的z score平均值，这样便可以画一个整体趋势线</span><br><span class="line">j &lt;- df %&gt;%   </span><br><span class="line">  group_by(time) %&gt;%</span><br><span class="line">  summarise(avg=mean(zscore))   # 计算每个时间点的数值平均值</span><br><span class="line">k &lt;- as.data.frame(j, stringsAsFactors=FALSE) # The stringsAsFactors=FALSE setting is important, do not omit.</span><br><span class="line">#&gt; head(k)</span><br><span class="line">#  time        avg</span><br><span class="line">#1    1 -0.8349276</span><br><span class="line">#2    2 -0.7264787</span><br><span class="line">#3    3 -0.4482506</span><br><span class="line">#4    4 -0.2034883</span><br><span class="line">#5    5  0.4347488</span><br><span class="line">#6    6  1.7783964</span><br><span class="line">#</span><br><span class="line">ggplot() +   # 显示各个基因的表达趋势，另外增加一个红色的总趋势线</span><br><span class="line">  geom_line(data = df, aes(x=time, y=zscore, group=gene), colour=&quot;darkgrey&quot;, size=0.7, alpha=0.5) +</span><br><span class="line">  geom_smooth(data = k, aes(x=time, y=avg), colour=&quot;red&quot;, size=1, se = FALSE, span=0.5) +</span><br><span class="line">  ylim(-2.5, 2.5) +</span><br><span class="line">  theme_bw() +</span><br><span class="line">  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_line(colour = &quot;black&quot;)) +</span><br><span class="line">  scale_x_continuous(breaks=c(1,2,3,4,5,6), labels = c(&quot;zygote&quot;, &quot;2-cell&quot;, &quot;4-cell&quot;, &quot;8-cell&quot;, &quot;morula&quot;, &quot;blastocyst&quot;)) +</span><br><span class="line">  theme(axis.text.x = element_text(size = 8, color = &quot;black&quot;)) +</span><br><span class="line">  theme(axis.text.y = element_text(size = 8, color = &quot;black&quot;)) +</span><br><span class="line">  ylab(&quot;Normalized expression&quot;) +</span><br><span class="line">  xlab(&quot;&quot;) +</span><br><span class="line">  theme(axis.title.x = element_text(size = 10)) +</span><br><span class="line">  theme(axis.title.y = element_text(size = 10)) +</span><br><span class="line">  theme(legend.position=&quot;none&quot;)</span><br></pre></td></tr></table></figure>
<center>
<img src="https://i.imgur.com/6M74QGg.jpeg" width=600 />
</center>]]></content>
      <categories>
        <category>Bioinfo</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | 如何向 NCBI 的 SRA 数据库提交 RNA seq 的原始数据（2022 年版本）</title>
    <url>/2022/09/20/Deposit-RNA-sequencing-data-to-NCBI-SRA-database/</url>
    <content><![CDATA[<p>在测序相关文章投稿的过程中，杂志社多要求作者将测序的原始数据提交到公开数据库（例如 NCBI 的 SRA 数据库），并获得一个数据编号，即 Accession Number。网络上有不少热心的同行分享关于 NCBI 提交数据的流程，比如<a href="http://www.bgitechsolutions.com/resources/95">某测序公司</a>和<a href="https://cloud.tencent.com/developer/article/1806824">某微信公众号</a>，但是 NCBI 的数据提交系统近年有做改版，流程跟前几年已经有所不同。这里做一个简单记录。</p>
<span id="more"></span>
<h3 id="ncbi-账号注册"><a class="markdownIt-Anchor" href="#ncbi-账号注册"></a> NCBI 账号注册</h3>
<p>打开 NCBI 主页 <a href="https://www.ncbi.nlm.nih.gov/">https://www.ncbi.nlm.nih.gov/</a>，直接点击登录，我以前的私人 email 注册过 NCBI，但是密码忘了，点击“忘记密码”都无法找回或重设密码，但是现在可以用第三方账号登录，所以我点击了“ORCID”，因为我已经注册过 ORCID，跟随 NCBI 网站引导输入 ORCID 的账户密码即可登录 NCBI。</p>
<h3 id="找到-sra-提交入口并创建一个新的-submission"><a class="markdownIt-Anchor" href="#找到-sra-提交入口并创建一个新的-submission"></a> 找到 SRA 提交入口并创建一个新的 submission</h3>
<p>打开NCBI主页 <a href="https://www.ncbi.nlm.nih.gov/">https://www.ncbi.nlm.nih.gov/</a>，并点击 submit。页面打开后，向下拉找到SRA，再点击 submit。进入 my submissions 页面，底部列表中可以看到过往提交的内容以及当前处理状态，没完成的任务也在里面。点击 new submit，跟着网页的引导继续填资料即可。</p>
<h3 id="1-submitter"><a class="markdownIt-Anchor" href="#1-submitter"></a> 1. Submitter</h3>
<p>如果第一次提交数据，系统先提醒认证个人信息，其中邮箱需要两个，在过去要求有一个必须是教育网 edu 的邮箱，现在似乎没有这个要求了。如果该账号以前提交过数据，那么系统会确认提交者个人信息是否正确并分配任务编号。检查无误，然后点击“continue”按钮往下一页。</p>
<p>如果以前提交过数据，则这一步的个人信息栏目无需再填.</p>
<p><img src="https://i.imgur.com/i3RCAMR.jpeg" alt="" /></p>
<h3 id="2-general-info"><a class="markdownIt-Anchor" href="#2-general-info"></a> 2. General info</h3>
<p>这一步是填写所提交数据是作为独立的一次实验数据，还是属于之前提交过的某个项目的子数据集，以及设定数据 release date（公开日期）。为了节省信息填报时间，项目和样品信息这里可以选NO，这些信息系统可以自动生成。数据 release date 按个人需求大概填写，该日期在数据提交完后还可以修改。然后点击“continue”按钮往下一页。</p>
<p><img src="https://i.imgur.com/ly0iS0o.png" alt="" /></p>
<h3 id="3-project-info"><a class="markdownIt-Anchor" href="#3-project-info"></a> 3. Project info</h3>
<p>这一步填写一个数据相关的标题和小结，类似于投文章的 title 和 abstract。带 * 的 Project title 和 description 简单填写。Relevance 根据自身研究内容选，我的数据是农业相关。其他内容暂不管。然后点击“continue”按钮往下一页。</p>
<p><img src="https://i.imgur.com/jWv2UXp.png" alt="" /></p>
<h3 id="4-biosample-type"><a class="markdownIt-Anchor" href="#4-biosample-type"></a> 4. Biosample type</h3>
<p>这里填写样品类型，是植物还是动物之类的。样品类型关系到后面需要下载和填写的信息，要看清楚。我的是植物样本，直接选了 plant，然后点击“continue”按钮往下一页。</p>
<p><img src="https://i.imgur.com/feV1xCL.png" alt="" /></p>
<h3 id="5-biosample-attributes"><a class="markdownIt-Anchor" href="#5-biosample-attributes"></a> 5. Biosample attributes</h3>
<p>这一步填写每个测序样本的信息以及相关属性。需要填写的信息较多，最好是本地做好表格再上传。先下载模版，按要求填好后再上传。注意：organism 的拉丁名一定要写对，否则可能需要至少2天才能改过来。如果不确定名称，可以去 NCBI 中搜索，确保准确。注意：每个样品不是依据样品名称的差异来区分的，而是利用多个属性组合把每个样品区分开。所以不能仅仅是样品名称不同，其他属性都相同，应该能填的属性多填几个，保证样品之间总有某个或多个属性不同，这样就能区分样品。具体填写可参考我的表格。如果上传不成功，系统会给错误提示。报错后，删除旧表，修改信息，重新传。上传完就 continue。</p>
<p><font face="Georgia" color=red>Note：这一步我就遇到了问题。按照网页下载的模板 Excel 文件，填写各个样品名称以及样品相关的信息（植物品种、提交人、处理信息等），然后在网页端上传，结果显示不通过。明明我填写的样品名字都是唯一的，没有冗余（如例 1 图所示），怎么会报错呢。原来是需要自己额外增加一个列，关于生物学重复的属性，列名为“replicate”，然后将各个样品的生物学重复信息填写，比如 biological replicate 1、biological replicate 2、biological replicate 3（如例 2 图所示）。</font></p>
<p><img src="https://i.imgur.com/ma2pMqi.png" alt="" /></p>
<p><img src="https://i.imgur.com/W0okDKR.png" alt="例 1" /></p>
<p><img src="https://i.imgur.com/aMsu9BN.jpeg" alt="例 2" /></p>
<h3 id="6-sra-metadata"><a class="markdownIt-Anchor" href="#6-sra-metadata"></a> 6. SRA metadata</h3>
<p>上一步已经填写了所有待提交的样品名，这一步就提交另一个表格：样品对应的文件名信息。先下载模版（SRA_metadata.xlsx），填好后上传。模板表格有三个 sheets，先看 sheet1 里的说明，然后再填 SRA_data 表中的信息。样品名称要和上一步表格中一致。可参考我的表格，我的是 ILLUMINA 平台双端测序的转录组数据，每个样品有两个压缩数据包，分别是 1 和 2，填在 filename 和 filename1 栏中。将 SRA_data 这个页面导出为以 tab 分隔的文本格式文件（txt）并上传即可。</p>
<p><img src="https://i.imgur.com/LtKxeIm.png" alt="" /></p>
<p><img src="https://i.imgur.com/UTJQvR4.png" alt="" /></p>
<h3 id="7-file"><a class="markdownIt-Anchor" href="#7-file"></a> 7. File</h3>
<p>这一步就到了将测序原始数据上传到 NCBI 数据库，如果数据量很小（&lt; 10 G），估计直接网页端上传就可以。但是我有超过 50 G，用网页上传失败。查了好几个网上的心得分享，对于几十 G 数据甚至更大量数据，都推荐选用 Aspera 高速上传的方法。那么执行以下步骤：</p>
<ol>
<li>选择“FTP or Aspera Command file preload”，并点击“Select preload folder”，此时网页上会显示 Aspera Command-Line 的信息，即 cmd 命令行。注意 Aspera command line 中包含的上传命令，等一下在自己电脑 cmd 命令上传时候需要用到。</li>
<li>点击网页上出现的 key file，下载得到 aspera.openssh。</li>
<li>安装 aspera 这个软件，在网址 <a href="http://downloads.asperasoft.com/connect2/">http://downloads.asperasoft.com/connect2/</a>，下载之后得到安装文件 <code>ibm-aspera-connect_4.2.2.135_win64.msi</code>，双击按照软件自身的引导进行安装，默认安装位置：<code>C:\Program Files\IBM\Aspera Connect\bin</code>。</li>
<li>接下来就是上传数据，先将所有测序文件放在一个文件夹中，比如 <code>D:\seq_data</code>；然后将 key file 放在另一个文件目录，比如 <code>D:\key_file</code>； 在 windows 电脑进入 cmd 界面，进入上面所述的 Aspera 安装目录，再依据网页给出的 Aspera 命令进行数据提交，如下代码框所示。我的网速比较快，接近 100 Mb/s，所以一两个小时就传输完毕 50 G 数据。</li>
<li>所有数据上传完后，点击 NCBI 网页中的 Select preload folder，选择自己文件夹名字（比如我下面的命令中用的 seq_data，那么此时 NCBI 网页上会显示 seq_data 这个字符）。然后点击 continue 进入下一步。</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">cd C:\Program Files\IBM\Aspera Connect\bin</span><br><span class="line">ascp.exe -i D:\key_file\aspera.openssh -QT -l100m -k1 -d D:\seq_data\ subasp@upload.ncbi.nlm.nih.gov:uploads/myemailinfo_xxxx</span><br></pre></td></tr></table></figure>
<p><font face="Georgia" color=red>Note: 我在这一步遇到的问题就是一开始不知道怎么生成自己专属的 key file 和 Aspera command line，原来选择“FTP or Aspera Command file preload”之后是不会生成这些信息，必须点击“Select preload folder”才可以。</font></p>
<p><img src="https://i.imgur.com/5CPUhMR.png" alt="" /></p>
<p><img src="https://i.imgur.com/s8j5VR2.jpeg" alt="" /></p>
<p><img src="https://i.imgur.com/dXgSCi0.jpeg" alt="" /></p>
<h3 id="8-review-submit"><a class="markdownIt-Anchor" href="#8-review-submit"></a> 8. Review &amp; submit</h3>
<p>最后整体检查一下所有表格和数据内容，没问题就点击 submit。整个提交完毕，等待 NCBI 系统处理。可以在 my submissions 中查看处理进度。系统处理完后可以查看 accession number，稍后我们也会收到官方的邮件通知。</p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<ol>
<li><a href="https://cloud.tencent.com/developer/article/1806824">最新 （2021版_Windows）| 测序原始数据上传NCBI的详细过程</a></li>
<li><a href="http://www.bgitechsolutions.com/resources/95">华大科技：NCBI数据上传</a></li>
<li><a href="http://www.bgitechsolutions.com/storage/tool/NCBI%20data%20upload.zip">华大科技：《上传clean reads至NCBI的SRA帮助文档-v2.pdf》</a></li>
</ol>
]]></content>
      <categories>
        <category>Bioinfo</category>
      </categories>
  </entry>
  <entry>
    <title>Plant | 霍格兰营养液的配置</title>
    <url>/2022/10/14/Hoagland-Solution/</url>
    <content><![CDATA[<p>霍格兰营养液配方，记录在此，留存备用。</p>
<span id="more"></span>
<p>霍格兰营养液看似简单，实际上配制不妥的话会严重影响植物生长，尤其是水培植物，完全依赖霍格兰营养液提供营养。霍格兰营养液包括两个组分：“主要元素”和“微量元素”。微量元素可以混合成 1000 倍的母液（stock），每次量取母液按照倍数稀释即可使用。而主要元素不可以提前混合成高浓度母液，否则会出现钙质沉淀，且稀释之后也不溶于水。所以我的经验是使用的时候逐个称取主要元素（下表中 1—5 号元素）装入不同的 50 mL 管，直接溶于大量水中配制成霍格兰溶液。下表列出了配制 80 升 1/2 Hoagland 营养液需要的各种化合物成分的质量，根据实际用量进行调整即可。溶解的过程也有技巧，比如我需要配 80 升 1/2 Hoagland 营养液，那我可以先在大桶里放入 40 升自来水，然后每加入一种化合物，搅拌溶解之后再加另一种。特别注意硝酸钙，如果此时水量较少，非常容易形成硫酸钙沉淀。配制完成之后应该是见不到明显的絮状沉淀才好。</p>
<h3 id="主要元素macronutrients"><a class="markdownIt-Anchor" href="#主要元素macronutrients"></a> 主要元素（Macronutrients）</h3>
<table>
<thead>
<tr>
<th>序号</th>
<th>成分</th>
<th>摩尔质量</th>
<th>终浓度(1X)</th>
<th>称取质量(for 80 L 0.5X)</th>
<th>状态</th>
<th>货号</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>KNO<sub>3</sub></td>
<td>101.1</td>
<td>5 mM</td>
<td>20.2 g</td>
<td>白色粉末</td>
<td>P8394 Sigma</td>
</tr>
<tr>
<td>2</td>
<td>Ca(NO<sub>3</sub>)<sub>2</sub>·4H<sub>2</sub>O</td>
<td>236.15</td>
<td>5 mM</td>
<td>47.2 g</td>
<td>无色晶体</td>
<td>237124 Sigma</td>
</tr>
<tr>
<td>3</td>
<td>MgSO<sub>4</sub>·7H<sub>2</sub>O</td>
<td>246.47</td>
<td>2 mM</td>
<td>19.72 g</td>
<td>无色晶体</td>
<td>230391 Sigma</td>
</tr>
<tr>
<td>4</td>
<td>KH<sub>2</sub>PO<sub>4</sub></td>
<td>136.09</td>
<td>1 mM</td>
<td>5.44 g</td>
<td>白色粉末</td>
<td>P5655 Sigma</td>
</tr>
<tr>
<td>5</td>
<td>Fe·EDTA</td>
<td>367.05</td>
<td>-</td>
<td>0.8 g</td>
<td>黄褐色粉末</td>
<td>03650 Sigma</td>
</tr>
<tr>
<td>6</td>
<td>Micronutrients</td>
<td>-</td>
<td>-</td>
<td>40 mL stock</td>
<td>无色液体</td>
<td>-</td>
</tr>
</tbody>
</table>
<p>注意：大豆对铁元素要求更大量，比如 60 L 营养液至少 0.6g FeEDTA，且 4~5 天左右需要换水。2020年实验，60L 培养液只加 0.4g FeEDTA，大豆叶片会黄化，明显发育不良。对于 80 升营养液，我一般加 0.8 g 铁盐，甚至 1.2 g 也可以，植物比较正常，如本文后面的附图所示。铁盐的具体化学成分是什么？查了一下 Sigma 03650，中文为EDTA 铁（III）钠盐，或称乙二胺四乙酸铁（III）钠盐的水合物，含 12-14% Fe basis。线性分子式: (OOCCH2)2NCH2CH2NCCH2COO)2FeNa · xH2O。</p>
<h3 id="微量元素micronutrients"><a class="markdownIt-Anchor" href="#微量元素micronutrients"></a> 微量元素（Micronutrients）</h3>
<table>
<thead>
<tr>
<th>序号</th>
<th>成分</th>
<th>摩尔质量</th>
<th>称取质量(for 1 L 1000X stock)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>H<sub>3</sub>BO<sub>3</sub></td>
<td>61.83</td>
<td>2.86 g/L</td>
</tr>
<tr>
<td>2</td>
<td>MnCl<sub>2</sub>·4H<sub>2</sub>O</td>
<td>197.91</td>
<td>1.81 g/L</td>
</tr>
<tr>
<td>3</td>
<td>ZnSO<sub>4</sub>·7H<sub>2</sub>O</td>
<td>287.56</td>
<td>0.22 g/L</td>
</tr>
<tr>
<td>4</td>
<td>CuSO<sub>4</sub>·5H<sub>2</sub>O</td>
<td>249.69</td>
<td>0.08 g/L</td>
</tr>
<tr>
<td>5</td>
<td>MoO<sub>3</sub></td>
<td>161.95</td>
<td>0.02 g/L</td>
</tr>
</tbody>
</table>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p>下图是我在网上找的<a href="https://www.researchgate.net/file.PostFileLoader.html?id=581dca0e48954c23b916bbb8&amp;assetKey=AS%3A425033446236162%401478347278559">一份配方</a>，注意FeEDTA有问题，不可照抄。微量元素配方是可以用的。</p>
<p><img src="https://i.imgur.com/1FGcTSK.jpeg" alt="" /></p>
<p>下图中水培装置是我种植的植物，一盆 20 升 1/2 Hoagland 培养液，每周更换两次，植物可以正常生长到顺利结果。注意旁边土壤种植的植物由于营养不足，明显叶片颜色更浅。</p>
<p><img src="https://i.imgur.com/JjOMmQv.jpeg" alt="" /></p>
<p>下图中水培装置是我种植的植物，一盆 20 升 1/2 Hoagland 培养液，每周更换两次，植物可以正常生长。右侧是其他人没有及时更换营养液的植物，可见明显生长缓慢，叶片发黄。</p>
<p><img src="https://i.imgur.com/5YhT1CL.jpeg" alt="" /></p>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>Plant | 拟南芥种子灭菌</title>
    <url>/2022/10/20/Sterilization-of-Arabidopsis-seeds/</url>
    <content><![CDATA[<p>拟南芥等植物的种子灭菌播种的方法，记录在此，留存备用。</p>
<span id="more"></span>
<h3 id="氯气灭菌法拟南芥种子-vapor-phase-sterilization-of-arabidopsis-seed"><a class="markdownIt-Anchor" href="#氯气灭菌法拟南芥种子-vapor-phase-sterilization-of-arabidopsis-seed"></a> 氯气灭菌法（拟南芥种子） Vapor-Phase Sterilization of Arabidopsis Seed</h3>
<p>Steve Clough and Andrew Bent, University of Illinois at Urbana-Champaign.</p>
<p>The following protocol contains a convenient method for surface-sterilization of plant seeds. In particular, the method does not require all of the soaking and rinsing of liquid-phase bleach-sterilization methods. While this protocol substantially reduces hands-on manipulations, it does require some incubation<br />
time (a few hours to overnight).</p>
<p>We often use this protocol in conjunction with selection of Arabidopsis transformants on MS medium + antibiotics. See the related “Simplified Arabidopsis Transformation Protocol.” This vapor-phase sterilization protocol was adapted from a version supplied by Maud Hinchee and colleagues at Monsanto.</p>
<ol>
<li>Obtain a vessel for seed sterilization, typically a dessicator jar. Place in fume hood.</li>
<li>Place seed that is to be sterilized into appropriate resealable containers (for example, microcentrifuge tubes).</li>
<li>Place open containers of seed into a rack or stand inside the dessicator jar.</li>
<li>Place a 250 ml beaker containing 100 ml bleach into the dessicator jar.</li>
<li>Immediately prior to sealing the jar, carefully add 3 ml concentrated HCl to the bleach.</li>
<li>Seal jar and allow sterilization by chlorine fumes to proceed for a period of between three and sixteen hours. The time needed will vary based on the configuration of seed and the extent to which seed is contaminated. Three to four hours is often sufficient for reasonably clean seed. Overnight is usually acceptable although some seed killing may occur, especially if seed is not fully mature and dry.</li>
<li>Depending on the application, open container in fume hood or in sterile laminar flow hood, seal microfuge tubes or other seed containers, and remove surface-sterilized seed for use.</li>
</ol>
<p>NOTES:<br />
* Some lab members suspect that sterilization in 15 ml orange-cap tubes is more likely to result in seed mortality? We welcome your feedback on this or other aspects of this protocol.<br />
* Obtain proper approval for transformation work from institutional authorities.<br />
Autoclave and properly dispose of all materials.<br />
* Chlorine gas is poisonous to humans - work with proper ventilation.</p>
<p>Reference: <a href="http://plantpath.wisc.edu/~afb/vapster.html">http://plantpath.wisc.edu/~afb/vapster.html</a></p>
<h3 id="酒精灭菌法拟南芥种子"><a class="markdownIt-Anchor" href="#酒精灭菌法拟南芥种子"></a> 酒精灭菌法（拟南芥种子）</h3>
<p>该方法适用于少量品种的灭菌，或者每管的种子量太大，不适宜用上述氯气灭菌法。</p>
<ol>
<li>拟南芥种子装入 2-mL Eppendorf 管；加入 1 mL 70% 酒精，置于旋转机或摇床 10 min；</li>
<li>在超净台吸走 70% 酒精，加入 1 mL 100% 酒精，吸走酒精；重复加入一次 100% 酒精，并吸走酒精，换用 200 uL 枪头可以抵达管底小心尽可能吸走酒精，此时种子表面仍然残留酒精；</li>
<li>管子平放于超净台靠近出风口的地方，吹 30 min 左右，种子表面就干燥了；</li>
<li>种子直接撒在 1/2 MS 培养基，黑暗 4 °C 春化 3——4 天，然后转移到 22 °C 光照培养箱即可萌芽。</li>
</ol>
<h3 id="消毒水灭菌法适用于某豆科植物"><a class="markdownIt-Anchor" href="#消毒水灭菌法适用于某豆科植物"></a> 消毒水灭菌法（适用于某豆科植物）</h3>
<p>Surface sterilization of seeds includes:</p>
<ol>
<li>10 min in 70% ethanol; washing 3 times with distilled water;</li>
<li>30 min in bleach（bleach可用自来水稀释一倍，灭菌时间 15 min 亦可）; washing 5 times with distilled water.</li>
<li>Sterilized seeds were germinated on 1% Agar (or 1/2 MS medium) (20 seeds/petri dish, 10 × 25 mm) in darkness at 28 °C.</li>
<li>Two days after gemination, seedlings were transferred into flasks with ½ MS for further growth in the dark. Or transfer to soil for further growth, and water plants with 1/2 Hoagland solution.</li>
</ol>
<h3 id="异丙醇加消毒水灭菌法适用于拟南芥"><a class="markdownIt-Anchor" href="#异丙醇加消毒水灭菌法适用于拟南芥"></a> 异丙醇加消毒水灭菌法（适用于拟南芥）</h3>
<p>该方法是浏览 <a href="http://clough.cropsci.illinois.edu/pages/protocols.html">Clough Lab</a> 时候偶然看到他们分享的液体灭菌法，也可参考。</p>
<p>Seed Sterilization by Liquid Method</p>
<ol>
<li>Rinse seed with 100% Isopropanol for 30 to 60 seconds.  Spin down, and discard supernatant.</li>
<li>Rinse with 50% bleach containing 0.05% Tween for 5 minutes with gentle rocking.  Spin, and discard supernatant.</li>
<li>Rinse with sterile water, spin down, and discard supernatant.</li>
<li>Repeat 3 to 5 times (until a bleach odor is not detected).</li>
<li>Use seeds immediately.</li>
</ol>
<p>Notes:<br />
Approximately:  1 mg = 50 seeds; 40 mg = 2000 seeds.<br />
If plating seeds out, resuspend seed in 0.1% sterile agarose.<br />
From:  Liquid Method: Eric Baima 6/97. See Methods in Clough and Bent (1998) Plant Journal 16, 735-743.</p>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>Plant | MS 培养基的配方</title>
    <url>/2022/10/24/Murashige-Skoog-MS-Medium/</url>
    <content><![CDATA[<p>Murashige and Skoog medium，在实验室植物培养中通常使用减半的浓度，即 1/2 MS 培养基，记录在此，留存备用。</p>
<span id="more"></span>
<p>MS 培养基是 Murashige 和 Skoog 于 1962 年为烟草细胞培养设计的，其特点是无机盐和离子浓度较高，是较稳定的离子平衡溶液，它的硝酸盐含量高，其养分的数量和比例合适，能满足植物细胞的营养和生理需要，因而适用范围比较广，多数植物组织培养快速繁殖用它作为培养基的基本培养基，也是目前使用最普遍的植物组织培养基。</p>
<p>MS 培养基具有较高的无机盐浓度，能够保证组织生长所需的矿质营养还能加速愈伤组织的生长。由于配方中的离子浓度高，在配制、贮存和消毒等过程中，即使有些成分略有出入，也不会影响离子间的平衡。由于植物的多样性和生长环境复杂性和多变性，所以不可能有一种能够适应所有类型的植物组织和器官，满足所有植物并实现其培养材料的再生，通常需要根据材料来源、培养目的等的不同，选择不同的培养基或者对培养成分做适当的改良。</p>
<p>MS 固体培养基可用于诱导愈伤组织，也可用于胚、茎段、茎尖及花药的培养，其液体培养基用于细胞悬浮培养时能获得明显的成功。其养分的数量和比例较合适，可满足植物的营养和生理需要，一般情况下，无须再添加氨基酸、酪蛋白水解物、酵母提取物及椰子汁等有机附加成分。</p>
<p>对于 MS 植物组织培养基的配制，由于 MS 培养基含有近 30 种营养成分，为了避免每次配制培养基都要对这几十种成分进行称量，可将培养基中的各种成分，按原量的 20 倍或 200 倍分别称量，配成浓缩液，这种浓缩液叫做培养基母液。这样每次使用时，取其总量的 1/20(50 mL) 或 1/200(5 mL)，加水稀释，制成混合培养液，再加入到煮沸的琼脂中，最后使用蒸馏水定容后搅拌均匀。美国植物培养专家 Caisson 的 MS 植物组织培养基粉末，这是因为商业化的培养基产品能确保批次的一致性，以及各组分的有效性。从而确保每个培养批次之间的数据有效且一致，培养效果具有可比对性。</p>
<p>Caisson 根据客户不同的需求提供不同等级和规格的 MS 培养基，包括 MS 基本培养基、含维生素的 MS 基本培养基、不含甘氨酸的 MS 基本培养基、不含氮磷钾的 MS 基本培养基，以及含蔗糖的 MS 基本培养基等不同产品。产品规格从 10 L、50 L 到 100 L 甚至更大的定制规格。</p>
<p>下面以使用 Caisson 品牌的 MS 培养基浓缩产品为例，配制实验室用到的植物培养基。我一般以 1.2 L 为配制量，因为这个体积刚好分装到 3 个 500 mL 尺寸的瓶子，每个瓶子 400 mL 培养基。</p>
<table>
<thead>
<tr>
<th>序号</th>
<th>成分</th>
<th>货号</th>
<th>保存环境</th>
<th>称取质量(for 1 L 1/2MS)</th>
<th>称取质量(for 1.2 L 1/2MS)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>MS (Murashige &amp; Skoog)</td>
<td>Caisson Ref:MSP06-50LT</td>
<td>4 °C</td>
<td>2.22 g</td>
<td>2.664 g</td>
</tr>
<tr>
<td>2</td>
<td>Sucrose</td>
<td>usb?</td>
<td>常温</td>
<td>10 g</td>
<td>12 g</td>
</tr>
<tr>
<td>3</td>
<td>MES</td>
<td>SIGMA Ref:M2933-100G</td>
<td>常温</td>
<td>0.25 g</td>
<td>0.3 g</td>
</tr>
</tbody>
</table>
<p>配制 1.2 L 培养基的过程：</p>
<ol>
<li>先往 2 L 大小的塑料杯中加入 1 L milliQ water，在搅拌仪上搅动；</li>
<li>按照上方表格依次称量 3 种物质加入上一步的杯中，搅拌均匀；</li>
<li>测量 pH 值，初始值大约在 4 左右，使用 KOH 溶液调整 pH 值至 5.7——5.8，并加水定容到 1.2 L。对于 2 M 浓度的 KOH，大约需要加 400 uL 就接近目的 pH 值；</li>
<li>取 3 个 500 mL 容量的瓶子，每个瓶子加入 0.7—0.8 g 左右的 Phytoblend (Caisson Ref:PTP01-1KG)；</li>
<li>再往每个瓶子里加入 400 mL 配制好的 MS 液体，灭菌之后即可使用；或常温保存，再次使用的时候用微波炉熔化即可。</li>
</ol>
]]></content>
      <categories>
        <category>Plant</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | 提交蛋白质组学原始数据到公共数据库</title>
    <url>/2022/11/07/submit-proteomics-raw-data-to-PRIDE/</url>
    <content><![CDATA[<p>蛋白组学原始数据如何提交？投文章的过程中，杂志反馈说：“We note that your manuscript contains RNA sequencing and LC-MS/MS data. Before publication, you must deposit this data in a public, community-supported repository. Your manuscript will not be held and you can resolve this query alongside review. Authors are required to deposit the following mandatory data types in public, community-supported repositories, such as those listed below, prior to publication of an associated manuscript. Proteome profiling data, PRIDE, PeptideAtlas, ProteomeXchange.”</p>
<p>虽然上面提到有多个数据库可以选择，比如 PRIDE 和 ProteomeXchange。但是我发现进入 ProteomeXchange 之后其实也是链接到了 PRIDE，所以这里以 PRIDE 为例做个记录。</p>
<span id="more"></span>
<h3 id="注册-pride-数据库的账户"><a class="markdownIt-Anchor" href="#注册-pride-数据库的账户"></a> 注册 PRIDE 数据库的账户</h3>
<p>PRIDE 数据库主页是 <a href="https://www.ebi.ac.uk/pride/">https://www.ebi.ac.uk/pride/</a>，按照主页提供的信息操作，比如在该页面下下拉有提供“Submission Tool”和“Documentation: How to Submit data”。如果没有注册过账户，需要有email地址注册账户，注册之后会收到通知邮件，包含账户密码的信息。</p>
<h3 id="在本地电脑安装数据提交软件"><a class="markdownIt-Anchor" href="#在本地电脑安装数据提交软件"></a> 在本地电脑安装数据提交软件</h3>
<p>PRIDE Submission Tool: <a href="https://www.ebi.ac.uk/pride/markdownpage/pridesubmissiontool#submission_tool">https://www.ebi.ac.uk/pride/markdownpage/pridesubmissiontool#submission_tool</a></p>
<p>The PRIDE Submission Tool is the main tool used to submit proteomics datasets to PRIDE Archive. This tool has been implemented as a wizard, guiding submitters through a set of simple steps to complete each dataset submission.</p>
<p><a href="https://ftp.pride.ebi.ac.uk/pub/databases/pride/resources/tools/submission-tool/latest/desktop/px-submission-tool.zip">DOWNLOAD TOOL</a></p>
<p>下载这个文件 <code>px-submission-tool.zip</code>，解压之后有一个 <code>px-submission-tool-2.5.7.jar</code> 文件，双击即可运行数据提交程序，注意这里要求电脑已经安装 Java。</p>
<p><img src="https://i.imgur.com/XUwfpMW.jpeg" alt="" /></p>
<h3 id="填写实验相关信息并上传原始数据"><a class="markdownIt-Anchor" href="#填写实验相关信息并上传原始数据"></a> 填写实验相关信息并上传原始数据</h3>
<p>进入软件之后，按照网站提供的流程逐步操作：<a href="https://www.ebi.ac.uk/pride/markdownpage/pridesubmissiontool#submission_tool">https://www.ebi.ac.uk/pride/markdownpage/pridesubmissiontool#submission_tool</a>。还需要填写实验相关的信息：研究摘要、实验设计，以及数据分析方法等。选择“Partial Submission”开始吧。</p>
<p><img src="https://i.imgur.com/Owm6MsJ.jpeg" alt="" /></p>
<p>除了原始 raw 文件，还需要搜库的结果（Peptide/protein identification files (called ‘SEARCH’) (Mandatory for Partial Submissions, Optional for Complete Submissions): These are the files output by the software used to perform the data analysis - Mascot .dat, ProteomeDiscover .msf - check the full list here. Each SEARCH file needs to be related with at least one RAW file.）。</p>
<p>我有若干个质谱样品，对应多个 raw 文件，搜库的结果为“dia-proteinSummary.txt”，另外，我还提交了一个“sample_information.xls”和“md5sum.txt”</p>
<p>SampleInformation.xls 就是类似下面的表格。（我忘记是否来源于软件生成的模板？）</p>
<table>
<thead>
<tr>
<th>plant_sample</th>
<th>MS_raw_file</th>
<th>Note</th>
</tr>
</thead>
<tbody>
<tr>
<td>Col_ck</td>
<td>P1805080001.raw</td>
<td>Col-0; normal conditions</td>
</tr>
<tr>
<td>Col_ck</td>
<td>P1805080002.raw</td>
<td>Col-0; normal conditions</td>
</tr>
<tr>
<td>Col_ck</td>
<td>P1805080002.raw</td>
<td>Col-0; normal conditions</td>
</tr>
</tbody>
</table>
<p><img src="https://i.imgur.com/Kcl2gSn.jpeg" alt="" /></p>
<p>数据上传完毕，还需要对数据进行核对，再选择确认提交，能收到一封提交通知的邮件。</p>
<p><img src="https://i.imgur.com/wQDVXOA.jpeg" alt="" /></p>
<h3 id="收到数据库编号"><a class="markdownIt-Anchor" href="#收到数据库编号"></a> 收到数据库编号</h3>
<p>过一两天，如果一切正常，就会收到 PRIDE 的通知，并提供一个数据库编号，这个编号投文章的时候要用到。此时该数据集并未公开，可以等文章发表的时候通知 PRIDE 进行公开。</p>
<p><img src="https://i.imgur.com/8dbR1JR.jpeg" alt="" /></p>
<p>如图，下面就是登录自己账户之后的界面，数据集的信息状态为“PRIVATE”，我发现右上角有一个“Publish”按钮，如果该数据集相关文章发表，可能可以点击此处进行数据公开。</p>
<p><img src="https://i.imgur.com/Gm1PXIK.jpeg" alt="" /></p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<ol>
<li><a href="https://zhuanlan.zhihu.com/p/468439344">教你如何上传蛋白质组学原始数据 – 联川生物</a></li>
</ol>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | 使用 Trimmomatic 软件对 Illumina 测序数据进行过滤</title>
    <url>/2022/11/07/Illumina-raw-reads-filtering/</url>
    <content><![CDATA[<p>Illumina 测序产生大量的短片段　DNA　序列，即 Reads。如果是下机原始数据 Raw data，通常需要进行过滤得到 Clean data，才能用于正式的组装和比对等数据分析。好几年没做过过滤，因为好多次收到公司交付的数据已经是过滤后的高质量数据，今年收到一批 Raw data，需要自己过滤，这里参考其他资料做个小结。</p>
<span id="more"></span>
<h3 id="为什么需要过滤低质量-reads"><a class="markdownIt-Anchor" href="#为什么需要过滤低质量-reads"></a> 为什么需要过滤低质量 Reads？</h3>
<p>下图为例，可以用来理解 Illumina 的测序原理，待测 DNA 片段两端连接有 Adapter（这就是通常所称的“文库”），上机的过程中，测序引物结合在 Adapter 的特定区域并且通过“边合成、边测序”的原理逐个碱基向未知的待测片段读取碱基信息，从而获得所谓的 Reads。目前，拿到的 Reads 长度通常为 100 bp 和 150 bp 两种规格。设想，如果文库中某些片段小于 Reads 长度，那么测序的过程中将“测通”整个待测 DNA，甚至读到另一端的 Adapter，这就使我们获得的 Reads 序列包含 Adapter 序列。另一个情况就是 Illumina 对每个碱基会生成质量值，如果某个碱基质量值很低，就不可靠，可以过滤掉。还有一个情况，根据我的经验，基因组测序的 Reads 集中会包括一部分简单重复序列，比如大量重复的 AAAAAA，这种简单序列对组装可能没什么用，可以滤掉。</p>
<p><img src="https://i.imgur.com/SMmxiuX.png" alt="" /></p>
<p>其实对于转录组测序而言，如果不经过过滤，对基因组比对的影响也很小，因为低质量的 Reads 在比对的过程中很可能使无法比对到基因组序列的。</p>
<h3 id="过滤软件的选择"><a class="markdownIt-Anchor" href="#过滤软件的选择"></a> 过滤软件的选择</h3>
<p>早期（2014年）的文献中有各种不同的过滤软件，我甚至拿不少软件做过测试，后来 Trimmomatic 软件发表，我发现非常好用。该文章至今已被大量引用，是一个广受欢迎的 Illumina 平台数据过滤工具。Trimmomatic 支持多线程，处理数据速度快，主要用来去除 Illumina 平台的 Fastq 序列中的接头，并根据碱基质量值对 Fastq 进行修剪。软件有两种过滤模式，分别对应 SE 和 PE 测序数据，同时支持 gzip 和 bzip2 压缩文件。另外也支持 phred-33 和 phred-64 格式互相转化，现在之所以会出现 phred-33 和 phred-64 格式的不同，是 Illumina 公司的不同质量体系，不过现在绝大部分 Illumina 平台的产出数据也都转为使用 phred-33 格式。下面的脚本代码可以快速识别具体的质量格式。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ cat 00.fq_qual_type.sh </span><br><span class="line">less $1 | head -n 1000 | awk &#x27;&#123;if(NR%4==0) printf(&quot;%s&quot;,$0);&#125;&#x27; \</span><br><span class="line">        | od -A n -t u1 -v \</span><br><span class="line">        | awk &#x27;BEGIN&#123;min=100;max=0;&#125; \</span><br><span class="line">        &#123;for(i=1;i&lt;=NF;i++) &#123;if($i&gt;max) max=$i; if($i&lt;min) min=$i;&#125;&#125;END \</span><br><span class="line">                &#123;if(max&lt;=126 &amp;&amp; min&lt;59) print &quot;Phred33&quot;; \</span><br><span class="line">                        else if(max&gt;73 &amp;&amp; min&gt;=64) print &quot;Phred64&quot;; \</span><br><span class="line">                        else if(min&gt;=59 &amp;&amp; min&lt;64 &amp;&amp; max&gt;73) print &quot;Solexa64&quot;; \</span><br><span class="line">                        else print &quot;Unknown score encoding&quot;; \</span><br><span class="line">                print &quot;( &quot; min &quot;, &quot; max, &quot;)&quot;;&#125;&#x27;</span><br></pre></td></tr></table></figure>
<h3 id="trimmomatic-的安装与运行"><a class="markdownIt-Anchor" href="#trimmomatic-的安装与运行"></a> Trimmomatic 的安装与运行</h3>
<p>官网：<a href="http://www.usadellab.org/cms/?page=trimmomatic">http://www.usadellab.org/cms/?page=trimmomatic</a>，我直接下载<a href="http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/Trimmomatic-0.39.zip">二进制文件</a>，解压即可使用。官网也提供详细的<a href="http://www.usadellab.org/cms/uploads/supplementary/Trimmomatic/TrimmomaticManual_V0.32.pdf">《Trimmomatic 使用说明书》</a>。</p>
<p>官网提供的一个示范：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># for reference only (less sensitive for adapters)</span><br><span class="line"></span><br><span class="line">java -jar trimmomatic-0.35.jar PE -phred33 \</span><br><span class="line">    input_forward.fq.gz input_reverse.fq.gz \</span><br><span class="line">    output_forward_paired.fq.gz output_forward_unpaired.fq.gz \</span><br><span class="line">    output_reverse_paired.fq.gz output_reverse_unpaired.fq.gz \</span><br><span class="line">    ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36</span><br><span class="line"></span><br><span class="line"># This will perform the following:</span><br><span class="line"># Remove adapters (ILLUMINACLIP:TruSeq3-PE.fa:2:30:10)</span><br><span class="line"># Remove leading low quality or N bases (below quality 3) (LEADING:3)</span><br><span class="line"># Remove trailing low quality or N bases (below quality 3) (TRAILING:3)</span><br><span class="line"># Scan the read with a 4-base wide sliding window, cutting when the average quality per base drops below 15 (SLIDINGWINDOW:4:15)</span><br><span class="line"># Drop reads below the 36 bases long (MINLEN:36)</span><br></pre></td></tr></table></figure>
<p>我根据该示范的实际操作代码：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">java -jar /home/fenglei/local/app/Trimmomatic/trimmomatic-0.39.jar PE \</span><br><span class="line">        -threads $NUMCPUS -phred33 -summary $CLEANDATAPATH/$&#123;sample&#125;_trim.summary \</span><br><span class="line">        $&#123;prefix&#125;_1.fq.gz $&#123;prefix&#125;_2.fq.gz \</span><br><span class="line">        $CLEANDATAPATH/$&#123;sample&#125;_pass_1.fq.gz $CLEANDATAPATH/$&#123;sample&#125;_unpass_1.fq.gz \</span><br><span class="line">        $CLEANDATAPATH/$&#123;sample&#125;_pass_2.fq.gz $CLEANDATAPATH/$&#123;sample&#125;_unpass_2.fq.gz \</span><br><span class="line">        ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:True LEADING:3 TRAILING:3 MINLEN:36</span><br><span class="line"># 这个参数别用：-trimlog $CLEANDATAPATH/$&#123;sample&#125;_trim.log  ### DO NOT USE THIS PARAMETER! IT WILL GENERATE A HUGE FILE WITH ALL RAED NAMES.</span><br><span class="line"># 这个参数可用：SLIDINGWINDOW:4:15</span><br></pre></td></tr></table></figure>
<p>注意：</p>
<ol>
<li>Adpater 序列文件 <code>TruSeq3-PE.fa</code> 默认在当前目录，如果文件在其他位置就需要添加路径，比如 <code>ILLUMINACLIP:/PATH/TO/TruSeq3-PE.fa:2:30:10:2:True</code>。</li>
<li>Adpater 序列文件里面序列名称有讲究，Naming of the sequences indicates how they should be used. For ‘Palindrome’ clipping, the sequence names should both start with ‘Prefix’, and end in ‘/1’ for the forward adapter and ‘/2’ for the reverse adapter. All other sequences are checked using ‘simple’ mode. Sequences with names ending in ‘/1’ or ‘/2’ will be checked only against the forward or reverse read. Sequences not ending in ‘/1’ or ‘/2’ will be checked against both the forward and reverse read. If you want to check for the reverse-complement of a specific sequence, you need to specifically include the reverse-complemented form of the sequence as well, with another name.</li>
<li>生成的质量过关的文件，包括 <code>$CLEANDATAPATH/$&#123;sample&#125;_pass_1.fq.gz</code> 和 <code>$CLEANDATAPATH/$&#123;sample&#125;_pass_2.fq.gz</code>，这两个文件的序列数目是一致的。但是里面有部分序列的长度是经过修剪的，因为设置了 <code>MINLEN:36</code> 参数，去掉 Adapter 污染的序列变短。</li>
<li>生成的 <code>$CLEANDATAPATH/$&#123;sample&#125;_unpass_1.fq.gz</code> 和 <code>$CLEANDATAPATH/$&#123;sample&#125;_unpass_2.fq.gz</code> 两个文件，大小是不一样的，打开查看，这两个文件包含主要是一些低质量的简单重复序列。</li>
</ol>
<p><img src="https://i.imgur.com/ppkg0Pu.png" alt="Flow of reads in Trimmomatic Paired End mode" /></p>
<h3 id="trimmomatic-软件参数的解释"><a class="markdownIt-Anchor" href="#trimmomatic-软件参数的解释"></a> Trimmomatic 软件参数的解释</h3>
<p>Trimmomatic 过滤数据的步骤与命令行中过滤参数的顺序有关，通常的过滤步骤如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">ILLUMINACLIP: 过滤 reads 中的 Illumina 测序接头和引物序列，并决定是否去除反向互补的 R1/R2 中的 R2。</span><br><span class="line">SLIDINGWINDOW: 从 reads 的 5’ 端开始，进行滑窗质量过滤，切掉碱基质量平均值低于阈值的滑窗。</span><br><span class="line">MAXINFO: 一个自动调整的过滤选项，在保证 reads 长度的情况下尽量降低测序错误率，最大化 reads 的使用价值。</span><br><span class="line">LEADING: 从 reads 的开头切除质量值低于阈值的碱基。</span><br><span class="line">TRAILING: 从 reads 的末尾开始切除质量值低于阈值的碱基。</span><br><span class="line">CROP: 从 reads 的末尾切掉部分碱基使得 reads 达到指定长度。</span><br><span class="line">HEADCROP: 从 reads 的开头切掉指定数量的碱基。</span><br><span class="line">MINLEN: 如果经过剪切后 reads 的长度低于阈值则丢弃这条 reads。</span><br><span class="line">AVGQUAL: 如果 reads 的平均碱基质量值低于阈值则丢弃这条 reads。</span><br><span class="line">TOPHRED33: 将 reads 的碱基质量值体系转为 phred-33。</span><br><span class="line">TOPHRED64: 将 reads 的碱基质量值体系转为 phred-64。</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<ol>
<li><a href="http://www.usadellab.org/cms/?page=trimmomatic">Trimmomatic: A flexible read trimming tool for Illumina NGS data</a></li>
<li><a href="http://www.biotrainee.com/thread-1484-1-1.html">生信技能树：NGS 数据过滤之 Trimmomatic 详细说明</a></li>
<li><a href="https://www.modb.pro/db/376116">生信洞：Trimmomatic 使用简介</a></li>
<li><a href="https://www.cnblogs.com/Sunny-King/p/Bioinformatics-Trimmomatic.html">Sunny King：Trimmomatic 安装和使用</a></li>
</ol>
]]></content>
      <categories>
        <category>Bioinformatics</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | plantiSMASH 软件鉴定生物合成相关的基因簇</title>
    <url>/2022/11/20/gene-clusters-analysis-by-plantiSMASH/</url>
    <content><![CDATA[<p>读一篇 Science paper 的时候了解到 plantiSMASH 软件，可以鉴定生物合成相关的基因簇，并且该工具被不少文章引用，做一个学习记录。</p>
<span id="more"></span>
<h3 id="简介"><a class="markdownIt-Anchor" href="#简介"></a> 简介</h3>
<p><img src="https://i.imgur.com/iT0DJE8.jpeg" alt="" /></p>
<p>Plants around the globe produce a wide variety of specialized metabolites that play key roles in communication and defense. Recently, evidence has been accumulating that (like in microbes) the genes encoding the biosynthetic pathways towards these metabolites are often densely clustered in specific genomic loci: biosynthetic gene clusters (BGCs). This offers great potential for genome-based discovery of plant natural products.</p>
<p>Here, we introduce plantiSMASH, a versatile online analysis platform that automates the identification of candidate plant BGCs, as well as their comparative genomic and transcriptomic analysis. The cluster detection logic, validated on a set of all plant BGCs that have been experimentally characterized thus far, is able to pinpoint many complex metabolic loci across the Plant Kingdom. Additionally, interactively visualized coexpression analysis and comparative cluster-cluster alignment allow users to judge multiple sources of evidence for a candidate BGC to encode a group of enzymes that truly functions jointly in a biosynthetic pathway. Furthermore, plantiSMASH finds coexpression correlations between candidate BGCs and genes elsewhere in the genome.</p>
<p>Altogether, this new software provides a comprehensive toolkit for plant geneticists to further explore the nature of gene clustering in plant metabolism. Moreover, spurred by the continuing decrease in costs of plant genome sequencing and assembly, it will soon allow natural product chemists to apply genome mining technologies to the discovery of novel medicinal compounds from a wide range of plant species.</p>
<h3 id="安装"><a class="markdownIt-Anchor" href="#安装"></a> 安装</h3>
<p>Download plantiSMASH standalone. Stand-alone versions of plantiSMASH are available through our GitHub page. The current standalone release is plantiSMASH 1.0 (December 12th, 2019). Install from source. First of all, download the plantiSMASH python source from our GitHub repo: <a href="https://github.com/plantismash/plantismash/releases">https://github.com/plantismash/plantismash/releases</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># Then, make sure you have the following plantiSMASH dependencies installed:</span><br><span class="line">glimmer (version 3.02 tested)</span><br><span class="line">GlimmerHMM (version 3.0.4 tested)</span><br><span class="line">hmmer2 (version 2.3.2 tested, append a 2 to all hmmer2 executables to avoid conflict with hmmer3 executable names, like hmmalign -&gt; hmmalign2)</span><br><span class="line">hmmer3 (version 3.0 and 3.1b2 tested)</span><br><span class="line">fasttree (version 2.1.7 tested)</span><br><span class="line">diamond (&gt; 0.7.9 required, version 0.7.10 tested1)</span><br><span class="line">muscle (version 3.8.31 tested)</span><br><span class="line">prodigal (version 2.6.1 tested)</span><br><span class="line">NCBI blast+ (version 2.2.31 tested)</span><br><span class="line">CD-HIT (version 4.6.6 tested)</span><br><span class="line">xz development headers (version 5.1.1 tested)</span><br><span class="line">xml development headers (version 2.9.1 tested)</span><br><span class="line">python (version 2.7 tested, anything &gt;= python 2.6 should work)</span><br><span class="line">python-virtualenv (not needed, but highly recommended)</span><br><span class="line"></span><br><span class="line"># Then, create a python virtualenv for installing the plantiSMASH python dependencies. This is not required, but highly recommended.</span><br><span class="line">virtualenv as3source as3/bin/activate</span><br><span class="line"></span><br><span class="line"># All the python dependencies are listed in requirements.txt, you can grab them all and install them with a simple command:</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line"></span><br><span class="line"># Last but not least, run download_databases.py to grab and prepare the databases:</span><br><span class="line">python download_databases.py</span><br></pre></td></tr></table></figure>
<p>上面官网教程给的依赖软件挺多，逐个下载 source code 安装比较慢，我看到<a href="https://twitter.com/lewseylab/status/1554381604826513408?s=20&amp;t=IG3DJmbxB4ImEX3Ds2gHnw">推特</a>上一个博主的帖子和讨论，有用户分享安装与使用的经验，她切换到 python27 环境之后用 <code>conda</code> 安装。该博主分享的脚本：<a href="https://github.com/agolicz/antismash-install/blob/main/install.sh">https://github.com/agolicz/antismash-install/blob/main/install.sh</a>。</p>
<p><img src="https://i.imgur.com/zJ3usYf.jpeg" alt="" /></p>
<p>我基本按照该博主分享的代码操作，操作如有不同，在下方代码框内有注释，顺利安装并运行下述代码。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">conda create --name py27 python=2.7  # 由于我电脑已经有 python 2.7 环境（基于 anaconda3），这步骤不需要操作。</span><br><span class="line">source activate py27 # 我用 source activate python27 进入 python 2.7 环境</span><br><span class="line">conda install -c bioconda glimmerhmm</span><br><span class="line">conda install -c bioconda glimmer</span><br><span class="line">conda install -c bioconda hmmer2</span><br><span class="line">conda install -c bioconda hmmer</span><br><span class="line">conda install -c bioconda fasttree</span><br><span class="line">conda install -c bioconda diamond</span><br><span class="line">conda install -c bioconda muscle</span><br><span class="line">conda install -c bioconda prodigal</span><br><span class="line">conda install -c bioconda cd-hit</span><br><span class="line">conda install -c bioconda blast</span><br><span class="line">sudo apt-get install libxml2-dev  # 我电脑是 CentOS，不需要这个步骤</span><br><span class="line">sudo apt-get install liblzma-dev  # 我电脑是 CentOS，不需要这个步骤</span><br><span class="line">mkdir test</span><br><span class="line">cd test/</span><br><span class="line">wget https://github.com/plantismash/plantismash/archive/refs/tags/1.0.tar.gz</span><br><span class="line">tar -xvzf 1.0.tar.gz</span><br><span class="line">cd plantismash-1.0/</span><br><span class="line">pip install numpy</span><br><span class="line">pip install -r requirements.txt</span><br><span class="line">python download_databases.py</span><br><span class="line">./run_antismash.py -h</span><br><span class="line">wget https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/003/018/455/GCF_003018455.1_ASM301845v1/GCF_003018455.1_ASM301845v1_genomic.fna.gz</span><br><span class="line">gunzip GCF_003018455.1_ASM301845v1_genomic.fna.gz</span><br><span class="line">/plantismash-1.0/run_antismash.py -c 15 GCF_003018455.1_ASM301845v1_genomic.fna</span><br></pre></td></tr></table></figure>
<p>数据库下载的记录：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python27) [fenglei@localhost plantiSMARSH]$ python --version</span><br><span class="line">Python 2.7.17 :: Anaconda, Inc.</span><br><span class="line">(python27) [fenglei@localhost plantiSMARSH]$ python download_databases.py</span><br><span class="line">Downloading large file Pfam-A.hmm.gz. Please be patient...</span><br><span class="line">Downloading Pfam-A.hmm.gz finished successfully.</span><br><span class="line">Creating checksum of Pfam-A.hmm.gz</span><br><span class="line">Extraction of Pfam-A.hmm.gz finished successfully.</span><br><span class="line">Downloading large file clusterblast_dmnd07.tar.xz. Please be patient...</span><br><span class="line">Downloading clusterblast_dmnd07.tar.xz finished successfully.</span><br><span class="line">Creating checksum of clusterblast_dmnd07.tar.xz</span><br><span class="line">Extraction of clusterblast_dmnd07.tar.xz finished successfully.</span><br><span class="line">Extraction of clusterblast_dmnd07.tar finished successfully.</span><br></pre></td></tr></table></figure>
<h3 id="测试"><a class="markdownIt-Anchor" href="#测试"></a> 测试</h3>
<p>用罂粟基因组来做个测试。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget -c -t 100 --no-check-certificate https://ftp.ensemblgenomes.org/pub/plants/release-55/fasta/papaver_somniferum/dna/Papaver_somniferum.ASM357369v1.dna_sm.toplevel.fa.gz</span><br><span class="line">wget --no-check-certificate https://ftp.ensemblgenomes.org/pub/plants/release-55/gff3/papaver_somniferum/Papaver_somniferum.ASM357369v1.55.chr.gff3.gz</span><br><span class="line">wget --no-check-certificate https://ftp.ensemblgenomes.org/pub/plants/release-55/gff3/papaver_somniferum/Papaver_somniferum.ASM357369v1.55.gff3.gz</span><br><span class="line"></span><br><span class="line">#(python27) [fenglei@localhost opium_poppy_Papaver_somniferum]$ </span><br><span class="line">~/local/app/genometools-1.6.1/bin/gt gff3validator Papaver_somniferum.ASM357369v1.55.chr.gff3</span><br><span class="line"># input is valid GFF3</span><br><span class="line"></span><br><span class="line"># (python27) [fenglei@localhost opium_poppy_Papaver_somniferum]$  # 注意运行 plantiSMAH 的时候应该处于 python27 环境</span><br><span class="line">~/local/app/plantiSMARSH/run_antismash.py -c 12 --input-type nucl --taxon plants --outputfolder ./output1 --gff3 Papaver_somniferum.ASM357369v1.55.gff3 Papaver_somniferum.ASM357369v1.dna_sm.toplevel.fa</span><br><span class="line"># WARNING: Only analysing the first 9999 records (increase via --limit)     # 怎么出现这个警告？但是似乎对结果没有影响。</span><br><span class="line"># 这个程序运行了一整晚，才出来结果</span><br></pre></td></tr></table></figure>
<p>得到的结果文件夹有如下内容：</p>
<p><img src="https://i.imgur.com/hvuwGFf.jpeg" alt="" /></p>
<p>将该文件夹打包下载到本地，Web 浏览器打开 index.html 就可以看到分析结果：</p>
<p><img src="https://i.imgur.com/FvyhXIV.jpeg" alt="" /></p>
<p>回到罂粟的 Science paper，该文提到11号染色体上一个 584 kb 的区域内有一个 BIA 代谢相关的基因簇。上面的若干个 clusters，其中属于11 号染色体的簇有两个，cluster 8 的范围大致符合文献的描述。（Gene Cluster 8. Type = alkaloid. Location: 127703190 - 128443625 ）。点进去，比如下面红色箭头所指，就是 STORR 基因。</p>
<p><img src="https://i.imgur.com/ISM9JNN.jpeg" alt="" /></p>
<p><img src="https://i.imgur.com/qqJLzCZ.jpeg" alt="" /></p>
<p>将疑似 STORR 的基因氨基酸序列复制，并做 blast 分析鉴定。（序列有些差别，为什么？）</p>
<p><img src="https://i.imgur.com/YvrMfqi.jpeg" alt="" /></p>
<h3 id="使用"><a class="markdownIt-Anchor" href="#使用"></a> 使用</h3>
<p>原作者发表了 protocol，介绍参数设置，<a href="https://link.springer.com/protocol/10.1007/978-1-4939-7874-8_15">https://link.springer.com/protocol/10.1007/978-1-4939-7874-8_15</a>。</p>
]]></content>
      <categories>
        <category>Bioinfo</category>
      </categories>
  </entry>
  <entry>
    <title>Bioinfo | gff3 格式</title>
    <url>/2022/11/22/gff3-format/</url>
    <content><![CDATA[<p>用软件处理 gff3 格式的文件报错。为什么会报错？</p>
<span id="more"></span>
<p>下面是罂粟的 gff3 文件摘录。gff3 原始文件下载自 <a href="https://ftp.ensemblgenomes.org/pub/plants/release-55/gff3/papaver_somniferum">Ensembl</a>.</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">##gff-version 3</span><br><span class="line">##sequence-region   1 1 248500730</span><br><span class="line">##sequence-region   10 1 166527240</span><br><span class="line">##sequence-region   11 1 140193751</span><br><span class="line">##sequence-region   2 1 219560757</span><br><span class="line">##sequence-region   3 1 229600373</span><br><span class="line">##sequence-region   4 1 163710198</span><br><span class="line">##sequence-region   5 1 216867838</span><br><span class="line">##sequence-region   6 1 180516484</span><br><span class="line">##sequence-region   7 1 270405062</span><br><span class="line">##sequence-region   8 1 176451499</span><br><span class="line">##sequence-region   9 1 204470928</span><br><span class="line">#!genome-build Xi&#x27;an Jiaotong University ASM357369v1</span><br><span class="line">#!genome-version ASM357369v1</span><br><span class="line">#!genome-build-accession GCA_003573695.1</span><br><span class="line">#!genebuild-last-updated 2019-06</span><br><span class="line">1       ASM357369v1     chromosome      1       248500730       .       .       .       ID=chromosome:1;Alias=CM010715.1</span><br><span class="line">###</span><br><span class="line">1       ena     gene    272248  278625  .       +       .       ID=gene:C5167_036297;biotype=protein_coding;description=hypothetical protein;gene_id=C5167_036297;logic_name=ena</span><br><span class="line">1       ena     mRNA    272248  278625  .       +       .       ID=transcript:RZC43352;Parent=gene:C5167_036297;biotype=protein_coding;tag=Ensembl_canonical;transcript_id=RZC43352</span><br><span class="line">1       ena     five_prime_UTR  272248  272375  .       +       .       Parent=transcript:RZC43352</span><br><span class="line">1       ena     exon    272248  272747  .       +       .       Parent=transcript:RZC43352;Name=RZC43352-1;constitutive=1;ensembl_end_phase=0;ensembl_phase=0;exon_id=RZC43352-1;rank=1</span><br><span class="line">1       ena     CDS     272376  272747  .       +       0       ID=CDS:RZC43352;Parent=transcript:RZC43352;protein_id=RZC43352</span><br><span class="line">1       ena     exon    273021  273108  .       +       .       Parent=transcript:RZC43352;Name=RZC43352-2;constitutive=1;ensembl_end_phase=1;ensembl_phase=0;exon_id=RZC43352-2;rank=2</span><br><span class="line">1       ena     CDS     273021  273108  .       +       0       ID=CDS:RZC43352;Parent=transcript:RZC43352;protein_id=RZC43352</span><br><span class="line">1       ena     exon    274314  274443  .       +       .       Parent=transcript:RZC43352;Name=RZC43352-3;constitutive=1;ensembl_end_phase=2;ensembl_phase=1;exon_id=RZC43352-3;rank=3</span><br><span class="line">1       ena     CDS     274314  274443  .       +       2       ID=CDS:RZC43352;Parent=transcript:RZC43352;protein_id=RZC43352</span><br><span class="line">1       ena     CDS     275008  275584  .       +       1       ID=CDS:RZC43352;Parent=transcript:RZC43352;protein_id=RZC43352</span><br><span class="line">1       ena     exon    275008  278625  .       +       .       Parent=transcript:RZC43352;Name=RZC43352-4;constitutive=1;ensembl_end_phase=2;ensembl_phase=2;exon_id=RZC43352-4;rank=4</span><br><span class="line">1       ena     three_prime_UTR 275585  278625  .       +       .       Parent=transcript:RZC43352</span><br><span class="line">###</span><br></pre></td></tr></table></figure>
<p>对于摘录的这个基因，一共九列，每一列代表什么意思呢？GFF3 has 9 required fields, though not all are utilized (either blank or a default value of ‘.’).</p>
<ol>
<li>Sequence ID</li>
<li>Source<br />
Describes the algorithm or the procedure that generated this feature. Typically Genescane or Genebank, respectively.</li>
<li>Feature Type<br />
Describes what the feature is (mRNA, domain, exon, etc.).<br />
These terms are constrained to the <a href="http://www.sequenceontology.org/">Sequence Ontology terms</a>.</li>
<li>Feature Start</li>
<li>Feature End</li>
<li>Score<br />
Typically E-values for sequence similarity and P-values for predictions.</li>
<li>Strand</li>
<li>Phase<br />
Indicates where the feature begins with reference to the reading frame. The phase is one of the integers 0, 1, or 2, indicating the number of bases that should be removed from the beginning of this feature to reach the first base of the next codon.</li>
<li>Atributes<br />
A semicolon-separated list of tag-value pairs, providing additional information about each feature. Some of these tags are predefined, e.g. ID, Name, Alias, Parent . You can see the full list <a href="https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md">here</a>.</li>
</ol>
<p>那么第八列的“Phase”到底是什么呢？</p>
<p>我看的一个<a href="https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md">网站</a>对此的解释是：For features of type “CDS”, the phase indicates where the next codon begins relative to the 5’ end (where the 5’ end of the CDS is relative to the strand of the CDS feature) of the current CDS feature. For clarification the 5’ end for CDS features on the plus strand is the feature’s start and and the 5’ end for CDS features on the minus strand is the feature’s end. The phase is one of the integers 0, 1, or 2, indicating the number of bases forward from the start of the current CDS feature the next codon begins. A phase of “0” indicates that a codon begins on the first nucleotide of the CDS feature (i.e. 0 bases forward), a phase of “1” indicates that the codon begins at the second nucleotide of this CDS feature and a phase of “2” indicates that the codon begins at the third nucleotide of this region. Note that ‘Phase’ in the context of a GFF3 CDS feature should not be confused with the similar concept of frame that is also a common concept in bioinformatics. Frame is generally calculated as a value for a given base relative to the start of the complete open reading frame (ORF) or the codon (e.g. modulo 3) while CDS phase describes the start of the next codon relative to a given CDS feature. The phase is REQUIRED for all CDS features.</p>
<p>以本文最开始摘录的罂粟基因为例，下图是我的笔记，CDS 区域一共包含四个片段，分别长度为 372，88，130 和 577 bp。DNA 总长度 1167 bp，对应 389 aa 长度的蛋白。注意第二个 CDS 翻译之后多出一个碱基，需要与第三个 CDS 的首二位碱基组成密码子，也就是说第三个 CDS 的翻译起始标记点是第三位碱基（由于基因组坐标的起始点为 0，所以该翻译标记点在基因组坐标为 2）。第三个 CDS 翻译之后多出两个碱基，需要与第四个 CDS 的首位碱基组成密码子，也就是说第四个 CDS 的翻译起始标记点是第二位碱基（在基因组坐标为 1）。</p>
<p><img src="https://i.imgur.com/psjLK2i.jpeg" alt="" /></p>
<p>有时候基因有多个转录本，如下所示，下面摘抄的 gff3 信息来自：<a href="https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md">https://github.com/The-Sequence-Ontology/Specifications/blob/master/gff3.md</a>。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"> 0  ##gff-version 3.1.26</span><br><span class="line"> 1  ##sequence-region ctg123 1 1497228</span><br><span class="line"> 2  ctg123 . gene            1000  9000  .  +  .  ID=gene00001;Name=EDEN</span><br><span class="line"> 3  ctg123 . TF_binding_site 1000  1012  .  +  .  ID=tfbs00001;Parent=gene00001</span><br><span class="line"> 4  ctg123 . mRNA            1050  9000  .  +  .  ID=mRNA00001;Parent=gene00001;Name=EDEN.1</span><br><span class="line"> 5  ctg123 . mRNA            1050  9000  .  +  .  ID=mRNA00002;Parent=gene00001;Name=EDEN.2</span><br><span class="line"> 6  ctg123 . mRNA            1300  9000  .  +  .  ID=mRNA00003;Parent=gene00001;Name=EDEN.3</span><br><span class="line"> 7  ctg123 . exon            1300  1500  .  +  .  ID=exon00001;Parent=mRNA00003</span><br><span class="line"> 8  ctg123 . exon            1050  1500  .  +  .  ID=exon00002;Parent=mRNA00001,mRNA00002</span><br><span class="line"> 9  ctg123 . exon            3000  3902  .  +  .  ID=exon00003;Parent=mRNA00001,mRNA00003</span><br><span class="line">10  ctg123 . exon            5000  5500  .  +  .  ID=exon00004;Parent=mRNA00001,mRNA00002,mRNA00003</span><br><span class="line">11  ctg123 . exon            7000  9000  .  +  .  ID=exon00005;Parent=mRNA00001,mRNA00002,mRNA00003</span><br><span class="line">12  ctg123 . CDS             1201  1500  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1</span><br><span class="line">13  ctg123 . CDS             3000  3902  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1</span><br><span class="line">14  ctg123 . CDS             5000  5500  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1</span><br><span class="line">15  ctg123 . CDS             7000  7600  .  +  0  ID=cds00001;Parent=mRNA00001;Name=edenprotein.1</span><br><span class="line">16  ctg123 . CDS             1201  1500  .  +  0  ID=cds00002;Parent=mRNA00002;Name=edenprotein.2</span><br><span class="line">17  ctg123 . CDS             5000  5500  .  +  0  ID=cds00002;Parent=mRNA00002;Name=edenprotein.2</span><br><span class="line">18  ctg123 . CDS             7000  7600  .  +  0  ID=cds00002;Parent=mRNA00002;Name=edenprotein.2</span><br><span class="line">19  ctg123 . CDS             3301  3902  .  +  0  ID=cds00003;Parent=mRNA00003;Name=edenprotein.3</span><br><span class="line">20  ctg123 . CDS             5000  5500  .  +  1  ID=cds00003;Parent=mRNA00003;Name=edenprotein.3</span><br><span class="line">21  ctg123 . CDS             7000  7600  .  +  1  ID=cds00003;Parent=mRNA00003;Name=edenprotein.3</span><br><span class="line">22  ctg123 . CDS             3391  3902  .  +  0  ID=cds00004;Parent=mRNA00003;Name=edenprotein.4</span><br><span class="line">23  ctg123 . CDS             5000  5500  .  +  1  ID=cds00004;Parent=mRNA00003;Name=edenprotein.4</span><br><span class="line">24  ctg123 . CDS             7000  7600  .  +  1  ID=cds00004;Parent=mRNA00003;Name=edenprotein.4</span><br></pre></td></tr></table></figure>
<p><img src="https://i.imgur.com/lkk3KPb.png" alt="" /></p>
<p>我现在遇到一个问题，手上一个基因组 gff3 文件报错。经过探究，我发现染色体负链上的 Phase 信息有误，“2”其实应该写成“1”；而“1”则应该是“2”，我在下面摘录的内容里做了批注，注意坐标出现的顺序，我用 <code>#1 #2 #3</code> 字样标记。。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost AM]$ awk &#x27;NR&lt;=526 &amp;&amp; NR&gt;=509&#x27; AMO.protein.gff_6 | grep CDS</span><br><span class="line">scaffold_1      EVM     CDS     83908   85562   .       -       0       ID=scaffold_1.g00002.m1.cds;Parent=scaffold_1.g00002.m1;</span><br><span class="line">scaffold_1      EVM     CDS     83193   83430   .       -       2       ID=scaffold_1.g00002.m1.cds;Parent=scaffold_1.g00002.m1;</span><br><span class="line">scaffold_1      EVM     CDS     82539   82811   .       -       0       ID=scaffold_1.g00002.m1.cds;Parent=scaffold_1.g00002.m1;</span><br><span class="line">scaffold_1      EVM     CDS     82210   82453   .       -       0       ID=scaffold_1.g00002.m1.cds;Parent=scaffold_1.g00002.m1;</span><br><span class="line">scaffold_1      EVM     CDS     81891   82129   .       -       1       ID=scaffold_1.g00002.m1.cds;Parent=scaffold_1.g00002.m1;</span><br><span class="line">scaffold_1      EVM     CDS     81688   81762   .       -       0       ID=scaffold_1.g00002.m1.cds;Parent=scaffold_1.g00002.m1;</span><br><span class="line">scaffold_1      EVM     CDS     81403   81594   .       -       0       ID=scaffold_1.g00002.m1.cds;Parent=scaffold_1.g00002.m1;</span><br><span class="line">(python37) [fenglei@localhost AM]$ awk &#x27;NR&lt;=526 &amp;&amp; NR&gt;=509&#x27; AMO.protein.gff_6 | grep CDS | awk &#x27;&#123;a=$5-$4+1; print $3&quot;\t&quot;$4&quot;\t&quot;$5&quot;\t&quot;$7&quot;\t&quot;$8&quot;\t&quot;a &#125;&#x27;</span><br><span class="line">CDS     83908   85562   -       0       1655 #1 CDS 1655 / 3 = 551  ... 2</span><br><span class="line">CDS     83193   83430   -       2       238  #2 CDS (238 - 1) / 3 = 79 括号里“-1”表示该CDS的首位碱基与上游CDS的末两位碱基组成密码子，所以这里Phase值理论上应该是1</span><br><span class="line">CDS     82539   82811   -       0       273  #3 CDS 273 / 3 = 91</span><br><span class="line">CDS     82210   82453   -       0       244  #4 CDS 244 / 3 = 81  ... 1</span><br><span class="line">CDS     81891   82129   -       1       239  #5 CDS (239 -2) / 3 = 79 括号里“-2”表示该CDS的首两位碱基与上游CDS的末位碱基组成密码子，所以这里Phase值理论上应该是2</span><br><span class="line">CDS     81688   81762   -       0       75   #6 CDS 75 / 3 = 25</span><br><span class="line">CDS     81403   81594   -       0       192  #7 CDS 192 / 3 = 64</span><br></pre></td></tr></table></figure>
<p>另一个没有报错的基因组 gff 文件摘录如下。手动计算 Phase 值，确实是能与 gff3 文件匹配的。注意坐标出现的顺序，我用 <code>#1 #2 #3</code> 字样标记。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(base) [fenglei@localhost opium_poppy_Papaver_somniferum]$ awk &#x27;NR&gt;=82 &amp;&amp; NR&lt;=95&#x27; Papaver_somniferum.ASM357369v1.55.chr.gff3 | grep CDS</span><br><span class="line">1       ena     CDS     276433  276552  .       -       0       ID=CDS:RZC43353;Parent=transcript:RZC43353;protein_id=RZC43353</span><br><span class="line">1       ena     CDS     276665  276747  .       -       2       ID=CDS:RZC43353;Parent=transcript:RZC43353;protein_id=RZC43353</span><br><span class="line">1       ena     CDS     276870  276953  .       -       2       ID=CDS:RZC43353;Parent=transcript:RZC43353;protein_id=RZC43353</span><br><span class="line">1       ena     CDS     278336  278468  .       -       0       ID=CDS:RZC43353;Parent=transcript:RZC43353;protein_id=RZC43353</span><br><span class="line">(base) [fenglei@localhost opium_poppy_Papaver_somniferum]$ awk &#x27;NR&gt;=82 &amp;&amp; NR&lt;=95&#x27; Papaver_somniferum.ASM357369v1.55.chr.gff3 | grep CDS | awk &#x27;&#123;a=$5-$4+1; print $3&quot;\t&quot;$4&quot;\t&quot;$5&quot;\t&quot;$7&quot;\t&quot;$8&quot;\t&quot;a &#125;&#x27;            </span><br><span class="line">CDS     276433  276552  -       0       120 #4 CDS 120 / 3 = 40</span><br><span class="line">CDS     276665  276747  -       2       83  #3 CDS (83-2) / 3 = 27 括号里“-2”表示该CDS的首两位碱基与上游CDS的末位碱基组成密码子</span><br><span class="line">CDS     276870  276953  -       2       84  #2 CDS (84-2) / 3 = 27 ... 1 括号里“-2”表示该CDS的首两位碱基与上游CDS的末位碱基组成密码子</span><br><span class="line">CDS     278336  278468  -       0       133 #1 CDS 133 / 3 = 44 ... 1</span><br></pre></td></tr></table></figure>
<p>我以为我终于发现问题所在，既然是 Phase 值问题，那我统一将1改成2，将2改成1，那不就行了？结果改完发现还是有报错，原来旧 gff3 文件也有一部分是正确标记的。所以其实是最初生成的 gff3 文件本身比较“混乱”。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python37) [fenglei@localhost AM]$ awk &#x27;$0~/Chr01.g00017.m3.cds/&#123;print NR&quot;\t&quot;$0&#125;&#x27; AMO.protein.gff_6</span><br><span class="line">727     Chr01   EVM     CDS     56788   57559   .       -       0       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">729     Chr01   EVM     CDS     56395   56647   .       -       2       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">731     Chr01   EVM     CDS     55428   56244   .       -       1       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">733     Chr01   EVM     CDS     53917   54041   .       -       0       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">735     Chr01   EVM     CDS     53661   53745   .       -       1       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">737     Chr01   EVM     CDS     52591   52756   .       -       0       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">739     Chr01   EVM     CDS     52448   52488   .       -       2       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">741     Chr01   EVM     CDS     52094   52361   .       -       0       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">743     Chr01   EVM     CDS     47492   47615   .       -       2       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">745     Chr01   EVM     CDS     47048   47408   .       -       1       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br><span class="line">747     Chr01   EVM     CDS     36866   37144   .       -       0       ID=Chr01.g00017.m3.cds;Parent=Chr01.g00017.m3;</span><br></pre></td></tr></table></figure>
<p>修复工具：GFF3 Toolkit <a href="https://gff3toolkit.readthedocs.io/en/latest/index.html">https://gff3toolkit.readthedocs.io/en/latest/index.html</a></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(python27) [fenglei@localhost AM]$ pip install gff3tool</span><br><span class="line">(python27) [fenglei@localhost AM]$ # conda install -c bioconda gff3tool</span><br><span class="line">(python27) [fenglei@localhost AM]$ gff3_QC -g genes.gff3 -f genome_softmasked.fa -o gff3_QC_statistic.txt</span><br><span class="line">(python27) [fenglei@localhost AM]$ le gff3_QC_statistic.txt</span><br><span class="line">      1 Error_code      Number_of_problematic_models    Error_level     Error_tag</span><br><span class="line">      2 Emr0003 171368  Error   Duplicate ID</span><br><span class="line">      3 Esf0012 4       Info    Found Ns in a feature using the external FASTA</span><br><span class="line">      4 Ema0002 96      Warning Protein sequence contains internal stop codons</span><br><span class="line">      5 Emr0002 5       Warning Incorrectly split gene parent?</span><br><span class="line">      6 Ema0001 3148    Warning Parent feature start and end coordinates exceed those of child features</span><br></pre></td></tr></table></figure>
<p>我自己编写了一个专门修复 Phase 值的 Perl 程序，将 gff3 文件按照每个基因依次进行修复，代码此处未附上。</p>
]]></content>
      <categories>
        <category>Bioinfo</category>
      </categories>
  </entry>
  <entry>
    <title>Life | R2S 软路由器的安装</title>
    <url>/2023/02/15/R2S_installation/</url>
    <content><![CDATA[<h3 id="r2s-简介"><a class="markdownIt-Anchor" href="#r2s-简介"></a> R2S 简介</h3>
<p>NanoPi R2S（以下简称R2S）是友善电子团队推出的一款卡片式电脑，它包含了两个千兆的网口，可以用来构建软路由。下面就介绍一下如何使用R2S构建一个软路由。使用到的配件：1. NanoPi R2S；2. 电源适配器（必须为5V2A或5V3A） + USB电源线；3. 网线；4. TF存储卡 + 读卡器；5. 普通的路由器一个。</p>
<span id="more"></span>
<h3 id="r2s-固件下载"><a class="markdownIt-Anchor" href="#r2s-固件下载"></a> R2S 固件下载</h3>
<p>主要参考了 BigDongDong 的视频教学，此处是他整理的资源列表，可以在国内访问（<a href="https://www.kancloud.cn/bigdongdong/armgear/2662921">https://www.kancloud.cn/bigdongdong/armgear/2662921</a>）。<br />
进去该网页之后，选择“<a href="https://cccscls-my.sharepoint.com/:f:/g/personal/boss_jldjld_com/ElWgGfaKZbxPjAa1T2A7y34ByD3glYWj_aO-iC4mfKhn1A?e=MDjxyF">Alist网盘聚合-点此跳转下载</a>”; 然后点击“夸克网盘”，点击“固件及工具”，点击“ARM架构机型如R2SR4S”，点击“R2S固件”，点击“东东打包丨后台192.168.2.1密码password”，点击“R2S-20221225 kiddin9”，此时就可以下载文件“openwrt-12.25.2022-rockchip-armv8-friendlyarm_nanopi-r2s-squashfs-sysupgrade.img.gz”，该压缩文件大小为 180 MB。</p>
<h3 id="r2s-固件安装"><a class="markdownIt-Anchor" href="#r2s-固件安装"></a> R2S 固件安装</h3>
<p>需要用一个软件将固件系统刷到TF卡里面，下载网址为<a href="https://www.balena.io/etcher">https://www.balena.io/etcher</a>，在该网站主页选择版本为“ETCHER FOR WINDOWS (X86|X64) (INSTALLER)”，我好像试了好几次才下载成功，下载的刷机软件是“balenaEtcher-Setup-1.10.2.exe”，大小为 141 MB，双击即可使用，没有选择安装路径这些操作。</p>
<p>把 TF 卡插入读卡器并接入到电脑的 USB 接口中，在电脑上双击 balenaEtcher 镜像烧录软件，之后选择之前下载好的镜像文件（openwrt-12.25.2022-rockchip-armv8-friendlyarm_nanopi-r2s-squashfs-sysupgrade.img.gz），<br />
把镜像文件写入到TF卡中去。这个步骤可参考：<a href="https://www.bilibili.com/video/av371600621/?vd_source=df0c38c3fefeb36c7240d89ee3901025">NanoPi-R2S balenaEtcher通用烧录教程</a>。</p>
<h3 id="r2s-系统设置"><a class="markdownIt-Anchor" href="#r2s-系统设置"></a> R2S 系统设置</h3>
<p>我的光猫本身具有PPPoE拨号功能，已经可以通过光猫联网。此时，将光猫的LAN口与R2S的WAN口用网线相连，再将R2S的LAN口与电脑的网口用网线相连，此时将R2S通电，然后在电脑浏览器输入 &lt;192.168.2.1&gt;，出来的页面会要求输入密码，默认密码“password”，就可以打开OpenWRT页面，并且此时电脑已经联网。</p>
<p>在OpenWRT的页面左侧选择“服务”栏目，选择“ShadowSocksRPlus”，进入该应用的设置页面。“服务器节点” → 输入订阅URL（可点加号，输入多个订阅地址，点粘贴，粘贴刚才的订阅地址），然后点 “更新订阅URL列表”，再然后点 “更新所有服务器节点” 按钮。待更新获取节点列表，选取延时值小，连接测试ok的节点应用保存就可以。此时，电脑就可以打开谷歌等网站。运行模式，请勿选择全局（全局模式下所有流量都走国外），请选择GFW模式或者绕开大陆地址模式（这样访问国内就不消耗机场流量了）。</p>
<p>上面是将R2S的LAN口与电脑的网口用网线相连进行网络配置的，为了让多个终端可以使用该R2S，需要将一台无线路由器与R2S连起来，我选择将无线路由器的WAN口与R2S的LAN口连起来，就可以通过WiFi连入无线路由器进行上网。这一步注意无线路由器的网关地址避开192.168.2.X网段，可以设为192.168.3.1之类的。也有人选择将无线路由器的LAN口与R2S的LAN口连起来，此时无线路由器就是一个AP而已，我没有这么做，需要的话再参考其他人的设置。</p>
<p>关于订阅URL，有不少产品可以选择。有人整理了若干产品在此：<a href="https://52.mk/">https://52.mk/</a>。选择其中一个产品测试使用是可行的：<a href="https://52.mk/sites/57.html">https://52.mk/sites/57.html</a>。</p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<ol>
<li><a href="https://blog.csdn.net/qq_42359416/article/details/115267080">R2S食用指南（含 R2S软路由系统刷入、R2S做主路由、二级路由AP模式、NAS的DDNS实现+URL转发）</a></li>
<li><a href="https://mmensee.gitbook.io/r2s-r4s/ke-xue-guan-guang-ru-he-cao-zuo/shdowsocksr-plus+-de-tu-wen-jiao-cheng">ShdowsocksR plus+的图文教程</a></li>
</ol>
]]></content>
      <categories>
        <category>Life</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | 无 root 权限安装 tmux</title>
    <url>/2023/02/22/install-tmux-without-root-permission/</url>
    <content><![CDATA[<p>tmux（terminal multiplexer）是 Linux 上的终端复用神器。办公室网络连接机房的 Linux 服务器，网络经常开小差掉线，如果使用tmux，就可以在网络重连之后继续之前的操作页面。我没有该服务器的 root 权限，所以只能安装在用户目录下。</p>
<span id="more"></span>
<h3 id="安装-tmux"><a class="markdownIt-Anchor" href="#安装-tmux"></a> 安装 tmux</h3>
<p>下载tmux安装包及其依赖软件。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">wget -c https://github.com/tmux/tmux/releases/download/3.3a/tmux-3.3a.tar.gz</span><br><span class="line">wget -c https://github.com/libevent/libevent/releases/download/release-2.1.12-stable/libevent-2.1.12-stable.tar.gz</span><br><span class="line">wget -c https://ftp.gnu.org/gnu/ncurses/ncurses-6.3.tar.gz</span><br></pre></td></tr></table></figure>
<p>先安装依赖，再安装tmux。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#libevent</span><br><span class="line">./configure --prefix=/data3/home/fenglei/local --disable-shared</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"></span><br><span class="line">#ncurses</span><br><span class="line">./configure --prefix=--prefix=/data3/home/fenglei/local</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"></span><br><span class="line">#tmux</span><br><span class="line">./configure CFLAGS=&quot;-I/my/path/tmux_depend/include -I/my/path/tmux_depend/include/ncurses&quot; LDFLAGS=&quot;-L/my/path/tmux_depend/lib -L/my/path/tmux_depend/include/ncurses -L/my/path/tmux_depend/include&quot; --prefix=/data3/home/fenglei/local</span><br><span class="line"></span><br><span class="line">./configure CFLAGS=&quot;-I/data3/home/fenglei/local/include -I/data3/home/fenglei/local/include/ncurses&quot; LDFLAGS=&quot;-L/data3/home/fenglei/local/lib -L/data3/home/fenglei/local/include/ncurses -L/data3/home/fenglei/local/include&quot; --prefix=/data3/home/fenglei/local</span><br><span class="line"></span><br><span class="line">#CPPFLAGS=&quot;-I/my/path/tmux_depend//include -I/my/path/tmux_depend//include/ncurses&quot; LDFLAGS=&quot;-static -L/my/path/tmux_depend//include -L/my/path/tmux_depend//include/ncurses -L/my/path/tmux_depend//lib&quot;   ## 我没有运行这条命令</span><br><span class="line"></span><br><span class="line">make</span><br><span class="line">make install</span><br><span class="line">cp tmux  /data3/home/fenglei/local/bin</span><br></pre></td></tr></table></figure>
<p>设置环境变量。在 <code>~/.bashrc</code> 中添加此内容：<code>export PATH=/data3/home/fenglei/local/bin:$PATH</code>。</p>
<h3 id="使用-tmux"><a class="markdownIt-Anchor" href="#使用-tmux"></a> 使用 tmux</h3>
<p>我常用的命令如下：</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">tmux    # 在客户端启动tmux，一般会以“0、1、2、3”这样的顺序命名会话，也可以自命名</span><br><span class="line">exit    # 在 tmux 界面退出</span><br><span class="line">tmux ls # 在客户端查看当前存在的会话列表</span><br><span class="line">tmux attach -t 0 # 在客户端进入“0”号tmux（假如网络断开，就用这个命令重新进入之前的操作界面。）</span><br></pre></td></tr></table></figure>
<p>如果需要保存当前的tmux会话，就先按下“Crtl + b”，松开按键再按一下“d”（就是deattach的意思），下次就可以用 <code>tmux attach -t mysession</code> 这样的命令重新进入会话界面。</p>
<p>更多的操作可查阅下面的参考资料。</p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<ol>
<li><a href="https://www.cnblogs.com/jessepeng/p/12452169.html">https://www.cnblogs.com/jessepeng/p/12452169.html</a></li>
</ol>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | PBS作业管理系统使用技巧</title>
    <url>/2023/04/05/PBS-job-submission/</url>
    <content><![CDATA[<p>学校的服务器分为“登录节点”和“计算节点”，要求使用PBS投递任务，现做个记录。</p>
<span id="more"></span>
<h3 id="作业提交和管理命令"><a class="markdownIt-Anchor" href="#作业提交和管理命令"></a> 作业提交和管理命令</h3>
<table>
<thead>
<tr>
<th>命令</th>
<th>功能</th>
<th>使用说明</th>
<th>示例</th>
</tr>
</thead>
<tbody>
<tr>
<td>qsub</td>
<td>提交pbs作业</td>
<td>qsub [script]</td>
<td>$ qsub job.pbs</td>
</tr>
<tr>
<td>qdel</td>
<td>删除pbs作业</td>
<td>qdel [job_id]</td>
<td>$ qdel 12345</td>
</tr>
<tr>
<td>qhold</td>
<td>挂起pbs作业</td>
<td>qhold [job_id]</td>
<td>$ qhold 12345</td>
</tr>
<tr>
<td>qrls</td>
<td>释放挂起的pbs作业</td>
<td>qrls [job_id]</td>
<td>$ qrls 12345</td>
</tr>
</tbody>
</table>
<h3 id="作业状态查询命令"><a class="markdownIt-Anchor" href="#作业状态查询命令"></a> 作业状态查询命令</h3>
<table>
<thead>
<tr>
<th>命令</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>qstat -q</td>
<td>列出所有队列</td>
</tr>
<tr>
<td>qstat -an</td>
<td>列出所有作业</td>
</tr>
<tr>
<td>qstat -u user_id</td>
<td>列出user_id的所有作业</td>
</tr>
<tr>
<td>qstat -r</td>
<td>列出所有正在运行的作业</td>
</tr>
<tr>
<td>qstat -f job_id</td>
<td>列出作业job_id的信息</td>
</tr>
<tr>
<td>qstat -fQ queue</td>
<td>列出队列queue的信息</td>
</tr>
<tr>
<td>qstat -B</td>
<td>列出所有作业状态的汇总</td>
</tr>
<tr>
<td>pbsnodes</td>
<td>列出所有节点的详细信息</td>
</tr>
<tr>
<td>pestat</td>
<td>列出所有节点的状态</td>
</tr>
</tbody>
</table>
<h3 id="pbs作业参数"><a class="markdownIt-Anchor" href="#pbs作业参数"></a> PBS作业参数</h3>
<p>下面是摘抄他人的PBS投递脚本</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">#PBS -l nodes=1:ppn=16</span><br><span class="line">#PBS -l walltime=1000:00:00</span><br><span class="line">#PBS -q high</span><br><span class="line">#PBS -N Job_Name</span><br><span class="line">#PBS -oe</span><br><span class="line">your_commands_goes_here</span><br></pre></td></tr></table></figure>
<p>我在实践投递任务的过程中，是准备两个类型的文件：xxx.pbs 和 <a href="http://yyy.sh">yyy.sh</a>。通过一个 pbs 文件来运行一个或多个 sh 脚本。</p>
<p>比如 my.pbs 文件包含下面的内容。注意要用 cd 命令进入工作目录，且 sh 脚本最好通过重定向功能保存屏幕输出信息和错误信息到指定记录文件，便于查看潜在错误信息。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#PBS -N lfeng_RNA_seq</span><br><span class="line">#PBS -o /data3/home/fenglei/pbs.out</span><br><span class="line">#PBS -e /data3/home/fenglei/pbs.err</span><br><span class="line">#PBS -q top_q</span><br><span class="line">#PBS -l nodes=1:ppn=8</span><br><span class="line"></span><br><span class="line">cd /data3/home/fenglei/data/xxx_path</span><br><span class="line">sh hisat2.sh &gt; hisat2.sh_log 2&gt;&amp;1</span><br><span class="line">sh stringtie.sh &gt; stringtie.sh 2&gt;&amp;1 </span><br></pre></td></tr></table></figure>
<p>上面的 pbs 文件中，-N 后面是任务名称，自定义一个字符串即可；-o 和 -e 后面分别是重定向标准输出和错误信息，一般我很少看；-q 后面指定特定的计算节点（根据服务器管理方提供的名称来填写）；-l 后面就是指定节点数目和处理器数目。比如我上面 pbs 文件的意思就是在 top_q 这个计算服务器申请 8 个处理器，用来运行 hisat2 和 <a href="http://stringtie.sh">stringtie.sh</a> 这两个脚本文件。</p>
<p><a href="http://hisat2.sh">hisat2.sh</a> 包含以下内容。注意调用程序用绝对路径，我测试发现我所使用的服务器必须这样操作才能正常运行。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">set -e</span><br><span class="line">set -u</span><br><span class="line">set -o pipefail</span><br><span class="line">/path/to/hisat2 -i xxx.fa -o yyy.sam  # 仅作示范</span><br></pre></td></tr></table></figure>
<p>stringtie 包含以下内容。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#!/bin/bash</span><br><span class="line">set -e</span><br><span class="line">set -u</span><br><span class="line">set -o pipefail</span><br><span class="line">/path/to/stringtie -i yyy.bam -o zzz.fpkm # 仅作示范</span><br></pre></td></tr></table></figure>
<p>那么我运行 <code>qsub my.pbs</code> 之后，首先可以通过 <code>qstat -an</code> 看看任务列表里面有没有我这个新的任务，其次在当前工作目录会生成 hisat2.sh_log 这样的记录文件，如果没有报错，最后能看到脚本生成的结果文件。</p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<ol>
<li><a href="https://kevinzjy.github.io/2018/08/13/180813-Server-PBS/">kevinzjy：PBS作业管理系统使用技巧</a></li>
<li><a href="http://www.ihb.cas.cn/cszx/cszx_zlxz/201808/P020180827310973379054.pdf">《中国科学院超级计算武汉分中心 PBS 用户指南》文件格式：pdf</a></li>
<li><a href="http://hpc.cczu.edu.cn/_upload/article/files/78/96/07d83fbf4fb682744db33b4c6a72/655073ed-ad02-4e57-ae0e-f46394e8d09c.pdf">《国家高性能计算中心（西安）------PBS 提交作业使用指南》文件格式：pdf</a></li>
</ol>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | Vim 的设置</title>
    <url>/2023/03/28/Setting_Vim/</url>
    <content><![CDATA[<p>VIM 的配置主要参考博文：<a href="https://www.cnblogs.com/xuyaowen/p/vim_usage.html">https://www.cnblogs.com/xuyaowen/p/vim_usage.html</a>。直接将下面的代码复制到 <code>~/.vimrc</code> 就可以了。</p>
<span id="more"></span>
<p>注意我将第 2、第 45-59 行注释掉了。</p>
<p>第 2 行是指“set cursorcolumn”，这个设定 vim 编辑界面鼠标光标所在位置的列会高亮，我不需要，将其用双引号注释掉即可。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">&quot; vim 自身功能配置 (https://www.cnblogs.com/xuyaowen/) </span><br><span class="line">&quot; Line 45-59 被我注释掉，因为它们会导致报错</span><br><span class="line">set nu &quot; line number </span><br><span class="line">set cursorline &quot; row line</span><br><span class="line">&quot; set cursorcolumn &quot;col line </span><br><span class="line">set hlsearch</span><br><span class="line">set laststatus=2</span><br><span class="line">set nowrap</span><br><span class="line"></span><br><span class="line">&quot; 前导键</span><br><span class="line">let mapleader=&quot;;&quot;</span><br><span class="line"></span><br><span class="line">&quot; 基础配置</span><br><span class="line">&quot; filetype plugin on</span><br><span class="line">&quot; 命令映射，&lt;Leader&gt; 表示前导键</span><br><span class="line">nmap LB 0</span><br><span class="line">nmap LE $</span><br><span class="line">nmap &lt;Leader&gt;q :q&lt;CR&gt;</span><br><span class="line">nmap &lt;Leader&gt;w :w&lt;CR&gt;</span><br><span class="line">nmap &lt;Leader&gt;Q :qa!&lt;CR&gt;</span><br><span class="line">&quot; 设置快捷键遍历子窗口</span><br><span class="line">&quot; &quot; 依次遍历</span><br><span class="line">nnoremap nw &lt;C-W&gt;&lt;C-W&gt;</span><br><span class="line">&quot; 跳转至右方的窗口</span><br><span class="line">nnoremap &lt;Leader&gt;lw &lt;C-W&gt;l</span><br><span class="line">&quot; 跳转至方的窗口</span><br><span class="line">nnoremap &lt;Leader&gt;hw &lt;C-W&gt;h</span><br><span class="line">&quot; 跳转至上方的子窗口</span><br><span class="line">nnoremap &lt;Leader&gt;kw &lt;C-W&gt;k</span><br><span class="line">&quot; 跳转至下方的子窗口</span><br><span class="line">nnoremap &lt;Leader&gt;jw &lt;C-W&gt;j</span><br><span class="line">&quot; 让配置变更立即生效</span><br><span class="line">autocmd BufWritePost $MYVIMRC source $MYVIMRC</span><br><span class="line">&quot; 实时搜索</span><br><span class="line">set incsearch</span><br><span class="line">&quot; vim 自动补全</span><br><span class="line">set wildmenu</span><br><span class="line"></span><br><span class="line">&quot; 关闭兼容模式</span><br><span class="line">set nocompatible &quot; vundle required</span><br><span class="line">&quot; 插件安装</span><br><span class="line">&quot; vundle 环境设置</span><br><span class="line">filetype off</span><br><span class="line">set rtp+=~/.vim/bundle/Vundle.vim</span><br><span class="line">&quot; vundle 管理的插件列表必须位于 vundle#begin() 和 vundle#end() 之间</span><br><span class="line">&quot; call vundle#begin()</span><br><span class="line">&quot; let Vundle manage Vundle, required</span><br><span class="line">&quot; Plugin &#x27;VundleVim/Vundle.vim&#x27;</span><br><span class="line">&quot; Plugin &#x27;altercation/vim-colors-solarized&#x27;</span><br><span class="line">&quot; Plugin &#x27;octol/vim-cpp-enhanced-highlight&#x27;</span><br><span class="line">&quot; Plugin &#x27;Lokaltog/vim-powerline&#x27;</span><br><span class="line">&quot; Plugin &#x27;scrooloose/nerdcommenter&#x27;</span><br><span class="line">&quot; Plugin &#x27;SirVer/ultisnips&#x27;</span><br><span class="line">&quot; Plugin &#x27;honza/vim-snippets&#x27;</span><br><span class="line">&quot; Plugin &#x27;scrooloose/nerdtree&#x27;</span><br><span class="line">&quot; Plugin &#x27;sjl/gundo.vim&#x27;</span><br><span class="line">&quot; Plugin &#x27;Valloric/YouCompleteMe&#x27;</span><br><span class="line">&quot; Plugin &#x27;Valloric/YouCompleteMe&#x27;</span><br><span class="line">&quot; 插件列表结束</span><br><span class="line">&quot; call vundle#end()</span><br><span class="line">filetype plugin indent on</span><br><span class="line"></span><br><span class="line">&quot; code scheme </span><br><span class="line">syntax enable</span><br><span class="line">syntax on</span><br><span class="line">&quot; set background=light</span><br><span class="line">&quot; colorscheme solarized</span><br><span class="line"></span><br><span class="line">&quot; powerline scheme</span><br><span class="line">let g:Powerline_colorscheme=&#x27;solarized256&#x27;</span><br><span class="line">&quot; 代码缩进</span><br><span class="line">&quot; 设置编辑时制表符占用空格数</span><br><span class="line">set tabstop=4</span><br><span class="line">&quot; 设置格式化时制表符占用空格数</span><br><span class="line">set shiftwidth=4</span><br><span class="line">&quot; 自适应不同语言的智能缩进</span><br><span class="line">filetype indent on</span><br><span class="line"></span><br><span class="line">&quot; 基于缩进或语法进行代码折叠</span><br><span class="line">set foldmethod=indent</span><br><span class="line">&quot;set foldmethod=syntax</span><br><span class="line">set nofoldenable</span><br><span class="line"></span><br><span class="line">&quot; vim-snippets</span><br><span class="line">&quot; let g:UltiSnipsExpandTrigger=&quot;&lt;tab&gt;&quot;</span><br><span class="line">&quot; let g:UltiSnipsJumpForwardTrigger=&quot;&lt;c-b&gt;&quot;</span><br><span class="line">&quot; let g:UltiSnipsJumpBackwardTrigger=&quot;&lt;c-z&gt;&quot;</span><br><span class="line">let g:UltiSnipsExpandTrigger=&quot;&lt;leader&gt;&lt;tab&gt;&quot;</span><br><span class="line">let g:UltiSnipsJumpForwardTrigger=&quot;&lt;leader&gt;&lt;tab&gt;&quot;</span><br><span class="line">let g:UltiSnipsJumpBackwardTrigger=&quot;&lt;leader&gt;&lt;s-tab&gt;&quot;</span><br><span class="line">let g:UltiSnipsEditSplit=&quot;vertical&quot;</span><br><span class="line"></span><br><span class="line">&quot; 启用:Man命令查看各类man信息</span><br><span class="line">source $VIMRUNTIME/ftplugin/man.vim</span><br><span class="line">&quot;</span><br><span class="line">&quot; &quot; 定义:Man命令查看各类man信息的快捷键</span><br><span class="line">nmap &lt;Leader&gt;man :Man 3 &lt;cword&gt;&lt;CR&gt;</span><br><span class="line"></span><br><span class="line">&quot; 使用 NERDTree 插件查看工程文件。设置快捷键，速记：file list</span><br><span class="line">nmap &lt;Leader&gt;fl :NERDTreeToggle&lt;CR&gt;</span><br><span class="line">&quot; 设置 NERDTree 子窗口宽度</span><br><span class="line">let NERDTreeWinSize=22</span><br><span class="line">&quot; 设置 NERDTree 子窗口位置</span><br><span class="line">let NERDTreeWinPos=&quot;right&quot;</span><br><span class="line">&quot; 显示隐藏文件</span><br><span class="line">let NERDTreeShowHidden=1</span><br><span class="line">&quot; NERDTree 子窗口中不显示冗余帮助信息</span><br><span class="line">let NERDTreeMinimalUI=1</span><br><span class="line">&quot; 删除文件时自动删除文件对应 buffer</span><br><span class="line">let NERDTreeAutoDeleteBuffer=1</span><br><span class="line"></span><br><span class="line">&quot; 调用 gundo 树</span><br><span class="line">nnoremap &lt;Leader&gt;ud :GundoToggle&lt;CR&gt;</span><br><span class="line">&quot; YCM 补全菜单配色</span><br><span class="line">&quot; 菜单</span><br><span class="line">highlight Pmenu ctermfg=2 ctermbg=3 guifg=#005f87 guibg=#EEE8D5</span><br><span class="line">&quot; 选中项</span><br><span class="line">&quot;highlight PmenuSel ctermfg=2 ctermbg=3 guifg=#AFD700 guibg=#106900</span><br><span class="line">&quot; 补全功能在注释中同样有效</span><br><span class="line">let g:ycm_complete_in_comments=1</span><br><span class="line">&quot; 允许 vim 加载 .ycm_extra_conf.py 文件，不再提示</span><br><span class="line">let g:ycm_confirm_extra_conf=0</span><br><span class="line">&quot; 开启 YCM 标签补全引擎</span><br><span class="line">let g:ycm_collect_identifiers_from_tags_files=1</span><br><span class="line">&quot; 禁止缓存匹配项，每次都重新生成匹配项</span><br><span class="line">let g:ycm_cache_omnifunc=0</span><br><span class="line">&quot; &quot; 语法关键字补全            </span><br><span class="line">let g:ycm_seed_identifiers_with_syntax=1</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | Ubuntu 挂载新硬盘，使用 parted 工具将其格式化为 XFS 格式</title>
    <url>/2023/04/03/Adding_new_harddisk_to_Ubuntu/</url>
    <content><![CDATA[<p>Ubuntu 挂载新硬盘，分区工具 parted 的详解及常用分区使用方法。</p>
<span id="more"></span>
<p>硬盘买回来一开始装在 Windows 系统里，当时已经在 windows 里面分成一个区。</p>
<p>现在将硬盘更改位置装在 Ubuntu 机器里面之后，开机之后其可以自动挂载到 Ubuntu 的 media 目录下。用 fdisk 命令可看到该硬盘有两个分区，分别 sdb1 和 sdb2。</p>
<p>我比较担心 Windows 系统格式化的硬盘可能会遇到格式问题？就想重新格式化成 Linux 使用的格式。</p>
<p>原来分区工具有 fdisk 和 parted，分区格式则有 ext2、ext3、fat16、fat32、NTFS、ReiserFS、JFS、XFS、UFS、HFS 以及 Linux 交换分区。</p>
<p>我的 Ubuntu 系统是 Ubuntu 20.04，计划用 parted 工具，将一个 12TB 的硬盘格式化成 xfs 格式，并做成一个分区，然后挂载在 Ubuntu 作为数据存储盘。</p>
<h3 id="查看新硬盘"><a class="markdownIt-Anchor" href="#查看新硬盘"></a> 查看新硬盘</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@fenglei-OptiPlex-990:~# fdisk -l</span><br><span class="line">。。。（省略若干内容）</span><br><span class="line">Disk /dev/sdb: 10.91 TiB, 12000138625024 bytes, 23437770752 sectors</span><br><span class="line">Disk model: ST12000VN0008-2Y</span><br><span class="line">Units: sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 4096 bytes</span><br><span class="line">I/O size (minimum/optimal): 4096 bytes / 4096 bytes</span><br><span class="line">Disklabel type: gpt</span><br><span class="line">Disk identifier: 17860562-C2F9-4832-A505-00C29497C741</span><br><span class="line"></span><br><span class="line">Device     Start         End     Sectors  Size Type</span><br><span class="line">/dev/sdb1     34       32767       32734   16M Microsoft reserved</span><br><span class="line">/dev/sdb2  32768 23437766655 23437733888 10.9T Microsoft basic data</span><br><span class="line">。。。（省略若干内容）</span><br></pre></td></tr></table></figure>
<h3 id="删除原来的分区"><a class="markdownIt-Anchor" href="#删除原来的分区"></a> 删除原来的分区</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">$ parted /dev/sdb rm 1</span><br><span class="line"># 删除分区号为 1 的分区</span><br><span class="line">$ parted /dev/sdb rm 2</span><br><span class="line"># 删除分区号为 2 的分区</span><br></pre></td></tr></table></figure>
<h3 id="重新格式化"><a class="markdownIt-Anchor" href="#重新格式化"></a> 重新格式化</h3>
<p>运行 mkfs.xfs /dev/sdb1，我电脑说没安装这个工具，所以还运行<code>apt install xfsprogs</code>安装它。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@fenglei-OptiPlex-990:~# mkfs.xfs /dev/sdb1</span><br><span class="line">meta-data=/dev/sdb1              isize=512    agcount=11, agsize=268435455 blks</span><br><span class="line">         =                       sectsz=4096  attr=2, projid32bit=1</span><br><span class="line">         =                       crc=1        finobt=1, sparse=1, rmapbt=0</span><br><span class="line">         =                       reflink=1    bigtime=0 inobtcount=0</span><br><span class="line">data     =                       bsize=4096   blocks=2929720832, imaxpct=5</span><br><span class="line">         =                       sunit=0      swidth=0 blks</span><br><span class="line">naming   =version 2              bsize=4096   ascii-ci=0, ftype=1</span><br><span class="line">log      =internal log           bsize=4096   blocks=521728, version=2</span><br><span class="line">         =                       sectsz=4096  sunit=1 blks, lazy-count=1</span><br><span class="line">realtime =none                   extsz=4096   blocks=0, rtextents=0</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="查看格式化之后的硬盘"><a class="markdownIt-Anchor" href="#查看格式化之后的硬盘"></a> 查看格式化之后的硬盘</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@fenglei-OptiPlex-990:~# fdisk -l</span><br><span class="line">。。。（省略若干内容）</span><br><span class="line">Disk /dev/sdb: 10.91 TiB, 12000138625024 bytes, 23437770752 sectors</span><br><span class="line">Disk model: ST12000VN0008-2Y</span><br><span class="line">Units: sectors of 1 * 512 = 512 bytes</span><br><span class="line">Sector size (logical/physical): 512 bytes / 4096 bytes</span><br><span class="line">I/O size (minimum/optimal): 4096 bytes / 4096 bytes</span><br><span class="line">Disklabel type: gpt</span><br><span class="line">Disk identifier: 17860562-C2F9-4832-A505-00C29497C741</span><br><span class="line"></span><br><span class="line">Device     Start         End     Sectors  Size Type</span><br><span class="line">/dev/sdb1   2048 23437768703 23437766656 10.9T Linux filesystem</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="挂载硬盘"><a class="markdownIt-Anchor" href="#挂载硬盘"></a> 挂载硬盘</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">root@fenglei-OptiPlex-990:~# mount /dev/sdb1 /mnt/my_12TB_disk/</span><br><span class="line">root@fenglei-OptiPlex-990:~# df -h</span><br><span class="line">Filesystem      Size  Used Avail Use% Mounted on</span><br><span class="line">tmpfs           381M  3.3M  377M   1% /run</span><br><span class="line">/dev/sda3       457G   14G  421G   4% /</span><br><span class="line">tmpfs           1.9G     0  1.9G   0% /dev/shm</span><br><span class="line">tmpfs           5.0M  4.0K  5.0M   1% /run/lock</span><br><span class="line">/dev/sda2       512M  6.1M  506M   2% /boot/efi</span><br><span class="line">tmpfs           381M  2.4M  378M   1% /run/user/1000</span><br><span class="line">/dev/sdb1        11T   78G   11T   1% /mnt/my_12TB_disk</span><br></pre></td></tr></table></figure>
<h3 id="设置开机自动挂载"><a class="markdownIt-Anchor" href="#设置开机自动挂载"></a> 设置开机自动挂载</h3>
<p>获取要自动挂载的分区的UUID和分区类型TYPE</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo blkid</span><br><span class="line"></span><br><span class="line">root@fenglei-OptiPlex-990:/home/fenglei# sudo blkid</span><br><span class="line">/dev/sda3: UUID=&quot;9eb61ee0-0980-40f9-9e2c-463753c65203&quot; BLOCK_SIZE=&quot;4096&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;11db8e86-aa98-4a24-ac92-4d394cf5f657&quot;</span><br><span class="line">/dev/loop1: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/loop8: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/sdb1: UUID=&quot;72ac6c8b-e0ae-4b23-ac7d-2cdc3f9f8050&quot; BLOCK_SIZE=&quot;4096&quot; TYPE=&quot;xfs&quot; PARTLABEL=&quot;primary&quot; PARTUUID=&quot;54376b6d-cd0d-4c08-b36e-7471e33fc7e3&quot;</span><br><span class="line">/dev/loop6: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/loop4: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/loop2: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/loop0: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/loop9: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/loop7: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/sda2: UUID=&quot;A169-2504&quot; BLOCK_SIZE=&quot;512&quot; TYPE=&quot;vfat&quot; PARTLABEL=&quot;EFI System Partition&quot; PARTUUID=&quot;d51688b4-f1ea-414c-8905-0557a9b6297b&quot;</span><br><span class="line">/dev/loop5: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/loop3: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/loop10: TYPE=&quot;squashfs&quot;</span><br><span class="line">/dev/sda1: PARTUUID=&quot;bce3bf39-cf9a-466c-b040-f7395b1c03d1&quot;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>显示信息如下，这里只摘出来一条，这条是我要挂载的硬盘。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">/dev/sdb1: UUID=&quot;72ac6c8b-e0ae-4b23-ac7d-2cdc3f9f8050&quot; BLOCK_SIZE=&quot;4096&quot; TYPE=&quot;xfs&quot; PARTLABEL=&quot;primary&quot; PARTUUID=&quot;54376b6d-cd0d-4c08-b36e-7471e33fc7e3&quot;</span><br></pre></td></tr></table></figure>
<p>修改fstab文件</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo vi /etc/fstab</span><br></pre></td></tr></table></figure>
<p>在最下面添加要挂载的盘，建议用uuid</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># /etc/fstab: static file system information.</span><br><span class="line">#</span><br><span class="line"># Use &#x27;blkid&#x27; to print the universally unique identifier for a</span><br><span class="line"># device; this may be used with UUID= as a more robust way to name devices</span><br><span class="line"># that works even if disks are added and removed. See fstab(5).</span><br><span class="line">#</span><br><span class="line"># &lt;file system&gt; &lt;mount point&gt;   &lt;type&gt;  &lt;options&gt;       &lt;dump&gt;  &lt;pass&gt;</span><br><span class="line"># / was on /dev/sda3 during curtin installation</span><br><span class="line">/dev/disk/by-uuid/55adsfad460-6cd2-4e26-a79f-5ba8351fafcf / ext4 defaults 0 0</span><br><span class="line"># /boot was on /dev/sda2 during curtin installation</span><br><span class="line">/dev/disk/by-uuid/d8asdf092-e938-47fc-bb5e-7010667bb3b3 /boot ext4 defaults 0 0</span><br><span class="line"># /boot/efi was on /dev/sda1 during curtin installation</span><br><span class="line">/dev/disk/by-uuid/5C76-6134 /boot/efi vfat defaults 0 0</span><br><span class="line">/swap.img       none    swap    sw      0       0</span><br><span class="line"></span><br><span class="line">UUID=&quot;72ac6c8b-e0ae-4b23-ac7d-2cdc3f9f8050&quot;     /mnt/my_12TB_disk       xfs     defaults        0       2</span><br><span class="line"># UUID=&quot;f69d03b0-9ba3-4553-98b8-756a3ec19a74&quot; /media/data1 ext4 defaults 0 2</span><br></pre></td></tr></table></figure>
<p>fstab 中每个字段代表的含义，请参考本文末尾的参考资料 3。</p>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p>主要参考下面第一篇文章进行的操作！</p>
<ol>
<li><a href="https://www.cnblogs.com/lvzhenjiang/p/14391479.html">吕振江：分区工具 parted 的详解及常用分区使用方法</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/55159881">Linux xfs 和 ext4 的区别</a></li>
<li><a href="https://www.jianshu.com/p/5adb37efd478">Ubuntu 20.04 开机自动挂载硬盘</a></li>
</ol>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
  <entry>
    <title>Linux | 旧电脑安装 Ubuntu 系统，通过 Samba 作为 NAS 使用</title>
    <url>/2023/03/25/Setting_Ubuntu_as_NAS_by_Samba/</url>
    <content><![CDATA[<p>老旧台式机，通过安装 Ubuntu 系统，挂载新的硬盘，作为 NAS 使用。</p>
<span id="more"></span>
<h3 id="安装-ubuntu"><a class="markdownIt-Anchor" href="#安装-ubuntu"></a> 安装 Ubuntu</h3>
<p>Dell OptiPlex 990 台式机，内存 4 GB，硬盘 500 GB。有两个硬盘位，以前有一块 500 GB 的机械硬盘，现还有一个空余。新购一块 12 TB 的 NAS 专用盘（希捷酷狼）安装进去。</p>
<p>先下载 Ubuntu 安装包：<code>ubuntu-22.04.2-desktop-amd64.iso</code>，使用 BalenaEtcher 程序将 Ubuntu 安装包写入 U 盘，随后 U 盘插入机箱，开机之后按 F2 进入 bios，设置 U 盘优先启动，就进入安装程序了。</p>
<p>安装的过程可以在网上找到大量相似的记录，比如 <a href="https://www.sysgeek.cn/install-ubuntu-20-04-lts-desktop/">Ubuntu 20.04 LTS 桌面版详细安装指南</a>。</p>
<h3 id="添加新硬盘"><a class="markdownIt-Anchor" href="#添加新硬盘"></a> 添加新硬盘</h3>
<p>刚好手头有一个 12 TB 的硬盘（曾在Windows系统进行分区），发现戴尔的机箱还需要用到专门的硬盘支架，某宝10块钱买了一个支架，刚好把这个硬盘放进去。</p>
<p><img src="https://i.imgur.com/5iMed4P.jpeg" alt="下方蓝色支架和硬盘就是新增的部分" /></p>
<p>顺便清理了主板和CPU散热器上面的灰尘，结果装 CPU 风扇的时候没将它的电源线装回去，后面导致无法开机，必须连接好 CPU 的风扇电源线才可以开机。</p>
<p>开机之后发现新的硬盘已经自动挂载，挂在位点<code>/media/my_user_name/新加卷</code>，在 Ubuntu 桌面版可以看到该硬盘里面存储的资料。</p>
<p>我自己尝试挂在到其他地方，反而遇到一些错误，可能是因为该硬盘已经在 Windows 上面被分区过。</p>
<h3 id="挂载硬盘"><a class="markdownIt-Anchor" href="#挂载硬盘"></a> 挂载硬盘</h3>
<p>格式化硬盘</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo mkfs -t ext4 -c /dev/sdb1</span><br><span class="line">sudo mkfs -t ext4 -c /dev/sdb2</span><br></pre></td></tr></table></figure>
<p>后来又重新对这个12TB的新硬盘进行了格式化，格式化成为xfs格式，这整个硬盘作为一个分区。</p>
<h3 id="在-ubuntu-安装-samba-服务"><a class="markdownIt-Anchor" href="#在-ubuntu-安装-samba-服务"></a> 在 Ubuntu 安装 Samba 服务</h3>
<p>主要参考下面这两篇博文进行安装。</p>
<p>一、<a href="https://www.linuxmi.com/ubuntu-20-04-samba-windows.html">Ubuntu 20.04 安装配置 Samba 服务器，实现与 Windows 共享文件</a><br />
二、<a href="https://www.jianshu.com/p/74fdb7ba260a">Ubuntu 上 Samba 的安装使用和卸载</a></p>
<p><strong>安装 Samba</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo apt-get install -y samba samba-common smbclient</span><br></pre></td></tr></table></figure>
<p>创建共享目录</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">sudo mkdir /home/fenglei/Share</span><br><span class="line">#给创建的这个目录设置权限</span><br><span class="line">sudo chmod 777 /home/fenglei/Share</span><br></pre></td></tr></table></figure>
<p><strong>配置 Samba</strong></p>
<p>下一步修改配置文件。在更改 Samba 配置文件之前，请先运行 <code>sudo cp /etc/samba/smb.conf&#123;,.backup&#125;</code> 命令创建备份以供将来参考。</p>
<p>Samba 软件包随附的默认配置文件是独立 Samba 服务器配置。使用你喜欢的文本编辑器打开文件 <code>/etc/samba/smb.conf</code>。</p>
<p>我们使用 vim 编辑文件 /etc/samba/smb.conf（记得 sudo，不然保存不了！）。在配置文件 smb.conf 的最后添加下面的内容，然后保存并退出 vim。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[Share]</span><br><span class="line">path=/home/fenglei/Share</span><br><span class="line">writable=yes</span><br><span class="line">public=yes</span><br><span class="line">guest ok=no</span><br><span class="line">valid user=fenglei</span><br><span class="line">browsable = yes</span><br></pre></td></tr></table></figure>
<p>其中 <code>[Share]</code> 表示在网络上映射的名称, <code>path=/home/fenglei/Share</code> 表示你要映射的路径，<code>guest ok=no</code> 表示连接需要输入密码，<code>valid user=fenglei</code> 表示连接这个位置需要登录验证 fenglei 这个账户。<br />
也有博客推荐下面这样的配置，反正我用的是上面这样的。</p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">[share]</span><br><span class="line">comment = share folder</span><br><span class="line">browseable = yes</span><br><span class="line">path = /home/linuxmi/linuxmi.com/share</span><br><span class="line">create mask = 0700</span><br><span class="line">directory mask = 0700</span><br><span class="line">valid users = linuxmi</span><br><span class="line">force user = linuxmi</span><br><span class="line">force group = linuxmi</span><br><span class="line">public = yes</span><br><span class="line">available = yes</span><br><span class="line">writable = yes</span><br></pre></td></tr></table></figure>
<p>完成编辑 smb.conf 后，保存文件并退出 vim。</p>
<p><strong>启动 Samba</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#启动服务</span><br><span class="line">sudo systemctl restart smbd.service</span><br><span class="line">sudo systemctl restart nmbd.service</span><br><span class="line"></span><br><span class="line">#设置 samba 的用户名密码，需要是电脑已经存在的用户名【注意！！！】</span><br><span class="line">sudo smbpasswd -a fenglei</span><br></pre></td></tr></table></figure>
<p><strong>检查Samba服务状态</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 检查 smbd 状态，active 表示正在运行</span><br><span class="line">sudo systemctl status smbd.service</span><br><span class="line"></span><br><span class="line"># 返回结果</span><br><span class="line">fenglei@fenglei-OptiPlex-990:~/Share$ sudo systemctl status smbd.service</span><br><span class="line">● smbd.service - Samba SMB Daemon</span><br><span class="line">     Loaded: loaded (/lib/systemd/system/smbd.service; enabled; vendor preset: enabled)</span><br><span class="line">     Active: active (running) since Thu 2023-03-23 22:25:35 CST; 53s ago</span><br><span class="line">       Docs: man:smbd(8)</span><br><span class="line">             man:samba(7)</span><br><span class="line">             man:smb.conf(5)</span><br><span class="line">    Process: 251530 ExecStartPre=/usr/share/samba/update-apparmor-samba-profile (code=exited, status=0/SUCCESS)</span><br><span class="line">   Main PID: 251539 (smbd)</span><br><span class="line">     Status: &quot;smbd: ready to serve connections...&quot;</span><br><span class="line">      Tasks: 4 (limit: 4468)</span><br><span class="line">     Memory: 8.8M</span><br><span class="line">        CPU: 114ms</span><br><span class="line">     CGroup: /system.slice/smbd.service</span><br><span class="line">             ├─251539 /usr/sbin/smbd --foreground --no-process-group</span><br><span class="line">             ├─251541 /usr/sbin/smbd --foreground --no-process-group</span><br><span class="line">             ├─251542 /usr/sbin/smbd --foreground --no-process-group</span><br><span class="line">             └─251543 /usr/lib/x86_64-linux-gnu/samba/samba-bgqd --ready-signal-fd=45 --parent-watch-fd=11 --debuglevel=0 -F</span><br><span class="line"></span><br><span class="line">3月 23 22:25:35 fenglei-OptiPlex-990 systemd[1]: Starting Samba SMB Daemon...</span><br><span class="line">3月 23 22:25:35 fenglei-OptiPlex-990 systemd[1]: Started Samba SMB Daemon.</span><br><span class="line"></span><br><span class="line"># 检查 nmbd 状态，active 表示正在运行</span><br><span class="line">sudo systemctl status nmbd.service</span><br><span class="line"></span><br><span class="line">#返回结果</span><br><span class="line">fenglei@fenglei-OptiPlex-990:~/Share$ sudo systemctl status nmbd.service</span><br><span class="line">● nmbd.service - Samba NMB Daemon</span><br><span class="line">     Loaded: loaded (/lib/systemd/system/nmbd.service; enabled; vendor preset: enabled)</span><br><span class="line">     Active: active (running) since Thu 2023-03-23 22:25:53 CST; 59s ago</span><br><span class="line">       Docs: man:nmbd(8)</span><br><span class="line">             man:samba(7)</span><br><span class="line">             man:smb.conf(5)</span><br><span class="line">   Main PID: 251569 (nmbd)</span><br><span class="line">     Status: &quot;nmbd: ready to serve connections...&quot;</span><br><span class="line">      Tasks: 1 (limit: 4468)</span><br><span class="line">     Memory: 2.4M</span><br><span class="line">        CPU: 34ms</span><br><span class="line">     CGroup: /system.slice/nmbd.service</span><br><span class="line">             └─251569 /usr/sbin/nmbd --foreground --no-process-group</span><br><span class="line"></span><br><span class="line">3月 23 22:25:53 fenglei-OptiPlex-990 systemd[1]: Starting Samba NMB Daemon...</span><br><span class="line">3月 23 22:25:53 fenglei-OptiPlex-990 systemd[1]: Started Samba NMB Daemon.</span><br></pre></td></tr></table></figure>
<p>此时，Samba 就在正常运行中。</p>
<h3 id="连接测试"><a class="markdownIt-Anchor" href="#连接测试"></a> 连接测试</h3>
<p>来到 Windows 电脑，Win + r ，并输入<code>//192.168.18.113/Share</code>，即 Ubuntu 的IP 地址，加上smb.conf里面配置的共享文件夹信息，输入账户密码就可以了！</p>
<p>还可以添加成“磁盘”，直接成为电脑本机 D、E 盘这种用法。到了这一步以后，可以在Windows上进行网络驱动的映射了，注意是网络驱动映射，不是添加网络位置，格式为<code>\\192.168.1.102\qlx</code>，qlx是你添加在smb.cnf末尾的<code>[qlx]</code>去掉括号之后的，如果你在smb.conf没有设置guest ok=yes，那就需要勾选使用其它凭据进行登录。（作者：Analyas 链接：<a href="https://www.jianshu.com/p/74fdb7ba260a%EF%BC%89">https://www.jianshu.com/p/74fdb7ba260a）</a></p>
<p>也有可能遇到“拒绝访问”的问题，这是Windows电脑的问题，我换一台 windows 测试就没有这个问题。</p>
<p><strong>其它检查服务的命令</strong></p>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">#检查正在监听的tcp和udp端口</span><br><span class="line">ss -tlnpu</span><br><span class="line"></span><br><span class="line">#检查samba正在映射的文件位置，</span><br><span class="line">#smbclient -L 192.168.1.102 -U qlx</span><br><span class="line"></span><br><span class="line">#登录到指定samba服务器，可以查看服务器的文件</span><br><span class="line">#smbclient //192.168.1.102/qlx -U qlx</span><br></pre></td></tr></table></figure>
<h3 id="完全卸载samba"><a class="markdownIt-Anchor" href="#完全卸载samba"></a> 完全卸载samba</h3>
<figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line"># 1.卸载，注意使用的是 autoremove</span><br><span class="line">sudo apt-get autoremove samba samba-common</span><br><span class="line"># 2.该操作会删除配置文件，包括 /etc/samba/smb.conf</span><br><span class="line">sudo apt-get remove --purge samba</span><br></pre></td></tr></table></figure>
<h3 id="参考资料"><a class="markdownIt-Anchor" href="#参考资料"></a> 参考资料</h3>
<p>作者：Analyas 链接：<a href="https://www.jianshu.com/p/74fdb7ba260a">https://www.jianshu.com/p/74fdb7ba260a</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
  </entry>
</search>
